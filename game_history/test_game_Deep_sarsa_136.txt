 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.82133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0    -150       0       0      64       0] 
sum of rewards: 3000109 

action type: buy - action 29.0
Learning step: 299969.625
desired expected reward: 300382.28125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 36.78509 ]
 [ 72.35904 ]
 [ 52.588634]
 [ 15.945847]
 [ 67.62324 ]
 [ 69.35431 ]
 [ 51.38411 ]
 [115.590775]
 [ 27.280256]
 [ 36.659256]
 [ 56.876965]
 [ 34.562477]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.37017822265625



buy possibilites: [-1] 
expected returns: [[14.409016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 115.5907974243164






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.310509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.409015655517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.622248]
 [53.67545 ]
 [37.17427 ]
 [ 5.514698]
 [52.20144 ]
 [36.010258]
 [23.109646]
 [21.858776]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.17955207824707



buy possibilites: [-1] 
expected returns: [[24.882586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 53.67546463012695






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[11.162831]
 [39.66611 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.882585525512695



action possibilites: [-1.] 
expected returns: [[31.734425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.50049591064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.59496 ]
 [ 78.29969 ]
 [ 27.69079 ]
 [ 58.358566]
 [ 35.533802]
 [ 19.094046]
 [ 74.549965]
 [ 73.92747 ]
 [ 58.026993]
 [133.5514  ]
 [121.46028 ]
 [ 31.535774]
 [ 80.711876]
 [ 40.514153]
 [ 45.289474]
 [ 62.93617 ]
 [ 35.10832 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.734424591064453



buy possibilites: [-1] 
expected returns: [[13.944027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 133.55140686035156






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.394413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.944026947021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.30769 ]
 [76.38929 ]
 [57.14011 ]
 [15.856413]
 [73.57119 ]
 [56.4461  ]
 [38.842968]
 [34.260326]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.767948150634766



buy possibilites: [-1] 
expected returns: [[10.063399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 76.3893051147461






Player: 1 
cards in hand: [ 0.  3.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [8. 0. 3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-15.196681]
 [ 33.497284]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.063399314880371



action possibilites: [-1.] 
expected returns: [[31.022121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.1958122253418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 47.392403]
 [ 80.16574 ]
 [ 62.063496]
 [ 38.529297]
 [ 19.517662]
 [ 76.91352 ]
 [ 76.50761 ]
 [ 61.78326 ]
 [134.79451 ]
 [122.30586 ]
 [ 33.95934 ]
 [ 82.069016]
 [ 44.035526]
 [ 49.138924]
 [ 66.54459 ]
 [ 37.670048]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.02212142944336



buy possibilites: [-1] 
expected returns: [[13.119415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 134.79452514648438






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.724592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.119415283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.07735 ]
 [ 55.529667]
 [ 37.05901 ]
 [ 18.518703]
 [  8.087207]
 [ 52.230343]
 [ 52.002766]
 [ 36.813698]
 [107.35142 ]
 [ 94.300835]
 [ 15.724907]
 [ 57.36845 ]
 [ 22.710339]
 [ 26.38895 ]
 [ 41.64551 ]
 [ 19.649284]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  8.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.743928909301758



buy possibilites: [-1] 
expected returns: [[20.292238]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  8.  0. 10.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 107.3514175415039






Player: 1 
cards in hand: [ 0.  1.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 10.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8  3 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [10.  3.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-28.197723]
 [ 31.82536 ]
 [ 31.82536 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.292238235473633



action possibilites: [-1] 
expected returns: [[15.155235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.27312469482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.349682]
 [41.55769 ]
 [26.022348]
 [ 3.247986]
 [38.855408]
 [38.390503]
 [25.812029]
 [76.28243 ]
 [10.848257]
 [16.509438]
 [29.48909 ]
 [12.169828]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.155235290527344



buy possibilites: [-1] 
expected returns: [[7.847355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  1.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.28242492675781






Player: 1 
cards in hand: [8. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  3 10  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.431583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.847354888916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.882057]
 [47.16613 ]
 [36.78705 ]
 [17.422867]
 [45.74853 ]
 [45.24769 ]
 [36.53634 ]
 [74.611786]
 [23.59301 ]
 [27.619406]
 [39.368492]
 [27.190403]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 25.  3. 25.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.0777645111084



buy possibilites: [-1] 
expected returns: [[64.01824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 25.  3. 25.  1.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 74.6117935180664






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 8. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 8. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  0.  3.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-17.862946]
 [ 24.36826 ]
 [ 30.156567]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.01824188232422



action possibilites: [-1] 
expected returns: [[34.145077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.616979598999023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.292423]
 [68.8292  ]
 [54.993275]
 [28.202063]
 [67.61724 ]
 [64.79148 ]
 [55.353992]
 [96.984825]
 [38.700993]
 [43.926807]
 [58.011745]
 [38.419495]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.145076751708984



buy possibilites: [-1] 
expected returns: [[39.406353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.  3.  3.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.9848403930664






Player: 1 
cards in hand: [ 0.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [6. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25. 25.  3.] 
adversary cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[56.807667]
 [90.89743 ]
 [90.89743 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 25.  3.] 
cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.40635299682617



action possibilites: [-1] 
expected returns: [[97.62762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3.  0.  0.] 
cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  7.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.33157348632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.030304]
 [134.95335 ]
 [120.53988 ]
 [104.038246]
 [ 91.51389 ]
 [133.07178 ]
 [131.61563 ]
 [120.60213 ]
 [170.52672 ]
 [162.9239  ]
 [101.65786 ]
 [136.62254 ]
 [108.41768 ]
 [112.17613 ]
 [124.17792 ]
 [103.5532  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  3.  0.  0.] 
cards in discard: [29. 25.  0. 29.  1.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 29. 30.  8.  7.  9. 10.  9.  7.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.62761688232422



buy possibilites: [-1] 
expected returns: [[66.41905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  3.  0.  0.] 
cards in discard: [29. 25.  0. 29.  1.  0.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 170.52670288085938






Player: 1 
cards in hand: [16.  3.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  3.  0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  6  0 16  6  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[17.088785]
 [49.279133]
 [49.279133]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.41905212402344



action possibilites: [-1. 29. 25.] 
expected returns: [[40.237675]
 [85.22141 ]
 [91.43896 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  7.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.653663635253906



action possibilites: [-1] 
expected returns: [[73.61234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.4389419555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 92.58396 ]
 [125.54868 ]
 [108.377556]
 [ 83.327995]
 [ 68.12593 ]
 [121.89594 ]
 [123.02847 ]
 [107.610466]
 [168.86403 ]
 [158.37369 ]
 [ 79.76402 ]
 [126.91114 ]
 [ 90.381134]
 [ 93.83313 ]
 [112.75019 ]
 [ 85.302185]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  6.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.61234283447266



buy possibilites: [-1] 
expected returns: [[66.371346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.  3.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 168.86402893066406






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0. 25.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  5.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0. 25.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6.  1. 10.  0.  0.  0. 10.  8.  6.  3.  0. 16.  3.  3.  0.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  5.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 25.  0. 25.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[41.92232 ]
 [76.514275]
 [81.62577 ]
 [81.62577 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0. 25.] 
cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6.  9. 10.  9.  5.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.37134552001953



action possibilites: [-1] 
expected returns: [[85.91364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 25.  3.  1.] 
cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.72147369384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 70.032394]
 [ 90.06155 ]
 [ 82.230385]
 [ 61.179066]
 [ 85.32853 ]
 [ 92.807556]
 [ 79.386826]
 [109.386055]
 [ 69.689384]
 [ 76.068665]
 [ 83.94856 ]
 [ 82.53126 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  3.  1.] 
cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.91364288330078



buy possibilites: [-1] 
expected returns: [[64.72832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  3.  1.] 
cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.38605499267578






Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29.  1.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3. 29. 25. 29.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29.  1.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3. 29. 25. 29.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [25. 29.  1.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3. 29. 25. 29.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25. 29.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[31.068012]
 [83.538864]
 [73.857666]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  0.  3.] 
cards in discard: [25. 29. 25.  0. 29.  0.  0.  0.  3. 29. 25. 29.  0.  0. 25.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  5.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.72831726074219



action possibilites: [-1] 
expected returns: [[67.223915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3.  3. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.53885650634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[71.12707 ]
 [89.17288 ]
 [79.04311 ]
 [55.732838]
 [87.130005]
 [78.99221 ]
 [68.856155]
 [64.78295 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  3.  3. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.22391510009766



buy possibilites: [-1] 
expected returns: [[58.028183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  3.  3. 25.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  6. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 89.17288208007812






Player: 1 
cards in hand: [ 6.  0. 10.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6. 10.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-16.325386]
 [ 81.13181 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  1.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.02818298339844



action possibilites: [-1.] 
expected returns: [[25.152283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.56746673583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 36.94189 ]
 [ 71.80456 ]
 [ 19.629618]
 [ 54.618904]
 [ 26.740349]
 [ 10.054541]
 [ 66.53976 ]
 [ 70.96198 ]
 [ 53.28497 ]
 [117.265236]
 [105.1528  ]
 [ 23.870142]
 [ 72.244385]
 [ 36.38255 ]
 [ 37.693024]
 [ 59.110466]
 [ 30.038692]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  5.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.15228271484375



buy possibilites: [-1] 
expected returns: [[89.77499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 117.26518249511719






Player: 1 
cards in hand: [ 3.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  4.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  4.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 52.215023]
 [107.8693  ]
 [ 99.3576  ]
 [107.8693  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 25.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  4.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 16.  6.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.77498626708984



action possibilites: [-1] 
expected returns: [[16.701227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25. 25. 29.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 16.  6.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.86931610107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.150091]
 [28.832932]
 [-3.797953]
 [27.414436]
 [17.29243 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25. 25. 29.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 16.  6.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.70122718811035



buy possibilites: [-1] 
expected returns: [[72.52099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25. 25. 29.] 
cards in discard: [ 1. 25. 29.  1.  0.  3.  3. 25. 25. 29.  3.  0.  0.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 16.  6.  0.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 28.83293914794922






Player: 1 
cards in hand: [ 3. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  0.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6. 22.  0.  0.  1.  3.  0.  6. 10. 10.  6.  0.  6.  0.  8.  3.  3.  3.
 15.  0.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[55.005306]
 [86.4154  ]
 [86.4154  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.52098846435547



action possibilites: [-1. 29. 25.] 
expected returns: [[78.33271 ]
 [94.583466]
 [98.4932  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  3.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.14714813232422



action possibilites: [-1] 
expected returns: [[56.645206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.49320220947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 57.729965]
 [ 77.498825]
 [ 67.42762 ]
 [ 52.35829 ]
 [ 42.41188 ]
 [ 75.119484]
 [ 75.591064]
 [ 67.261986]
 [102.74909 ]
 [ 97.02418 ]
 [ 50.445087]
 [ 78.44561 ]
 [ 57.303738]
 [ 58.381126]
 [ 69.92167 ]
 [ 53.775303]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  4.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.645206451416016



buy possibilites: [-1] 
expected returns: [[83.04701]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0. 25.  1.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 102.74910736083984






Player: 1 
cards in hand: [ 3.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 25.  0. 25.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[141.29999]
 [198.96152]
 [198.96152]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 25.  3.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  2.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6] -> size -> 29 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.04701232910156



action possibilites: [-1] 
expected returns: [[75.03194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  3. 25.  3.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  1.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 198.96153259277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[68.02973]
 [83.27524]
 [79.00322]
 [55.31432]
 [87.51198]
 [76.60101]
 [72.32902]
 [76.45132]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  3. 25.  3.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 26. 30.  8.  1.  9. 10.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.03193664550781



buy possibilites: [-1] 
expected returns: [[45.990437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  3. 25.  3.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.5119857788086






Player: 1 
cards in hand: [ 3.  1.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 15.  6.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6
  3  6  0  0  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 29.] 
expected returns: [[ 83.50652 ]
 [131.42151 ]
 [122.523575]
 [122.523575]
 [122.523575]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 29. 29.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  1.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1] -> size -> 30 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.99043655395508



action possibilites: [-1] 
expected returns: [[92.3704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  3.  0.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 131.42152404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[94.153984]
 [99.19683 ]
 [98.85161 ]
 [93.24748 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 29.  3.  0.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.37039947509766



buy possibilites: [-1] 
expected returns: [[105.69061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 29.  3.  0.] 
cards in discard: [25. 29. 25.  0.  3. 29.  0. 25.  1. 11. 25.  1.  0. 25.  3. 25.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 99.19686889648438






Player: 1 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.24204]
 [72.3546 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  6.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.69061279296875



action possibilites: [-1.] 
expected returns: [[76.87232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  6.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.14487075805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[79.12155]
 [95.52561]
 [86.79511]
 [94.9961 ]
 [86.01746]
 [79.22277]
 [78.31333]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  6.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.87232208251953



buy possibilites: [-1] 
expected returns: [[76.18]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [22.  0.  6.  6.  6.] 
adversary cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 95.52560424804688






Player: 1 
cards in hand: [22.  0.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  6.  6.  6.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  9.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 10.  3.  0.  6.  1. 15.  3.  1.  6.  6.  8.  6.  0.  0.  0.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 93.99763]
 [140.02344]
 [140.02344]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  1.  0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.18000030517578



action possibilites: [-1] 
expected returns: [[197.10796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0.  3. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.0234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[200.66599]
 [236.8175 ]
 [220.59346]
 [229.38269]
 [239.04526]
 [218.14449]
 [267.4747 ]
 [189.37688]
 [202.84306]
 [225.0628 ]
 [202.14937]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  3. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.1079559326172



buy possibilites: [-1] 
expected returns: [[156.34816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  3. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 267.4747619628906






Player: 1 
cards in hand: [ 0.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[206.84]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 156.34815979003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[214.65826]
 [245.34856]
 [229.76027]
 [205.91658]
 [240.61914]
 [244.49432]
 [228.59299]
 [291.0461 ]
 [279.26093]
 [203.38615]
 [246.0091 ]
 [213.9888 ]
 [215.25258]
 [233.5717 ]
 [210.30612]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  3.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 206.83999633789062



buy possibilites: [-1] 
expected returns: [[239.67477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 291.046142578125






Player: 1 
cards in hand: [ 0. 10.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  8.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 25.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 8. 3.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 25.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 8. 3.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 29. 25. 25. 25.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 25.] 
expected returns: [[ 76.682495]
 [110.34065 ]
 [117.656654]
 [117.656654]
 [117.656654]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 25. 25.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 239.67477416992188



action possibilites: [-1] 
expected returns: [[94.822105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 25. 11. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.65662384033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[94.672966]
 [97.67666 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 25. 25. 11. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  3. 29. 25.  0. 25.  1.  0.  3. 29. 25.  0.  3.
  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.82210540771484






Player: 1 
cards in hand: [ 0.  0. 22.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  0.  6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 1. 1. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1. 1. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  2.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 1. 1. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  3. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[-26.91805 ]
 [ 28.637539]
 [ 41.93285 ]
 [ 28.637539]
 [ 41.93285 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25. 29. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.67666625976562



action possibilites: [-1] 
expected returns: [[172.25725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.93283462524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[180.3606]
 [172.2284]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 172.2572479248047



buy possibilites: [-1] 
expected returns: [[127.1403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 25.  0. 11.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 285.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 180.360595703125






Player: 1 
cards in hand: [11.  6.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  6.  0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 1. 1. 3.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  6.  0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 1. 1. 3.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  6.  0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 1. 1. 3.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[259.4299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.14029693603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[258.81622]
 [279.72018]
 [269.42056]
 [251.06715]
 [276.41138]
 [279.27847]
 [268.11612]
 [309.98697]
 [302.12378]
 [250.03033]
 [280.11823]
 [259.4839 ]
 [258.83456]
 [271.54172]
 [258.8354 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  1.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 259.4299011230469



buy possibilites: [-1] 
expected returns: [[246.99803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 309.98699951171875






Player: 1 
cards in hand: [0. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29. 29. 25.  0. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29. 29. 25.  0. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10. 10.  0.  6.  6.  8.  3. 25. 22. 15.  0.  0.  0.
  6.  1.  1.  6.  0. 11.  6.  3.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29. 29. 25.  0. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 29. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[189.63841]
 [232.46031]
 [232.46031]
 [239.2753 ]
 [239.2753 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0. 25.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 246.99803161621094



action possibilites: [-1] 
expected returns: [[123.22897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25. 25. 29.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 239.27532958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[127.16096]
 [124.3673 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25. 25. 29.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.22897338867188



buy possibilites: [-1] 
expected returns: [[145.77953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25. 25. 29.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 285.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 127.16097259521484






Player: 1 
cards in hand: [11.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  9.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.] 
cards in discard: [14.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[183.34639]
 [270.0159 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  1.  0.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.77952575683594



action possibilites: [-1.] 
expected returns: [[126.79452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 226.37020874023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[130.54887 ]
 [166.6028  ]
 [149.6256  ]
 [118.716156]
 [161.17636 ]
 [166.10713 ]
 [148.08691 ]
 [199.81715 ]
 [117.38753 ]
 [167.13538 ]
 [130.918   ]
 [130.66568 ]
 [154.03746 ]
 [127.71848 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  4.  9. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.79451751708984



buy possibilites: [-1] 
expected returns: [[170.91682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 317.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 199.81719970703125






Player: 1 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  8.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  7.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[30.661076]
 [87.33803 ]
 [87.33803 ]
 [87.33803 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 25. 25.] 
cards in discard: [ 0. 25. 29.  3. 29. 25.  0. 11. 25.  0.  3.  1.  1.  3.  0. 25. 29. 29.
  0. 25. 25. 29.  0.  0. 29. 29.  1.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  7.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  1. 10.  0.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 170.9168243408203



action possibilites: [-1] 
expected returns: [[53.41146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  7.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  1. 10.  0.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.33802032470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.5122  ]
 [70.661354]
 [72.3593  ]
 [59.199955]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  7.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  1. 10.  0.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.411460876464844



buy possibilites: [-1] 
expected returns: [[264.16434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 25.  3.  0.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  1. 10.  0.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 291 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 72.35928344726562






Player: 1 
cards in hand: [ 1.  3.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1. 10.  0.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1.  0. 22.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  1.  0. 22.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  9.  9.] 
adversary cards in hand: [25.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  1.  0. 22.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [25.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25.  0.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[145.85403]
 [200.00015]
 [187.24472]
 [200.00015]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1. 29. 25.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  8.  6.  0. 25.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 264.1643371582031



action possibilites: [-1] 
expected returns: [[188.07394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 25.  3. 25.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  8.  6.  0. 25.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 200.00015258789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[180.67189]
 [204.36972]
 [195.14394]
 [206.43573]
 [191.95143]
 [186.41821]
 [192.71577]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25.  3. 25.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  8.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  8.  6.  0. 25.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 188.07394409179688



buy possibilites: [-1] 
expected returns: [[99.1471]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25.  3. 25.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  8.  6.  0. 25.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 319 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 206.43572998046875






Player: 1 
cards in hand: [10.  8.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  0. 25.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [ 3. 29. 29. 29. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  0. 25.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [ 3. 29. 29. 29. 11.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 11.] 
expected returns: [[142.44034]
 [169.85086]
 [169.85086]
 [169.85086]
 [157.01154]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 29. 11.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.14710235595703



action possibilites: [-1. 11. 29.] 
expected returns: [[197.0536 ]
 [202.66928]
 [203.0853 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 149.5612030029297



action possibilites: [-1.] 
expected returns: [[264.9302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 199.09352111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[256.60934]
 [267.5608 ]
 [265.6959 ]
 [268.24905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 264.9302062988281






Player: 1 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [25. 29.  0. 25.  1.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [25. 29.  0. 25.  1.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [25. 29.  0. 25.  1.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 29.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[36.45385 ]
 [68.0625  ]
 [61.211582]
 [68.0625  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 25.  1.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 268.2490234375



action possibilites: [-1] 
expected returns: [[80.2901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1.  0.  1.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.06248474121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 86.15832 ]
 [108.68945 ]
 [ 79.132385]
 [100.75879 ]
 [ 78.03737 ]
 [101.38813 ]
 [112.48456 ]
 [ 98.07807 ]
 [129.9411  ]
 [ 81.104256]
 [106.87328 ]
 [ 91.68913 ]
 [ 84.49839 ]
 [103.01252 ]
 [ 94.1634  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1.  0.  1.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  3.  9. 10.  8.  8.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.29010009765625



buy possibilites: [-1] 
expected returns: [[100.198006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1.  0.  1.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
  32.   0.] 
sum of rewards: 287.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 129.94107055664062






Player: 1 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.684044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.19800567626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 97.445206]
 [124.703804]
 [ 87.385605]
 [113.75599 ]
 [ 89.26421 ]
 [118.29606 ]
 [128.58638 ]
 [111.35251 ]
 [148.73997 ]
 [ 90.11964 ]
 [123.33827 ]
 [100.19549 ]
 [ 96.605965]
 [116.80598 ]
 [101.68404 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  2.  9. 10.  8.  8.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.68404388427734



buy possibilites: [-1] 
expected returns: [[202.82281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 25.  3.  0. 25. 25.  3.  0. 11. 25.  0.  1. 29. 25.  3. 25. 29. 29.
 11. 29. 29. 29.  3. 29. 25. 29.  0. 25.  1.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 240.   0.   0.   0.   0.   0.   0.   0. -40.   0.   0.
  32.   0.] 
sum of rewards: 227.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 148.739990234375






Player: 1 
cards in hand: [ 3.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3.  3.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.  3.  0.  6.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [29. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  3.  3.] 
cards in discard: [14.  8. 11.  6.  0.  0. 16.  8.  6.  0.  0.  6.  6. 22. 10.  1.  3.  1.
  0. 22. 10.  8.  6.  0. 25.  0.  0.  6.  0.  0.  6.  3.  3.  0.  6.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [29. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[130.23091]
 [169.73459]
 [169.73459]
 [169.73459]
 [172.96193]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  6. 14.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 202.82281494140625



action possibilites: [-1] 
expected returns: [[216.00784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  6. 14.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 172.9619598388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[207.02528]
 [214.42633]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [10.  6. 14.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 216.00784301757812






Player: 1 
cards in hand: [10.  6. 14.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 14.  3.  6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [29.  3. 29.  1.  0.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 14.  3.  6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [29.  3. 29.  1.  0.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 14.  3.  6.] 
cards in discard: [0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [29.  3. 29.  1.  0.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[108.8691 ]
 [154.19266]
 [154.19266]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  1.  0.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 214.42630004882812



action possibilites: [-1. 29.] 
expected returns: [[132.25455]
 [181.22287]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 143.96524047851562



action possibilites: [-1.] 
expected returns: [[202.1498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 154.5057373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[204.5339 ]
 [232.70047]
 [219.6005 ]
 [233.3716 ]
 [218.06114]
 [204.96657]
 [203.5754 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  7.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 202.14979553222656



buy possibilites: [-1] 
expected returns: [[154.09117]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [8. 6. 6. 6. 3.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 233.37161254882812






Player: 1 
cards in hand: [8. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6. 3.] 
cards in discard: [ 0. 10.  6. 14.  3.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [11.  1. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6. 3.] 
cards in discard: [ 0. 10.  6. 14.  3.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [11.  1. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6. 3.] 
cards in discard: [ 0. 10.  6. 14.  3.  6.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [11.  1. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  1. 25. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[214.44043]
 [245.05661]
 [283.3917 ]
 [283.3917 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25. 25.  3.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.  0.  8.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0  0] -> size -> 44 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 154.09117126464844



action possibilites: [-1] 
expected returns: [[303.91104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25.  3. 11.  1.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.  0.  8.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0  0] -> size -> 44 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 283.39166259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[297.59854]
 [313.8345 ]
 [310.5999 ]
 [307.30563]
 [319.7805 ]
 [307.64365]
 [323.4173 ]
 [294.54526]
 [303.30188]
 [311.87222]
 [308.6043 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 25.  3. 11.  1.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  1.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.  0.  8.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0  0] -> size -> 44 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 303.9110412597656



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 4 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 3 
Chapel: 1 
Witch: 9 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  1. 25.  3. 11.  1.] 
cards in discard: [25. 29. 29. 29.  3.  3. 29.  1. 25.  3.  0. 11. 29. 29.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 25 25 29 29 29 25 25 29  1 25
  3 25 11  3  1 29 25  0 25  0 29  8 11 29 29 11 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 24. 30.  8.  0.  9.  6.  6.  0.  0.  9. 10.  8.  8.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6. 14.  3.  6.  0.  8.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  3 10  0  0 16  6  1  6  3  0  6 15  6 22  6  3
  6  0  0  6  6  1  6 11  0 25  0  0 14  8  8 22  0  3  0  0] -> size -> 44 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      20       0       0
       0       0     -60       0       0      64       0] 
sum of rewards: 3000259 

action type: buy - action 29.0
Learning step: 299993.5625
desired expected reward: 300316.96875



