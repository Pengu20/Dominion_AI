 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.580696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.449911117553711
desired expected reward: 27.78618621826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.70015 ]
 [19.7746  ]
 [18.5754  ]
 [14.85233 ]
 [21.415852]
 [20.519207]
 [19.306023]
 [19.882282]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5439122915267944
desired expected reward: 19.406511306762695



buy possibilites: [-1] 
expected returns: [[18.722912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.398979187011719
desired expected reward: 5.453348159790039






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.006529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49922141432762146
desired expected reward: 18.223690032958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.617887]
 [20.692991]
 [19.493135]
 [15.770065]
 [19.205624]
 [22.334244]
 [21.437601]
 [22.445143]
 [18.55632 ]
 [20.224415]
 [20.629908]
 [20.800674]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5417649745941162
desired expected reward: 19.69308090209961



buy possibilites: [-1] 
expected returns: [[23.067173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.378851056098938
desired expected reward: 22.823991775512695






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.120735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5963021516799927
desired expected reward: 22.470870971679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.209614]
 [23.293373]
 [22.094244]
 [18.361809]
 [21.803116]
 [24.93793 ]
 [24.039068]
 [25.049095]
 [21.148045]
 [22.830288]
 [23.231047]
 [23.400583]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6094552278518677
desired expected reward: 22.79178237915039



buy possibilites: [-1] 
expected returns: [[25.161993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.43975958228111267
desired expected reward: 21.587804794311523






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.159798]
 [23.804268]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6607847213745117
desired expected reward: 24.501209259033203



action possibilites: [-1.] 
expected returns: [[28.498547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.032143935561180115
desired expected reward: 23.935171127319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.370117]
 [28.520908]
 [27.2734  ]
 [23.445526]
 [30.20986 ]
 [29.287155]
 [28.038742]
 [28.631695]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10864940285682678
desired expected reward: 28.389896392822266



buy possibilites: [-1] 
expected returns: [[29.855904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [14.  3.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.005284938495606184
desired expected reward: 27.2786865234375






Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  3. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[24.764982]
 [22.418194]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16. 11.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7930195331573486
desired expected reward: 29.062883377075195



action possibilites: [-1] 
expected returns: [[28.634312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [16. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.07102369517087936
desired expected reward: 22.725576400756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.478207]
 [28.585194]
 [25.276981]
 [27.366024]
 [24.79064 ]
 [23.5895  ]
 [27.074347]
 [30.253933]
 [29.342266]
 [32.12085 ]
 [30.367018]
 [26.415745]
 [26.2746  ]
 [28.108774]
 [24.185556]
 [28.52107 ]
 [28.694645]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [16. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11060256510972977
desired expected reward: 28.52370834350586



buy possibilites: [-1] 
expected returns: [[27.078083]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [16. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 1.0
Learning step: 0.01004808396100998
desired expected reward: 28.59524154663086






Player: 1 
cards in hand: [11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [16. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [16. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  6.] 
adversary cards in discard: [ 1. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.25317 ]
 [24.888172]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  6.] 
cards in discard: [ 1. 14.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7068622708320618
desired expected reward: 26.3712215423584



action possibilites: [-1.] 
expected returns: [[26.752071]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 1. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.018666686490178108
desired expected reward: 24.966779708862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.921534]
 [26.999496]
 [25.800083]
 [22.083082]
 [28.623335]
 [27.735909]
 [26.533821]
 [27.111227]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 1. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.07215419411659241
desired expected reward: 26.679916381835938



buy possibilites: [-1] 
expected returns: [[30.594654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 1. 14.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.45254388451576233
desired expected reward: 29.075876235961914






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16. 10. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16. 10. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16. 10. 11.  3.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.615276]
 [29.17818 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7669289112091064
desired expected reward: 29.82772445678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.733423]
 [26.650635]
 [22.748552]
 [28.654161]
 [28.00847 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7000226378440857
desired expected reward: 27.02039337158203



buy possibilites: [-1] 
expected returns: [[26.079319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 10. 11.  3.  3. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.4957919716835022
desired expected reward: 28.158369064331055






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16. 10. 11.  3.  3. 15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16. 10. 11.  3.  3. 15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.556953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6742041707038879
desired expected reward: 25.405115127563477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.675163]
 [24.724201]
 [23.538822]
 [19.86448 ]
 [23.25867 ]
 [26.331808]
 [25.45324 ]
 [26.446259]
 [22.614666]
 [24.263203]
 [24.662678]
 [24.834736]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6300390958786011
desired expected reward: 23.95808982849121



buy possibilites: [-1] 
expected returns: [[29.955254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  3.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.38464975357055664
desired expected reward: 25.047327041625977






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 14.  6.] 
adversary cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[24.780151]
 [22.622025]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 14.  6.] 
cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7965033650398254
desired expected reward: 29.158750534057617



action possibilites: [-1] 
expected returns: [[27.341013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6.] 
cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.05548633635044098
desired expected reward: 22.775297164916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.455395]
 [27.595848]
 [26.353447]
 [23.758005]
 [22.547848]
 [26.058989]
 [29.278328]
 [28.356974]
 [31.158432]
 [29.399076]
 [25.392841]
 [25.255049]
 [27.11457 ]
 [23.15143 ]
 [27.531683]
 [27.711283]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6.] 
cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08108510822057724
desired expected reward: 27.25992774963379



buy possibilites: [-1] 
expected returns: [[32.177265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6.] 
cards in discard: [ 8. 11.  0.  3.  3.  0. 15.  0.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.04451150819659233
desired expected reward: 29.322837829589844






Player: 1 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.941347]
 [27.548248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8324933052062988
desired expected reward: 31.344772338867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.003214]
 [26.041636]
 [24.863405]
 [21.203772]
 [27.643887]
 [26.76452 ]
 [25.584385]
 [26.151258]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6586318612098694
desired expected reward: 25.309797286987305



buy possibilites: [-1] 
expected returns: [[27.486784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.577781617641449
desired expected reward: 23.30198097229004






Player: 1 
cards in hand: [ 3. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.  1. 11.  0.  0.  0.  0. 15.  3.  0.  3.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[29.953428]
 [31.523268]
 [31.523268]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6473966240882874
desired expected reward: 26.839387893676758



action possibilites: [-1] 
expected returns: [[18.65994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.02794000506401062
desired expected reward: 29.627586364746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.948812]
 [17.74366 ]
 [14.474792]
 [19.526274]
 [18.91616 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07839128375053406
desired expected reward: 18.738332748413086



buy possibilites: [-1] 
expected returns: [[18.128973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.793889045715332
desired expected reward: 5.680902481079102






Player: 1 
cards in hand: [ 3. 10.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  8.  0.  3.  1.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  8.  0.  3.  1.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  8.  0.  3.  1.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  8.  0.  3.  1.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [15.  8.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[23.955147]
 [23.808683]
 [24.623594]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  1.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 15 11  0  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 15. 16.  0.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.439165860414505
desired expected reward: 17.689807891845703



action possibilites: [-1] 
expected returns: [[20.473206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 15. 16.  0.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.07115644216537476
desired expected reward: 24.46634864807129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.872671]
 [19.650438]
 [16.329603]
 [21.435091]
 [20.828718]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 15. 16.  0.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04397329315543175
desired expected reward: 20.517179489135742



buy possibilites: [-1] 
expected returns: [[23.455164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 0.  0.  3.  0.  0. 29.  1.  6. 11.  0.  6.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 15. 16.  0.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.3467661142349243
desired expected reward: 19.997203826904297






Player: 1 
cards in hand: [ 3. 15. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 16.  0.  1.] 
cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 16.  0.  1.] 
cards in discard: [ 0. 10.  3.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 16.  0.  1.] 
cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[22.565523]
 [20.345385]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6248244643211365
desired expected reward: 22.830339431762695



action possibilites: [-1] 
expected returns: [[24.902292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.09781768918037415
desired expected reward: 20.55303192138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.004635]
 [25.144705]
 [23.908308]
 [20.04984 ]
 [26.816734]
 [25.904203]
 [24.661678]
 [25.224432]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03630334883928299
desired expected reward: 24.865989685058594



buy possibilites: [-1] 
expected returns: [[23.839743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.04306795075535774
desired expected reward: 23.951379776000977






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  3.  0.  3. 10.  0.  1.  3. 15. 16.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 1. 0.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3] -> size -> 22 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.322884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6613351702690125
desired expected reward: 23.178407669067383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.51694 ]
 [19.603912]
 [18.394737]
 [15.846196]
 [14.678935]
 [18.101841]
 [21.225834]
 [20.340588]
 [23.027357]
 [21.332258]
 [17.444817]
 [17.302584]
 [19.131413]
 [15.243936]
 [19.530731]
 [19.644238]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.520794153213501
desired expected reward: 18.672338485717773



buy possibilites: [-1] 
expected returns: [[21.078611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.45418262481689453
desired expected reward: 17.06275177001953






Player: 1 
cards in hand: [ 3.  0.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[19.790236]
 [21.290865]
 [21.290865]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 15.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5627541542053223
desired expected reward: 20.515857696533203



action possibilites: [-1] 
expected returns: [[23.609756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 15.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.5637431144714355
desired expected reward: 21.03571891784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.63643 ]
 [22.536222]
 [18.684483]
 [24.514011]
 [23.806196]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 15.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.020035285502672195
desired expected reward: 23.5897216796875






Player: 1 
cards in hand: [ 0.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 15.] 
cards in discard: [ 3.  0.  6.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  1. 29.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3.  0.  6.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  1. 29.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3.  0.  6.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 26. 30. 25. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  1. 29.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 3.  0.  6.  3. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  1. 29.  0.  3.] 
adversary cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8.  1. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[23.821695]
 [24.46364 ]
 [25.404844]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.  0.  3.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6045032143592834
desired expected reward: 23.20169448852539



action possibilites: [-1.  8.] 
expected returns: [[22.276882]
 [22.946348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3. 6.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.07402049750089645
desired expected reward: 25.330825805664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.339327]
 [22.352802]
 [21.190329]
 [17.572477]
 [20.908674]
 [23.911955]
 [23.060955]
 [24.014282]
 [20.268976]
 [21.898476]
 [22.282454]
 [22.391487]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3. 6.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.014258136041462421
desired expected reward: 22.2911376953125



buy possibilites: [-1] 
expected returns: [[24.294825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3. 6.] 
cards in discard: [ 3. 14.  3.  3.  0.  3.  0.  6.  0.  0.  1.  0. 14. 11.  3. 11.  0.  0.
 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 14.0
Learning step: 1.0570263862609863
desired expected reward: 21.326000213623047






Player: 1 
cards in hand: [ 3.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  9. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [1. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.06873 ]
 [24.786545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  1. 16.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6207581758499146
desired expected reward: 23.6740665435791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.324566]
 [24.46084 ]
 [23.222212]
 [19.379665]
 [22.925222]
 [26.144888]
 [25.225729]
 [26.255377]
 [22.2504  ]
 [23.970789]
 [24.384886]
 [24.502668]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  9.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  1. 16.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6197619438171387
desired expected reward: 23.5279483795166



buy possibilites: [-1] 
expected returns: [[23.368494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 8. 0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  1. 16.] 
adversary cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.2677079141139984
desired expected reward: 26.52308464050293






Player: 1 
cards in hand: [ 0. 10.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1. 16.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8. 10.  3.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0. 11.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1. 16.] 
cards in discard: [ 3.  0.  6.  3. 11.  3. 15.  0.  0.  1.  8. 10.  3.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0. 11.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[23.3247  ]
 [21.322771]
 [24.800045]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0. 11.] 
cards in discard: [29.  1.  6.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6041514277458191
desired expected reward: 22.76434326171875



action possibilites: [-1] 
expected returns: [[24.24154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29.  1.  6.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.06376127153635025
desired expected reward: 21.422924041748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.365128]
 [24.396776]
 [23.223867]
 [19.65729 ]
 [22.939747]
 [26.004545]
 [25.122377]
 [26.110641]
 [22.2941  ]
 [23.938467]
 [24.325747]
 [24.435904]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29.  1.  6.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 24. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02304365113377571
desired expected reward: 24.218496322631836



buy possibilites: [-1] 
expected returns: [[23.03906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.059827592223882675
desired expected reward: 23.12924575805664






Player: 1 
cards in hand: [16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 14. 29.  6.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 14. 29.  6.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 14. 29.  6.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 14. 29.  6.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 14. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[18.81809 ]
 [16.862919]
 [20.403912]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 29.  6.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.64128577709198
desired expected reward: 22.397775650024414



action possibilites: [-1. 14.] 
expected returns: [[24.014868]
 [22.003613]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  6.  3.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.08159139752388
desired expected reward: 20.485504150390625



action possibilites: [-1] 
expected returns: [[22.998943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.631380558013916
desired expected reward: 22.634990692138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.085478]
 [23.067467]
 [21.911661]
 [18.476055]
 [21.635397]
 [24.611649]
 [23.772476]
 [24.706043]
 [21.008614]
 [22.614412]
 [22.98941 ]
 [23.05835 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  8.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6001702547073364
desired expected reward: 23.59911346435547



buy possibilites: [-1] 
expected returns: [[29.480762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.578366756439209
desired expected reward: 26.28441047668457






Player: 1 
cards in hand: [ 6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  1.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  1.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  1.] 
adversary cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[26.209143]
 [24.282566]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0.  1.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  1.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7673184871673584
desired expected reward: 28.713443756103516



action possibilites: [-1] 
expected returns: [[26.739334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.00228601461276412
desired expected reward: 24.284852981567383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.640688]
 [26.614279]
 [23.503675]
 [25.469858]
 [23.055046]
 [21.94265 ]
 [25.192486]
 [28.150513]
 [27.310928]
 [29.881042]
 [28.245043]
 [24.563557]
 [24.418797]
 [26.16642 ]
 [22.475138]
 [26.53715 ]
 [26.605207]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8. 10.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07460105419158936
desired expected reward: 26.66473388671875



buy possibilites: [-1] 
expected returns: [[30.08195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  1.  6.  0.  8.  0.  3. 14.  3.  0.  0. 11. 29. 29. 14.  0.  3.  6.
  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 25.0
Learning step: 0.24442920088768005
desired expected reward: 30.125471115112305






Player: 1 
cards in hand: [1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  7.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[27.750267]
 [29.437698]
 [29.437698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7477361559867859
desired expected reward: 29.334213256835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.858826]
 [22.92862 ]
 [28.006393]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7096755504608154
desired expected reward: 27.07404899597168



buy possibilites: [-1] 
expected returns: [[23.315228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6809547543525696
desired expected reward: 25.177867889404297






Player: 1 
cards in hand: [0. 0. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  8.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [ 3.  0.  0.  0. 16.  0.  0. 15.  0.  6. 10.  3. 10.  3. 29.  1.  0.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3.  8.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[22.20726 ]
 [23.697332]
 [23.697332]
 [22.852757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3.  8.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6055375337600708
desired expected reward: 22.70969009399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.545988]
 [21.29817 ]
 [18.141497]
 [22.982012]
 [22.336517]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3.  8.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  7.  9.  7.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.591044545173645
desired expected reward: 21.616214752197266



buy possibilites: [-1] 
expected returns: [[26.358315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3.  8.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  9.  7.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8] -> size -> 27 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.27255699038505554
desired expected reward: 21.025615692138672






Player: 1 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  9.  7.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 22. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[25.337414]
 [23.339268]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6830987334251404
desired expected reward: 25.675216674804688



action possibilites: [-1] 
expected returns: [[19.7025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0.  0.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.04330180957913399
desired expected reward: 23.29596519470215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.922632]
 [19.702631]
 [18.65752 ]
 [15.488516]
 [18.410507]
 [21.101305]
 [20.343765]
 [21.185942]
 [17.848843]
 [19.293293]
 [19.627083]
 [19.647324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0.  0.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06387605518102646
desired expected reward: 19.766374588012695






Player: 1 
cards in hand: [29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.  6.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.  6.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 21. 30.  8.  7.  9.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.  6.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  7.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.  6.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[22.134548]
 [23.737566]
 [25.301788]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  6.  0.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  7.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 10. 16.  0.  8.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16] -> size -> 30 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4869990944862366
desired expected reward: 19.16032600402832



action possibilites: [-1] 
expected returns: [[26.668245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0.  0.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 10. 16.  0.  8.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.029037093743681908
desired expected reward: 25.272750854492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.04613 ]
 [26.899323]
 [25.811428]
 [22.489742]
 [28.38875 ]
 [27.571781]
 [26.468628]
 [26.84109 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  0.  0.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 21. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 10. 16.  0.  8.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07043832540512085
desired expected reward: 26.597806930541992



buy possibilites: [-1] 
expected returns: [[26.70148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  0.  0.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 10. 16.  0.  8.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.0160227008163929
desired expected reward: 25.827451705932617






Player: 1 
cards in hand: [ 1. 10. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 16.  0.  8.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  8.  3.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  8.  3.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  6.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  8.  3.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [14.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[21.237896]
 [19.2243  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 15.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6 11] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7365036010742188
desired expected reward: 25.964977264404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.533646]
 [20.36353 ]
 [16.761522]
 [22.232792]
 [21.46358 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  0.  3.] 
cards in discard: [ 0. 11.  3.  0.  3. 11.  3.  1. 29. 29.  3.  8. 14.  0.  0.  3.  3.  3.
 25.  0. 29.  6.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 15.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6 11] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5718514919281006
desired expected reward: 20.666044235229492



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 15.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0
  0 29  8 11  3 16  6 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 26. 30. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.  3.  0. 16. 29.  0.  0.  0.  6. 11. 10.  1.
 16.  0.  8.  3.  2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[27.357538]
 [25.255333]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [29.  6.  3.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.515482485294342
desired expected reward: 20.948097229003906



action possibilites: [-1] 
expected returns: [[31.11144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 29. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [6. 3. 1.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.019010238349437714
desired expected reward: 25.27433967590332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.41048 ]
 [31.507313]
 [28.187574]
 [30.284405]
 [27.702917]
 [26.491257]
 [29.9913  ]
 [33.126785]
 [32.252865]
 [34.93051 ]
 [33.22295 ]
 [29.32239 ]
 [29.15766 ]
 [31.029955]
 [27.060825]
 [31.41922 ]
 [31.442823]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 26. 29. 20. 30.  8.  6.  8.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [6. 3. 1.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15475696325302124
desired expected reward: 30.956684112548828



buy possibilites: [-1] 
expected returns: [[32.410988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1.] 
cards in discard: [16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [6. 3. 1.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 16.0
Learning step: 0.13057628273963928
desired expected reward: 30.12187957763672






Player: 1 
cards in hand: [6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1.] 
cards in discard: [29.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [29.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  7.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [29.  8.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.88918 ]
 [27.592758]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [16. 14.  0.  6.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8397606611251831
desired expected reward: 31.57122802734375



action possibilites: [-1.] 
expected returns: [[27.661171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.08734045177698135
desired expected reward: 27.505416870117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.837482]
 [27.758274]
 [26.635971]
 [24.277271]
 [23.17231 ]
 [26.368164]
 [29.269323]
 [28.451588]
 [30.97422 ]
 [29.360249]
 [25.75695 ]
 [25.606441]
 [27.31716 ]
 [23.690517]
 [27.676323]
 [27.698267]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.08911777287721634
desired expected reward: 27.572053909301758



buy possibilites: [-1] 
expected returns: [[31.02013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 22.0
Learning step: 1.5623422861099243
desired expected reward: 25.341310501098633






Player: 1 
cards in hand: [11. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  1.  0.] 
cards in discard: [29.  8.  8.  6.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  1.  8.  3.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  1.  8.  3.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  1.  8.  3.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  1.  8.  3.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  0.  1.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[24.247196]
 [25.819893]
 [25.03758 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  8.  3.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 16. 16.  0. 15.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8160890340805054
desired expected reward: 30.20404052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.515438]
 [24.350897]
 [23.263353]
 [20.029552]
 [25.805458]
 [25.026268]
 [23.921051]
 [24.23588 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  8.  3.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  5.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 16. 16.  0. 15.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6246190667152405
desired expected reward: 23.622577667236328



buy possibilites: [-1] 
expected returns: [[23.476719]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  8.  3.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 16. 16.  0. 15.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.1376582235097885
desired expected reward: 25.66779899597168






Player: 1 
cards in hand: [ 3. 16. 16.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  0. 15.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0
 29  8 11  3 16  6 11  2  8  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  6.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14. 14.  3.  6.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 15.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14. 14.  3.  6.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 15.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14. 14.  3.  6.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 14. 14.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[20.06533 ]
 [18.441788]
 [18.441788]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 14.  3.  6.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6527073979377747
desired expected reward: 22.824010848999023



action possibilites: [-1] 
expected returns: [[22.267515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  6.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.13055528700351715
desired expected reward: 18.572343826293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.729925]
 [21.448599]
 [18.30425 ]
 [23.095194]
 [22.36547 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  6.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  6.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.008459415286779404
desired expected reward: 22.27597427368164



buy possibilites: [-1] 
expected returns: [[22.570625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  6.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 22 

action type: buy - action 8.0
Learning step: 0.2041357010602951
desired expected reward: 23.299331665039062






Player: 1 
cards in hand: [ 3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.077236]
 [16.591957]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 29.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6592650413513184
desired expected reward: 21.911359786987305



action possibilites: [-1.] 
expected returns: [[18.479715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.1462782621383667
desired expected reward: 16.738235473632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.904757]
 [18.605152]
 [17.597097]
 [14.595783]
 [19.928616]
 [19.21962 ]
 [18.211563]
 [18.50055 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  4.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.08819989860057831
desired expected reward: 18.567914962768555



buy possibilites: [-1] 
expected returns: [[16.670181]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 18  0] 
sum of rewards: 31 

action type: buy - action 11.0
Learning step: 0.5071784853935242
desired expected reward: 20.435792922973633






Player: 1 
cards in hand: [11.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 25.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 25.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 25.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 25.] 
adversary cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  3. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[16.820717]
 [18.116924]
 [18.186264]
 [19.500067]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  3. 25.] 
cards in discard: [16. 14.  0.  6.  0.  1. 22. 29.  0.  3.  0.  0.  0. 11. 11.  0.  1.  8.
  3.  8. 14.  3. 14.  3.  6. 11. 29.  3.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  5.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [0. 6. 0. 2. 3.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0] -> size -> 38 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4566449522972107
desired expected reward: 16.213537216186523



action possibilites: [-1] 
expected returns: [[27.246737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [0. 6. 0. 2. 3.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.1510886698961258
desired expected reward: 19.65115737915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.575928]
 [22.980995]
 [27.34792 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [0. 6. 0. 2. 3.] 
adversary cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09743791073560715
desired expected reward: 27.1492977142334






Player: 1 
cards in hand: [0. 6. 0. 2. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 2. 3.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 2. 3.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  5.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 2. 3.] 
cards in discard: [29.  8.  8.  6.  3.  1.  0. 29. 11. 10.  0.  1.  0.  6. 16.  3. 16. 15.
  3.  0.  0. 10.  3.  0.  8.  0.  0. 11.  0.  0.  0. 11.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  4.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.182854]
 [22.592663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  4.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 10.  1. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7391358017921448
desired expected reward: 26.608783721923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.544638]
 [20.217667]
 [17.241014]
 [21.819317]
 [21.044855]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  4.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 10.  1. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5665167570114136
desired expected reward: 20.437305450439453



buy possibilites: [-1] 
expected returns: [[24.941095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 10.  1. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 0 

action type: buy - action 8.0
Learning step: -0.39269793033599854
desired expected reward: 21.426616668701172






Player: 1 
cards in hand: [ 0. 10.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 10.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  3. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  3. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 29. 20. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  3. 11.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[19.81973 ]
 [21.252817]
 [21.321623]
 [20.576965]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  8.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0. 16. 29.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.679218053817749
desired expected reward: 24.261877059936523



action possibilites: [-1. 11.  8.] 
expected returns: [[21.788214]
 [23.309933]
 [22.592295]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  0.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 29 14  3  1 11  8 11  0  1  6  3  3  0 14
 14 29  3 29 25  0  3  3 16 22 11  8 11  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0. 16. 29.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.048835430294275284
desired expected reward: 21.370458602905273



action possibilites: [-1] 
expected returns: [[24.026865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0. 16. 29.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.7354103922843933
desired expected reward: 19.631132125854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.36728 ]
 [23.109507]
 [19.865408]
 [24.919777]
 [24.048542]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0. 16. 29.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.573567271232605
desired expected reward: 24.600431442260742






Player: 1 
cards in hand: [11.  0. 16. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16. 29.  6.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14. 16.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  6.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29
  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  3.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14. 16.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14. 16.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14. 16.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [14. 16.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 11.] 
expected returns: [[20.375109]
 [18.83362 ]
 [19.349394]
 [21.80552 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  8.  0. 16.  0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0.] 
adversary owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6569010615348816
desired expected reward: 23.391643524169922



action possibilites: [-1] 
expected returns: [[23.00648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.12655934691429138
desired expected reward: 18.96018409729004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.604187]
 [23.301832]
 [22.296886]
 [19.22993 ]
 [24.630518]
 [23.916872]
 [22.909302]
 [23.138039]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 29. 19. 30.  8.  4.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0016086386749520898
desired expected reward: 23.008087158203125



buy possibilites: [-1] 
expected returns: [[20.594597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 11.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -286.0 

action type: buy - action 6.0
Learning step: -8.940654754638672
desired expected reward: 10.289276123046875






Player: 1 
cards in hand: [8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  8  0  0  0 29  8
 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 22.  1.  0.  3.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 22.  1.  0.  3.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 22.  1.  0.  3.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8. 22.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[21.946146]
 [22.697935]
 [18.668043]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  1.  0.  3.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5428982377052307
desired expected reward: 20.051698684692383



action possibilites: [-1] 
expected returns: [[24.412195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  3. 14.  6.  1.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: LIBRARY: skip_action_card - action 0
Learning step: 0.6477479934692383
desired expected reward: 22.600418090820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.91923 ]
 [24.643759]
 [23.617414]
 [21.526337]
 [20.551403]
 [23.381338]
 [25.990389]
 [25.269384]
 [27.580685]
 [26.066767]
 [22.828611]
 [22.678074]
 [24.243036]
 [20.98435 ]
 [24.550985]
 [24.476532]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  3. 14.  6.  1.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.575740396976471
desired expected reward: 24.98793601989746



buy possibilites: [-1] 
expected returns: [[23.06325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  3. 14.  6.  1.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0 50  0] 
sum of rewards: 83 

action type: buy - action 23.0
Learning step: 2.0393424034118652
desired expected reward: 25.13339614868164






Player: 1 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 14.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 14.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  2.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 14.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 14.] 
adversary cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[25.653875]
 [24.02604 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 14.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [0. 6. 0. 0. 2.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5793687105178833
desired expected reward: 22.4838809967041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.127197]
 [24.829128]
 [21.746588]
 [26.515596]
 [25.653875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 14.] 
cards in discard: [25. 11.  3. 29.  3.  3.  3.  8.  0.  0.  3.  3. 11. 29.  8.  0.  6. 14.
 16.  0.  3. 11. 23. 22. 29.  8.  1.  0.  3. 14.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [0. 6. 0. 0. 2.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6575078964233398
desired expected reward: 24.996368408203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 6. 0. 0. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 2.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 2.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  9.  8.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 2.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.294691]
 [22.09971 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6951503753662109
desired expected reward: 24.95872688293457



action possibilites: [-1. 14.] 
expected returns: [[23.952015]
 [22.164122]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.030995693057775497
desired expected reward: 22.130706787109375



action possibilites: [-1] 
expected returns: [[28.677595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.6861910820007324
desired expected reward: 22.850313186645508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.134583]
 [29.09021 ]
 [27.92494 ]
 [25.519258]
 [24.391565]
 [27.661343]
 [30.590445]
 [29.800081]
 [32.28248 ]
 [30.667152]
 [27.01949 ]
 [26.83638 ]
 [28.634813]
 [24.880749]
 [28.97512 ]
 [28.841963]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  9.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.49384695291519165
desired expected reward: 29.17144203186035



buy possibilites: [-1] 
expected returns: [[23.634874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0 50  0] 
sum of rewards: 82 

action type: buy - action 25.0
Learning step: 1.7396918535232544
desired expected reward: 34.02217102050781






Player: 1 
cards in hand: [8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [22.  3. 29.  6. 29.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [22.  3. 29.  6. 29.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [22.  3. 29.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29. 29.] 
expected returns: [[28.103323]
 [24.661335]
 [29.712118]
 [29.712118]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 29.  6. 29.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5610541105270386
desired expected reward: 23.073820114135742



action possibilites: [-1. 22. 29. 11.] 
expected returns: [[25.243986]
 [21.872738]
 [26.853703]
 [26.784426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  6. 29. 11.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.1733855903148651
desired expected reward: 29.538732528686523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.821333]
 [21.494482]
 [25.281668]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  6. 29. 11.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
adversary owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.056555211544036865
desired expected reward: 25.18743324279785






Player: 1 
cards in hand: [ 8. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  3.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3
 16  6 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 0. 11. 25. 14.  3.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 0. 11. 25. 14.  3.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 3. 10.  0.  1. 10.  3. 11.  8. 29. 16. 11.  6.  0. 16.  0.  8.  8. 29.
  3.  0.  0.  0.  1. 22.  0.  6.  0.  0.  2.  0. 11.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 0. 11. 25. 14.  3.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 14.] 
expected returns: [[15.674803]
 [16.978487]
 [18.318338]
 [14.37429 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 14.  3.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7327551245689392
desired expected reward: 24.548913955688477



action possibilites: [-1] 
expected returns: [[20.14963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  3.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.23034238815307617
desired expected reward: 14.604633331298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.819845]
 [20.488298]
 [19.487808]
 [16.568441]
 [21.792456]
 [21.102407]
 [20.09733 ]
 [20.275202]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  3.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.057838667184114456
desired expected reward: 20.207468032836914






Player: 1 
cards in hand: [11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [23. 11.  3.  0.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [23. 11.  3.  0.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [6. 3. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [23. 11.  3.  0.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [23. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
expected returns: [[18.806322]
 [17.253439]
 [20.186075]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 11.  3.  0.  0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  7.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 10.  0.  0. 10.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5583769679069519
desired expected reward: 19.716827392578125



action possibilites: [-1] 
expected returns: [[21.597002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 10.  0.  0. 10.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 4
Learning step: 0.5594598650932312
desired expected reward: 16.469751358032227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.272715]
 [20.954798]
 [17.937733]
 [22.6298  ]
 [21.71557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 8. 10.  0.  0. 10.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.] 
adversary owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 40 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.023510340601205826
desired expected reward: 21.620512008666992






Player: 1 
cards in hand: [ 8. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0. 10.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6
 11  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 6.  3.  8. 14.  0.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[21.156641]
 [22.076654]
 [19.599932]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 14.  0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [ 6.  3.  3. 16.  8.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.] 
adversary owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5791730880737305
desired expected reward: 21.136398315429688



action possibilites: [-1] 
expected returns: [[28.928816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
adversary owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.16575461626052856
desired expected reward: 19.76568603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.44574 ]
 [29.257227]
 [28.170336]
 [24.951014]
 [30.642624]
 [29.918028]
 [28.831133]
 [28.96914 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  8.  8.  8.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
adversary owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11392049491405487
desired expected reward: 28.814895629882812



buy possibilites: [-1] 
expected returns: [[25.49122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
adversary owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 10.0
Learning step: 0.24272386729717255
desired expected reward: 29.073856353759766






Player: 1 
cards in hand: [3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11
  2  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [ 1.  3. 16.  8.  1.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [ 1.  3. 16.  8.  1.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [ 1.  3. 16.  8.  1.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 16.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[21.725187]
 [20.785315]
 [22.583138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 16.  8.  1.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [11.  1.  8.  0. 22.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6850497722625732
desired expected reward: 24.806171417236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.347612]
 [21.985567]
 [21.002846]
 [18.123196]
 [20.785313]
 [23.23837 ]
 [22.583136]
 [23.300001]
 [20.241625]
 [21.600412]
 [21.87958 ]
 [21.725183]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16.  8.  1.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  1.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [11.  1.  8.  0. 22.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5730565190315247
desired expected reward: 21.152128219604492



buy possibilites: [-1] 
expected returns: [[20.285688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16.  8.  1.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  0.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [11.  1.  8.  0. 22.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -6.  0.  0.  2.  0.] 
sum of rewards: -9.0 

action type: buy - action 8.0
Learning step: -0.7344943284988403
desired expected reward: 21.84864044189453






Player: 1 
cards in hand: [11.  1.  8.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8.  0. 22.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  0.  8.  5.  7.  9.  7.  8.  8.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 22.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 22.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  3.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 22.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.503187]
 [21.368654]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 6.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3
 29 25  0  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  2.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5378347039222717
desired expected reward: 19.747854232788086



action possibilites: [-1] 
expected returns: [[12.1361685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  2.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.11375192552804947
desired expected reward: 22.925636291503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.890107 ]
 [ 8.976262 ]
 [12.1361685]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 29. 14.  0.  0.  3.  3. 29. 22.  3.  6. 29. 11. 14.  0. 11. 25.  3.
 16. 11. 23.  3.  0.  0. 10. 14.  6.  3.  8.  0.  8.  1.  3. 16.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  2.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20100800693035126
desired expected reward: 12.337176322937012






Player: 1 
cards in hand: [ 0.  0. 29.  6.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6.  2.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [ 3. 29. 16.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  6.  2.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  8.  7.] 
adversary cards in hand: [ 3. 29. 16.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  6.  2.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3. 29. 16.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 16.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11.] 
expected returns: [[29.422106]
 [31.318888]
 [28.309118]
 [31.24468 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 16.  1. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11. 15. 29.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.19569633901119232
desired expected reward: 11.940472602844238



action possibilites: [-1. 16. 11.] 
expected returns: [[31.00074 ]
 [29.940786]
 [32.868347]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 11.  0.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0
  3  3 16 22 11  8 11  8  6 23 25 16 10  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  5.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11. 15. 29.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: -0.10870656371116638
desired expected reward: 29.627077102661133



action possibilites: [-1] 
expected returns: [[26.227518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  4.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11. 15. 29.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0 16  0] 
sum of rewards: 48 

action type: gain_card_n - action 6
Learning step: 0.8040889501571655
desired expected reward: 31.180757522583008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[24.924047]
 [25.668694]
 [22.382433]
 [26.448505]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  4.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11. 15. 29.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5275059342384338
desired expected reward: 26.755023956298828






Player: 1 
cards in hand: [11. 15. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29.  0.  6.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  4.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  6. 11.  6.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  6.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  6. 11.  6.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  0.  6.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  6. 11.  6.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.412098]
 [24.059637]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 11.  6.] 
cards in discard: [ 1. 29. 29. 16. 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  6.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6977486610412598
desired expected reward: 25.75075912475586



action possibilites: [-1] 
expected returns: [[34.002865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 4
Learning step: 0.5786150097846985
desired expected reward: 20.19244956970215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.462013]
 [29.777887]
 [34.020554]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
adversary owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.22911351919174194
desired expected reward: 33.77375030517578






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  0  6  0  0  1  3  0  0  0 29  8 11  3 16  6 11  2
  8  0 29  6  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  3.  0. 11.  3.  3.  8. 10.  0. 10.  6. 16.  8.  3. 15. 11. 11.  1.
  8.  0. 22. 22.  0.  0. 29.  6.  2. 29. 11. 15. 29.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [14.  0.  0.  3. 16.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [14.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[17.07395 ]
 [15.919507]
 [16.35751 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 0.  0.  8. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9965786337852478
desired expected reward: 33.02397537231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[16.09378 ]
 [16.613058]
 [14.247544]
 [17.156752]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 29. 19. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 0.  0.  8. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4915558993816376
desired expected reward: 16.582393646240234



buy possibilites: [-1] 
expected returns: [[17.972155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 16.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 0.  0.  8. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0  8  0] 
sum of rewards: -2 

action type: buy - action 3.0
Learning step: -0.369684100151062
desired expected reward: 16.24337387084961






Player: 1 
cards in hand: [ 0.  0.  8. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 16.  1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10 11 16  3 15 10  1  6  1  3  0  0 29  8 11  3 16  6 11  2  8  0 29  6
  0  0  0  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  0. 14.  1.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  0. 14.  1.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 3.  3.  0. 14.  1.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[17.071238]
 [15.816914]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.  1.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [ 8. 15.  3.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5151848196983337
desired expected reward: 17.45697021484375



action possibilites: [-1] 
expected returns: [[20.4507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.19022494554519653
desired expected reward: 16.007139205932617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.222887]
 [20.82078 ]
 [19.854568]
 [17.901667]
 [16.984781]
 [19.6432  ]
 [22.042686]
 [23.450926]
 [22.099234]
 [19.112036]
 [18.951332]
 [20.440962]
 [17.364725]
 [20.708874]
 [20.520027]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  2.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.05323236435651779
desired expected reward: 20.50393295288086



buy possibilites: [-1] 
expected returns: [[22.668005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -6.   0.   0.
  4.5  0. ] 
sum of rewards: 13.5 

action type: buy - action 11.0
Learning step: -0.018266601487994194
desired expected reward: 22.02442169189453






Player: 1 
cards in hand: [15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [ 8.  0.  8. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3  0 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0
  6  8  3  8  8 22  0 15 11 22 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [25.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [25.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [25.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [25.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [25.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8.] 
expected returns: [[16.957567]
 [19.400515]
 [18.23156 ]
 [17.697245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11.  8.  3.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11.  3.  8. 29. 22.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6374965906143188
desired expected reward: 22.030508041381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.871887]
 [14.122511]
 [16.89756 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 11.  8.  3.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [11.  3.  8. 29. 22.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0] -> size -> 36 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48689836263656616
desired expected reward: 16.302459716796875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3.  8. 29. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 29. 22.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  7.  9.  7.  7.  7.] 
adversary cards in hand: [14.  8. 22. 23. 25.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29. 22.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [14.  8. 22. 23. 25.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29. 22.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [14.  8. 22. 23. 25.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [14.  8. 22. 23. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 22. 23. 25.] 
expected returns: [[15.550838]
 [14.544041]
 [16.270296]
 [13.246296]
 [14.419292]
 [17.885326]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 22. 23. 25.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [6. 1. 6. 0. 6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4906851053237915
desired expected reward: 16.406875610351562



action possibilites: [-1] 
expected returns: [[21.449867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22. 23. 25.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [6. 0. 6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.23890233039855957
desired expected reward: 14.782944679260254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[20.173279]
 [20.814228]
 [17.91084 ]
 [21.449865]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22. 23. 25.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [6. 0. 6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.020279960706830025
desired expected reward: 21.47014808654785






Player: 1 
cards in hand: [6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [10.  8. 29.  0.  8.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [10.  8. 29.  0.  8.] 
adversary cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.] 
adversary owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10.  8. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.  8.] 
expected returns: [[24.810373]
 [24.777563]
 [25.72208 ]
 [26.38191 ]
 [25.72208 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  0.  8.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 14  3  1  8 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3
  3 16 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [16. 10. 15.  8.  6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5240384340286255
desired expected reward: 20.92582893371582



action possibilites: [-1] 
expected returns: [[18.977188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [16. 10. 15.  8.  6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.16907013952732086
desired expected reward: 27.108617782592773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.766243]
 [15.663462]
 [18.977188]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [16. 10. 15.  8.  6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0672757551074028
desired expected reward: 19.044464111328125



buy possibilites: [-1] 
expected returns: [[15.225201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1. 29. 29. 16. 11.  0. 16. 11.  3.  3.  6.  6.  3. 14.  0.  0.  3. 16.
 11. 14.  3.  3.  0.  1. 25.  0. 11.  8.  3. 14.  8. 22. 23. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [16. 10. 15.  8.  6.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: 10.0 

action type: buy - action 0.0
Learning step: -0.07312268018722534
desired expected reward: 17.6931209564209






Player: 1 
cards in hand: [16. 10. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 15.  8.  6.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29  8 11  3 16  6 11  2  8  0 29  6  0  0  0  6
  8  3  8  8 22  0 15 11 22 29  0  0 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  1.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  6.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [ 6. 14. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 6. 14. 16.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 29.] 
expected returns: [[26.381048]
 [24.73312 ]
 [25.377796]
 [28.338387]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 16.  3. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14 29  3 29 25  0  3  3 16
 22 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  7.] 
adversary cards in hand: [ 2.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3271016478538513
desired expected reward: 14.898098945617676



action possibilites: [-1] 
expected returns: [[22.487577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  6.] 
adversary cards in hand: [ 2.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 16  0] 
sum of rewards: 26 

action type: gain_card_n - action 13
Learning step: 0.16943693161010742
desired expected reward: 28.39219093322754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.265152]
 [18.786552]
 [22.68541 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  6.] 
adversary cards in hand: [ 2.  0.  3.  8. 11.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.001324024167843163
desired expected reward: 22.48625373840332






Player: 1 
cards in hand: [ 2.  0.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0.  3.  8. 11.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  6.] 
adversary cards in hand: [11.  3. 11.  0.  3.] 
adversary cards in discard: [15. 16.  6. 14.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  3.  8. 11.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  7.  7.  6.] 
adversary cards in hand: [11.  3. 11.  0.  3.] 
adversary cards in discard: [15. 16.  6. 14.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  3.  8. 11.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  6.  7.  6.] 
adversary cards in hand: [11.  3. 11.  0.  3.] 
adversary cards in discard: [15. 16.  6. 14.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[27.210392]
 [29.044474]
 [29.044474]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  3.] 
cards in discard: [15. 16.  6. 14.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  6.  7.  6.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5307307243347168
desired expected reward: 22.154678344726562



action possibilites: [-1] 
expected returns: [[24.6176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [15. 16.  6. 14.  3. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0 16  0] 
sum of rewards: 25 

action type: gain_card_n - action 8
Learning step: 0.1608387529850006
desired expected reward: 28.41570472717285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.26825 ]
 [20.675549]
 [24.668884]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [15. 16.  6. 14.  3. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 29. 18. 30.  8.  3.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04460781067609787
desired expected reward: 24.5729923248291



buy possibilites: [-1] 
expected returns: [[24.83317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 29. 18. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -9.11951732635498
desired expected reward: 11.556029319763184






Player: 1 
cards in hand: [29. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  0.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 18. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 29. 18. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.  0. 22. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [13. 26. 29. 18. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.  0. 22. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10] -> size -> 38 
action values: 1 
buys: 1 
player value: 2 
card supply: [13. 26. 29. 18. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0.  8. 11.  0. 15.  3. 14. 11.  3.  8. 29. 22.  1.  6.  6.  0.  6.
 11. 16. 10. 15.  6. 10.  2.  0.  3.  8. 11.  0. 22. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3. 14.  8.  3.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[16.292763]
 [14.931392]
 [17.28833 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  3.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22
 11  8 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7228546142578125
desired expected reward: 24.110315322875977



action possibilites: [-1] 
expected returns: [[19.919155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.2027057260274887
desired expected reward: 15.41755199432373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.840324]
 [16.660582]
 [20.014042]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04989669844508171
desired expected reward: 19.969051361083984






Player: 1 
cards in hand: [ 0.  8.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  5.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
adversary owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[23.057705]
 [24.06485 ]
 [24.702717]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  8. 11.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  3  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8
 11  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 15. 29.  0. 29.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4974347651004791
desired expected reward: 19.5166072845459



action possibilites: [-1] 
expected returns: [[18.575798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 15. 29.  0. 29.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.018408050760626793
desired expected reward: 20.906335830688477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[17.62948 ]
 [19.207195]
 [18.231434]
 [15.431135]
 [18.816412]
 [18.813614]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 15. 29.  0. 29.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08444211632013321
desired expected reward: 18.660240173339844



buy possibilites: [-1] 
expected returns: [[15.558667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 15. 29.  0. 29.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 1.0
Learning step: 0.42715010046958923
desired expected reward: 19.634347915649414






Player: 1 
cards in hand: [ 8. 15. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 29.  0. 29.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8  0 29  6  0  0  0  6  8
  3  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [16. 25.  6. 29.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 25. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [16. 25.  6. 29.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 29.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [16. 25.  6. 29.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [16. 25.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 29.] 
expected returns: [[15.058626]
 [14.425374]
 [17.485853]
 [16.391947]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25.  6. 29.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 29. 17. 30.  8.  2.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 22.  0. 11.  3.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44697993993759155
desired expected reward: 15.111687660217285



action possibilites: [-1] 
expected returns: [[17.801723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 29.  0.  0.  1.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 22.  0. 11.  3.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.11234252899885178
desired expected reward: 17.598194122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[16.683472]
 [18.194427]
 [17.270393]
 [14.62982 ]
 [17.073952]
 [19.40035 ]
 [16.560862]
 [17.82889 ]
 [18.070156]
 [17.826208]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 29.  0.  0.  1.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 22.  0. 11.  3.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10246141254901886
desired expected reward: 17.904184341430664



buy possibilites: [-1] 
expected returns: [[10.759981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 29.  0.  0.  1.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 8. 22.  0. 11.  3.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -6.  0.  0.  0.  0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -0.11769870668649673
desired expected reward: 16.565773010253906






Player: 1 
cards in hand: [ 8. 22.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 11.  3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 3.  3. 10. 22. 16.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 11.  3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 3.  3. 10. 22. 16.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 11.  3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [ 3.  3. 10. 22. 16.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 22. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 16.] 
expected returns: [[15.956764 ]
 [15.9758215]
 [13.44619  ]
 [15.318204 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 22. 16.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [29.  2.  0.  3.  6.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.31178656220436096
desired expected reward: 10.44819450378418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.981432]
 [13.167506]
 [15.956764]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 22. 16.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [29.  2.  0.  3.  6.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47169768810272217
desired expected reward: 15.485065460205078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  2.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  2.  0.  3.  6.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [14. 25.  0.  8.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [14. 25.  0.  8.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  6.  7.  4.] 
adversary cards in hand: [14. 25.  0.  8.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 3.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  5.  7.  4.] 
adversary cards in hand: [14. 25.  0.  8.  0.] 
adversary cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [14. 25.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.  8.] 
expected returns: [[19.981653]
 [18.66617 ]
 [23.180456]
 [21.037691]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  0.  8.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  5.  7.  4.] 
adversary cards in hand: [22.  3. 15.  6.  8.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4060054123401642
desired expected reward: 15.55075740814209



action possibilites: [-1] 
expected returns: [[16.991264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  5.  7.  4.] 
adversary cards in hand: [22. 15.  8.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.06842313706874847
desired expected reward: 18.73459243774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[15.845014]
 [17.390593]
 [16.442825]
 [13.661289]
 [16.240906]
 [18.614887]
 [15.714262]
 [17.013601]
 [17.25984 ]
 [16.991266]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  5.  7.  4.] 
adversary cards in hand: [22. 15.  8.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1180998757481575
desired expected reward: 17.109363555908203



buy possibilites: [-1] 
expected returns: [[18.30843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.  0.] 
cards in discard: [15. 16.  6. 14.  3. 15.  6. 11.  3. 11.  0.  3.  8. 14.  3.  1.  8.  0.
  1. 11.  0. 25. 16.  6. 29.  0.  0.  1.  3.  3. 10. 22. 16. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [22. 15.  8.] 
adversary cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -7.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 10.0
Learning step: 0.05683055892586708
desired expected reward: 17.070430755615234






Player: 1 
cards in hand: [22. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  8.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 0.  3. 11. 29. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  6.  3. 11. 10.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 14. 11. 11.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 0.  3. 11. 29. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  6.  3. 11. 10.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 14. 11. 11.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 0.  3. 11. 29. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  6.  3. 11. 10.] 
cards in discard: [15. 10.  0.  8.  1.  0.  0. 15.  8. 29. 29.  6.  0.  8. 22.  0. 11.  3.
  6. 16. 10. 29.  2.  0.  3.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 14. 11. 11.] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 0.  3. 11. 29. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 29. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 23.] 
expected returns: [[21.002264]
 [22.65597 ]
 [22.702639]
 [19.525488]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29. 23.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47121596336364746
desired expected reward: 17.83721351623535



action possibilites: [-1. 11. 29. 14.] 
expected returns: [[19.283115]
 [21.042826]
 [21.092453]
 [17.853165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29. 14.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.07499977201223373
desired expected reward: 19.600486755371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[18.043518]
 [18.703966]
 [15.640483]
 [19.31938 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29. 14.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10] -> size -> 42 
action values: 0 
buys: 2 
player value: 2 
card supply: [10. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.06266263872385025
desired expected reward: 19.34577751159668



buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.622978]
 [16.233318]
 [13.502161]
 [16.803484]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29. 14.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 29. 17. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0  0  0] 
sum of rewards: 7 

action type: buy - action 0.0
Learning step: -0.16547808051109314
desired expected reward: 17.87803840637207



buy possibilites: [-1] 
expected returns: [[16.916506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29. 14.] 
cards in discard: [0. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 16. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -9  0  0  8  0] 
sum of rewards: 14 

action type: buy - action 3.0
Learning step: 0.110623799264431
desired expected reward: 16.34394073486328






Player: 1 
cards in hand: [ 6. 10.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 16. 30.  8.  1.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 0. 25. 14. 15.  0.] 
adversary cards in discard: [ 0.  3. 23.  0.  3. 11. 29. 14.] 
adversary owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10  0  3] -> size -> 44 
adversary victory points: 4
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 2 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 5 
Chapel: 4 
Witch: 2 
Poacher: 3 
Militia: 2 
Market: 1 
Village: 2 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 25. 14. 15.  0.] 
cards in discard: [ 0.  3. 23.  0.  3. 11. 29. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  1 11  0  1  6  3  3  0 14 14  3 29 25  0  3  3 16 22 11  8 11
  8  6 23 25 16 10  8 29 16  3 11  0 15 15  6  1  0 10  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 16. 30.  8.  0.  5.  0.  0.  8.  3.  6.  9.  4.  7.  4.] 
adversary cards in hand: [ 6. 10.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [10 11  3 15 10  6  1  3 29 11  3 16  6 11  2  8 29  6  0  0  0  6  8  3
  8  8 22  0 15 11 22 29  0  0 14 11 10  3 15  6  0 10  0  6] -> size -> 44 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.342504501342773
desired expected reward: 31.259010314941406



