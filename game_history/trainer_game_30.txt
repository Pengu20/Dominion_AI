 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.83948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -3  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -558 

action type: buy - action -1.0
Learning step: -28.0616455078125
desired expected reward: -24.828760147094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.4729 ]
 [300.0478 ]
 [299.2122 ]
 [287.55814]
 [298.92606]
 [307.4794 ]
 [301.53705]
 [308.89493]
 [295.6252 ]
 [300.70145]
 [302.40314]
 [315.6819 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.011561393737793
desired expected reward: 305.8184814453125



buy possibilites: [-1] 
expected returns: [[284.7998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -7.038307189941406
desired expected reward: 291.88775634765625






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.18295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.4782257080078125
desired expected reward: 277.32159423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[309.14807]
 [314.84012]
 [314.1096 ]
 [303.85278]
 [321.53152]
 [316.18277]
 [315.45218]
 [329.36127]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.804717063903809
desired expected reward: 317.38482666015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[279.99338]
 [262.55734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.870393753051758
desired expected reward: 318.4908752441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.90564]
 [267.71048]
 [256.05933]
 [269.9998 ]
 [284.78555]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.633574485778809
desired expected reward: 274.00177001953125



buy possibilites: [-1] 
expected returns: [[300.77457]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -22.1855411529541
desired expected reward: 233.87380981445312






Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.66235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 16.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.341946601867676
desired expected reward: 291.4326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.12738]
 [282.6937 ]
 [282.05496]
 [268.28348]
 [281.51132]
 [291.71722]
 [284.44135]
 [293.2314 ]
 [277.94577]
 [283.8026 ]
 [285.86038]
 [301.7882 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 16.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.903907775878906
desired expected reward: 294.39752197265625



buy possibilites: [-1] 
expected returns: [[280.63156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 16.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 9 

action type: buy - action 16.0
Learning step: -7.3113555908203125
desired expected reward: 274.199951171875






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.81522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.156966209411621
desired expected reward: 272.474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[291.31927]
 [298.22446]
 [297.60855]
 [285.1752 ]
 [297.11356]
 [306.59613]
 [299.8513 ]
 [307.99628]
 [293.7699 ]
 [299.23538]
 [301.13055]
 [316.16537]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.955204010009766
desired expected reward: 302.2497863769531



buy possibilites: [-1] 
expected returns: [[329.8212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -8.415246963500977
desired expected reward: 289.8092041015625






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[293.41492]
 [276.3899 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [1. 0. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -11.198569297790527
desired expected reward: 318.62261962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[271.12778]
 [276.51456]
 [265.53796]
 [278.58533]
 [294.28772]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [1. 0. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.528243064880371
desired expected reward: 284.13421630859375



buy possibilites: [-1] 
expected returns: [[298.89355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [1. 0. 6. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 3.0
Learning step: -6.932145595550537
desired expected reward: 269.5823974609375






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  6.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  6.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  6.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[277.6729 ]
 [262.41888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.4299898147583
desired expected reward: 289.46356201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[255.79796]
 [261.40076]
 [260.7866 ]
 [250.62437]
 [267.87268]
 [262.67838]
 [262.06424]
 [275.00635]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.562407493591309
desired expected reward: 269.62677001953125



buy possibilites: [-1] 
expected returns: [[272.8859]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3. 16.  0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -6.849395751953125
desired expected reward: 253.93716430664062






Player: 1 
cards in hand: [ 0.  0. 14.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[228.3543 ]
 [209.01787]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  6 16  1  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 4
Learning step: -6.740306854248047
desired expected reward: 227.03201293945312



action possibilites: [-1] 
expected returns: [[285.67368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 34 

action type: gain_card_n - action 1
Learning step: -7.945827484130859
desired expected reward: 313.52386474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[259.15567]
 [253.65416]
 [281.79623]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 26. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -6.757091045379639
desired expected reward: 278.9165954589844



buy possibilites: [-1] 
expected returns: [[244.5172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 0.0 

action type: buy - action 0.0
Learning step: -7.4561448097229
desired expected reward: 251.69949340820312






Player: 1 
cards in hand: [ 3.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[225.18898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -7.1903557777404785
desired expected reward: 237.32684326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[209.56793]
 [213.8795 ]
 [213.39337]
 [205.8091 ]
 [213.16457]
 [218.91145]
 [214.86171]
 [219.91335]
 [211.03015]
 [214.3756 ]
 [215.5001 ]
 [225.31908]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.318241596221924
desired expected reward: 217.48196411132812



buy possibilites: [-1] 
expected returns: [[227.25648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  1.  6.  3. 16.  0.  3.  3.  3.  0. 16.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 4.5 

action type: buy - action 10.0
Learning step: -5.380508899688721
desired expected reward: 208.99508666992188






Player: 1 
cards in hand: [ 0.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0.  1.  3.  3.  3.  0.  0. 11.  3. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3 22] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[245.92502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [22.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3 22] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -5.854655742645264
desired expected reward: 221.40182495117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[232.39952]
 [238.1195 ]
 [237.36758]
 [226.97685]
 [244.73285]
 [239.40561]
 [238.64508]
 [251.41257]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  9. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [22.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3 22] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.820525646209717
desired expected reward: 237.9869842529297



buy possibilites: [-1] 
expected returns: [[266.88275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [22.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3 22] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 2.0 

action type: buy - action 8.0
Learning step: -5.740171909332275
desired expected reward: 233.66543579101562






Player: 1 
cards in hand: [22.  0.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14  0 11 15  8  3 22] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[260.68735]
 [247.64384]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -7.1276421546936035
desired expected reward: 259.7550964355469



action possibilites: [-1. 16.] 
expected returns: [[294.04633]
 [278.61768]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action 10.0
Learning step: -4.344480037689209
desired expected reward: 242.005615234375



action possibilites: [-1.] 
expected returns: [[321.50244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  8.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    4    0    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -261 

action type: gain_card_n - action 2
Learning step: -19.49460792541504
desired expected reward: 254.07362365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[299.33325]
 [293.6917 ]
 [322.33826]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  8.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -7.191703796386719
desired expected reward: 314.31072998046875



buy possibilites: [-1] 
expected returns: [[270.50635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0. 6. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -272.0 

action type: buy - action 6.0
Learning step: -22.19819450378418
desired expected reward: 271.4935302734375






Player: 1 
cards in hand: [ 3.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 8. 22.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 8. 22.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 8. 22.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 1.  3.  0. 16.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[200.09122]
 [184.15224]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 16.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  1  3  3  3  0 10  8  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 22.  3. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.872098922729492
desired expected reward: 260.6342468261719



action possibilites: [-1] 
expected returns: [[223.77231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 22.  3. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 24 

action type: gain_card_n - action 14
Learning step: -6.389825820922852
desired expected reward: 246.10421752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[211.61649]
 [206.97186]
 [228.41185]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 22.  3. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -5.885632514953613
desired expected reward: 217.8866729736328



buy possibilites: [-1] 
expected returns: [[282.01678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  0.  6.  6. 10. 16.  3.  3.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 22.  3. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -5.335446834564209
desired expected reward: 206.28103637695312






Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 8. 22.  3. 15.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 22.  3. 15.  3.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 22.  3. 15.  3.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8. 22.  3. 15.  3.  0.  1.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[201.22693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.257972717285156
desired expected reward: 271.7588195800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[178.97331]
 [174.3457 ]
 [198.96844]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 25. 30.  8.  7.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.271973133087158
desired expected reward: 191.1887664794922



buy possibilites: [-1] 
expected returns: [[222.86407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -19.636491775512695
desired expected reward: 154.70921325683594






Player: 1 
cards in hand: [ 1.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[218.21536]
 [205.77359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [6. 3. 6. 6. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 15.  3.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.562816619873047
desired expected reward: 215.30125427246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[201.21782]
 [205.43195]
 [196.89362]
 [206.97104]
 [217.57832]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [6. 3. 6. 6. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 15.  3.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -7.245671272277832
desired expected reward: 208.14352416992188



buy possibilites: [-1] 
expected returns: [[225.07623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [6. 3. 6. 6. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11.  3. 15.  3.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -53.0 

action type: buy - action 0.0
Learning step: -7.646676540374756
desired expected reward: 193.57115173339844






Player: 1 
cards in hand: [ 3. 11.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 15.  3.] 
cards in discard: [ 1.  0.  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 10.  3.  0.  6.] 
adversary cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3. 15.  3.] 
cards in discard: [ 1.  0.  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 10.  3.  0.  6.] 
adversary cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[144.90646]
 [129.60965]
 [129.08154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  6.] 
cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  3. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.37878131866455
desired expected reward: 215.69744873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.122696]
 [115.81631 ]
 [143.93192 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.  6.] 
cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  3. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.374341011047363
desired expected reward: 137.5878143310547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 1.  0.  3.  0. 14.  3. 11.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0.  3.] 
adversary cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 1.  0.  3.  0. 14.  3. 11.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10. 10.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0.  3.] 
adversary cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [ 1.  0.  3.  0. 14.  3. 11.  3. 15.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0.  3.] 
adversary cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[174.75488]
 [165.63086]
 [163.29651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 16.  0.  3.] 
cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -4.581710338592529
desired expected reward: 139.35018920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[155.25867]
 [159.0863 ]
 [151.33209]
 [160.48622]
 [170.24356]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 16.  0.  3.] 
cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  8. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.171895980834961
desired expected reward: 166.81103515625



buy possibilites: [-1] 
expected returns: [[149.55484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 16.  0.  3.] 
cards in discard: [ 6.  3.  6.  6.  0.  3.  0.  0.  3. 16.  3.  0.  8. 10.  3.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  3.  0. 22.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 8.0
Learning step: -5.409327507019043
desired expected reward: 155.07688903808594






Player: 1 
cards in hand: [ 1.  3.  0. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 22.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  8. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  8. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 25. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  8. 14.  0.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[163.41216]
 [154.07541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -5.625427722930908
desired expected reward: 143.92941284179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[148.20847]
 [144.9206 ]
 [160.49135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.189676761627197
desired expected reward: 153.3824005126953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  1. 15.] 
cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[160.72252]
 [149.5749 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [ 6.  3.  3. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  3. 11.] 
adversary cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3. 15. 15.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -6.213700771331787
desired expected reward: 154.2776336669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.12317]
 [151.19601]
 [143.75848]
 [152.69939]
 [163.41452]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [ 6.  3.  3. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  3. 11.] 
adversary cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3. 15. 15.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.110497951507568
desired expected reward: 152.2695770263672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 11.] 
cards in discard: [ 3. 22.  1.  3.  0.  8. 14.  0.  3. 15. 15.  1.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 22.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 15.  0.  3.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  6.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [15.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[132.41812]
 [122.69106]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  0.  3.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  6.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -7.005684852600098
desired expected reward: 156.40882873535156



action possibilites: [-1] 
expected returns: [[170.95264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  6.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 15.0
Learning step: -2.7732303142547607
desired expected reward: 116.62005615234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[162.20583]
 [165.89024]
 [165.40015]
 [158.75229]
 [170.01326]
 [166.71567]
 [166.22557]
 [174.25381]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  9.  9.  6.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -5.4265642166137695
desired expected reward: 165.5260772705078



buy possibilites: [-1] 
expected returns: [[95.77814]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -5.768817901611328
desired expected reward: 160.45680236816406






Player: 1 
cards in hand: [3. 3. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7. 10.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.952133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [14.  8. 15.  1.  3.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.999984264373779
desired expected reward: 90.77815246582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.656876]
 [58.848335]
 [58.66108 ]
 [52.810856]
 [58.3774  ]
 [62.76811 ]
 [59.581642]
 [63.35357 ]
 [56.88979 ]
 [59.394375]
 [60.26351 ]
 [67.40147 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  9. 10.  8.  9.  6.] 
adversary cards in hand: [14.  8. 15.  1.  3.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -3.4775493144989014
desired expected reward: 60.47458267211914



buy possibilites: [-1] 
expected returns: [[137.87068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.  0.  6. 10. 10. 15.  3.  6.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [14.  8. 15.  1.  3.] 
adversary cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -1 

action type: buy - action 14.0
Learning step: 0.20760078728199005
desired expected reward: 57.097389221191406






Player: 1 
cards in hand: [14.  8. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 15.  1.  3.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10
 14] -> size -> 25 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 15.  1.  3.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 24. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10
 14] -> size -> 25 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 15.  1.  3.] 
cards in discard: [15. 29. 22.  0.  0.  3. 11. 15.  0.  3. 25.  3.  3.  0.  1.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10
 14] -> size -> 25 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [15.  8.  8.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 16.] 
expected returns: [[57.608856]
 [51.613144]
 [51.173454]
 [51.173454]
 [50.26467 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  3. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29. 15. 25. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -7.894702434539795
desired expected reward: 129.97598266601562



action possibilites: [-1] 
expected returns: [[157.49214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29. 15. 25. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.04960022121667862
desired expected reward: 48.813865661621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.33008]
 [140.33038]
 [160.70602]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29. 15. 25. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -5.635836124420166
desired expected reward: 151.85630798339844






Player: 1 
cards in hand: [29. 15. 25. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 25. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 25. 15. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 15. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 15. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 15. 15.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[134.26183]
 [120.3354 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14.  0.] 
cards in discard: [ 8. 15.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  3.  8. 14.  1.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -7.370144844055176
desired expected reward: 153.3358917236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.5741  ]
 [120.980774]
 [113.995865]
 [122.26599 ]
 [132.39346 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 14.  0.] 
cards in discard: [ 8. 15.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  3.  8. 14.  1.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -5.910857200622559
desired expected reward: 124.82273864746094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  8. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 14.  1.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 14.  1.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  7.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 14.  1.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[108.533905]
 [ 98.49699 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 22.  0.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -6.464640140533447
desired expected reward: 125.9288101196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 90.94904 ]
 [ 95.34426 ]
 [ 94.892525]
 [ 87.22153 ]
 [101.40791 ]
 [ 96.505684]
 [ 96.053955]
 [108.16878 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 22.  0.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -5.264951705932617
desired expected reward: 101.31594848632812



buy possibilites: [-1] 
expected returns: [[71.7603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 22.  0.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -73.0 

action type: buy - action 0.0
Learning step: -6.582846164703369
desired expected reward: 84.36620330810547






Player: 1 
cards in hand: [ 3.  0.  1. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 22.  0.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 22.  0.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  8. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 22.  0.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[124.37905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 3.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -2.939486503601074
desired expected reward: 68.82081604003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.11746]
 [106.50534]
 [125.01801]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 3.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  6.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -5.7625322341918945
desired expected reward: 118.61651611328125



buy possibilites: [-1] 
expected returns: [[56.249405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 3.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -354.0 

action type: buy - action 6.0
Learning step: -21.75965690612793
desired expected reward: 84.74568176269531






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  3. 16.  3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.  3.  3.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  3. 16.  3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.  3.  3.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0. 15. 29. 25. 15. 15.  8.  3.  3.  8. 14.  1. 14.  3.  0.  1. 22.  0.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  3. 16.  3.] 
adversary cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.  3.  3.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[147.37354]
 [136.38982]
 [135.03508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 16.  3.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.  3.  3.
  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [15.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -2.8406903743743896
desired expected reward: 53.408714294433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.79253]
 [123.12113]
 [141.58426]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 16.  3.] 
cards in discard: [ 8. 15.  8.  3.  6.  0.  6. 14.  0.  0.  0.  6.  0. 10.  0.  6.  3.  3.
  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [15.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -7.326388835906982
desired expected reward: 134.80419921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 16.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 16.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1. 11.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 16.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[123.71876]
 [110.3533 ]
 [107.89587]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 14.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  5.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 15.  1. 29. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -7.748332977294922
desired expected reward: 133.83590698242188



action possibilites: [-1] 
expected returns: [[79.72621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 15.  1. 29. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -355 

action type: gain_card_n - action 2
Learning step: -17.843114852905273
desired expected reward: 19.89597511291504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.39256 ]
 [63.771423]
 [86.62584 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 15.  1. 29. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -5.041139125823975
desired expected reward: 74.68507385253906



buy possibilites: [-1] 
expected returns: [[52.90792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.] 
cards in discard: [6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0. 15.  1. 29. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -6.479200839996338
desired expected reward: 61.913368225097656






Player: 1 
cards in hand: [ 0. 15.  1. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1. 29. 14.] 
cards in discard: [10. 15.  0.  0.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1. 15. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1. 14. 25.] 
cards in discard: [10. 15.  0.  0.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1. 14. 25.] 
cards in discard: [10. 15.  0.  0.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 22. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1. 14. 25.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.690025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  3.  1. 22.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -5.979870796203613
desired expected reward: 46.92805099487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.87119 ]
 [35.63275 ]
 [30.25643 ]
 [36.479595]
 [43.42082 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  3.  1. 22.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.450074195861816
desired expected reward: 35.239952087402344



buy possibilites: [-1] 
expected returns: [[73.99945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  3.  1. 22.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -5.728572368621826
desired expected reward: 27.142620086669922






Player: 1 
cards in hand: [ 0.  3.  1. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 22.  3.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [8. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 22.  3.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  7.  9.  6.] 
adversary cards in hand: [8. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 22.  3.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [8. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [8. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[68.27725 ]
 [62.009018]
 [62.009018]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0
  6  6  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  3.  3.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -6.491206645965576
desired expected reward: 67.50824737548828



action possibilites: [-1] 
expected returns: [[139.96281]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  3.  3.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.705371618270874
desired expected reward: 60.38532638549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.02946]
 [135.2562 ]
 [143.09172]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  3.  3.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -6.564461708068848
desired expected reward: 133.39834594726562



buy possibilites: [-1] 
expected returns: [[70.3032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  3.  3.  3.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -9.469650268554688
desired expected reward: 127.55979919433594






Player: 1 
cards in hand: [15.  8.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  3.  3.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 14  0 11 15  8  3 22  1  1 29  3 15 15 25  3  0  8
 14  3 10  3 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[75.56081 ]
 [70.475876]
 [70.475876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10. 10.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 0.  3.  3.  8. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -4.077888488769531
desired expected reward: 66.22531127929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.159267]
 [53.88143 ]
 [65.88312 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10. 10.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 0.  3.  3.  8. 14.] 
adversary cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -4.180380821228027
desired expected reward: 62.38948059082031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 14.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 6.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  8. 14.] 
cards in discard: [10. 15.  0.  0.  1. 11.  3. 29.  0. 15.  1. 14. 25. 10.  0.  3.  1. 22.
  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [ 6.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[100.55278]
 [ 89.55768]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 15.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6
  6  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15. 22. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -3.3336379528045654
desired expected reward: 62.54948043823242



action possibilites: [-1] 
expected returns: [[68.03078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15. 22. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -4.147191047668457
desired expected reward: 85.41046905517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[59.081585]
 [61.273094]
 [60.962524]
 [57.031654]
 [60.88919 ]
 [63.78853 ]
 [61.758713]
 [64.28883 ]
 [59.727467]
 [61.44815 ]
 [61.986214]
 [67.20597 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  6.  9.  6.] 
adversary cards in hand: [15. 22. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -3.192960739135742
desired expected reward: 64.83781433105469



buy possibilites: [-1] 
expected returns: [[111.247345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 6.  0. 16.  0. 14.  6.  0.  0.  6.  0.  6.  3.  0.  8.  8.  3.  0.  3.
  3.  3. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  5.  9.  6.] 
adversary cards in hand: [15. 22. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -19.5 

action type: buy - action 10.0
Learning step: -1.5443423986434937
desired expected reward: 59.90380859375






Player: 1 
cards in hand: [15. 22. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 22. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  5.  9.  6.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 22. 10.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 22. 10.  0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 22. 10.  0.] 
cards in discard: [10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [15. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[80.13791]
 [74.12117]
 [73.37213]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -6.073445796966553
desired expected reward: 105.17389678955078



action possibilites: [-1. 15.] 
expected returns: [[55.202816]
 [51.030678]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6
  0  0  0 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -3.5381405353546143
desired expected reward: 68.2924575805664



action possibilites: [-1.] 
expected returns: [[66.525734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: -1.2547049522399902
desired expected reward: 49.77597427368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[60.981255]
 [63.130188]
 [60.621624]
 [62.829384]
 [59.585396]
 [59.13102 ]
 [62.741093]
 [65.69318 ]
 [63.631363]
 [69.00957 ]
 [66.271065]
 [61.596733]
 [63.007713]
 [63.330566]
 [60.777767]
 [63.897995]
 [70.26049 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 26. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.074035167694092
desired expected reward: 64.45169830322266



buy possibilites: [-1] 
expected returns: [[116.82059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -40.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 0.5 

action type: buy - action 1.0
Learning step: -0.5030462145805359
desired expected reward: 62.627140045166016






Player: 1 
cards in hand: [10.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 14. 16.  0.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  6.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 14. 16.  0.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  5.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 14. 16.  0.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8. 14. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.] 
expected returns: [[8.075486 ]
 [4.6817923]
 [3.213455 ]
 [4.047435 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 16.  0.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  5.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 3.  1.  3.  0. 25.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -7.916263580322266
desired expected reward: 108.90432739257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.3672369]
 [1.2704585]
 [7.3610353]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 16.  0.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  5.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 3.  1.  3.  0. 25.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -2.5066497325897217
desired expected reward: 5.56884765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  1.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  0. 25.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  5.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  0. 25.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  5.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  0. 25.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.278706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [29.  0. 14. 14.  3.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -1.3692814111709595
desired expected reward: 5.991761684417725





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.80749 ]
 [45.860928]
 [41.80122 ]
 [46.547516]
 [52.137405]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 21. 30.  8.  4.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [29.  0. 14. 14.  3.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -3.8040528297424316
desired expected reward: 49.47465133666992



buy possibilites: [-1] 
expected returns: [[22.792152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [29.  0. 14. 14.  3.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -19.327238082885742
desired expected reward: 22.47398567199707






Player: 1 
cards in hand: [29.  0. 14. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14. 14.  3.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 10.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 14. 14.  3.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  0.  6. 10.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[53.701485]
 [46.8332  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [1. 8. 3. 3. 1.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.744990348815918
desired expected reward: 20.047161102294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.583332]
 [36.506607]
 [47.818806]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [1. 8. 3. 3. 1.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.194468021392822
desired expected reward: 43.67377471923828



buy possibilites: [-1] 
expected returns: [[53.839283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [1. 8. 3. 3. 1.] 
adversary cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -4.967782497406006
desired expected reward: 33.61555099487305






Player: 1 
cards in hand: [1. 8. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 3. 1.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6.  6.  3.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3. 3. 1.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6.  6.  3.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3. 3. 1.] 
cards in discard: [10.  0. 11. 15. 22. 10.  0.  8. 10.  0. 15.  0.  8.  8.  3.  1.  3.  0.
 25. 29.  0. 14. 14.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  6.  6.  3.  3.] 
adversary cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  6.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[15.87481 ]
 [11.737017]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  3.  3.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.123136520385742
desired expected reward: 48.716148376464844



action possibilites: [-1.] 
expected returns: [[40.968803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -1.3650531768798828
desired expected reward: 10.371968269348145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.52504 ]
 [32.114124]
 [44.17137 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 21. 30.  8.  3.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.938706159591675
desired expected reward: 38.03009796142578



buy possibilites: [-1] 
expected returns: [[67.19394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 0.] 
cards in discard: [ 1. 10. 15.  0.  0.  0.  8. 14. 16.  0.  3.  6.  3.  0.  3.  6.  0.  0.
  6.  0.  6. 10.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 21. 30.  8.  2.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  3. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -17.393842697143555
desired expected reward: 14.720281600952148






Player: 1 
cards in hand: [ 3. 15.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  2.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3. 10.  8.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6  6] -> size -> 32 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[68.10197 ]
 [63.435017]
 [63.435017]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  3  3  3  0 10  8  6  6 15  0  6  0  8 10 14  0  6  6  0
  0  0 10  1  6  0  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14.  3. 22.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -377 

action type: buy - action -1
Learning step: -20.735082626342773
desired expected reward: 46.45885467529297



action possibilites: [-1] 
expected returns: [[43.773205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14.  3. 22.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: trash_cards_n_from_hand - action 5
Learning step: -4.989716529846191
desired expected reward: 57.5025520324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.18827 ]
 [33.215366]
 [42.841434]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 14.  3. 22.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -4.181508541107178
desired expected reward: 39.591697692871094






Player: 1 
cards in hand: [ 0.  1. 14.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3. 22.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  6.  1.  3.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3. 22.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  6.  1.  3.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3. 22.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  6.  1.  3.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  3.  6.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[6.494608]
 [3.910128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  1.  3.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0. 10.  8.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0  0] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -5.869900703430176
desired expected reward: 36.9715461730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[2.4033358]
 [3.3746643]
 [1.4075944]
 [3.7587676]
 [6.293473 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  1.  3.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0. 10.  8.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.] 
adversary owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0  0] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.085888862609863
desired expected reward: 2.4087305068969727



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 29.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10.  8.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14  0 11  8  3 22  1  1 29  3 15 15 25  3  0  8 14  3 10  3
 10 10  0  8  8 10  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.27251 ]
 [23.706905]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -3.544403076171875
desired expected reward: 2.749077796936035



action possibilites: [-1. 10.] 
expected returns: [[85.3713 ]
 [79.41012]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  6. 10.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 10.0
Learning step: -2.169748544692993
desired expected reward: 21.537153244018555



action possibilites: [-1.] 
expected returns: [[23.27583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 3 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -5.246799468994141
desired expected reward: 74.16331481933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.550626 ]
 [13.4246855]
 [ 9.740657 ]
 [14.103098 ]
 [20.876728 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -2.6726818084716797
desired expected reward: 20.603147506713867






Player: 1 
cards in hand: [ 0. 10. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  1.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  1.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 21. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  1.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[32.118034]
 [24.644526]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 14.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 10. 15.  0.  8.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.473960876464844
desired expected reward: 11.072845458984375



action possibilites: [-1] 
expected returns: [[60.561363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 14.0
Learning step: -3.219595432281494
desired expected reward: 21.424928665161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.974392]
 [51.143135]
 [50.83465 ]
 [47.78461 ]
 [47.363163]
 [50.767143]
 [53.554745]
 [51.627346]
 [55.72311 ]
 [53.99536 ]
 [49.591114]
 [50.966785]
 [51.31887 ]
 [48.730907]
 [51.826996]
 [56.14504 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 25. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -5.2051520347595215
desired expected reward: 55.3562126159668



buy possibilites: [-1] 
expected returns: [[43.25986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.] 
adversary cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8.] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -62.5 

action type: buy - action 1.0
Learning step: -4.708810329437256
desired expected reward: 46.434329986572266






Player: 1 
cards in hand: [ 1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [16.  6. 15.  6.  0.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6  1] -> size -> 31 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  3.  9.  6.] 
adversary cards in hand: [16.  6. 15.  6.  0.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6  1] -> size -> 31 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 0. 25.  3. 15.  3.  3. 10.  8.  0.  0.  1. 14.  3. 22.  8.  3. 10.  3.
  0. 10. 11.  1.  0. 10.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [16.  6. 15.  6.  0.] 
adversary cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6  1] -> size -> 31 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [16.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[ 2.0541668]
 [-1.6699328]
 [-1.4391093]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 15.  6.  0.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3  0 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0
 10  1  6  0  6  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  4.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.511375427246094
desired expected reward: 36.74848556518555



action possibilites: [-1] 
expected returns: [[25.92925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -63 

action type: gain_card_n - action 3
Learning step: -4.449160575866699
desired expected reward: 33.202205657958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.051094]
 [18.875345]
 [25.065615]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -4.151729106903076
desired expected reward: 21.77752113342285



buy possibilites: [-1] 
expected returns: [[21.234228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 6.  8.  6.  0. 10.  3.  6.  1.  3. 10. 10.  0.  3.  3.  6.  0.  1. 14.
  0.  0.  0.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action 0.0
Learning step: -5.374784469604492
desired expected reward: 14.676311492919922






Player: 1 
cards in hand: [ 3. 10.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 14  0 11  8  3 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10
  0  8  8 10  0  0  3 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.929424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1.  3. 14. 10.  3.] 
adversary cards in discard: [ 0.  8. 10. 14.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -3.9907994270324707
desired expected reward: 17.24342918395996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.790565]
 [36.336384]
 [33.256927]
 [36.87694 ]
 [40.969547]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  3.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1.  3. 14. 10.  3.] 
adversary cards in discard: [ 0.  8. 10. 14.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -5.058517932891846
desired expected reward: 35.870906829833984



buy possibilites: [-1] 
expected returns: [[30.351955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  2.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1.  3. 14. 10.  3.] 
adversary cards in discard: [ 0.  8. 10. 14.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: -4.610927581787109
desired expected reward: 32.26599884033203






Player: 1 
cards in hand: [ 1.  3. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14. 10.  3.] 
cards in discard: [ 0.  8. 10. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  2.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 14.  8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  3.  0.] 
cards in discard: [ 0.  8. 10. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  2.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 14.  8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  3.  0.] 
cards in discard: [ 0.  8. 10. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  2.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 14.  8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  3.  0.] 
cards in discard: [ 0.  8. 10. 14.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 14.  8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
expected returns: [[ 0.1724726]
 [-1.1524637]
 [-1.6110445]
 [-1.1524637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 14.  8.] 
cards in discard: [8. 0. 0. 6. 3. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  1.  3. 22. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.384265422821045
desired expected reward: 24.967689514160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.6699328 ]
 [-1.6699328 ]
 [ 0.06238556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 14.  8.] 
cards in discard: [8. 0. 0. 6. 3. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  1.  3. 22. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8] -> size -> 32 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.8786303997039795
desired expected reward: -3.7061574459075928



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1.  3. 22. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 22. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  6. 16.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 22. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 20. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  6. 16.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 22. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  6. 16.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 16.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[36.26812 ]
 [32.33928 ]
 [33.087654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 16.  0. 15.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8  3] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -3.5810201168060303
desired expected reward: -3.5186333656311035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.626556]
 [24.676973]
 [29.54575 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 16.  0. 15.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10. 15.  3.  3. 11.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10.] 
adversary owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8  3] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.317525386810303
desired expected reward: 26.242422103881836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 15.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  3. 11.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 11.  0.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8
  8 10  0  0  3 10  0  8  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  9.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.776928]
 [28.278324]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6.  1.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.184428691864014
desired expected reward: 24.361318588256836



action possibilites: [-1.] 
expected returns: [[35.619595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: -3.8624751567840576
desired expected reward: 24.41584587097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.741123]
 [36.145424]
 [35.944283]
 [35.423267]
 [35.28089 ]
 [36.02793 ]
 [36.39496 ]
 [36.226883]
 [36.847828]
 [36.539085]
 [35.717   ]
 [35.887268]
 [36.025753]
 [35.51805 ]
 [36.08622 ]
 [36.62045 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.317127704620361
desired expected reward: 31.302467346191406



buy possibilites: [-1] 
expected returns: [[61.14892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0. 10.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -5.261206150054932
desired expected reward: 30.47992515563965






Player: 1 
cards in hand: [ 1. 15.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  0. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  9.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0. 10.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[57.48553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8.  0.  8. 25.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10 11] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.114021301269531
desired expected reward: 55.03489685058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.597237]
 [46.927837]
 [42.25706 ]
 [47.799038]
 [54.046726]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 19. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8.  0.  8. 25.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10 11] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -6.136537075042725
desired expected reward: 51.348995208740234



buy possibilites: [-1] 
expected returns: [[21.84373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8.  0.  8. 25.] 
adversary cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
adversary owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -68 

action type: buy - action 3.0
Learning step: -5.254907608032227
desired expected reward: 41.67292022705078






Player: 1 
cards in hand: [ 8.  8.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  8. 25.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14  0 11  8 22  1  1  3 15 15 25  3  0  8 14  3 10  3 10 10  0  8  8
 10  0  0  3 10  0  8  3 29 10 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 14.  8. 10.  1.  3. 14.  3.  0.  3.  0.  1.  3. 22. 10. 29.
 10. 10. 15. 11.  3.  3. 11.  1. 15.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  6. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [10.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[57.1897 ]
 [50.74041]
 [50.74041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11  0] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.6851279735565186
desired expected reward: 18.15860366821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.32318 ]
 [51.012302]
 [45.361435]
 [52.03545 ]
 [58.10682 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11  0] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -5.484433174133301
desired expected reward: 51.70527648925781



buy possibilites: [-1] 
expected returns: [[30.655596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  3.  3.  3.  8.  3. 14.  8.  6.  6. 16.  0. 15.  0. 10.
  3.  0.  6.  1.  1.  3.  6.  0.  3.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 8.  8. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11  0] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -107.0 

action type: buy - action 0.0
Learning step: -7.076408386230469
desired expected reward: 41.24677658081055






Player: 1 
cards in hand: [ 8.  8. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  0. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3  0  8 14  3 10  3 10 10  0  8  8 10  0  0
  3 10  0  8  3 29 10 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [16.  1.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [16.  1.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [16.  1.  8.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3  0] -> size -> 36 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [16.  1.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[-1.6744967]
 [-1.6744967]
 [-1.6744967]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  8.  6.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  1  6  0  6  6  1  8  0  8  0  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  8.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.370456218719482
desired expected reward: 25.285139083862305



action possibilites: [-1] 
expected returns: [[3.5444465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0  -1   0   0  16   0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: -1.8865251541137695
desired expected reward: -3.5610218048095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.6865735]
 [1.6264951]
 [2.8531413]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -2.927816152572632
desired expected reward: 0.6166303157806396



buy possibilites: [-1] 
expected returns: [[10.647742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [29.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20 -30   0   0   0  -2   0   0   0   0] 
sum of rewards: -88 

action type: buy - action 0.0
Learning step: -4.07634162902832
desired expected reward: -5.758028984069824






Player: 1 
cards in hand: [ 0.  3. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10. 10.] 
cards in discard: [ 8. 10. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 11. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10. 29.] 
cards in discard: [ 8. 10. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29. 11.] 
cards in discard: [ 8. 10. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11.] 
cards in discard: [ 8. 10. 14.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  7.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 8. 10. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 11. 11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 8. 10. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 11. 11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  6. 10.  6.  6.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[ 0.91087294]
 [-1.1121905 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  6.  6.] 
cards in discard: [29.  0. 16.  8.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 15. 10.  3. 14.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -4.330645561218262
desired expected reward: 6.317096710205078



action possibilites: [-1. 14.] 
expected returns: [[-1.6816871]
 [-1.6816871]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  6. 14.] 
cards in discard: [29.  0. 16.  8.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 15. 10.  3. 14.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action 10.0
Learning step: -2.782228708267212
desired expected reward: -3.894416332244873



action possibilites: [-1.] 
expected returns: [[-1.6816871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [29.  0. 16.  8.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 15. 14.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 14.0
Learning step: -1.753753662109375
desired expected reward: -3.4354407787323





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [29.  0. 16.  8.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 15. 14.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.753753662109375
desired expected reward: -3.4354407787323



buy possibilites: [-1] 
expected returns: [[0.16867709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 15. 14.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -70.   0.   0.  40. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -69.0 

action type: buy - action 0.0
Learning step: -3.3621203899383545
desired expected reward: -5.043807506561279






Player: 1 
cards in hand: [ 0. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 14.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  0  8  8 10  0  0  3 10
  0  8  3 29 10 11  0  1 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.3138003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -3.7788734436035156
desired expected reward: -3.610196352005005





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 0.00447106]
 [ 0.250198  ]
 [-0.28822947]
 [ 0.38141537]
 [ 0.975019  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 18. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -3.8569228649139404
desired expected reward: -2.5431225299835205



buy possibilites: [-1] 
expected returns: [[-0.6228136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 17. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  3.  0.  8.  1.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0  -4   0   0   8   0] 
sum of rewards: -61 

action type: buy - action 3.0
Learning step: -3.0765233039855957
desired expected reward: -2.826324224472046






Player: 1 
cards in hand: [10.  3.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  1.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 17. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  1.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 23. 30. 17. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  1.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-1.6816871]
 [-1.6816871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [22.  1.  0.  3.  0.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -3.756697416305542
desired expected reward: -4.379510879516602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]
 [-1.6816871]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  1.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [22.  1.  0.  3.  0.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.703753709793091
desired expected reward: -5.385440826416016



buy possibilites: [-1] 
expected returns: [[8.689404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [22.  1.  0.  3.  0.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0  -5   0   0   8   0] 
sum of rewards: -72 

action type: buy - action 8.0
Learning step: -3.320404052734375
desired expected reward: -5.002091407775879






Player: 1 
cards in hand: [22.  1.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.  0.  3.  0.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8] -> size -> 40 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  1.  0.  3.  0.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8] -> size -> 40 
adversary victory points: 0
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[10.165927]
 [ 7.585243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  1.  8.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -3.979658603668213
desired expected reward: 4.709744930267334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[5.828245 ]
 [6.8730884]
 [4.8079567]
 [9.818032 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 16. 30.  8.  1.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  1.  8.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -4.092751979827881
desired expected reward: 6.073172092437744



buy possibilites: [-1] 
expected returns: [[9.825259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 3. 15.  3.  1.  8.] 
adversary cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -80.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -392.0 

action type: buy - action 6.0
Learning step: -19.61932945251465
desired expected reward: -14.81137466430664






Player: 1 
cards in hand: [ 3. 15.  3.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  1.  8.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10. 15.  3.  1.  3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 8.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10. 15.  3.  1.  3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 8.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10. 15.  3.  1.  3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 8.] 
cards in discard: [ 8. 10. 14.  1. 29. 10. 10. 11. 11.  0.  3. 29. 10.  3.  0. 15. 14.  3.
 10.  3.  0.  8.  1. 22.  1.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10. 15.  3.  1.  3.] 
adversary cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10. 15.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[2.644475 ]
 [2.165988 ]
 [2.2088842]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  1.  3.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.737411022186279
desired expected reward: 5.08784818649292



action possibilites: [-1. 15. 10.] 
expected returns: [[ 0.9528432 ]
 [-0.36514843]
 [-0.5060591 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  3. 10.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 10.0
Learning step: -3.273001194000244
desired expected reward: -3.7274067401885986





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-1.2033924]
 [-0.6553639]
 [ 0.9528432]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  3. 10.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.349466323852539
desired expected reward: -2.396620273590088



buy possibilites: [-1] 
expected returns: [[6.600207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  3. 10.] 
cards in discard: [29.  0. 16.  8.  6.  6.  0. 10. 14.  0.  6.  6.  6.  3.  6.  6.  3.  0.
  0.  8.  0.  0.  3.  8.  3.  6.  0.  8.  6.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  20. -30.   0.   0.   0.  -7.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -4.941325664520264
desired expected reward: -6.14471435546875






Player: 1 
cards in hand: [ 1.  0.  1. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 10. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  0. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  0  3 10  0
  8  3 29 10 11  0  1 29  0  3  0] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 3 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  6.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[0.23667574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [11.  8. 14. 10.  1.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.624684810638428
desired expected reward: 1.9755220413208008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.0566337e+00]
 [-1.1327511e-01]
 [-2.2224963e-01]
 [ 1.2066810e+00]
 [ 5.9676170e-04]
 [ 2.6833110e+00]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [11.  8. 14. 10.  1.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.29348611831665
desired expected reward: -4.05681037902832



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8. 14. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 14. 10.  1.] 
cards in discard: [29. 10. 10. 15.  1.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  8.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0.  6.  6. 15.] 
adversary cards in discard: [6. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 10.  1.] 
cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0.  6.  6. 15.] 
adversary cards in discard: [6. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 10.  1.] 
cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0.  6.  6. 15.] 
adversary cards in discard: [6. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 10.  1.] 
cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0.  6.  6. 15.] 
adversary cards in discard: [6. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [10.  0.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-1.6831297]
 [-1.692804 ]
 [-1.692804 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  6. 15.] 
cards in discard: [6. 0. 3. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  0  6  0  8 10 14  0  6  6  0  0  0 10
  6  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.  0. 11.  8. 14. 10.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11  0] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.472155570983887
desired expected reward: -1.7888472080230713



action possibilites: [-1] 
expected returns: [[103.57008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.] 
cards in discard: [6. 0. 3. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  6  0  8 10 14  0  6  6  0  0  0 10  6
  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.  0. 11.  8. 14. 10.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11  0] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 15.0
Learning step: -0.8850329518318176
desired expected reward: -2.5778369903564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 98.17852]
 [ 99.57595]
 [ 99.30858]
 [101.04871]
 [ 99.62412]
 [102.56595]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [6. 0. 3. 0. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  6  0  8 10 14  0  6  6  0  0  0 10  6
  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.  0. 11.  8. 14. 10.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11  0] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -6.217408180236816
desired expected reward: 97.35267639160156



Player 1 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 3 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 2 
Workshop: 0 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  6.  6.] 
cards in discard: [ 6.  0.  3.  0.  0. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16  3  3  3 10  6  6 15  6  0  8 10 14  0  6  6  0  0  0 10  6
  0  6  6  1  8  0  8  0  3  0 29  0  0  3  8  6  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 16. 30.  8.  0.  8.  7.  0.  9.  5.  7. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [29. 10. 10. 15.  1.  1.  0. 11.  0. 11.  8. 14. 10.  1.] 
adversary owned cards: [ 1 14 11 22  1  1  3 15 15  3 14  3 10  3 10 10  8  8 10  0  3 10  0  8
  3 29 10 11  0  1 29  0  3  0 29 11  0] -> size -> 37 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -80    0    0   20    0    0    0    0   -7    0    0
    9    0] 
sum of rewards: -564 

action type: buy - action 10.0
Learning step: -33.181209564208984
desired expected reward: 66.44291687011719



