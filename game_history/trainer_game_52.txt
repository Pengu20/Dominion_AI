 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.53598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   7  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 582 

action type: discard_down_to_3_cards - action 9
Learning step: 27.882001876831055
desired expected reward: 52.24201965332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.81183]
 [292.19617]
 [290.11325]
 [263.36517]
 [301.50815]
 [290.98624]
 [289.25116]
 [307.67133]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.883363723754883
desired expected reward: 300.5148620605469



buy possibilites: [-1] 
expected returns: [[284.83456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.140533447265625
desired expected reward: 282.845703125






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.85843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.3599700927734375
desired expected reward: 277.474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.15683]
 [297.69257]
 [295.41937]
 [265.85342]
 [290.53333]
 [307.80557]
 [296.23618]
 [299.7172 ]
 [278.23145]
 [294.32434]
 [291.71268]
 [314.52856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.81713581085205
desired expected reward: 301.48321533203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[275.83926]
 [266.531  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.701559066772461
desired expected reward: 304.8269958496094



action possibilites: [-1] 
expected returns: [[292.5103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 1
Learning step: -7.776452541351318
desired expected reward: 297.3822326660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[262.80054]
 [267.72147]
 [249.57648]
 [269.69058]
 [280.3969 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.6042938232421875
desired expected reward: 284.906005859375






Player: 1 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.97604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [1. 0. 3. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.711097717285156
desired expected reward: 273.68585205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[293.1373 ]
 [305.07608]
 [302.39258]
 [272.0083 ]
 [314.75665]
 [303.64972]
 [301.31125]
 [321.50354]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [1. 0. 3. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.588541984558105
desired expected reward: 319.689208984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [1. 0. 3. 3. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [1. 0. 3. 3. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.58597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.256836891174316
desired expected reward: 312.2467041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.75473]
 [292.4299 ]
 [290.0732 ]
 [265.374  ]
 [300.5989 ]
 [291.41214]
 [289.34793]
 [305.64038]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.805500030517578
desired expected reward: 298.67626953125



buy possibilites: [-1] 
expected returns: [[285.40506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.497085571289062
desired expected reward: 242.8769073486328






Player: 1 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[272.00027]
 [258.72037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [3. 1. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.381219863891602
desired expected reward: 276.0238342285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[251.26224]
 [257.59982]
 [236.01727]
 [259.04257]
 [272.54886]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [3. 1. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.87263011932373
desired expected reward: 263.7159423828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [3. 1. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  1.  3.  3.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  1.  3.  3.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  1.  3.  3.  0.  0. 16. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[360.6033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -6.651857852935791
desired expected reward: 265.8970031738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[320.90683]
 [332.2127 ]
 [329.81827]
 [300.79584]
 [342.08807]
 [330.85834]
 [328.82748]
 [348.5178 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.936751365661621
desired expected reward: 336.59478759765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.00693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  0.  3.] 
adversary cards in discard: [16. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -11.344191551208496
desired expected reward: 337.1736755371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[290.02557]
 [301.1422 ]
 [298.967  ]
 [270.95224]
 [311.14285]
 [299.7799 ]
 [297.97684]
 [318.03357]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  0.  3.] 
adversary cards in discard: [16. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.319998741149902
desired expected reward: 311.0888977050781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [16. 11.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [16. 11.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [16. 11.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[374.4726 ]
 [355.76242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [3. 0. 0. 6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [16. 11.  3.  0.  0.  3.  1. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -9.217618942260742
desired expected reward: 308.8160400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[347.50342]
 [356.5533 ]
 [328.05356]
 [357.37524]
 [375.28247]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [3. 0. 0. 6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [16. 11.  3.  0.  0.  3.  1. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -12.290627479553223
desired expected reward: 363.5614318847656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16. 11.  3.  0.  0.  3.  1. 29.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16. 11.  3.  0.  0.  3.  1. 29.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16. 11.  3.  0.  0.  3.  1. 29.  3.  0.  3.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[294.249 ]
 [278.3186]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -15.3527250289917
desired expected reward: 359.9297790527344



action possibilites: [-1] 
expected returns: [[259.76556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: trash_cards_n_from_hand - action 0
Learning step: -9.876968383789062
desired expected reward: 261.556884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[238.9106 ]
 [243.96584]
 [225.76074]
 [245.45003]
 [258.45032]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -9.531549453735352
desired expected reward: 250.2340087890625



buy possibilites: [-1] 
expected returns: [[254.05644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -24 

action type: buy - action 3.0
Learning step: -7.6820220947265625
desired expected reward: 236.2838134765625






Player: 1 
cards in hand: [ 3. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[325.16626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 16.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -7.992503643035889
desired expected reward: 246.06393432617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[299.45502]
 [307.92175]
 [279.08743]
 [309.52008]
 [326.19464]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 16.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -11.790202140808105
desired expected reward: 313.11285400390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 16.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 16.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 16.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.3436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 1.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  0.  0.  0.  0.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -12.241223335266113
desired expected reward: 313.9534606933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[265.48575]
 [245.40501]
 [293.7994 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 1.] 
adversary cards in discard: [ 8. 11.  3.  3.  0.  0.  0.  0.  0.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -11.14266586303711
desired expected reward: 285.235595703125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [4. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 3. 0. 1.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.  0.  0.  0.  1.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 6. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 3. 0. 1.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.  0.  0.  0.  1.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 6. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 3. 0. 1.] 
cards in discard: [ 8. 11.  3.  3.  0.  0.  0.  0.  0.  1.  0. 16.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 6. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[338.55283]
 [320.2136 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [3. 6. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 6 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -9.751218795776367
desired expected reward: 284.0481872558594



action possibilites: [-1] 
expected returns: [[230.52339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 6. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 6 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -103 

action type: trash_cards_n_from_hand - action 6
Learning step: -13.341394424438477
desired expected reward: 254.22201538085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[206.32085]
 [193.06773]
 [224.14851]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 6. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 6 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -103 

action type: take_action - action -1
Learning step: -11.84593677520752
desired expected reward: 218.67745971679688






Player: 1 
cards in hand: [16.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3] -> size -> 6 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3] -> size -> 6 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3] -> size -> 6 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3. 11.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3] -> size -> 6 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[266.75665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 1. 8. 3.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -123 

action type: buy - action -1.0
Learning step: -11.348959922790527
desired expected reward: 212.79953002929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[245.51976]
 [230.13991]
 [266.67673]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 1. 8. 3.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -123 

action type: take_action - action -1.0
Learning step: -13.753308296203613
desired expected reward: 253.2895965576172



buy possibilites: [-1] 
expected returns: [[239.19789]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 1. 8. 3.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.   0. -30.   0.   0. -30.   0.   0.   0.
   0.   0.] 
sum of rewards: -123.0 

action type: buy - action 0.0
Learning step: -13.044035911560059
desired expected reward: 232.47572326660156






Player: 1 
cards in hand: [0. 4. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 1. 8. 3.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 1. 8. 3.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 1. 8. 3.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[212.31737]
 [201.83775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11] -> size -> 23 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1
Learning step: -11.891423225402832
desired expected reward: 227.3064727783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[193.09767]
 [179.31143]
 [209.6097 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11] -> size -> 23 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -10.771777153015137
desired expected reward: 201.9088134765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0] -> size -> 7 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[231.72086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -9.91086483001709
desired expected reward: 199.69883728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[208.9779 ]
 [214.66106]
 [194.99216]
 [216.12772]
 [226.4554 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -11.339694023132324
desired expected reward: 220.64341735839844



buy possibilites: [-1] 
expected returns: [[278.60507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -93.0 

action type: buy - action 0.0
Learning step: -8.830279350280762
desired expected reward: 200.14759826660156






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 29. 16.  3.  0.  3. 11. 11.  0.  4.  1.  8.  3. 11.  0.  3.  1.  1.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[258.4772 ]
 [242.40157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -11.267186164855957
desired expected reward: 267.337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[234.57819]
 [242.66678]
 [216.33665]
 [243.61234]
 [259.688  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -10.736075401306152
desired expected reward: 252.53480529785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  4.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  4.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  4.  0.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[261.43213]
 [245.15932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11. 29.  1.  8.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -10.302530288696289
desired expected reward: 249.3854522705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[236.42558]
 [217.40674]
 [262.6192 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11. 29.  1.  8.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -10.7539644241333
desired expected reward: 253.28121948242188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 11. 29.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  1.  8.] 
cards in discard: [11.  0. 11.  0.  4.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  8.  1.] 
cards in discard: [11.  0. 11.  0.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 1.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 1.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[278.25433]
 [262.2074 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 11.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11  1] -> size -> 27 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -10.075690269470215
desired expected reward: 252.54348754882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.13637]
 [262.35825]
 [260.18707]
 [233.37347]
 [271.4187 ]
 [261.16525]
 [259.33118]
 [277.45175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 11.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11  1] -> size -> 27 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -11.162321090698242
desired expected reward: 269.29058837890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 11.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  3 16 29  3  4  8  0  1  0 11 11
  0 11  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.53152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3. 16.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -10.472917556762695
desired expected reward: 242.44569396972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[234.26683]
 [219.06618]
 [254.17476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3. 16.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -11.110819816589355
desired expected reward: 247.6897430419922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3. 16.  0.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3. 16.  0.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  0.  4.  0.  1. 29. 11.  3.  1.  8.  1. 23.  3. 16.  0.  3.
  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[235.44627]
 [229.80165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -11.060905456542969
desired expected reward: 243.11383056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.74077]
 [222.22838]
 [207.46077]
 [224.82504]
 [230.81204]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -10.445533752441406
desired expected reward: 226.71652221679688



buy possibilites: [-1] 
expected returns: [[217.42891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -384.0 

action type: buy - action 6.0
Learning step: -24.68088722229004
desired expected reward: 182.77987670898438






Player: 1 
cards in hand: [1. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[235.05785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11 14] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -9.796774864196777
desired expected reward: 207.63214111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[217.6765 ]
 [200.373  ]
 [239.89973]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11 14] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -10.792808532714844
desired expected reward: 223.63699340820312



buy possibilites: [-1] 
expected returns: [[260.4711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11 14] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -114.0 

action type: buy - action 0.0
Learning step: -10.723223686218262
desired expected reward: 206.9532470703125






Player: 1 
cards in hand: [ 8.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 29.] 
cards in discard: [14.  1.  3.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0
 11  1 23  3 11 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [14.  1.  3.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [14.  1.  3.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[250.8456 ]
 [233.44432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -11.200959205627441
desired expected reward: 249.2701416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[222.98651]
 [231.59543]
 [203.78754]
 [232.47202]
 [249.92007]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  8. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -10.888514518737793
desired expected reward: 239.6549072265625



buy possibilites: [-1] 
expected returns: [[234.52153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -66 

action type: buy - action 8.0
Learning step: -9.646867752075195
desired expected reward: 222.82516479492188






Player: 1 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 8.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 8.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 8.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[186.17125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  4. 23.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -11.370575904846191
desired expected reward: 223.1509552001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[162.72076]
 [170.42216]
 [146.19772]
 [171.16135]
 [186.0188 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  4. 23.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -8.771437644958496
desired expected reward: 171.47303771972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11.  0.  4. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  4. 23.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  4. 23.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.06448]
 [203.42747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 16.  0.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -8.266217231750488
desired expected reward: 177.75259399414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[190.58534]
 [171.92677]
 [211.75899]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 16.  0.] 
adversary cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -9.901348114013672
desired expected reward: 204.10073852539062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 16.  0.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11
  1 23  3 11 14  0 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [6. 0. 8. 6. 3.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [6. 0. 8. 6. 3.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 26. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [6. 0. 8. 6. 3.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  1.  3.  1.  0.  0.  0.  8.  0.  0. 29. 14.  0.  0.  1.  3.  3. 11.
 11.  0.  4. 23. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [6. 0. 8. 6. 3.] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[143.28847]
 [131.6653 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [6. 0. 8. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3] -> size -> 32 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -11.20476245880127
desired expected reward: 200.55421447753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.22299 ]
 [123.85874 ]
 [105.86462 ]
 [124.825615]
 [135.25702 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [6. 0. 8. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3] -> size -> 32 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -7.213877201080322
desired expected reward: 120.3603744506836



buy possibilites: [-1] 
expected returns: [[138.76576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [6. 0. 8. 6. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 25. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3] -> size -> 32 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -104.0 

action type: buy - action 0.0
Learning step: -7.98892068862915
desired expected reward: 110.23408508300781






Player: 1 
cards in hand: [ 0.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[193.41412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3. 14. 16.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -6.904534816741943
desired expected reward: 131.86122131347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.85248]
 [181.11632]
 [177.89003]
 [155.7516 ]
 [188.11917]
 [180.15965]
 [177.1278 ]
 [192.6659 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 6 3 0 0 6 0 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  5.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3. 14. 16.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -9.463953018188477
desired expected reward: 178.70285034179688



buy possibilites: [-1] 
expected returns: [[146.18127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3. 14. 16.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -66 

action type: buy - action 11.0
Learning step: -9.416878700256348
desired expected reward: 178.70225524902344






Player: 1 
cards in hand: [ 0. 14.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 14. 16.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 6.] 
adversary cards in discard: [11.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 16.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 16.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 16.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[166.13126]
 [154.4827 ]
 [154.4827 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: discard_down_to_3_cards - action 7
Learning step: -6.6518707275390625
desired expected reward: 103.362548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.24559]
 [131.30588]
 [163.8562 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -9.348791122436523
desired expected reward: 152.9038543701172



buy possibilites: [-1] 
expected returns: [[118.37603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [11.  0.  6.  0.  3.  0.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -124.0 

action type: buy - action 0.0
Learning step: -10.798818588256836
desired expected reward: 134.44676208496094






Player: 1 
cards in hand: [ 0.  3. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29.  0.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0] -> size -> 14 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29.  0.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0] -> size -> 14 
adversary victory points: 1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[176.72116]
 [162.33727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -6.884246826171875
desired expected reward: 111.49178314208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[151.94646]
 [159.47432]
 [158.04645]
 [138.64246]
 [167.21735]
 [158.4904 ]
 [157.32947]
 [172.72789]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -9.514274597167969
desired expected reward: 160.64425659179688



buy possibilites: [-1] 
expected returns: [[156.34087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  8. 10. 10.] 
adversary cards in hand: [23.  0.  1.  3.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -76 

action type: buy - action 10.0
Learning step: -8.148802757263184
desired expected reward: 149.18063354492188






Player: 1 
cards in hand: [23.  0.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.  3.  1.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  8. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 3.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  8. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 3.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3] -> size -> 35 
action values: 0 
buys: 2 
player value: 6 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  8. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 10 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 3.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  4.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  8. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 3.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  8. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[76.727196]
 [67.10814 ]
 [73.245605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 11.  3.  3.] 
cards in discard: [10.  0.  0.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 4. 10.  8.  0.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 37 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -10.86530590057373
desired expected reward: 145.47555541992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.23097 ]
 [50.779728]
 [76.1055  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11.  3.  3.] 
cards in discard: [10.  0.  0.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 4. 10.  8.  0.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 37 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -6.960171699523926
desired expected reward: 68.98743438720703



buy possibilites: [-1] 
expected returns: [[90.35157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 11.  3.  3.] 
cards in discard: [10.  0.  0.  8.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 4. 10.  8.  0.  1.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 37 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -124 

action type: buy - action 0.0
Learning step: -7.2286376953125
desired expected reward: 54.002323150634766






Player: 1 
cards in hand: [ 4. 10.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  8.  0.  1.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1
 23  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  0.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  0.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[121.318054]
 [114.63051 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.  8.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -6.524787902832031
desired expected reward: 83.8267822265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[103.13783 ]
 [108.246475]
 [106.803024]
 [ 94.28533 ]
 [112.28127 ]
 [107.69889 ]
 [106.39383 ]
 [114.251884]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  3.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.  8.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -7.870876312255859
desired expected reward: 104.96925354003906



buy possibilites: [-1] 
expected returns: [[89.06886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.  8.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -76 

action type: buy - action 11.0
Learning step: -7.410014629364014
desired expected reward: 104.87126922607422






Player: 1 
cards in hand: [ 0.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.  8.  4. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [ 3.  0. 11.  0.  3.  0. 11.  3. 14.  0.  3. 14. 16.  0.  3. 11. 29.  0.
 10. 11. 23.  0.  1.  3.  1.  3.  8.  4. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.34297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -7.570725917816162
desired expected reward: 81.49813842773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.67309 ]
 [65.4278  ]
 [64.84791 ]
 [53.464924]
 [70.417786]
 [64.70533 ]
 [64.32776 ]
 [74.07776 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 23. 29.  8.  8.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -6.67242431640625
desired expected reward: 63.67054748535156



buy possibilites: [-1] 
expected returns: [[36.719227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [11.  8.  0.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 23. 29.  8.  7.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -405.0 

action type: buy - action 6.0
Learning step: -22.097064971923828
desired expected reward: 31.367855072021484






Player: 1 
cards in hand: [8. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  7.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 23. 29.  8.  7.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 22. 29.  8.  7.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10. 11.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6] -> size -> 18 
adversary victory points: 0
player victory points: 11 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[93.16493]
 [78.97531]
 [77.64958]
 [87.98534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10. 11.] 
cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  7.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0. 11.] 
adversary cards in discard: [3. 8. 3. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -5.603752136230469
desired expected reward: 31.115474700927734



action possibilites: [-1] 
expected returns: [[73.028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.] 
cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0. 11.] 
adversary cards in discard: [3. 8. 3. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -406 

action type: gain_card_n - action 3
Learning step: -22.588333129882812
desired expected reward: 56.04095458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.43176 ]
 [51.959137]
 [73.66904 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.] 
cards in discard: [11.  8.  0.  0.  0.  6.  6.  0.  0.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0. 11.] 
adversary cards in discard: [3. 8. 3. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1
Learning step: -7.441764831542969
desired expected reward: 65.58623504638672






Player: 1 
cards in hand: [14.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  9.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 11 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[78.56183]
 [77.48891]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.] 
cards in discard: [0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  7. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -126 

action type: discard_down_to_3_cards - action 1
Learning step: -8.259312629699707
desired expected reward: 65.6568374633789



action possibilites: [-1] 
expected returns: [[37.985764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [0. 3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  6. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -102 

action type: gain_card_n - action 6
Learning step: -7.295081615447998
desired expected reward: 53.70014190673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.92689 ]
 [23.598475]
 [38.06159 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0. 3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  6.  9.  2.  6. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1
Learning step: -6.441368103027344
desired expected reward: 31.544395446777344



buy possibilites: [-1] 
expected returns: [[6.544622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0. 3. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  5.  9.  2.  6. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -417 

action type: buy - action 6.0
Learning step: -21.88266944885254
desired expected reward: 1.7157936096191406






Player: 1 
cards in hand: [ 0.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  5.  9.  2.  6. 10.  8.  8.  9.  7. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  3.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  5.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  3.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 22. 29.  8.  5.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  3.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 21. 29.  8.  5.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  3.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 12 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[55.356285]
 [51.475887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  3.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  5.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [23. 14.  3.  4.  3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: buy - action -1
Learning step: -6.457076549530029
desired expected reward: 0.08754539489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.92417 ]
 [41.546925]
 [51.025097]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  3.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 21. 29.  8.  5.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [23. 14.  3.  4.  3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: take_action - action -1.0
Learning step: -8.687067985534668
desired expected reward: 39.745079040527344



buy possibilites: [-1] 
expected returns: [[37.52993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  3.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [23. 14.  3.  4.  3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -150.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -458.0 

action type: buy - action 6.0
Learning step: -24.132925033569336
desired expected reward: 17.413999557495117






Player: 1 
cards in hand: [23. 14.  3.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  3.  4.  3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  4.  3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  4.  3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 21. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  4.  3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 13 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.201933]
 [22.169455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
adversary victory points: 13
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -168 

action type: discard_down_to_3_cards - action 1
Learning step: -8.018392562866211
desired expected reward: -5.02536153793335





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.129215]
 [11.250687]
 [24.224897]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
adversary victory points: 13
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -168 

action type: take_action - action -1.0
Learning step: -9.156844139099121
desired expected reward: 15.045084953308105



buy possibilites: [-1] 
expected returns: [[-4.5994663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.] 
cards in discard: [ 0.  3.  8.  6. 11.  6.  6.  6. 10.  3.  6.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
adversary victory points: 13
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -160.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -198.0 

action type: buy - action 0.0
Learning step: -10.809948921203613
desired expected reward: 5.3192644119262695






Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 20. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[20.411436]
 [14.064169]
 [14.064169]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1
Learning step: -8.266082763671875
desired expected reward: -12.865549087524414



action possibilites: [-1] 
expected returns: [[-1.5453801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -158 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.59047794342041
desired expected reward: 4.523653984069824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-4.238681 ]
 [-3.4187212]
 [-3.1710448]
 [-3.683368 ]
 [-2.1112514]
 [-3.5364695]
 [-3.2346263]
 [-1.0292541]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -158 

action type: take_action - action -1
Learning step: -7.872342586517334
desired expected reward: -9.417722702026367






Player: 1 
cards in hand: [ 3. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3. 10.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 16.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14 10  3  3  0  3 10 11  3 29 29  3  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 19. 29.  8.  4.  9.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.29395 ]
 [18.602533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0] -> size -> 43 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1.0
Learning step: -8.402978897094727
desired expected reward: -9.432232856750488





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.68845  ]
 [13.94355  ]
 [ 6.5860887]
 [14.4988365]
 [19.317757 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0] -> size -> 43 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -9.559927940368652
desired expected reward: 10.734023094177246



buy possibilites: [-1] 
expected returns: [[31.91136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11.  1.  0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0] -> size -> 43 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -208.0 

action type: buy - action 0.0
Learning step: -10.266417503356934
desired expected reward: 1.4220380783081055






Player: 1 
cards in hand: [11. 11. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  1.  0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 19. 29.  8.  4.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 19. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1.  0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 19. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1.  0.] 
cards in discard: [ 3.  8.  3.  3.  1.  0. 29. 14.  0.  3.  0. 11. 29.  3. 11.  0.  0.  1.
  0.  3. 14. 23.  3.  4.  3.  3.  0.  0.  0.  0. 10. 16.  0. 29. 16.  3.
  0.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[13.553188]
 [10.767044]
 [10.834139]
 [12.550928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  6.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1
Learning step: -10.21188735961914
desired expected reward: 21.699472427368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.773766]
 [ 9.57435 ]
 [14.601709]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  6.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -9.287705421447754
desired expected reward: 4.265469551086426



buy possibilites: [-1] 
expected returns: [[62.140034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  6.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -208.0 

action type: buy - action 0.0
Learning step: -9.278426170349121
desired expected reward: 1.4953298568725586






Player: 1 
cards in hand: [0. 3. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  7. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.347279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [14.  0.  1.  0.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1
Learning step: -11.616687774658203
desired expected reward: 50.523345947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.890754 ]
 [ 2.7317548]
 [15.56093  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [14.  0.  1.  0.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -9.506564140319824
desired expected reward: 7.840714454650879



buy possibilites: [-1] 
expected returns: [[25.068968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  3. 11.  0.  0.  0.  8. 10. 11.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [14.  0.  1.  0.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -208.0 

action type: buy - action 0.0
Learning step: -10.230486869812012
desired expected reward: -2.3397269248962402






Player: 1 
cards in hand: [14.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.  0.  0.] 
cards in discard: [10.  0.  3.  0.  0.  4.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  4.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  4.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.445988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [14.  1.  3.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23] -> size -> 47 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: discard_down_to_3_cards - action 3
Learning step: -10.971092224121094
desired expected reward: 56.751434326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.504963]
 [38.017925]
 [58.322147]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [14.  1.  3.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23] -> size -> 47 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -10.65437126159668
desired expected reward: 47.79161834716797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  1.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  0. 29.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.  0. 29.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.  0. 29.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[12.319445]
 [ 9.353645]
 [ 4.24436 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1.0
Learning step: -11.587027549743652
desired expected reward: 46.7351188659668



action possibilites: [-1. 11.] 
expected returns: [[-4.492815]
 [-5.194721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -157 

action type: take_action - action 10.0
Learning step: -8.16789436340332
desired expected reward: -3.923536777496338





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.4871674]
 [-5.95898  ]
 [-5.244675 ]
 [-4.7646327]
 [-5.226959 ]
 [-5.913953 ]
 [-5.1536827]
 [-4.429353 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 18. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -158 

action type: take_action - action -1.0
Learning step: -7.786040782928467
desired expected reward: -12.278857231140137



buy possibilites: [-1] 
expected returns: [[13.188431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -160.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -145.0 

action type: buy - action 3.0
Learning step: -6.691026210784912
desired expected reward: -11.935701370239258






Player: 1 
cards in hand: [29.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 11.  0.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 


action possibilites: [-1. 11. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 23.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 23.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 23.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 23.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-4.2670975]
 [-4.573436 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1] -> size -> 50 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: buy - action -1
Learning step: -9.107433319091797
desired expected reward: 4.080997467041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-4.569415 ]
 [-4.331586 ]
 [-4.309492 ]
 [-4.9623556]
 [-4.399638 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3. 11.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1] -> size -> 50 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: take_action - action -1.0
Learning step: -8.236289024353027
desired expected reward: -12.503385543823242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3. 11.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
adversary victory points: -2
player victory points: 14 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[64.587685]
 [58.683826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [10.  1.  6. 29. 11.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: buy - action -1.0
Learning step: -6.7153825759887695
desired expected reward: -11.115022659301758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.261246]
 [60.952213]
 [60.239807]
 [51.150265]
 [58.642105]
 [64.34377 ]
 [60.44663 ]
 [61.51221 ]
 [54.658867]
 [59.86744 ]
 [58.90775 ]
 [66.6051  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [10.  1.  6. 29. 11.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: take_action - action -1.0
Learning step: -10.173007011413574
desired expected reward: 54.414676666259766



buy possibilites: [-1] 
expected returns: [[93.97785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  6.  6.  3. 10. 11.  0.  6.  0.  0.  3. 11.  0.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [10.  1.  6. 29. 11.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5.     0.    -2.  -160.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -162.5 

action type: buy - action 1.0
Learning step: -9.05810832977295
desired expected reward: 51.89409255981445






Player: 1 
cards in hand: [10.  1.  6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  6. 29. 11.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
adversary victory points: -2
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  6. 29. 11.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
adversary victory points: -2
player victory points: 14 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[6.6602283]
 [5.220336 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: buy - action -1
Learning step: -12.908449172973633
desired expected reward: 81.06940460205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.09180999]
 [-1.0556724 ]
 [ 1.886558  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: take_action - action -1.0
Learning step: -8.415095329284668
desired expected reward: -6.67703914642334



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [6. 0. 6. 6. 8.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
adversary victory points: -2
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [6. 0. 6. 6. 8.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
adversary victory points: -2
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [11.  3.  6.  3.  0.] 
adversary cards in discard: [6. 0. 6. 6. 8.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
adversary victory points: -2
player victory points: 14 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11.  3.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-4.298375 ]
 [-4.9992237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [6. 0. 6. 6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3. 16.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0  0] -> size -> 52 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: buy - action -1.0
Learning step: -8.545622825622559
desired expected reward: -6.65906286239624





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.0750475]
 [-4.296424 ]
 [-4.3188276]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [6. 0. 6. 6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 30. 17. 29.  8.  3.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3. 16.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0  0] -> size -> 52 
adversary victory points: 14
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -167 

action type: take_action - action -1.0
Learning step: -8.235241889953613
desired expected reward: -12.533617973327637



buy possibilites: [-1] 
expected returns: [[-10.238555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  3.  0.] 
cards in discard: [6. 0. 6. 6. 8. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 23. 30. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 16.  3. 16.] 
adversary cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0  0] -> size -> 52 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -170.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -478.0 

action type: buy - action 6.0
Learning step: -23.91554832458496
desired expected reward: -28.211971282958984






Player: 1 
cards in hand: [ 3.  8. 16.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16.  3. 16.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 16 29  3  4  8  0  1  0 11 11  0 11  1 23
  3 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0
  1  1  0  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.  2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [10.  0.  3.  0.  0.  4. 23. 14.  0.  1.  0.  0.  0. 14.  1.  3.  0. 29.
  1.  1. 29. 11.  0. 11.  0. 23.  0. 11.  3.  0.  3. 11. 10.  1.  6. 29.
 11.  0.  3.  3.  3.  3.  3.  2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[6.6055446]
 [4.21464  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1
Learning step: -8.255074501037598
desired expected reward: -18.493629455566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[3.6903157]
 [4.7403383]
 [0.8977566]
 [5.2335453]
 [7.0505786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -9.107300758361816
desired expected reward: -2.5017523765563965



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  6. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  6.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[28.67778 ]
 [27.208801]
 [24.162048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  6.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 11.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8] -> size -> 53 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: buy - action -1.0
Learning step: -8.633357048034668
desired expected reward: -1.5827765464782715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.404947]
 [22.842575]
 [14.589886]
 [23.273903]
 [28.410652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  6.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 11.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8] -> size -> 53 
adversary victory points: 14
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -9.779698371887207
desired expected reward: 18.898090362548828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 29. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 11.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  2.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 14 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3. 6.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  1.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3. 6.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  1.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
adversary victory points: -3
player victory points: 13 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.5601575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  1.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  1.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
adversary victory points: 13
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -168 

action type: buy - action -1.0
Learning step: -9.87813663482666
desired expected reward: 18.532520294189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-4.018994 ]
 [-5.0627556]
 [-4.3144226]
 [-2.6731343]
 [-2.1201158]
 [-4.393754 ]
 [-4.9861965]
 [-4.913836 ]
 [-5.9353676]
 [-4.707194 ]
 [-2.7470155]
 [-3.176696 ]
 [-4.139702 ]
 [-2.3052416]
 [-3.676094 ]
 [-4.5060234]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 23. 29. 17. 29.  8.  1.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  1.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
adversary victory points: 13
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -168 

action type: take_action - action -1.0
Learning step: -8.34400463104248
desired expected reward: -10.904162406921387



buy possibilites: [-1] 
expected returns: [[31.896973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [ 6.  0.  6.  6.  8.  6. 11.  3.  6.  3.  0.  0.  0. 10.  6.  3.  0. 11.
  0.  8.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [11. 23. 29. 17. 29.  8.  0.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  1.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -170.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -479.0 

action type: buy - action 6.0
Learning step: -23.126312255859375
desired expected reward: -25.246429443359375






Player: 1 
cards in hand: [ 0. 29. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  1.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 17. 29.  8.  0.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 29. 17. 29.  8.  0.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 22. 29. 17. 29.  8.  0.  8.  2.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.3136344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -10.619405746459961
desired expected reward: 21.27756690979004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-2.6660728]
 [-2.7630959]
 [-3.1601272]
 [-2.6666944]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: take_action - action -1.0
Learning step: -8.84623908996582
desired expected reward: -12.159873962402344



buy possibilites: [-1] 
expected returns: [[8.084824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -209.0 

action type: buy - action 0.0
Learning step: -10.134787559509277
desired expected reward: -12.800859451293945






Player: 1 
cards in hand: [ 0.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  5. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11  8] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-4.90768 ]
 [-5.417471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.  0.] 
cards in discard: [0. 6. 6. 6. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [1. 4. 8. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11  8] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -9.467996597290039
desired expected reward: -1.3831729888916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-3.3287725]
 [-3.7458699]
 [-3.9532804]
 [-4.5166683]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 11.  0.] 
cards in discard: [0. 6. 6. 6. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [1. 4. 8. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11  8] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: take_action - action -1.0
Learning step: -8.786799430847168
desired expected reward: -13.694480895996094



buy possibilites: [-1] 
expected returns: [[-2.4493513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 11.  0.] 
cards in discard: [0. 6. 6. 6. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [1. 4. 8. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11  8] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -209.0 

action type: buy - action 0.0
Learning step: -10.22805118560791
desired expected reward: -15.769241333007812






Player: 1 
cards in hand: [1. 4. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 8. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3
 11 14  0 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1
  1  0  0  2  8  6  1 11  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.334627]
 [27.639477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [10.  3. 29. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0] -> size -> 55 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -8.178583145141602
desired expected reward: -10.627934455871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.879932]
 [24.589132]
 [23.939894]
 [22.706509]
 [27.028248]
 [24.260645]
 [25.014809]
 [20.181393]
 [23.709915]
 [22.948341]
 [28.597406]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  8.  8.  6. 10. 10.] 
adversary cards in hand: [10.  3. 29. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0] -> size -> 55 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: take_action - action -1.0
Learning step: -9.832368850708008
desired expected reward: 19.502260208129883



buy possibilites: [-1] 
expected returns: [[30.432716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [10.  3. 29. 11.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0] -> size -> 55 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -147 

action type: buy - action 14.0
Learning step: -7.674333095550537
desired expected reward: 12.507055282592773






Player: 1 
cards in hand: [10.  3. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 11.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  8.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  7.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16] -> size -> 56 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 22. 29. 17. 29.  8.  0.  7.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-10.274087]
 [-12.110692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  2.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -10.714807510375977
desired expected reward: 19.71790885925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-8.687075 ]
 [-8.811531 ]
 [-8.5521555]
 [-7.701391 ]
 [-8.721947 ]
 [-8.422843 ]
 [-6.859133 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  4. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  2.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: take_action - action -1.0
Learning step: -8.608818054199219
desired expected reward: -18.88290786743164



buy possibilites: [-1] 
expected returns: [[13.479823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  3. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  2.  0. 11.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -170.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -177.0 

action type: buy - action 8.0
Learning step: -8.110607147216797
desired expected reward: -16.832548141479492






Player: 1 
cards in hand: [ 1. 10.  2.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  2.  0. 11.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  3. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2.  0. 11.  3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0] -> size -> 57 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  3. 10.  7.  7.  8.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10] -> size -> 58 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  7.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[1.7280781]
 [3.7290614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -9.553166389465332
desired expected reward: 3.926656723022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[4.3622837]
 [3.790796 ]
 [4.2851105]
 [2.4779365]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: take_action - action -1.0
Learning step: -8.94653034210205
desired expected reward: -7.218454360961914



buy possibilites: [-1] 
expected returns: [[-9.31237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [ 0.  6.  6.  6.  0.  0.  0.  6.  0.  6. 11.  0. 14.  1.  6.  0.  0. 11.
  8.  8.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -170.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -209.0 

action type: buy - action 0.0
Learning step: -10.877642631530762
desired expected reward: -6.515358924865723






Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8  0] -> size -> 34 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  3. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8  0] -> size -> 34 
adversary victory points: -4
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8  0] -> size -> 34 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-0.91673493]
 [-1.9701322 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0
  0  3  1  6  6  0  0 14  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  0.  3. 16.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -8.511893272399902
desired expected reward: -17.824264526367188



action possibilites: [-1] 
expected returns: [[-14.747256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  0.  3. 16.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: trash_cards_n_from_hand - action 9
Learning step: -8.189813613891602
desired expected reward: -10.029815673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.944589]
 [-15.259545]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  0.  3. 16.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: take_action - action -1
Learning step: -7.5509490966796875
desired expected reward: -22.298206329345703



buy possibilites: [-1] 
expected returns: [[2.2093904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  0.  3. 16.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -189 

action type: buy - action 0.0
Learning step: -8.653059005737305
desired expected reward: -23.59764862060547






Player: 1 
cards in hand: [ 3. 23.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.  3. 16.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 13 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 16.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 16.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8] -> size -> 60 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 5. 22. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 13 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 16.  0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 6.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 13 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-9.017114]
 [-8.977838]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 6.] 
cards in discard: [0. 8. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1
  6  6  0  0 14  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.  1. 23.  3.  0.  3.
 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -179 

action type: buy - action -1
Learning step: -9.262728691101074
desired expected reward: -7.053338050842285



action possibilites: [-1] 
expected returns: [[3.9353104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [0. 8. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.  1. 23.  3.  0.  3.
 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -170 

action type: trash_cards_n_from_hand - action 6
Learning step: -8.095056533813477
desired expected reward: -14.4230375289917





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.1767633]
 [ 3.3925128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [0. 8. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 23.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.  1. 23.  3.  0.  3.
 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -170 

action type: take_action - action -1
Learning step: -8.656834602355957
desired expected reward: -4.721524238586426






Player: 1 
cards in hand: [ 1. 14.  3.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  3. 23.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  6. 11.  3. 29. 11.  3.  1. 11. 11.  0. 29.  1.
  0.  8.  0.  6.  0.  0. 14.  0.  8.  4. 16.  0. 11. 10.  3. 29.  3. 10.
 16. 10. 11.  1.  2.  0.  3.  8.  3.  0.  1.  0.  3.  1. 23.  3.  0.  3.
 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [0. 8. 3. 8. 0. 6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
adversary victory points: -5
player victory points: 13 


action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [0. 8. 3. 8. 0. 6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
adversary victory points: -5
player victory points: 13 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [0. 8. 3. 8. 0. 6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
adversary victory points: -5
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [0. 8. 3. 8. 0. 6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
adversary victory points: -5
player victory points: 13 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.354527]
 [20.31343 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [0. 8. 3. 8. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [16.  3. 10.  6.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -190 

action type: buy - action -1.0
Learning step: -9.1799898147583
desired expected reward: -5.787473201751709





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[15.490564]
 [18.022043]
 [17.665838]
 [20.781954]
 [17.631004]
 [17.400845]
 [22.794785]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [0. 8. 3. 8. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  1.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [16.  3. 10.  6.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -190 

action type: take_action - action -1.0
Learning step: -10.160449028015137
desired expected reward: 12.194077491760254



buy possibilites: [-1] 
expected returns: [[22.09018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [16.  3. 10.  6.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
adversary victory points: 13
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -180    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -172 

action type: buy - action 11.0
Learning step: -9.142068862915039
desired expected reward: 11.639875411987305






Player: 1 
cards in hand: [16.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 10.  6.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  6  3 10 23  0  1  1  0  0
  2  8  6  1 11  8  0 16  0 10 16  8  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  2. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8.] 
cards in deck: 49 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8.] 
cards in deck: 49 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 14 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-1.1491133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
adversary victory points: 14
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -190    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -200 

action type: buy - action -1
Learning step: -11.130364418029785
desired expected reward: 10.95981502532959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.18393612]
 [ 0.34999442]
 [ 0.27229   ]
 [-0.05768514]
 [ 0.21448398]
 [ 0.37665892]
 [ 0.7113843 ]
 [ 0.46174645]
 [ 0.06532907]
 [ 0.12162519]
 [ 0.31283283]
 [-0.11590219]
 [ 0.30555224]
 [ 0.64811516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
adversary victory points: 14
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -190    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -200 

action type: take_action - action -1.0
Learning step: -9.932242393493652
desired expected reward: -11.081356048583984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 14 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 21. 29. 17. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 14 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 15 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [14.  8.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
expected returns: [[-10.731062 ]
 [ -7.9718456]
 [-10.497339 ]
 [ -9.651468 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  6. 10.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [23.  8.  0. 16.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8  3] -> size -> 62 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: buy - action -1.0
Learning step: -10.73453140258789
desired expected reward: -10.086421012878418



action possibilites: [-1. 14.  8. 11.] 
expected returns: [[-9.641653 ]
 [-7.3004146]
 [-9.632828 ]
 [-9.957243 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  6. 11.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [23.  8.  0. 16.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8  3] -> size -> 62 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -190 

action type: take_action - action 10.0
Learning step: -9.205641746520996
desired expected reward: -18.85710906982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.398674]
 [-9.358889]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  6. 11.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [23.  8.  0. 16.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8  3] -> size -> 62 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -190 

action type: take_action - action -1.0
Learning step: -9.213164329528809
desired expected reward: -18.854816436767578






Player: 1 
cards in hand: [23.  8.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0. 16.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1 23  3 11 14  0
 14  3  3  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2
  8  6  1 11  8  0 16  0 10 16  8  1  8  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [1. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 15 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [1. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 15 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3] -> size -> 59 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [1. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 15 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [1. 6. 6. 6. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
adversary victory points: -5
player victory points: 15 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [1. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-6.3355885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0.  1.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: buy - action -1.0
Learning step: -10.174606323242188
desired expected reward: -19.533485412597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-5.6205606]
 [-6.8152776]
 [-6.203317 ]
 [-6.605035 ]
 [-6.0134053]
 [-6.8748693]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0.  1.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: take_action - action -1.0
Learning step: -10.319289207458496
desired expected reward: -16.654876708984375



buy possibilites: [-1] 
expected returns: [[0.34730387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  6. 11.  0.  6. 11.  0.  0.  0.  0.  0.  0.  0. 10.
 14.  8.  3.  6. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0.  1.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -200.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -240.0 

action type: buy - action 0.0
Learning step: -11.71115779876709
desired expected reward: -17.33171844482422






Player: 1 
cards in hand: [ 0. 14.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  0.  1.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
adversary victory points: -5
player victory points: 15 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0.  1.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0] -> size -> 60 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
adversary victory points: -5
player victory points: 15 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0.  1.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0 22] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5.  9. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
adversary victory points: -5
player victory points: 15 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.493629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5.  9. 10.] 
adversary cards in hand: [ 3. 29. 16.  1.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0 22] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: buy - action -1
Learning step: -10.685972213745117
desired expected reward: -10.338668823242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-7.04354  ]
 [-8.1570015]
 [-7.372525 ]
 [-8.019066 ]
 [-7.217004 ]
 [-7.493629 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  5.  9. 10.] 
adversary cards in hand: [ 3. 29. 16.  1.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0 22] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: take_action - action -1.0
Learning step: -10.290425300598145
desired expected reward: -17.784053802490234



buy possibilites: [-1] 
expected returns: [[-7.946685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  4.  9. 10.] 
adversary cards in hand: [ 3. 29. 16.  1.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0 22] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -192 

action type: buy - action 10.0
Learning step: -9.404151916503906
desired expected reward: -16.897117614746094






Player: 1 
cards in hand: [ 3. 29. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 16.  1.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  1  0 11 11  0 11  1  3 11 14  0 14  3  3
  0  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1
 11  8  0 16  0 10 16  8  1  8  3  0 22] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  4.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 14.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
adversary victory points: -5
player victory points: 15 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 14.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
adversary victory points: -5
player victory points: 15 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 14.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
adversary victory points: -5
player victory points: 15 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
expected returns: [[-7.946684 ]
 [-8.317784 ]
 [-7.4929667]
 [-5.736247 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 14.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [ 0. 11.  0. 11.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -210 

action type: buy - action -1
Learning step: -10.253131866455078
desired expected reward: -18.199817657470703



action possibilites: [-1.  8. 14.] 
expected returns: [[-3.365759 ]
 [-3.6071012]
 [-3.1167507]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  0.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [ 0. 11.  0. 11.  0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -189 

action type: take_action - action 10.0
Learning step: -9.148699760437012
desired expected reward: -16.641666412353516



action possibilites: [-1.  8.] 
expected returns: [[ 0.16975331]
 [-0.6387627 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3  0  6  0  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6
  0  0 14  8  0  0 11  0 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -170 

action type: take_action - action 14.0
Learning step: -8.345627784729004
desired expected reward: -11.462379455566406



action possibilites: [-1] 
expected returns: [[-26.270864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 3  6  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6  0  0
 14  8  0  0 11  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.059647560119629
desired expected reward: -8.688590049743652





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-24.898682]
 [-26.359795]
 [-25.529459]
 [-26.138807]
 [-25.30254 ]
 [-26.428778]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 3  6  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6  0  0
 14  8  0  0 11  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  1. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -200    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: take_action - action -1
Learning step: -6.758150577545166
desired expected reward: -33.029014587402344



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 3 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0.] 
cards in discard: [10.  0.  6.  0.  0.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 3  6  8  0 11  0 10  0 11  6  6  8  6  6  0  0  0  0  3  1  6  6  0  0
 14  8  0  0 11  0 10  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 21. 29. 16. 29.  8.  0.  6.  0.  0. 10.  7.  7.  8.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [23. 10.  1. 14.  3.  3.  3.  8. 16.  3. 10.  0.  3.  0.  3.  0.  3. 11.
  0.  8. 16. 22.  0. 14.  1.  0.  1. 10. 16.  3. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 29  3  4  8  0  0 11 11  0 11  1  3 11 14  0 14  3  3  0
  3 10 11  3 29 29  3  3  3 16  0  3 10 23  0  1  1  0  0  2  8  6  1 11
  8  0 16  0 10 16  8  1  8  3  0 22 10] -> size -> 61 
adversary victory points: 15
player victory points: -5 

Reward from previous game state: 
[  -5 -500   -5 -200    0    0   60    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -646 

action type: buy - action 8.0
Learning step: -30.993061065673828
desired expected reward: -57.131866455078125



