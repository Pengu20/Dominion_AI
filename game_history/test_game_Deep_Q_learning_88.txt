 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.485855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0    -230       0    -300       0       0] 
sum of rewards: 2999645 

action type: buy - action 6.0
Learning step: 119987.265625
desired expected reward: 119950.4140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.41966 ]
 [107.45894 ]
 [101.341095]
 [ 74.17791 ]
 [105.72023 ]
 [116.14394 ]
 [109.67633 ]
 [116.44497 ]
 [ 86.55673 ]
 [103.558495]
 [ 98.97122 ]
 [102.69249 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.51181030273438



buy possibilites: [-1] 
expected returns: [[89.26874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 116.44496154785156






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.86618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.26873779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[101.81281 ]
 [108.73483 ]
 [103.6335  ]
 [ 86.95064 ]
 [114.75632 ]
 [110.23103 ]
 [105.129654]
 [100.42569 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.35604858398438



buy possibilites: [-1] 
expected returns: [[109.601746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.75634765625






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 99.52725 ]
 [107.487595]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.60174560546875



action possibilites: [-1.] 
expected returns: [[98.73279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.22303009033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.00601 ]
 [ 97.37907 ]
 [ 92.48938 ]
 [ 64.74486 ]
 [ 95.46547 ]
 [107.55524 ]
 [ 99.61618 ]
 [108.75025 ]
 [ 80.35431 ]
 [ 94.69232 ]
 [ 92.79763 ]
 [ 98.373795]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.7327880859375



buy possibilites: [-1] 
expected returns: [[113.967285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 108.750244140625






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[118.68718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.96728515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.49716 ]
 [125.137695]
 [119.42259 ]
 [ 94.9829  ]
 [123.72594 ]
 [132.23213 ]
 [127.04816 ]
 [132.55618 ]
 [106.28937 ]
 [121.33307 ]
 [116.77136 ]
 [120.14688 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.66835021972656



buy possibilites: [-1] 
expected returns: [[110.8863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 132.5561981201172






Player: 1 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[108.201035]
 [120.6238  ]
 [119.679565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.88629913330078



action possibilites: [-1. 11.] 
expected returns: [[111.65028 ]
 [126.105194]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.49215698242188



action possibilites: [-1] 
expected returns: [[114.750534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.28347778320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.073135]
 [119.71448 ]
 [115.515396]
 [ 87.94036 ]
 [ 84.628235]
 [118.0061  ]
 [127.16136 ]
 [121.67394 ]
 [140.44011 ]
 [128.15341 ]
 [104.95422 ]
 [112.25195 ]
 [117.47294 ]
 [ 99.83475 ]
 [115.6249  ]
 [116.87998 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.75053405761719



buy possibilites: [-1] 
expected returns: [[128.77184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 140.4401092529297






Player: 1 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[74.652725]
 [85.39986 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [10.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.77183532714844



action possibilites: [-1. 29.] 
expected returns: [[109.792755]
 [130.06717 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [10.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.43498992919922



action possibilites: [-1.] 
expected returns: [[135.5549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [10.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.0671844482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[145.3562 ]
 [153.42068]
 [148.22522]
 [128.79971]
 [125.18889]
 [152.39781]
 [158.05685]
 [154.75723]
 [172.45125]
 [157.61028]
 [136.33054]
 [142.08916]
 [149.55606]
 [134.00935]
 [144.28085]
 [138.55669]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [10.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 135.55490112304688



buy possibilites: [-1] 
expected returns: [[122.94812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [10.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 172.45126342773438






Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [10.  0.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [10.  0.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [10.  0.  1.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[132.03027]
 [147.45538]
 [147.72562]
 [161.37018]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10.  8. 10.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.9481201171875



action possibilites: [-1] 
expected returns: [[137.63345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 160.57638549804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[139.06525 ]
 [143.62112 ]
 [124.463394]
 [149.91104 ]
 [142.12407 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 30. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.63345336914062



buy possibilites: [-1] 
expected returns: [[136.75702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  3.  0. 29.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9. 10.  8.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 149.9110565185547






Player: 1 
cards in hand: [ 0.  1. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  3.  0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9. 10.  8.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  3.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  8.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  3.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  8.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  3.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 6.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  7.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  3.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 98.81709]
 [111.47295]
 [126.56503]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  3.] 
cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  7.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.75701904296875



action possibilites: [-1] 
expected returns: [[104.32664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 10.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  7.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.76371765136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.54503 ]
 [112.15598 ]
 [107.88419 ]
 [ 92.322586]
 [119.19707 ]
 [113.43071 ]
 [109.10021 ]
 [107.997406]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 10.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  7.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.3266372680664



buy possibilites: [-1] 
expected returns: [[114.26505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 10.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  3.  0. 29. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  6.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 119.19708251953125






Player: 1 
cards in hand: [ 0.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  6.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  6.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  6.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  5.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[143.98067]
 [154.01047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  5.  9.  8.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  1. 29.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.26505279541016



action possibilites: [-1] 
expected returns: [[146.14192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  5.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  1. 29.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 157.44424438476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[128.82036]
 [146.96614]
 [142.32329]
 [113.31313]
 [157.30629]
 [150.0469 ]
 [145.50426]
 [148.55414]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  5.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  1. 29.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.1419219970703



buy possibilites: [-1] 
expected returns: [[139.766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  1. 29.] 
adversary cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 157.30628967285156






Player: 1 
cards in hand: [ 0.  1.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  1. 29.] 
cards in discard: [ 6.  3. 11. 11.  0.  1.  3.  0.  6. 11. 10.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 29. 30.  8.  8.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [16.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [30. 27. 30. 28. 30.  8.  8.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 11.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25. 29. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 10.] 
expected returns: [[129.98325]
 [158.34236]
 [139.54881]
 [137.41728]
 [122.10934]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11.  0. 10.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  8.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.76600646972656



action possibilites: [-1] 
expected returns: [[141.18335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10.  0. 25.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.59365844726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.19386]
 [134.68732]
 [105.46653]
 [143.07832]
 [141.41197]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0. 25.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  9.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.183349609375



buy possibilites: [-1] 
expected returns: [[140.30388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0. 25.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 143.07830810546875






Player: 1 
cards in hand: [ 6. 11.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10.  1.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  1.  0.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 29.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[151.57536]
 [144.41693]
 [159.75006]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 29.  0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 140.3038787841797



action possibilites: [-1.  8.] 
expected returns: [[167.16203]
 [166.1201 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 159.75003051757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[148.32602]
 [163.67693]
 [158.92169]
 [132.82545]
 [173.02666]
 [165.77164]
 [161.0011 ]
 [168.57025]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  4.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 167.1619873046875



buy possibilites: [-1] 
expected returns: [[203.9581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8. 25. 29. 11.  0. 10.  0. 25. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 173.0266571044922






Player: 1 
cards in hand: [3. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [16.  3. 29. 11.  0.  1.  0.  1.  6. 10.  1. 10. 11.  6.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[126.30653]
 [118.9679 ]
 [133.09387]
 [133.09387]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 203.95809936523438



action possibilites: [-1. 10. 29.] 
expected returns: [[114.63151]
 [113.83206]
 [128.34906]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.28170776367188



action possibilites: [-1. 10.] 
expected returns: [[146.23077]
 [150.90097]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.34906005859375



action possibilites: [-1. 11.] 
expected returns: [[150.70114]
 [162.03603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11] -> size -> 23 
action values: 2 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 150.9010009765625



action possibilites: [-1.] 
expected returns: [[140.30867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 165.74891662597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.32738]
 [141.13747]
 [135.83034]
 [ 84.71727]
 [ 80.86229]
 [138.18156]
 [150.45578]
 [143.16847]
 [163.75871]
 [151.29211]
 [118.59981]
 [132.45576]
 [139.04736]
 [102.13478]
 [138.03958]
 [141.34886]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 140.3086700439453



buy possibilites: [-1] 
expected returns: [[119.41426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 163.75872802734375






Player: 1 
cards in hand: [ 3.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 11.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 26. 30. 28. 30.  8.  7.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 11.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  7.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 11.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[108.250046]
 [138.25598 ]
 [122.16264 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 11.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  7.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  1.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.41426086425781



action possibilites: [-1] 
expected returns: [[109.72282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3. 10.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  1.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 138.25596618652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.19374 ]
 [116.339615]
 [111.62232 ]
 [ 92.46817 ]
 [123.70703 ]
 [118.12416 ]
 [113.39928 ]
 [113.73399 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3. 10.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  3.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  1.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.72281646728516



buy possibilites: [-1] 
expected returns: [[148.91699]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3. 10.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  1.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 123.70701599121094






Player: 1 
cards in hand: [ 0.  0.  1. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  1.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  1. 29.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 26. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 25. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 25. 11.  3.] 
adversary cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[124.83952]
 [139.2879 ]
 [153.19545]
 [138.73361]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 11.  3.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  6.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 10.  6. 11.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.9169921875



action possibilites: [-1] 
expected returns: [[88.63421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.  8.  8.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 10.  6. 11.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.19544982910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.99562 ]
 [58.833527]
 [89.80492 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  3.  8.  8.] 
cards in discard: [10. 25. 29. 29. 10. 11.  3.  0.  0.  0. 11. 25.  0.  0.  0. 11.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 25. 30. 28. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1. 11. 10.  6. 11.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.63420867919922






Player: 1 
cards in hand: [ 1. 11. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  6. 11.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  6. 11.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 28. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  6. 11.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 25.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[ 99.18764 ]
 [ 95.21466 ]
 [118.86343 ]
 [103.270905]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.804931640625



action possibilites: [-1] 
expected returns: [[69.361374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.04574584960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[66.7931  ]
 [73.34866 ]
 [69.41214 ]
 [56.20752 ]
 [79.692184]
 [74.565895]
 [70.62938 ]
 [68.34709 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  2.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.36137390136719



buy possibilites: [-1] 
expected returns: [[97.230194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.  0. 11.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  0.  1.  3.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 79.69221496582031






Player: 1 
cards in hand: [16.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  1.  3.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1  1 10 29  6  3 11  6 11 16  3  6
 10  1  0  6  1  6  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.  1. 10. 29.  0.  0.  1.  1.  6.  6.  3.  1.
 11. 10.  6. 11.  6. 23.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[ 91.29466 ]
 [115.416794]
 [ 90.88501 ]
 [100.46034 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  3. 11.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  4.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.23019409179688



action possibilites: [-1] 
expected returns: [[43.17785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11. 25.  3.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  6.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.41676330566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.645676]
 [22.012346]
 [44.57898 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11. 25.  3.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0.  6.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.17784881591797






Player: 1 
cards in hand: [23.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  0.  0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  0.  0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  0.  0.] 
cards in discard: [6. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[81.21202]
 [89.77803]
 [89.77803]
 [88.25829]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 11.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.578956604003906



action possibilites: [-1. 29. 11.] 
expected returns: [[123.76561]
 [128.99548]
 [127.61752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  3.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.77806091308594



action possibilites: [-1. 11.  8.] 
expected returns: [[108.32825]
 [123.60013]
 [121.61187]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.99549865722656



action possibilites: [-1] 
expected returns: [[135.76784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.43312072753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.19641]
 [144.87898]
 [141.72786]
 [125.78949]
 [144.19382]
 [148.55394]
 [145.321  ]
 [148.86812]
 [133.93582]
 [142.33865]
 [139.55763]
 [138.73497]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  6. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.76783752441406



buy possibilites: [-1] 
expected returns: [[132.70612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  1.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 148.8681182861328






Player: 1 
cards in hand: [ 1. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  0.  1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  1 10 29  6  3 11  6 11 16  3  6 10
  1  0  6  1  6  3  6 23  0  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29. 29.
 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  5. 10.  8.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29. 29.
 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  8.  7.  5. 10.  8.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29. 29.
 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29. 29.
 29. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 10.] 
expected returns: [[133.37654]
 [136.46046]
 [122.38193]
 [133.5644 ]
 [119.31188]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 11. 10.] 
cards in discard: [11. 25. 10.  0.  0. 11.  0. 11. 25.  0. 10.  3. 11. 25.  3. 10. 29. 29.
 29. 11.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  1.  6. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.70611572265625



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[120.477196]
 [118.075226]
 [127.10445 ]
 [114.2861  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  1.  6. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 136.46044921875



action possibilites: [-1] 
expected returns: [[107.4905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [ 6.  0.  1.  6. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 130.46646118164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 77.78962 ]
 [ 89.494995]
 [ 67.40114 ]
 [ 97.24213 ]
 [109.178406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [ 6.  0.  1.  6. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.4905014038086






Player: 1 
cards in hand: [ 6.  0.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  6. 11.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  6. 11.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 27. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  6. 11.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[36.98268 ]
 [44.91413 ]
 [43.124084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  0.  3.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 109.17840576171875



action possibilites: [-1. 11.] 
expected returns: [[ 97.25961]
 [106.47946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  3. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.91412353515625



action possibilites: [-1] 
expected returns: [[150.05545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.48316192626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[136.92975 ]
 [151.03613 ]
 [146.76286 ]
 [118.398735]
 [160.50029 ]
 [152.83232 ]
 [148.48405 ]
 [151.99767 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  1.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.05545043945312



buy possibilites: [-1] 
expected returns: [[145.28809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0. 11.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 160.5002899169922






Player: 1 
cards in hand: [10.  3.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0. 11.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  0. 25. 25. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0. 11.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  0. 25. 25. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  0. 25. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25. 11.] 
expected returns: [[111.14078]
 [112.03818]
 [135.92497]
 [135.92497]
 [121.7357 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 25. 11.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  3.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.2880859375



action possibilites: [-1] 
expected returns: [[124.362015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 11. 11.  0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.92495727539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[113.67351 ]
 [127.38168 ]
 [ 96.779945]
 [131.6882  ]
 [126.48459 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25. 11. 11.  0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  7.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.36201477050781



buy possibilites: [-1] 
expected returns: [[91.52087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25. 11. 11.  0.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  6.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  3.  3.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 131.6881866455078






Player: 1 
cards in hand: [ 3.  6. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  3.  3.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  6.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  6.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  6.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 1.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[168.1047 ]
 [182.52391]
 [168.93282]
 [175.8863 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 10. 11.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  2.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.52086639404297



action possibilites: [-1] 
expected returns: [[115.941795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 29. 29.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 182.52389526367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.11302]
 [113.79196]
 [101.94151]
 [117.44142]
 [118.04338]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11. 29. 29.] 
cards in discard: [10. 29. 11.  0.  8. 10.  3. 10. 11. 29. 11.  3.  0.  3.  0.  8. 25. 10.
  0. 25. 11. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6] -> size -> 40 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.9417953491211






Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  0. 23.  0.  6.  0.  0. 23.  8. 16.  0.  0.  1.  3.  6.  0.  1.  6.
 11. 10.  3.  6.  0. 11.  6.  8. 10.  3.  6.  3.  3.  1.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
expected returns: [[98.06828 ]
 [89.59723 ]
 [73.219894]
 [89.59723 ]
 [70.15057 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3] -> size -> 41 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.04338073730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.64705 ]
 [27.509954]
 [97.69406 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3] -> size -> 41 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.06829833984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  1.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25. 25. 11. 10.  0.] 
adversary cards in discard: [11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 29.] 
cards in discard: [6.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25. 25. 11. 10.  0.] 
adversary cards in discard: [11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 29.] 
cards in discard: [6.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [25. 25. 11. 10.  0.] 
adversary cards in discard: [11.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25. 25. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11. 10.] 
expected returns: [[28.55062  ]
 [49.376274 ]
 [49.376274 ]
 [24.654423 ]
 [ 8.9702635]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 11. 10.  0.] 
cards in discard: [11.  0.  8. 11. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 1.  3. 16.  0.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.69407653808594



action possibilites: [-1] 
expected returns: [[99.536476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  0.  0. 11.] 
cards in discard: [11.  0.  8. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 1.  3. 16.  0.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.37628936767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 50.877495]
 [ 79.806046]
 [ 88.13704 ]
 [100.514565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11. 10.  0.  0. 11.] 
cards in discard: [11.  0.  8. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 1.  3. 16.  0.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.5364761352539






Player: 1 
cards in hand: [ 1.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 16.  0.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8. 29.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16.  0.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 25. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8. 29.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16.  0.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8. 29.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[125.38306]
 [137.28114]
 [130.76918]
 [137.28114]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  8. 29.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.51457214355469



action possibilites: [-1.  8.] 
expected returns: [[67.86998]
 [65.27707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 129.50807189941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[57.56392 ]
 [69.551956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 67.8699722290039






Player: 1 
cards in hand: [ 6.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 25. 11.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  5.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 25. 11.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  4.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 25. 11.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 11.] 
expected returns: [[35.469116]
 [29.9754  ]
 [29.9754  ]
 [54.007736]
 [39.465683]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 25. 11.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  4.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  1.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.55196380615234



action possibilites: [-1] 
expected returns: [[100.61958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.  0. 29.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  4.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  1.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.007728576660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[104.99344 ]
 [107.31315 ]
 [111.95997 ]
 [100.635254]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 11.  0. 29.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  4.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  1.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.61958312988281



buy possibilites: [-1] 
expected returns: [[29.519278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 11.  0. 29.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  1.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 111.96000671386719






Player: 1 
cards in hand: [11.  6.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6.  1.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10. 10.] 
adversary cards in hand: [29.  0. 11.  3.  8.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 1.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  8.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 24. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  8.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 1.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  8.] 
adversary cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[131.78278]
 [143.49573]
 [143.00813]
 [136.04797]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.  8.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.519277572631836



action possibilites: [-1. 10.] 
expected returns: [[115.893936]
 [120.85222 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 147.224853515625



action possibilites: [-1.] 
expected returns: [[107.051285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 120.85223388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[110.3973  ]
 [116.22332 ]
 [113.63199 ]
 [117.22861 ]
 [114.637276]
 [109.04364 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  3.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.05128479003906



buy possibilites: [-1] 
expected returns: [[123.98462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11.  0.  8. 11. 10. 25. 25. 11. 10.  0.  0. 11. 29. 10. 29.  3.  3.  8.
  8. 25. 10.  0. 10. 11.  0. 29. 11.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 90.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  4.  0.] 
sum of rewards: 129.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 117.22857666015625






Player: 1 
cards in hand: [ 0.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [11. 10.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [11. 10.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [11. 10.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[85.74994]
 [65.55252]
 [52.77294]
 [65.55252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 23.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.984619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.05706]
 [86.91349]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 23.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.74996948242188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  6.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 23.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0] -> size -> 47 
action values: 0 
buys: 2 
player value: 3 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25. 11.] 
expected returns: [[79.95272 ]
 [71.382195]
 [68.28688 ]
 [91.10191 ]
 [78.38456 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 25. 11.] 
cards in discard: [11. 10.  0.  3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.91350555419922



action possibilites: [-1] 
expected returns: [[57.66255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11. 25.  3.] 
cards in discard: [11. 10.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.10187530517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[75.109695]
 [57.820908]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11. 25.  3.] 
cards in discard: [11. 10.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.66255187988281



buy possibilites: [-1] 
expected returns: [[51.918175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11. 25.  3.] 
cards in discard: [11. 10.  0.  3. 11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 6.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 75.10967254638672






Player: 1 
cards in hand: [3. 0. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 6.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [11.  0. 29. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.  8.] 
expected returns: [[ 91.09749 ]
 [101.3561  ]
 [100.062035]
 [101.3561  ]
 [ 90.58994 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11.  8.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 23.  8.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.918174743652344



action possibilites: [-1] 
expected returns: [[86.09601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  8.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 3.  3.  8. 23.  8.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 119 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 90.58995819091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[91.82556]
 [87.28064]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  8.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 3.  3.  8. 23.  8.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.09600830078125



buy possibilites: [-1] 
expected returns: [[68.74931]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  8.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 3.  3.  8. 23.  8.] 
adversary cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.  3.  0.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 91.82554626464844






Player: 1 
cards in hand: [ 3.  3.  8. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 23.  8.] 
cards in discard: [ 6. 11. 10.  3.  3. 29.  3.  1.  3. 16.  0.  0.  8.  6.  0.  3. 11.  0.
 15.  3. 11.  6.  0.  6.  1.  0.  0.  6.  3. 10.  0. 10.  0. 23.  6.  6.
  0.  0.  6.  3.  3.  0.  6.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  3. 10.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8. 6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 10 29  6  3 11  6 11 16  3  6 10  1
  0  6  1  6  3  6 23  0  6  0 23  8  3  6  8  6  3  6  3  8 15  3  0 10
  0  3] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  3. 10.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  3. 10.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
action values: 0 
buys: 2 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  3. 10.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[28.348082]
 [30.718191]
 [30.718191]
 [28.235758]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3. 10.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [23.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.74931335449219



action possibilites: [-1. 29.] 
expected returns: [[ 98.01698]
 [111.32034]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [23.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 33.92823028564453



action possibilites: [-1.] 
expected returns: [[58.617157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [23.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.25520324707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.38424 ]
 [62.94677 ]
 [66.89637 ]
 [58.850914]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0] -> size -> 38 
action values: 1 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  2.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [23.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.617156982421875



buy possibilites: [-1] 
expected returns: [[60.110535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [23.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 66.89635467529297






Player: 1 
cards in hand: [3. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [23.  8.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [29. 10. 10. 10.  0.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [23.  8.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [29. 10. 10. 10.  0.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[91.765915]
 [88.667175]
 [47.616974]
 [47.616974]
 [47.616974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10.  0.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.11053466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 1.851057]
 [90.97321 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10. 10.  0.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.76591491699219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  6.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5. 10.  8.  1. 10.  8.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 25.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.  8.] 
expected returns: [[111.648315]
 [118.62018 ]
 [130.96255 ]
 [118.62018 ]
 [107.7241  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 11.  8.] 
cards in discard: [11. 10.  0.  3. 11.  0. 25.  0.  8. 10. 11. 25.  3. 15.  0. 11.  0. 29.
 11.  8. 10.  0.  0.  8.  8. 29. 29.  3. 29. 10. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.97320556640625



action possibilites: [-1] 
expected returns: [[60.768005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  8. 11.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.9625701904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.41954 ]
 [61.304184]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  8. 11.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  3.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.76800537109375






Player: 1 
cards in hand: [10.  6.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  3.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0.  0. 11.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  8.  3.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [15.  3.  0.  0. 11.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[58.38935 ]
 [45.05139 ]
 [55.965103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 11.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  0. 15.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.304168701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[33.986816]
 [42.240112]
 [47.390182]
 [58.359978]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0. 11.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  0. 15.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.38934326171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 15.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6
  1  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  8.  0. 25. 10.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  8.  0. 25. 10.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 25. 30. 22. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  8.  0. 25. 10.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 21. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [10.  8.  0. 25. 10.] 
adversary cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25. 10.] 
expected returns: [[49.801292]
 [20.995554]
 [26.263502]
 [71.04768 ]
 [20.995554]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 25. 10.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 11.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.  3. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0
  3] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.35997009277344



action possibilites: [-1] 
expected returns: [[93.764755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.  3.  0.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 11.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.  3. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0
  3] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.04772186279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[58.79928 ]
 [90.676895]
 [98.47189 ]
 [96.816956]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 10.  3.  0.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 21. 30.  8.  0.  9.  0.  1.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 11.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.  3. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0
  3] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.76475524902344



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 7 
Witch: 3 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  8.  0. 10.  3.  0.] 
cards in discard: [25. 11.  0. 11.  8. 11.  8. 15.  3.  0.  0. 11.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 25 25  8 11 10 11  8 11 10
 25 11 11 10 29 10 10 11  8  8  8  0 15  0  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 21. 30.  8.  0.  9.  0.  0.  7.  5.  9.  8.  1. 10.  8.] 
adversary cards in hand: [ 0. 10.  3. 11.  6.] 
adversary cards in discard: [23.  8.  3.  3.  6.  6.  3.  6. 14.  0. 11.  0. 11.  3.  6. 10.  6.  3.
  8.  3.  3. 15.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1 10 29  3 11  6 11 16  3  6 10  1  0  6  1
  6  3  6 23  0  6  0 23  3  6  8  6  3  6  3  8 15  3  0 10  0  3 14  0
  3] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0     -50       0       0       8       0] 
sum of rewards: 3000003 

action type: buy - action 8.0
Learning step: 119996.1796875
desired expected reward: 120094.6484375



