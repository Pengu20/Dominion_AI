 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.4743023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -420        0        0       40        0
        0        0        0     -180        0        0       64        0] 
sum of rewards: -3000501 

action type: buy - action 29.0
Learning step: -120014.65625
desired expected reward: -120149.140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  1.1678538]
 [ 12.02316  ]
 [  4.9283943]
 [-38.02521  ]
 [ 10.840253 ]
 [  4.3872175]
 [  6.765691 ]
 [  3.2399917]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.7916107177734375



buy possibilites: [-1] 
expected returns: [[6.81551]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 12.023157119750977






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.949264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.815509796142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  7.3536406]
 [ 18.684044 ]
 [ 11.431134 ]
 [-31.545544 ]
 [ 13.866276 ]
 [ 17.536686 ]
 [ 10.545008 ]
 [ 25.529371 ]
 [ 10.99931  ]
 [ 13.158693 ]
 [ 20.064976 ]
 [  9.395489 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.777782440185547



buy possibilites: [-1] 
expected returns: [[-1.2069035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.52937126159668






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.291094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.2069034576416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.9714  ]
 [ 21.19163 ]
 [ 14.570585]
 [-27.121502]
 [ 20.22005 ]
 [ 13.802147]
 [ 16.3766  ]
 [ 13.193586]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.273550033569336



buy possibilites: [-1] 
expected returns: [[5.807911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.191627502441406






Player: 1 
cards in hand: [ 8.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-14.058485  ]
 [ -0.26203537]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.807910919189453



action possibilites: [-1.] 
expected returns: [[13.42992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -1.1974034309387207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 15.043535  ]
 [ 25.435253  ]
 [ -4.940049  ]
 [ 18.73043   ]
 [  0.46897697]
 [-23.15003   ]
 [ 21.159916  ]
 [ 24.460114  ]
 [ 18.01034   ]
 [ 29.19535   ]
 [ 31.524204  ]
 [ 18.425726  ]
 [ 26.51833   ]
 [ 20.505436  ]
 [  4.664869  ]
 [ 26.68343   ]
 [ 17.163952  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.429920196533203



buy possibilites: [-1] 
expected returns: [[0.515301]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.524208068847656






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0. 22.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0. 22.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.511372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.515300989151001





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.695177 ]
 [ 23.737606 ]
 [ -9.203088 ]
 [ 16.568718 ]
 [ -3.4421813]
 [-27.938747 ]
 [ 19.327385 ]
 [ 22.841722 ]
 [ 16.046495 ]
 [ 27.707129 ]
 [ 30.05534  ]
 [ 16.320051 ]
 [ 24.88049  ]
 [ 18.666426 ]
 [  1.1224551]
 [ 25.083273 ]
 [ 15.132336 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.509149551391602



buy possibilites: [-1] 
expected returns: [[-5.1423454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.055328369140625






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [29.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [29.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [29.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-23.83739]
 [-10.60256]
 [-10.60256]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  3.] 
cards in discard: [29.  0.  1.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.142345428466797



action possibilites: [-1. 29.] 
expected returns: [[ 6.3715715]
 [19.344936 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  3.] 
cards in discard: [29.  0.  1.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -9.648487091064453



action possibilites: [-1.] 
expected returns: [[25.661747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  1.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.34494400024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 24.280468]
 [ 34.914257]
 [ 27.989517]
 [-15.338404]
 [ 30.552917]
 [ 33.812485]
 [ 27.21262 ]
 [ 41.090034]
 [ 27.717722]
 [ 29.844662]
 [ 36.131027]
 [ 26.547558]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  1.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.661746978759766



buy possibilites: [-1] 
expected returns: [[8.771404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  1.  1.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.09002685546875






Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 22 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.392223]
 [31.341251]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.771404266357422



action possibilites: [-1. 29.] 
expected returns: [[ 6.0430965]
 [20.915058 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.697723388671875



action possibilites: [-1.] 
expected returns: [[9.574966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 20.915058135986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.2693825]
 [ 17.809528 ]
 [-13.413848 ]
 [ 10.951377 ]
 [ -7.8929496]
 [-32.185795 ]
 [ 13.607212 ]
 [ 16.748184 ]
 [  9.942411 ]
 [ 21.429476 ]
 [ 23.77277  ]
 [ 10.748659 ]
 [ 18.852716 ]
 [ 12.847355 ]
 [ -3.530954 ]
 [ 18.985523 ]
 [  9.755227 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.574966430664062



buy possibilites: [-1] 
expected returns: [[5.719697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 97.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.77277183532715






Player: 1 
cards in hand: [ 0.  0. 11.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 22.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  0.  0.] 
cards in discard: [22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.510677]
 [34.08075 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  1.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.719696998596191



action possibilites: [-1.] 
expected returns: [[41.62886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.06137466430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[38.64567   ]
 [48.56953   ]
 [42.067127  ]
 [23.569813  ]
 [ 0.33101487]
 [44.804764  ]
 [47.57843   ]
 [40.92289   ]
 [51.77134   ]
 [53.88722   ]
 [42.000526  ]
 [49.49242   ]
 [44.017277  ]
 [27.967464  ]
 [49.59873   ]
 [41.37383   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.62886047363281



buy possibilites: [-1] 
expected returns: [[13.646357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  4. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.887229919433594






Player: 1 
cards in hand: [ 8.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  3.] 
cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  4. 10. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [22. 22.  0.  0. 11.  0.  0.  0.  0. 14.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-4.433277]
 [ 8.15626 ]
 [ 8.15626 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.646356582641602



action possibilites: [-1. 29. 29.] 
expected returns: [[ 9.025648]
 [24.077972]
 [24.077972]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.181432723999023



action possibilites: [-1. 29. 29.] 
expected returns: [[29.841606]
 [44.955475]
 [44.955475]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.077970504760742



action possibilites: [-1. 29. 29.] 
expected returns: [[29.258244]
 [44.401867]
 [44.401867]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.95547103881836



action possibilites: [-1. 29.] 
expected returns: [[25.866535]
 [40.578506]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.40186309814453



action possibilites: [-1.] 
expected returns: [[37.938812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.57849884033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.584988]
 [48.50322 ]
 [15.531849]
 [41.33236 ]
 [21.012257]
 [49.626377]
 [-2.878551]
 [44.15813 ]
 [47.531002]
 [40.892113]
 [52.340218]
 [54.6978  ]
 [41.131462]
 [49.608368]
 [43.48531 ]
 [25.818941]
 [49.781708]
 [40.084473]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 10 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  4.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.938812255859375



buy possibilites: [-1] 
expected returns: [[31.25933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 6 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0. 100.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 54.69779968261719






Player: 1 
cards in hand: [ 0. 14. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  1. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  1. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  1. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  1. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 6.9815893]
 [20.610767 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  0.  3.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.25933074951172



action possibilites: [-1.] 
expected returns: [[55.270153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.324813842773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[59.531002]
 [69.762146]
 [39.186024]
 [63.07219 ]
 [44.431225]
 [21.25292 ]
 [65.69241 ]
 [68.80539 ]
 [62.458405]
 [73.315125]
 [75.54488 ]
 [62.870377]
 [70.785706]
 [65.022255]
 [48.695877]
 [70.93417 ]
 [61.872467]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.2701530456543



buy possibilites: [-1] 
expected returns: [[76.694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 75.54488372802734






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-4.4577785]
 [ 6.98798  ]
 [ 6.98798  ]
 [ 6.98798  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.69400024414062



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-3.9619725]
 [ 9.073845 ]
 [ 9.073845 ]
 [ 9.073845 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.099571228027344



action possibilites: [-1. 29. 29.] 
expected returns: [[ 5.189193]
 [18.081163]
 [18.081163]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.073835372924805



action possibilites: [-1. 29.] 
expected returns: [[16.505955]
 [28.881195]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.081153869628906



action possibilites: [-1.] 
expected returns: [[35.66526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.881210327148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.30011 ]
 [44.250412]
 [14.060261]
 [37.617226]
 [19.134888]
 [-3.809999]
 [40.393074]
 [43.282036]
 [36.674152]
 [47.569794]
 [49.714535]
 [37.588795]
 [45.20696 ]
 [39.63833 ]
 [23.549374]
 [45.32978 ]
 [37.047825]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  2.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.665260314941406



buy possibilites: [-1] 
expected returns: [[41.096653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 8. 22.  0. 22.  0.] 
adversary cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 49.71453094482422






Player: 1 
cards in hand: [ 8. 22.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 22.  0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 22.  0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  8. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 22.  0.] 
cards in discard: [ 3.  0. 11.  0. 14.  0.  3.  8.  0.  3.  3.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 1. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[41.33567 ]
 [54.994602]
 [54.994602]
 [54.994602]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.09665298461914



action possibilites: [-1. 29. 29.] 
expected returns: [[22.772945]
 [36.14614 ]
 [36.14614 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  0.  0.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.33119201660156



action possibilites: [-1. 29.] 
expected returns: [[37.672443]
 [51.562893]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  1.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.14612579345703



action possibilites: [-1.] 
expected returns: [[59.16048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.56290054321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[56.679302]
 [67.586624]
 [34.26752 ]
 [60.337193]
 [40.087254]
 [68.77654 ]
 [14.127834]
 [63.20732 ]
 [66.50432 ]
 [60.042526]
 [71.3693  ]
 [73.79584 ]
 [60.153614]
 [68.67658 ]
 [62.532455]
 [44.834732]
 [68.82109 ]
 [59.169544]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 9 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  1.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.16048049926758



buy possibilites: [-1] 
expected returns: [[152.61171]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 14.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 57.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.79582214355469






Player: 1 
cards in hand: [ 0. 14.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  8.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 11.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 2.454834]
 [14.064632]
 [14.064632]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.61170959472656



action possibilites: [-1.] 
expected returns: [[17.27253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.346978187561035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.400705]
 [ 26.138412]
 [ 19.7484  ]
 [-21.755161]
 [ 25.21752 ]
 [ 18.667103]
 [ 21.733904]
 [ 19.16521 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.27252960205078



buy possibilites: [-1] 
expected returns: [[29.658062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.13842010498047






Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [11.  0. 14.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0. 14.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0. 14.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[12.979385]
 [25.98656 ]
 [25.98656 ]
 [25.98656 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 29.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [22.  0.  8.  0.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.658061981201172



action possibilites: [-1. 29. 29.] 
expected returns: [[52.561172]
 [66.17527 ]
 [66.17527 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [22.  0.  8.  0.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.099811553955078



action possibilites: [-1.] 
expected returns: [[56.300423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [22.  0.  8.  0.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.44468688964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[58.718422]
 [68.8196  ]
 [38.19928 ]
 [62.10675 ]
 [43.59651 ]
 [19.568   ]
 [64.87186 ]
 [67.669495]
 [61.214455]
 [72.085556]
 [62.017082]
 [69.761536]
 [64.09629 ]
 [47.89473 ]
 [69.84028 ]
 [61.34771 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7. 10.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [22.  0.  8.  0.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.30042266845703



buy possibilites: [-1] 
expected returns: [[57.684143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [22.  0.  8.  0.  0.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 72.08554077148438






Player: 1 
cards in hand: [22.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  0.  0.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[113.02858 ]
 [123.983505]
 [123.983505]
 [123.983505]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3. 22. 11.  0.  3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.68414306640625



action possibilites: [-1. 29. 29.] 
expected returns: [[101.517715]
 [112.905945]
 [112.905945]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3. 22. 11.  0.  3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 117.33921813964844



action possibilites: [-1.] 
expected returns: [[4.7149086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3. 22. 11.  0.  3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 108.02976989746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  2.0482483]
 [ 12.198661 ]
 [-18.84527  ]
 [  5.464281 ]
 [-13.768239 ]
 [-37.053772 ]
 [  8.323476 ]
 [ 11.18519  ]
 [  4.683735 ]
 [ 15.49855  ]
 [  5.407795 ]
 [ 13.150185 ]
 [  7.5743265]
 [ -9.198715 ]
 [ 13.261581 ]
 [  4.786888 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  9.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3. 22. 11.  0.  3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.714908599853516



buy possibilites: [-1] 
expected returns: [[17.693832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1. 29.  3.  0.  0.  3. 29. 29. 25. 29. 29.  0.  0.  1. 29. 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3. 22. 11.  0.  3.] 
adversary cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.498550415039062






Player: 1 
cards in hand: [ 3. 22. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 11.  0.  3.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  8.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.  8.] 
cards in discard: [11.  0. 14.  0.  0. 11.  8.  3.  8. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 1.3021607]
 [13.287006 ]
 [13.287006 ]
 [13.287006 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  3. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.693832397460938



action possibilites: [-1. 29.] 
expected returns: [[40.78147]
 [53.94652]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  3. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.845541000366211



action possibilites: [-1.] 
expected returns: [[62.301895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  3. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.89096450805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[61.162544]
 [71.677925]
 [64.70448 ]
 [19.073034]
 [67.62997 ]
 [70.69275 ]
 [64.12298 ]
 [64.617805]
 [66.91043 ]
 [72.827034]
 [63.887558]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8. 10.] 
adversary cards in hand: [ 3.  3. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.30189514160156



buy possibilites: [-1] 
expected returns: [[55.46515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 3.  3. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 72.82704162597656






Player: 1 
cards in hand: [ 3.  3. 22.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 22.  8.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [29.  0.  0. 29. 29.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 22.  8.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [29.  0.  0. 29. 29.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[77.46234]
 [90.36691]
 [90.36691]
 [90.36691]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29. 29.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [11.  0. 11.  8. 14.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.46514892578125



action possibilites: [-1. 29.] 
expected returns: [[86.17268]
 [98.8609 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [11.  0. 11.  8. 14.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 81.9534912109375



action possibilites: [-1.] 
expected returns: [[144.16727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [11.  0. 11.  8. 14.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.42161560058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[141.20697 ]
 [151.4287  ]
 [144.5016  ]
 [124.17972 ]
 [ 98.327225]
 [147.58366 ]
 [150.43195 ]
 [144.24637 ]
 [154.69876 ]
 [144.5191  ]
 [152.3712  ]
 [146.88776 ]
 [129.11644 ]
 [152.48305 ]
 [144.0633  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  8.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [11.  0. 11.  8. 14.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 144.16726684570312



buy possibilites: [-1] 
expected returns: [[147.00735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [11.  0. 11.  8. 14.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 154.69874572753906






Player: 1 
cards in hand: [11.  0. 11.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  8. 14.] 
cards in discard: [ 3.  3. 22.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  7.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 0.  1. 29.  3.  1.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 14.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 0.  1. 29.  3.  1.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 14.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 0.  1. 29.  3.  1.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 14.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 0.  1. 29.  3.  1.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-28.539373]
 [-15.453756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3.  1.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22. 11.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.00735473632812



action possibilites: [-1.] 
expected returns: [[45.65172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22. 11.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.018028259277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[39.67423  ]
 [48.722935 ]
 [19.84667  ]
 [42.624172 ]
 [24.692049 ]
 [ 1.7588749]
 [45.461037 ]
 [47.769608 ]
 [41.757698 ]
 [51.419    ]
 [42.722263 ]
 [49.50051  ]
 [44.704353 ]
 [29.059849 ]
 [49.56469  ]
 [42.551163 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  7.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22. 11.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.65171813964844



buy possibilites: [-1] 
expected returns: [[50.353626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22. 11.] 
adversary cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 51.419002532958984






Player: 1 
cards in hand: [ 8.  0.  0. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 22. 11.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.
 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  0.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.
 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  0.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  6.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.
 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  0.] 
cards in discard: [ 3.  3. 22.  8.  3.  8.  0. 11.  0. 11.  8. 14.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.
 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[-0.5445018]
 [ 9.358269 ]
 [ 9.358269 ]
 [11.478576 ]
 [11.478576 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29. 29.  0.] 
cards in discard: [29. 29. 15. 29. 29.  3.  0.  0. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.
 29.  0.  3.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.3536262512207



action possibilites: [-1. 25. 25. 29.] 
expected returns: [[20.553104]
 [30.767647]
 [30.767647]
 [33.012848]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.357320785522461



action possibilites: [-1. 25. 25.] 
expected returns: [[27.304764]
 [37.519253]
 [37.519253]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.] 
cards in discard: [29.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.717100143432617



action possibilites: [-1] 
expected returns: [[41.625362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0.] 
cards in discard: [29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.519264221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[37.82044  ]
 [47.32653  ]
 [40.91337  ]
 [-1.9096076]
 [43.863434 ]
 [46.341072 ]
 [40.148945 ]
 [40.99515  ]
 [43.101597 ]
 [48.2343   ]
 [40.756382 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  0.] 
cards in discard: [29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.625362396240234



buy possibilites: [-1] 
expected returns: [[64.24944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  0.] 
cards in discard: [29.  1. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 48.23430633544922






Player: 1 
cards in hand: [8. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 3.  0. 15.  0. 25.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 3.  0. 15.  0. 25.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 3.  0. 15.  0. 25.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 3.  0. 15.  0. 25.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[49.07853]
 [57.09928]
 [59.40466]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0. 25.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  9. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0.  8.  3. 11. 22.] 
adversary cards in discard: [6. 0. 8. 3. 8.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.24944305419922



action possibilites: [-1] 
expected returns: [[5.7529755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0. 25.  3.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0.  8.  3. 11. 22.] 
adversary cards in discard: [6. 0. 8. 3. 8. 6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.60047149658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  3.4344788]
 [  6.467944 ]
 [-34.200043 ]
 [  5.4757805]
 [  6.2408705]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0. 25.  3.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0.  8.  3. 11. 22.] 
adversary cards in discard: [6. 0. 8. 3. 8. 6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.7529754638671875



buy possibilites: [-1] 
expected returns: [[11.203039]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0. 25.  3.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0.  8.  3. 11. 22.] 
adversary cards in discard: [6. 0. 8. 3. 8. 6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 6.4679155349731445






Player: 1 
cards in hand: [ 0.  8.  3. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11. 22.] 
cards in discard: [6. 0. 8. 3. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29.  1. 29.  1. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  8.  3. 11.  0.] 
cards in discard: [6. 0. 8. 3. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 22. 11.  8. 11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29.  1. 29.  1. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  8.  3. 11.  0.] 
cards in discard: [6. 0. 8. 3. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 22. 11.  8. 11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29.  1. 29.  1. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  8.  3. 11.  0.] 
cards in discard: [6. 0. 8. 3. 8. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 22. 11.  8. 11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29.  1. 29.  1. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  1. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 2.8629684]
 [14.781643 ]
 [14.781643 ]
 [14.781643 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  1. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.203039169311523



action possibilites: [-1. 29. 29.] 
expected returns: [[-11.835522  ]
 [ -0.44414687]
 [ -0.44414687]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.703781127929688



action possibilites: [-1. 29.] 
expected returns: [[-0.0614562]
 [11.798246 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.306522846221924



action possibilites: [-1. 29.] 
expected returns: [[24.672758]
 [36.45639 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.7415266036987305



action possibilites: [-1.] 
expected returns: [[-2.5556016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 22.010711669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -4.553189  ]
 [  4.962057  ]
 [ -1.2827153 ]
 [-17.97967   ]
 [-39.25371   ]
 [  1.2906232 ]
 [  3.8864202 ]
 [ -2.6258078 ]
 [  7.994459  ]
 [ -1.3543988 ]
 [  5.83665   ]
 [  0.48058677]
 [-14.247491  ]
 [  5.9081173 ]
 [ -1.9439051 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  6.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -2.5556015968322754



buy possibilites: [-1] 
expected returns: [[-7.5895677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  1. 15. 29. 29. 25. 25.  0. 29.  0.  3. 25.  3.  0. 15.  0. 25.  3.
 29.  1.  1.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [11.  3. 22.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.994472503662109






Player: 1 
cards in hand: [11.  3. 22.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 22.  0. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 22.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 22.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  7.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 22.  0.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[14.88311 ]
 [27.252148]
 [27.252148]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.] 
cards in discard: [3. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0    0    0    0
 1482    0] 
sum of rewards: 1567 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -7.435266017913818



action possibilites: [-1.] 
expected returns: [[32.713665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.17508316040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 31.93473 ]
 [ 42.312115]
 [ 35.36717 ]
 [-10.00666 ]
 [ 41.25348 ]
 [ 34.756184]
 [ 37.60041 ]
 [ 34.74642 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.71366500854492



buy possibilites: [-1] 
expected returns: [[58.92919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 29.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 42.31211853027344






Player: 1 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [11. 14. 11.  3. 22.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [11. 14. 11.  3. 22.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [11. 14. 11.  3. 22.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[50.526405]
 [63.206894]
 [63.206894]
 [63.206894]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  1.  0.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 22.  0.  8.  8.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.92919158935547



action possibilites: [-1. 29.] 
expected returns: [[53.550278]
 [66.20491 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  1.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 22.  0.  8.  8.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.81621551513672



action possibilites: [-1.] 
expected returns: [[59.024612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 22.  0.  8.  8.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.8309326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[56.75993 ]
 [67.88697 ]
 [60.57677 ]
 [41.766033]
 [17.591082]
 [63.38234 ]
 [66.79423 ]
 [59.676857]
 [71.79485 ]
 [60.339878]
 [69.01292 ]
 [62.61564 ]
 [46.084324]
 [69.16761 ]
 [59.323   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  5.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 22.  0.  8.  8.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.02461242675781



buy possibilites: [-1] 
expected returns: [[70.370735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 22.  0.  8.  8.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.79484558105469






Player: 1 
cards in hand: [ 0. 22.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  8.  8.] 
cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  0.  3.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  8.  8.] 
cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  0.  3.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[ 7.272043]
 [18.763065]
 [16.770098]
 [18.763065]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0.  3.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  8. 11.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.37073516845703



action possibilites: [-1. 25. 25.] 
expected returns: [[20.730053]
 [29.431114]
 [29.431114]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 25.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  8. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  8. 11.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.873008728027344



action possibilites: [-1] 
expected returns: [[1.3290601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 25.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  8. 11.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.431110382080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-2.5900564e+00]
 [ 6.7028618e+00]
 [ 5.7664394e-01]
 [-3.6614365e+01]
 [ 5.5994625e+00]
 [-7.3031807e-01]
 [ 2.3219485e+00]
 [-4.5783520e-03]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 25.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  8. 11.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.3290600776672363



buy possibilites: [-1] 
expected returns: [[4.416047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 25.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  8. 11.] 
adversary cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.702861785888672






Player: 1 
cards in hand: [ 8.  6. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 11.  8. 11.] 
cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 15.  1. 29. 29.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.  8. 11.] 
cards in discard: [11. 14. 11.  3. 22.  0.  0.  0.  3.  6.  3.  0.  0. 22.  0.  8.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 15.  1. 29. 29.] 
adversary cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 15.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 29.] 
expected returns: [[21.05299 ]
 [31.642075]
 [27.906355]
 [31.642075]
 [31.642075]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  1. 29. 29.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.416047096252441



action possibilites: [-1. 15. 29. 29.] 
expected returns: [[-3.0973516]
 [ 3.5390668]
 [ 7.100197 ]
 [ 7.100197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 29. 29.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.124189376831055



action possibilites: [-1. 15. 29.] 
expected returns: [[21.067093]
 [28.633066]
 [32.674736]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.755497932434082



action possibilites: [-1. 15.] 
expected returns: [[-3.7365713]
 [ 3.223565 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25
 25 15 25 25 15  3 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.731260299682617



action possibilites: [-1] 
expected returns: [[2.430746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 6 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 3.2235732078552246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -0.24427104]
 [  9.143795  ]
 [-18.412466  ]
 [  2.987607  ]
 [-13.436775  ]
 [-35.013657  ]
 [  5.472678  ]
 [  7.9647017 ]
 [  1.5490398 ]
 [ 12.090489  ]
 [  2.8902583 ]
 [  9.994191  ]
 [  4.6435122 ]
 [ -9.722275  ]
 [ 10.035088  ]
 [  2.2681713 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  4.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.430746078491211



buy possibilites: [-1] 
expected returns: [[-5.6512036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0. 29.  1. 29.  0.  0. 29.  1. 25. 29. 29.  0.  1.  3. 29.  1. 29.
 25.  0.  3. 25.  0. 25. 25.  1. 15. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [ 8. 22. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 12.090487480163574






Player: 1 
cards in hand: [ 8. 22. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  9. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0.  8.] 
cards in discard: [14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0.  8.] 
cards in discard: [14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0.  8.] 
cards in discard: [14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 29.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29. 29.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[33.349354]
 [46.230537]
 [46.230537]
 [43.933655]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.651203632354736



action possibilites: [-1. 25. 25.] 
expected returns: [[26.442192]
 [36.33889 ]
 [36.33889 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 30.  8.  7. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.74030303955078



action possibilites: [-1] 
expected returns: [[26.495178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 29.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.33888244628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 24.631855]
 [ 34.387577]
 [ 28.022655]
 [-11.351546]
 [ 33.218178]
 [ 26.659754]
 [ 29.720177]
 [ 27.110662]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.49517822265625



buy possibilites: [-1] 
expected returns: [[25.996403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.] 
cards in discard: [29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
adversary owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 34.387569427490234






Player: 1 
cards in hand: [14.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  8.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 22 11  0 11 22 14  3  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6
 14  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 1. 25. 15. 15.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 1. 25. 15. 15.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 1. 25. 15. 15.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 1. 25. 15. 15.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15.] 
expected returns: [[35.55731 ]
 [45.47224 ]
 [43.398354]
 [43.398354]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15. 15.  3.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 30.  8.  6. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 11.  6. 22.  6.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.996402740478516



action possibilites: [-1] 
expected returns: [[11.3487625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.  3.  3. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 27. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 11.  6. 22.  6.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 45.47223663330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  6.1578674]
 [  9.399874 ]
 [-32.447258 ]
 [  8.83349  ]
 [  8.726184 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  3.  3. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 27. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 11.  6. 22.  6.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.348762512207031



buy possibilites: [-1] 
expected returns: [[-2.6124027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  3.  3. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 11.  6. 22.  6.] 
adversary cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 9.399861335754395






Player: 1 
cards in hand: [ 0. 11.  6. 22.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 22.  6.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 11.  3.  6.  0.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.  8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  3.  6.  0.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.  8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  3.  6.  0.] 
cards in discard: [14.  0. 11.  8. 22.  0.  8.  6.  0.  8. 14.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 11.  8.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[-13.519667 ]
 [ -2.7507348]
 [ -4.725301 ]
 [ -2.7507348]
 [ -2.7507348]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  1. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0] -> size -> 27 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.6124026775360107



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 5.1333876]
 [14.073448 ]
 [16.01738  ]
 [16.01738  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  1.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0] -> size -> 27 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.362334251403809



action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-12.793967 ]
 [ -4.275282 ]
 [ -2.3219593]
 [ -4.275282 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0] -> size -> 27 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.377962112426758



action possibilites: [-1. 25. 25.] 
expected returns: [[-16.013546 ]
 [ -6.1145787]
 [ -6.1145787]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 24. 30. 26. 30.  8.  5. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0] -> size -> 27 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -15.376440048217773



action possibilites: [-1] 
expected returns: [[-16.801329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.114569664001465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-19.01208 ]
 [-10.024953]
 [-15.923298]
 [-31.690535]
 [-52.278187]
 [-13.521565]
 [-11.160746]
 [-17.336815]
 [ -7.229308]
 [-16.003735]
 [ -9.218083]
 [-14.326802]
 [-28.118784]
 [ -9.182936]
 [-16.565453]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  3.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.801328659057617



buy possibilites: [-1] 
expected returns: [[-16.764935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1. 29.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  80   0   0   0   0 -20   0   0 250   0] 
sum of rewards: 575 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -7.229305267333984






Player: 1 
cards in hand: [11.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  8.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
adversary victory points: 5
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 26. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 6. 15.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 25. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
adversary victory points: 5
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[14.258766]
 [26.083012]
 [23.91522 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  0.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 25. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.764934539794922



action possibilites: [-1. 25.] 
expected returns: [[-8.6379795 ]
 [-0.32659197]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 25. 30.  8.  4. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.035154342651367



action possibilites: [-1] 
expected returns: [[34.86481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 25. 30.  8.  3. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.3265810012817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.472652 ]
 [41.634483 ]
 [14.809631 ]
 [35.697388 ]
 [19.59736  ]
 [-1.3464977]
 [38.05959  ]
 [40.59823  ]
 [34.28518  ]
 [44.889465 ]
 [35.571472 ]
 [42.545673 ]
 [37.279934 ]
 [23.286322 ]
 [42.652122 ]
 [34.864815 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 24. 30. 25. 30.  8.  3. 10.  6.  5.  2.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.864810943603516



buy possibilites: [-1] 
expected returns: [[20.104044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  1. 29. 25.  0.  3. 25.  0. 29.  3. 25.  1. 15. 15.  3.  3. 29.  1.
  1. 25. 25. 29. 29. 29. 25. 25.  1. 29. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 25. 30.  8.  3. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   40.    0.    0.    0.    0.  -30.
   0.    0.   62.5   0. ] 
sum of rewards: 337.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 44.88945388793945






Player: 1 
cards in hand: [ 6.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 25. 30.  8.  3. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [25. 25. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 25. 30.  8.  3. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [25. 25. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 30. 25. 30.  8.  3. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [25. 25. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 25. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 25.] 
expected returns: [[-0.8466821]
 [ 9.284266 ]
 [ 9.284266 ]
 [ 9.284266 ]
 [ 9.284266 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  8. 22. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.10404396057129



action possibilites: [-1] 
expected returns: [[9.210212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  8. 22. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.284263610839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  7.7326345]
 [ 17.07379  ]
 [ 10.948472 ]
 [-26.856031 ]
 [ 15.893496 ]
 [  9.51162  ]
 [ 12.588969 ]
 [ 10.224859 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  8. 22. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.210211753845215



buy possibilites: [-1] 
expected returns: [[26.814999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 25.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 6.  6.  8. 22. 11.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
adversary owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 329 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 17.07379150390625






Player: 1 
cards in hand: [ 6.  6.  8. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8. 22. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 22 11 11 22 14  3  0  8  8 11  8  0  8  6  0  6  0 11  0  6 14  0  6
  0  6  0  6 15  3  6  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 0.1752441]
 [10.203594 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3.  0.  0.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  2. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.] 
adversary owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.814998626708984



action possibilites: [-1] 
expected returns: [[11.20892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 29. 29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
adversary owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.203596115112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  8.359705]
 [ 17.701042]
 [ 11.519689]
 [-28.962854]
 [ 14.221504]
 [ 16.694887]
 [ 10.356685]
 [ 11.522129]
 [ 13.430737]
 [ 18.604654]
 [ 11.110308]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 29. 29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  7.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
adversary owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.208919525146484



buy possibilites: [-1] 
expected returns: [[4.2999578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 29. 29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 0.  0.  8. 22.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
adversary owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0  6] -> size -> 33 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 393 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 18.604644775390625






Player: 1 
cards in hand: [ 0.  0.  8. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 22.  0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11 22 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6
  0  6 15  3  6  0  6  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [29. 29. 29. 29. 15.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [29. 29. 29. 29. 15.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [29. 29. 29. 29. 15.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
adversary victory points: 5
player victory points: -6 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 15.] 
expected returns: [[-5.448985]
 [ 4.550477]
 [ 4.550477]
 [ 4.550477]
 [ 4.550477]
 [ 0.953568]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 15.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.299957752227783



action possibilites: [-1. 29. 29. 29. 15.] 
expected returns: [[-24.172611]
 [-11.637594]
 [-11.637594]
 [-11.637594]
 [-15.995344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 15.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.24379682540893555



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-19.287733 ]
 [ -7.3448324]
 [ -7.3448324]
 [ -7.3448324]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.997024536132812



action possibilites: [-1. 29. 29.] 
expected returns: [[-22.11901 ]
 [-10.739342]
 [-10.739342]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.443329811096191



action possibilites: [-1. 29.] 
expected returns: [[-1.221082]
 [10.739958]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 4 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.594217300415039



action possibilites: [-1.] 
expected returns: [[-26.89672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 5 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -3.775618553161621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-30.017843]
 [-20.828726]
 [-26.882095]
 [-43.161934]
 [-60.98162 ]
 [-24.358244]
 [-22.008137]
 [-28.384901]
 [-18.033463]
 [-26.92842 ]
 [-20.021795]
 [-25.206629]
 [-39.455124]
 [-19.995989]
 [-27.408775]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 5 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  1.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -26.89672088623047



buy possibilites: [-1] 
expected returns: [[-18.118933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 8. 14. 14.  3.  0.] 
adversary cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0 100   0   0   0   0 -60   0   0 250   0] 
sum of rewards: 615 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -18.033479690551758






Player: 1 
cards in hand: [ 8. 14. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 14.  3.  0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [ 3.  0.  1.  1. 29.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
adversary victory points: 5
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.] 
cards in discard: [ 6. 15.  3. 11.  0.  0. 11.  8.  6.  0.  6.  6.  0.  0. 11.  6.  0.  8.
  6. 11.  6.  8.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
adversary victory points: 5
player victory points: -6 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.195963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  330    0    0    0    0    0    0    0  -60    0    0
 2231    0] 
sum of rewards: 2496 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -37.60341262817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 16.754295 ]
 [ 25.780743 ]
 [ 19.976599 ]
 [  3.9680185]
 [-16.74929  ]
 [ 22.319218 ]
 [ 24.822285 ]
 [ 18.429857 ]
 [ 19.866615 ]
 [ 26.618307 ]
 [ 21.532578 ]
 [  7.6854973]
 [ 26.702122 ]
 [ 19.19595  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  6.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.19596290588379



buy possibilites: [-1] 
expected returns: [[12.824781]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 330.   0.   0.   0.   0.   0.   0.   0. -70.   0.   0.
  32.   0.] 
sum of rewards: 287.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 26.702125549316406






Player: 1 
cards in hand: [8. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0
  6 15  3  6  0  6  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 29. 25.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0  6
 15  3  6  0  6  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 29. 25.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0  6
 15  3  6  0  6  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 29. 25.] 
adversary cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
adversary victory points: 5
player victory points: -6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-11.668791  ]
 [ -0.17539573]
 [ -0.17539573]
 [ -2.2579691 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1. 29. 25.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [8. 0. 6. 6.] 
adversary owned cards: [11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0  6
 15  3  6  0  6  0  6  0] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.82478141784668



action possibilites: [-1. 25. 25.] 
expected returns: [[-11.840073]
 [ -2.523282]
 [ -2.523282]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  1. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [8. 0. 6. 6.] 
adversary owned cards: [11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0  6
 15  3  6  0  6  0  6  0] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -3.9506845474243164



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 7 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 4 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 25.  3.  3.] 
cards in discard: [ 1. 25. 25. 25. 25.  0.  0.  0. 15. 25.  1.  3.  0.  0. 29. 29.  1. 15.
 25. 25. 15. 25. 29. 29. 29. 29. 29.  3. 29. 15.  0.  1.  1.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 29 29 29 29 29 29 29 29 29  1 25 25
 15 25 25 15  3 25  1 25  1 25  1  3 25 25  1 15 25 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  6.  5.  0.  0.  8. 10. 10.  8.  5.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [8. 0. 6. 6. 6.] 
adversary owned cards: [11 11 14  3  0  8  8 11  8  0  8  0  6  0 11  0  6 14  0  6  0  6  0  6
 15  3  6  0  6  0  6  0  6] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     330       0       0      40       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000365 

action type: take_action - action 25.0
Learning step: 120014.6953125
desired expected reward: 120012.171875



