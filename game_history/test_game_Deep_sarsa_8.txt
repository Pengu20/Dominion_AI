 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.22822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1
Learning step: -300003.0625
desired expected reward: -300007.53125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[84.76144]
 [84.76298]
 [84.76144]
 [84.76144]
 [84.76144]
 [84.76509]
 [84.76173]
 [84.76791]
 [84.76144]
 [84.76144]
 [84.76413]
 [84.76144]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.77582550048828



buy possibilites: [-1] 
expected returns: [[54.632603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 84.76790618896484






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.63915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.63260269165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[83.15816 ]
 [83.1597  ]
 [83.15816 ]
 [83.15816 ]
 [83.16181 ]
 [83.158455]
 [83.15816 ]
 [83.15816 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.66976165771484



buy possibilites: [-1] 
expected returns: [[82.76916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 83.16181945800781






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[61.909508]
 [61.912697]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.76915740966797



action possibilites: [-1.] 
expected returns: [[49.843178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.75267028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.502274]
 [50.502922]
 [50.502274]
 [50.502274]
 [50.502274]
 [50.503918]
 [50.502285]
 [50.505455]
 [50.502274]
 [50.502274]
 [50.503716]
 [50.502274]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.843177795410156



buy possibilites: [-1] 
expected returns: [[34.58219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.50545883178711






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0. 10.  0.  3.  0.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.261696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.582191467285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[102.503044]
 [102.50448 ]
 [102.503044]
 [102.503044]
 [102.503044]
 [102.50646 ]
 [102.503334]
 [102.50908 ]
 [102.503044]
 [102.503044]
 [102.50553 ]
 [102.503044]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.51277160644531



buy possibilites: [-1] 
expected returns: [[58.712265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.50908660888672






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[32.36367 ]
 [32.366814]
 [32.366814]
 [32.365303]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.71226501464844



action possibilites: [-1. 29. 11.] 
expected returns: [[31.441372]
 [31.444275]
 [31.442852]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.714698791503906



action possibilites: [-1. 11.] 
expected returns: [[32.8632  ]
 [32.864807]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.44427490234375



action possibilites: [-1] 
expected returns: [[28.096842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.98116683959961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.508545]
 [29.509167]
 [29.508545]
 [29.508545]
 [29.508545]
 [29.51012 ]
 [29.508549]
 [29.511642]
 [29.508545]
 [29.508545]
 [29.509975]
 [29.508545]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.09684181213379



buy possibilites: [-1] 
expected returns: [[50.588417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14. 10.  0.  0.  3.] 
adversary cards in discard: [15.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.511642456054688






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [14. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  0.  3.] 
cards in discard: [15.  0.  1.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [15.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [15.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [15.  0.  1.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[57.086914]
 [57.09295 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.588417053222656



action possibilites: [-1.] 
expected returns: [[65.51418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.147743225097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[74.041595]
 [74.042885]
 [74.041595]
 [74.041595]
 [74.041595]
 [74.041595]
 [74.044655]
 [74.04186 ]
 [74.04779 ]
 [74.04697 ]
 [74.041595]
 [74.042755]
 [74.041595]
 [74.041595]
 [74.0438  ]
 [74.041595]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.5141830444336



buy possibilites: [-1] 
expected returns: [[42.16528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 74.04779052734375






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[19.438229]
 [19.438229]
 [19.441557]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.165279388427734



action possibilites: [-1] 
expected returns: [[27.179829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.556015014648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.748055]
 [28.74866 ]
 [28.748055]
 [28.748055]
 [28.749586]
 [28.748062]
 [28.748055]
 [28.748055]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.179828643798828



buy possibilites: [-1] 
expected returns: [[46.99311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0. 29.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.749584197998047






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  0. 29.  3.] 
adversary cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  0. 29.  3.] 
adversary cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  0. 29.  3.] 
adversary cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[28.943684]
 [28.94915 ]
 [28.946762]
 [28.94915 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  3.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.99311065673828



action possibilites: [-1. 11. 29.] 
expected returns: [[29.516884]
 [29.520042]
 [29.522484]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  3.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.4268741607666



action possibilites: [-1. 11.] 
expected returns: [[35.67754]
 [35.68094]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.522483825683594



action possibilites: [-1] 
expected returns: [[4.3073435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.03140640258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[7.575614 ]
 [7.575816 ]
 [7.575614 ]
 [7.575614 ]
 [7.575614 ]
 [7.576153 ]
 [7.5755806]
 [7.57675  ]
 [7.575614 ]
 [7.575614 ]
 [7.576168 ]
 [7.575614 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  6.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.307343482971191



buy possibilites: [-1] 
expected returns: [[25.861546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11. 25.  0. 10.  3.  0.  0. 29. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  1.  0. 14.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 7.576751708984375






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  0. 14.] 
cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  0. 14.] 
cards in discard: [15.  0.  0.  3.  0.  0.  6.  8. 10.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[35.371265]
 [35.374393]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  1.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.86154556274414



action possibilites: [-1.] 
expected returns: [[31.1181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  1.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.765640258789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.253685]
 [34.25427 ]
 [34.253685]
 [34.253685]
 [34.253685]
 [34.25518 ]
 [34.25367 ]
 [34.256645]
 [34.253685]
 [34.253685]
 [34.255047]
 [34.253685]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  5.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  1.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.118099212646484



buy possibilites: [-1] 
expected returns: [[59.78868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  1.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 34.256649017333984






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [14.  1.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0 14 15  3 15  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25. 10.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25. 10.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25. 10.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25. 10.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[85.081505]
 [85.088455]
 [85.081505]
 [85.08753 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  0. 29.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.78868103027344



action possibilites: [-1] 
expected returns: [[38.41709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.06497955322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.013138]
 [40.013767]
 [40.013138]
 [40.013138]
 [40.014725]
 [40.01315 ]
 [40.013138]
 [40.013138]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 29. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.417091369628906



buy possibilites: [-1] 
expected returns: [[67.50915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 29. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.01472473144531






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  9.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3. 29.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.50914764404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3. 29.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.728313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3. 29.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 11. 25.  0. 10.  0. 29. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 55.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 29.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  7.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 29.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 1.  8. 14.  1.  0.  6.  8.  0.  6.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10. 29.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 29.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 29.] 
expected returns: [[34.91248 ]
 [34.91248 ]
 [34.915485]
 [34.914013]
 [34.915485]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.728312969207764



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[9.673386]
 [9.673386]
 [9.674371]
 [9.675189]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.87563133239746



action possibilites: [-1. 10. 11.] 
expected returns: [[8.417349]
 [8.417349]
 [8.418208]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.675189018249512



action possibilites: [-1] 
expected returns: [[-1.7214633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.596412658691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[1.5836403]
 [1.5838573]
 [1.5836403]
 [1.5836403]
 [1.5836403]
 [1.5836403]
 [1.5842168]
 [1.5836079]
 [1.5846627]
 [1.5848496]
 [1.5836403]
 [1.5839751]
 [1.5836403]
 [1.5836403]
 [1.5842264]
 [1.5836403]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  4.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.7214633226394653



buy possibilites: [-1] 
expected returns: [[26.58825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 15.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 147.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 1.5848491191864014






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 10  0 14 15  3 15  6  8  1  6  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[0.2008667 ]
 [0.20109725]
 [0.20144534]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.58824920654297



action possibilites: [-1. 11. 29.] 
expected returns: [[1.0312879]
 [1.0314944]
 [1.0318253]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -0.5007455348968506



action possibilites: [-1. 11.] 
expected returns: [[3.6060598]
 [3.6080987]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.0318245887756348



action possibilites: [-1] 
expected returns: [[1.4231207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  5. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 3.650747060775757





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[1.662256 ]
 [1.6630828]
 [1.662256 ]
 [1.662256 ]
 [1.662256 ]
 [1.664182 ]
 [1.6624715]
 [1.6655262]
 [1.662256 ]
 [1.662256 ]
 [1.6635516]
 [1.662256 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  3.  9. 10.  5. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.4231207370758057



buy possibilites: [-1] 
expected returns: [[0.857898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 1.6655261516571045






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [ 0.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [ 0.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  6.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [ 0.  8. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 29.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [15.  0. 14. 11.  1.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.8578979969024658





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 29.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [15.  0. 14. 11.  1.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.797638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 29.] 
cards in discard: [10. 29. 29. 29. 11. 10.  0.  0.  0. 10. 29. 29. 29. 11.  3.  3.  0.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [15.  0. 14. 11.  1.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 55.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [15.  0. 14. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14. 11.  1.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 14. 11.  1.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 14. 11.  1.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [29.  0. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 25.] 
expected returns: [[16.669222]
 [16.67162 ]
 [16.669222]
 [16.67048 ]
 [16.671661]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.797637939453125



action possibilites: [-1. 10. 11. 25. 29.] 
expected returns: [[8.221387]
 [8.221387]
 [8.222193]
 [8.222887]
 [8.222903]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 25. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.270696640014648



action possibilites: [-1. 10. 11. 25. 29.] 
expected returns: [[0.1238749 ]
 [0.1238749 ]
 [0.12418485]
 [0.12441707]
 [0.12469459]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 25. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.222901344299316



action possibilites: [-1. 10. 11. 25. 10.] 
expected returns: [[3.8782976]
 [3.8782976]
 [3.8789241]
 [3.8794453]
 [3.8782976]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 25. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 0.12469363212585449



action possibilites: [-1] 
expected returns: [[-1.846087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.879443883895874





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-3.6577663]
 [-3.6576285]
 [-3.6577663]
 [-3.6577663]
 [-3.6577663]
 [-3.6574244]
 [-3.6577563]
 [-3.6571183]
 [-3.6577663]
 [-3.6577663]
 [-3.6574783]
 [-3.6577663]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  2.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.8460869789123535



buy possibilites: [-1] 
expected returns: [[-3.1339564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10. 10. 29.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -3.6571192741394043






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 0.  8. 10. 11.  3.  3.  0.  6.  1.  0. 15.  0. 14. 11.  1.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.1339564323425293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  1 10  0 14  3 15  6  8  1  6  8 11  0 11  0  6 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 11. 11.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11. 11.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 11. 11.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 11. 11.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 55.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [14.  0. 10.  8. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[1.2466533]
 [1.2500727]
 [1.2466533]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29. 10.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879



action possibilites: [-1. 10.] 
expected returns: [[1.6032331]
 [1.6032331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.2500736713409424





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[1.4042428]
 [1.4049823]
 [1.4042428]
 [1.4042428]
 [1.4059317]
 [1.4044759]
 [1.4042428]
 [1.4042428]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  5.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.6032378673553467



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [29. 29. 29. 29. 25.  0. 10. 11. 10. 10. 29.  0.  0.  0. 29. 29.  0.  0.
  0.  3. 29. 11. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  4.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10.  1.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 1.4059388637542725






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10.  1.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  4.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  1.  0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  4.  8.  9.  1.  8. 10.  4. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  4.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  4.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  9.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14.  0. 10.  8. 11.  1.  8.  0.  6.  0. 10. 11. 10. 11.  6.  0.  1.  0.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [14. 25.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 29.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [14. 25.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.1873035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 29.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [14. 25.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [14. 25.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 29.  3. 29.  0.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 14.  3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  2. 10.  8.] 
adversary cards in hand: [10.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11.  6. 15. 11.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 638   0] 
sum of rewards: 723 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11.  6. 15. 11.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 11.  6. 15. 11.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  6. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 15. 11.] 
cards in discard: [10. 14. 25.  0. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  1.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15. 11.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15. 11.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15. 11.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[5.044505 ]
 [5.044505 ]
 [5.0467033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  8.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879



action possibilites: [-1] 
expected returns: [[42.161682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 5.047724723815918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.25057 ]
 [41.25057 ]
 [41.25057 ]
 [41.250748]
 [41.25057 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  8.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.16168212890625



buy possibilites: [-1] 
expected returns: [[17.79007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 101 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 41.25074005126953






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  0.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 28. 30. 29. 30.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  0.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [29. 11.  0.  3. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 11.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  8. 11.  1.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.790069580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  8. 11.  1.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[2.7960374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  3. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  8. 11.  1.] 
adversary cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
adversary owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10. 10.  8. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 11.  1.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  1.  8.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 10  0 14  3 15  8  1  6  8 11  0 11  0  6 10 14  0 10 11
 25 10 29  0  4] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [10. 14. 25.  0. 14.  3. 29.  0. 11.  0.  6. 15. 11.  4.  1.  0.  0.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [25. 11.  0.  0. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25. 11.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.796037435531616





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  0.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  0.  0. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0. 10. 10. 29.  0. 29. 29.  0.  0. 10.  3. 29.
 15.  8. 11.  0.  0. 10.  3.  0. 29. 11.  0.  3. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -40.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [14.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  6.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  1.  4.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  1.  4.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11. 29.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 29.  1.  4.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -50.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  4.  0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 0. 0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[-4.410125 ]
 [-4.409918 ]
 [-4.4101534]
 [-4.40965  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879



action possibilites: [-1. 11.  8.] 
expected returns: [[-5.1503143]
 [-5.150047 ]
 [-5.1503344]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.410052299499512



action possibilites: [-1] 
expected returns: [[-5.2477126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -5.14993953704834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.279832]
 [-5.279733]
 [-5.279832]
 [-5.279832]
 [-5.279565]
 [-5.279852]
 [-5.279832]
 [-5.279832]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  3.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.2477126121521



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -5.27956485748291






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10. 10. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  8.  0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8 11  0 11  0  6 10 14  0 10 11 25 10 29
  0  4  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  6.  0. 11. 25.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  6.  0. 11. 25.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  6.  0. 11. 25.] 
adversary cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -80.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11. 25.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 29. 29.  8.  7. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0] -> size -> 43 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11. 11. 15.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 11. 11. 15.] 
cards in discard: [ 0. 10. 14.  0.  0.  3.  6.  0.  0. 29.  1.  4.  0.  0.  0.  8. 10. 10.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6] -> size -> 44 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 10.  3.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0  -90    0 -300
    0    0] 
sum of rewards: -425 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 10.  3.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 10.  3.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -100.
    0.    0.    0.    0.] 
sum of rewards: -135.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14  3 15  1  6  8  0 11  0  6 10 14  0 10 11 25 10 29  0
  4  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 11.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 29. 11.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  8.  0. 14.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 29. 11.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  8.  0. 14.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 29. 11.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  8.  0. 14.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -110.
    0.    0.    0.    0.] 
sum of rewards: -145.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [ 0.  8.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [ 0.  8.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  2.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [ 0.  8.  0. 14. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 15.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 25. 15.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 25. 15.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 25. 15.  0. 14.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -120.
    0.    0.    0.    0.] 
sum of rewards: -155.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 25. 15.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.  0. 14.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 28. 30. 29. 29.  8.  6. 10.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  4.  0.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0 -120    0    0
  692    0] 
sum of rewards: 537 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  4.  0.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 29. 29. 15. 11. 29. 11.  0.  8.  0.  0. 25.  0.  0.
 29.  0.  6.  0. 29.  3.  0. 10.  3.  0.  0. 10. 10. 29. 11.  0.  0. 29.
 15.  0.  0. 10. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  4.  0.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -130.
    0.    0.    0.    0.] 
sum of rewards: -165.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  4.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  4.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  7.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  4.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 5. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -140.
    0.    0.    0.    0.] 
sum of rewards: -175.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29. 10.  3.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 10.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 10.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 29. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 10.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [ 0.  8.  0. 14. 11.  1.  0. 11.  0.  6. 16. 14.  0. 25. 15.  0.  8.  3.
  0. 10.  4.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [29.  3. 10.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [29.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-2.1429105]
 [-2.1423557]
 [-2.1429105]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [11. 15. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879



action possibilites: [-1. 10. 11.] 
expected returns: [[-3.8893976]
 [-3.8893976]
 [-3.889112 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  6.] 
adversary cards in hand: [11. 15. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.1428182125091553



action possibilites: [-1] 
expected returns: [[-4.997836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11. 15. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0   40    0    0    0    0 -150    0    0
   64    0] 
sum of rewards: -111 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -3.8889949321746826





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.128908]
 [-5.128908]
 [-5.128908]
 [-5.128937]
 [-5.128908]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11. 15. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.997836112976074



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11. 15. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -60.    0.    0.   40.    0.    0.    0.    0. -160.
    0.    0.    0.    0.] 
sum of rewards: -185.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.128907680511475






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11. 15. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 25. 11.  0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [3. 0. 4. 0. 6.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [3. 0. 4. 0. 6.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [3. 0. 4. 0. 6.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0. -170.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [3. 0. 4. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 0. 6.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29. 29. 11. 29. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 0. 6.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29. 29. 11. 29. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 0. 6.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29. 29. 11. 29. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 29. 10.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 29. 10.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29.  0.  6.  1.  0.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11. 29. 10.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0] -> size -> 52 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29.  0.  6.  1.  0.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11. 29. 10.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [29.  0.  6.  1.  0.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -180    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [29.  0.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  1.  0.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11.  0. 10.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  1.  0.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 28. 29.  8.  6.  9.  1.  6.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11.  0. 10.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  1.  0.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 28. 30. 28. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [11.  0. 10.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0] -> size -> 53 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[-1.0099393]
 [-1.0078053]
 [-1.0099393]
 [-1.0078053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.801163673400879



action possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 27. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -190    0    0
    8    0] 
sum of rewards: -197 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -1.0090084075927734





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-5.8011627]
 [-5.8011627]
 [-5.8011627]
 [-5.8011627]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 27. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.801163673400879



buy possibilites: [-1] 
expected returns: [[-5.8011637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -200    0    0
   16    0] 
sum of rewards: -169 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -5.801163673400879






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.  3. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3  3] -> size -> 55 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 26. 29.  8.  6.  9.  1.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.  3. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3  3] -> size -> 55 
adversary victory points: 4
player victory points: 4 


Game is draw!



Player 0 bought cards:
Copper: 19 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 1 
Witch: 1 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 29.  0. 15.  0.] 
cards in discard: [ 0.  0.  0.  0.  0. 29.  3. 15.  0. 29. 11. 10.  3.  0.  0.  0.  6.  0.
 11.  0.  0. 29. 29. 11. 29. 10.  3.  3. 11.  0. 10.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 25 11 10 29 29 11  0 10
 29 10 29  0 29  0  0 11  0  0  0 15  8  0  0  0 15 11  0  6  0  0  0  0
  0 15  0  0  0  3  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 26. 29.  8.  6.  9.  0.  5.  8.  0.  8. 10.  2. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 11. 15. 25. 11.  0.  0.  3.  0.  4.  0.  6.  8. 29.  0.  6.  1.  0.
 11.] 
adversary owned cards: [ 0  0  3  0 14  3 15  1  6  8  0 11  0  6 14  0 10 11 25 10 29  0  4  0
  0  0  0 11 16  8  3  0  0  8 11] -> size -> 35 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0.08011636883020401
desired expected reward: -5.721047401428223



