 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.63872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0        0        0
        0        0        0        0        0     -300        0        0] 
sum of rewards: -3000515 

action type: buy - action 6.0
Learning step: -120016.9765625
desired expected reward: -120107.4140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.88219 ]
 [105.73734 ]
 [ 98.48413 ]
 [ 72.24625 ]
 [114.97086 ]
 [105.6421  ]
 [ 98.38883 ]
 [ 98.228584]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.95498657226562



buy possibilites: [-1] 
expected returns: [[94.10056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.97085571289062






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[97.14809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.1005630493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.40152 ]
 [102.28528 ]
 [ 94.979996]
 [ 75.73849 ]
 [ 97.35303 ]
 [112.065895]
 [102.13121 ]
 [113.94973 ]
 [ 79.1736  ]
 [ 94.8453  ]
 [ 94.18346 ]
 [ 96.34426 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.08805847167969



buy possibilites: [-1] 
expected returns: [[83.56845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.94970703125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 96.132614]
 [111.41826 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.56845092773438



action possibilites: [-1] 
expected returns: [[108.44868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.04762268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.895676]
 [115.417404]
 [108.540924]
 [ 80.25136 ]
 [123.404724]
 [115.73158 ]
 [108.84262 ]
 [108.67351 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.44867706298828



buy possibilites: [-1] 
expected returns: [[102.08085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 123.40470886230469






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[105.45766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.08084869384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.77633 ]
 [114.329666]
 [107.3424  ]
 [ 70.45203 ]
 [110.005646]
 [122.34186 ]
 [113.96965 ]
 [123.97757 ]
 [ 90.9527  ]
 [106.99092 ]
 [105.521286]
 [105.90169 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.86990356445312



buy possibilites: [-1] 
expected returns: [[108.60781]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.97756958007812






Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [0. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [0. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 0.  0.  3.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[107.05681]
 [123.17607]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.6078109741211



action possibilites: [-1. 10.] 
expected returns: [[108.23988 ]
 [107.519775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.69548034667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.278946]
 [112.5143  ]
 [106.33168 ]
 [ 75.46842 ]
 [108.62487 ]
 [120.95929 ]
 [112.46774 ]
 [122.43266 ]
 [ 91.865585]
 [106.40645 ]
 [105.998535]
 [107.10963 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.23988342285156



buy possibilites: [-1] 
expected returns: [[111.02027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 122.43267822265625






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 95.51693]
 [112.13774]
 [114.10045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.  0.] 
cards in discard: [29. 29.  0.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.02027130126953



action possibilites: [-1. 11.] 
expected returns: [[100.31625]
 [117.92306]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [29. 29.  0.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 113.52125549316406



action possibilites: [-1] 
expected returns: [[152.53116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.46585083007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[144.7016 ]
 [159.1622 ]
 [152.41628]
 [126.14203]
 [154.78635]
 [170.11903]
 [159.1236 ]
 [171.79468]
 [137.24185]
 [152.24167]
 [151.7875 ]
 [154.4291 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.53115844726562



buy possibilites: [-1] 
expected returns: [[172.71251]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3. 10. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 171.79470825195312






Player: 1 
cards in hand: [ 0.  0. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 15.  0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  3.  3.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[117.52135]
 [120.64873]
 [134.59828]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 172.71250915527344



action possibilites: [-1] 
expected returns: [[119.587296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 140.257080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.17962 ]
 [122.977585]
 [ 81.82034 ]
 [129.88286 ]
 [122.61961 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.58729553222656



buy possibilites: [-1] 
expected returns: [[116.78407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 129.88290405273438






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[137.5192 ]
 [151.41238]
 [151.41238]
 [151.41238]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.78407287597656



action possibilites: [-1. 29. 29.] 
expected returns: [[142.40152]
 [156.6546 ]
 [156.6546 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 150.30166625976562



action possibilites: [-1. 29.] 
expected returns: [[166.69868]
 [182.63622]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 156.65460205078125



action possibilites: [-1.] 
expected returns: [[172.15433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 182.6361846923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[172.29895]
 [181.9986 ]
 [166.98074]
 [176.12492]
 [160.72559]
 [169.2373 ]
 [157.1259 ]
 [179.81427]
 [188.08359]
 [181.267  ]
 [205.39368]
 [189.09854]
 [162.76357]
 [171.33461]
 [175.3934 ]
 [162.5325 ]
 [173.4213 ]
 [174.2218 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 172.15432739257812



buy possibilites: [-1] 
expected returns: [[176.45747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 205.39369201660156






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10.  8. 11. 10.  0.  3.  0. 25. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10.  8. 11. 10.  0.  3.  0. 25. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10.  8. 11. 10.  0.  3.  0. 25. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[178.32846]
 [190.78864]
 [192.3405 ]
 [173.1538 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 29. 10.] 
cards in discard: [10.  8. 11. 10.  0.  3.  0. 25. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 176.4574737548828



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[132.1441  ]
 [144.00375 ]
 [127.568054]
 [127.568054]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 191.3080596923828



action possibilites: [-1] 
expected returns: [[151.57924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 10. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 150.0086212158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[138.64694]
 [115.83229]
 [153.71936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 10. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.57923889160156






Player: 1 
cards in hand: [ 3. 10. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15.  3.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[155.63783]
 [166.07455]
 [160.37321]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 10.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 29 10 29 10  8 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.7193603515625



action possibilites: [-1] 
expected returns: [[97.38075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 178.9700469970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 87.55783]
 [ 70.59087]
 [100.21141]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.38075256347656






Player: 1 
cards in hand: [ 8.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3. 15. 15.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [29. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[103.789505]
 [117.346176]
 [134.08936 ]
 [117.346176]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0.  0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.2114028930664



action possibilites: [-1] 
expected returns: [[133.19292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 11.  0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.6915740966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.06923 ]
 [144.64114 ]
 [139.04381 ]
 [114.601234]
 [150.01749 ]
 [145.07225 ]
 [139.42303 ]
 [138.09564 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0. 11.  0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.1929168701172



buy possibilites: [-1] 
expected returns: [[134.90546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0. 11.  0.] 
cards in discard: [10. 29. 11.  3.  3. 10. 10.  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 150.0175018310547






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[120.667496]
 [130.44836 ]
 [130.44836 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.90545654296875



action possibilites: [-1. 29. 11.] 
expected returns: [[104.45418]
 [115.56897]
 [113.35082]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.88916015625



action possibilites: [-1. 11.] 
expected returns: [[119.55851]
 [125.68332]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.56898498535156



action possibilites: [-1] 
expected returns: [[130.02664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.40431213378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[110.65222 ]
 [126.02536 ]
 [120.1179  ]
 [ 99.66039 ]
 [ 97.84146 ]
 [119.5202  ]
 [140.07915 ]
 [127.37189 ]
 [157.70105 ]
 [141.77287 ]
 [108.24504 ]
 [116.237335]
 [121.30341 ]
 [102.4663  ]
 [124.56653 ]
 [134.72572 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.02664184570312



buy possibilites: [-1] 
expected returns: [[197.29152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 157.7010498046875






Player: 1 
cards in hand: [ 3.  0.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 15.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 25.  8.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 25.  8.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 25.  8.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 25.  8.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[134.4033 ]
 [149.47614]
 [161.96361]
 [148.55362]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25.  8.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 15.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 197.29151916503906



action possibilites: [-1] 
expected returns: [[163.93437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8. 11. 29.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  8.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 15.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 161.8494415283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[175.14363]
 [175.15726]
 [152.00354]
 [178.38924]
 [166.6445 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 11. 29.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  8.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 15.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.9343719482422



buy possibilites: [-1] 
expected returns: [[150.58618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 11. 29.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 15.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 178.38922119140625






Player: 1 
cards in hand: [ 1.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 15.  0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 10. 10.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 15.  0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 10. 10.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 15.  0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  0. 15. 15.  3.  0. 10.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [10. 10. 10.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[122.879745]
 [119.31235 ]
 [119.31235 ]
 [119.31235 ]
 [138.28613 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3. 29.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.586181640625



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[160.48193]
 [156.99603]
 [156.99603]
 [156.99603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.28614807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.47331]
 [156.2829 ]
 [128.9343 ]
 [163.05415]
 [160.99455]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 160.48196411132812



buy possibilites: [-1] 
expected returns: [[148.46533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 11.  3.  0.  0.  0.  8. 25.  0. 11.  0.  8. 11. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 163.0541534423828






Player: 1 
cards in hand: [11.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  8. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11. 11.] 
expected returns: [[136.61578]
 [147.26102]
 [131.03625]
 [147.26102]
 [145.3229 ]
 [145.3229 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  8.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.46533203125



action possibilites: [-1.  8. 29. 11. 11. 10.] 
expected returns: [[133.81995]
 [133.001  ]
 [146.66762]
 [144.90813]
 [144.90813]
 [127.2034 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  8.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 146.15757751464844



action possibilites: [-1.  8. 11. 11. 10.  8.] 
expected returns: [[144.85164]
 [142.39551]
 [155.29218]
 [155.29218]
 [135.654  ]
 [142.39551]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  8.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 146.66757202148438



action possibilites: [-1] 
expected returns: [[138.79768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  8.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  8.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 161.98272705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.71147 ]
 [114.938446]
 [ 80.04245 ]
 [124.81534 ]
 [139.16806 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10.  8.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  8.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.7976837158203






Player: 1 
cards in hand: [ 6.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 15.  8.] 
cards in discard: [ 8. 15. 11.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 15 15 10  8  0  1  6 11 15  6  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [10. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 15. 11.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [10. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 15. 11.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [10. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 25.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
expected returns: [[129.69211]
 [132.87947]
 [159.89346]
 [132.87947]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  6.  3.  1.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.1680908203125



action possibilites: [-1] 
expected returns: [[92.15988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 10.  8.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  6.  3.  1.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.69357299804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 94.49416]
 [ 97.83519]
 [ 84.7023 ]
 [101.40459]
 [ 94.59778]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10.  8.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  5.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  6.  3.  1.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.15988159179688



buy possibilites: [-1] 
expected returns: [[145.30103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10.  8.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  4.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  6.  3.  1.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 101.40460205078125






Player: 1 
cards in hand: [ 3. 10.  6.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  3.  1.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  4.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.  1.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  4.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.  1.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  3. 29.] 
adversary cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[131.7403 ]
 [142.78633]
 [143.21698]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 29.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.301025390625



action possibilites: [-1. 11.] 
expected returns: [[133.73932]
 [142.93335]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 143.21697998046875



action possibilites: [-1] 
expected returns: [[191.84348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 146.82037353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[190.32129]
 [198.84885]
 [193.82866]
 [180.02257]
 [194.62894]
 [204.51398]
 [199.15565]
 [205.18834]
 [184.19217]
 [194.13544]
 [194.60846]
 [195.50449]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  5. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.84347534179688



buy possibilites: [-1] 
expected returns: [[217.57266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  8. 11. 10.  8.  8. 25. 10.  0.  0. 10. 10.  8. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 205.18836975097656






Player: 1 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 29. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 29. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 8. 15. 11.  3.  0.  8.  6.  6.  8.  3. 10.  6.  3.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11. 29. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 29. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[127.47449]
 [138.20512]
 [139.72903]
 [155.42073]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 217.57266235351562



action possibilites: [-1] 
expected returns: [[152.12984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.45901489257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.74916 ]
 [150.56863 ]
 [124.172104]
 [155.1311  ]
 [152.5336  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  3.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.1298370361328



buy possibilites: [-1] 
expected returns: [[126.3654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 155.13108825683594






Player: 1 
cards in hand: [8. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0 15 10  8  0  1  6 11 15  6  3  8  6  8 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0.  8. 10.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0.  8. 10.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0.  8. 10.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0.  8. 10.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 10.] 
expected returns: [[140.34149]
 [140.96518]
 [140.96518]
 [146.42027]
 [140.96518]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 10 29 10  8 25 10 11 10 25  8  8
 10  8 10 29  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [6. 0. 8.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 126.36540222167969



action possibilites: [-1] 
expected returns: [[136.46951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [6. 0. 8.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 145.42379760742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[128.71094]
 [115.81657]
 [137.38235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [6. 0. 8.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.46951293945312






Player: 1 
cards in hand: [3. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 6.] 
cards in discard: [6. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 6.] 
cards in discard: [6. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 6.] 
cards in discard: [6. 0. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8. 10. 25. 11.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25. 11.] 
expected returns: [[140.46632]
 [154.3059 ]
 [153.40094]
 [156.612  ]
 [149.18454]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 25. 11.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  6. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8. 15.  6.  0. 15.] 
adversary cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.38235473632812



action possibilites: [-1] 
expected returns: [[137.10652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  0. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8. 15.  6.  0. 15.] 
adversary cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0  3  6] -> size -> 20 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.61199951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.66493 ]
 [132.73718 ]
 [109.852554]
 [138.84044 ]
 [138.88962 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  0. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8. 15.  6.  0. 15.] 
adversary cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0  3  6] -> size -> 20 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.1065216064453






Player: 1 
cards in hand: [ 8. 15.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  0. 15.] 
cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 10  8  0  6 11 15  6  3  8  6  8 11  6  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  8. 29. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  8. 29. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  8. 29. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [6. 0. 8. 3. 3. 6. 0. 0. 6. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  8. 29. 29.  0.] 
adversary cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 29.] 
expected returns: [[102.48333]
 [106.40429]
 [106.40429]
 [110.24129]
 [110.24129]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 29.  0.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.88961791992188



action possibilites: [-1.  8.  8. 29. 29.] 
expected returns: [[123.98782]
 [130.58257]
 [130.58257]
 [135.06256]
 [135.06256]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0. 29.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.24127197265625



action possibilites: [-1.  8.  8. 29. 10.] 
expected returns: [[134.87236]
 [141.08987]
 [141.08987]
 [143.62772]
 [136.79492]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 29. 10.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.06256103515625



action possibilites: [-1.  8.  8. 10. 29.] 
expected returns: [[152.10426]
 [162.01207]
 [162.01207]
 [161.61462]
 [155.53242]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 10. 29.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10
  8 10 29  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 143.62771606445312



action possibilites: [-1] 
expected returns: [[175.38187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 163.19674682617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[167.89114]
 [177.79105]
 [175.03127]
 [151.92415]
 [182.22046]
 [177.61838]
 [174.62344]
 [175.93275]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  5.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 175.38186645507812



buy possibilites: [-1] 
expected returns: [[187.87549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.] 
cards in discard: [ 8. 25. 11. 29.  3.  0.  0. 11.  8. 10.  0. 10. 25.  0.  8. 10. 11.  0.
 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
adversary owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 182.22047424316406






Player: 1 
cards in hand: [ 0. 11.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 11. 10.] 
cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  0 11 15  6  3  8  6  8 11  6  0  3  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 6.  0.  8.  3.  3.  6.  0.  0.  6.  6.  0.  8.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[121.03395]
 [129.56969]
 [115.8561 ]
 [115.8561 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 187.87548828125



action possibilites: [-1] 
expected returns: [[110.16995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 133.70115661621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 66.14216 ]
 [ 29.954226]
 [113.602844]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.16995239257812






Player: 1 
cards in hand: [6. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  8. 11.  0.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 95.949295]
 [ 99.920715]
 [106.56259 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.  0.] 
cards in discard: [10. 11.  8.  0.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.60282897949219



action possibilites: [-1] 
expected returns: [[100.51521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.89164733886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 89.770294]
 [101.78916 ]
 [ 67.82907 ]
 [107.31213 ]
 [101.58562 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  2.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.51521301269531



buy possibilites: [-1] 
expected returns: [[113.93981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 0. 8. 8. 3.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 107.3121109008789






Player: 1 
cards in hand: [6. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 3.] 
cards in discard: [3. 6. 6. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  8  0 15  6  3  8  6  8  6  0  3  6  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 10. 10.  8.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [3. 6. 6. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 10. 10.  8.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [3. 6. 6. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 10. 10.  8.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 10.  8.] 
expected returns: [[126.05893 ]
 [129.59203 ]
 [135.90741 ]
 [123.976074]
 [123.976074]
 [129.59203 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 10.  8.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8.  3. 15.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
adversary owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.93981170654297



action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[148.66983]
 [140.1488 ]
 [140.1488 ]
 [146.09268]
 [158.73018]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 29.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8.  3. 15.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
adversary owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 129.39822387695312



action possibilites: [-1. 10.  8. 10.] 
expected returns: [[136.11742 ]
 [121.749725]
 [129.33766 ]
 [121.749725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8.  3. 15.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
adversary owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 144.94712829589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[104.31689]
 [119.52801]
 [ 87.0217 ]
 [130.13615]
 [137.0053 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  0.  8.  3. 15.] 
adversary cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
adversary owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 136.117431640625






Player: 1 
cards in hand: [10.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3. 15.] 
cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0 15  3  8  6  8  6  0  3  6  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  6  8  6  0  3  6  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [3. 6. 6. 0. 0. 6. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  6  8  6  0  3  6  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [3. 6. 6. 0. 0. 6. 8. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[133.57253]
 [143.37604]
 [146.80733]
 [147.27808]
 [147.27808]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 29.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.00527954101562



action possibilites: [-1. 11. 29. 25.] 
expected returns: [[154.64355]
 [163.36844]
 [164.25766]
 [176.33948]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 25.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  5. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 148.51370239257812



action possibilites: [-1] 
expected returns: [[100.120865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 25.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 13 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 176.33949279785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[101.20511 ]
 [109.33744 ]
 [106.1462  ]
 [ 84.50029 ]
 [111.22972 ]
 [108.215416]
 [101.85509 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  0. 25.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  4.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 13 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.12086486816406



buy possibilites: [-1] 
expected returns: [[130.9188]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  0. 25.] 
cards in discard: [10. 11.  8.  0.  8.  3. 10.  8. 11.  0.  3.  8.  0.  8. 10. 29. 29. 10.
  8. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 13 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.22970581054688






Player: 1 
cards in hand: [ 6.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 15.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  6  8  6  0  3  6  0  3  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 27. 30.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [6. 4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[108.37885]
 [ 90.59578]
 [118.80538]
 [ 90.59578]
 [119.84522]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [ 6.  4. 15.  6.  0.  0.] 
adversary owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.91879272460938



action possibilites: [-1. 10. 10.] 
expected returns: [[119.86909]
 [108.73578]
 [108.73578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [ 6.  4. 15.  6.  0.  0.] 
adversary owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 94.10986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 67.892586]
 [115.51947 ]
 [102.66444 ]
 [ 31.92597 ]
 [129.15694 ]
 [116.52328 ]
 [119.02555 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  3.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [ 6.  4. 15.  6.  0.  0.] 
adversary owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.8691177368164



buy possibilites: [-1] 
expected returns: [[141.77916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [ 6.  4. 15.  6.  0.  0.] 
adversary owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 129.15692138671875






Player: 1 
cards in hand: [0. 3. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 8.] 
cards in discard: [ 6.  4. 15.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  6  8  6  0  3  6  0  3  0  6  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8. 25.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  4. 15.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  6  6  0  0  6  4] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8. 25.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  4. 15.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  6  6  0  0  6  4] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8. 25.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  4. 15.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  6  6  0  0  6  4  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8. 25.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 25.] 
expected returns: [[107.06527 ]
 [124.88541 ]
 [121.179634]
 [121.179634]
 [136.5628  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  8. 25.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  4. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  6  0  0  6  4  0] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.77915954589844



action possibilites: [-1] 
expected returns: [[84.1406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  8. 10.  8.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8  6  6  0  0  6  4  0  6] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.4237823486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.59859 ]
 [79.61127 ]
 [83.440544]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  8. 10.  8.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8  6  6  0  0  6  4  0  6] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.1406021118164



buy possibilites: [-1] 
expected returns: [[96.346596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  8. 10.  8.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8  6  6  0  0  6  4  0  6] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 89.59861755371094






Player: 1 
cards in hand: [ 0.  8. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  6.  8.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  6  0  0  6  4  0  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 25. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 6 4 0 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 25. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 6 4 0 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 25. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 0 6 4 0 6 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 25. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 25. 10.] 
expected returns: [[ 79.118034]
 [ 91.27351 ]
 [ 80.73515 ]
 [109.35945 ]
 [ 74.23087 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 25. 10.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 4. 0. 6. 0.] 
adversary cards in discard: [6. 0. 8. 6. 8.] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0] -> size -> 10 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.34659576416016



action possibilites: [-1] 
expected returns: [[93.33323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 10.  8. 29.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 4. 0. 6. 0.] 
adversary cards in discard: [6. 0. 8. 6. 8. 6.] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6] -> size -> 11 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.35948181152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.8575  ]
 [58.87665 ]
 [93.323364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 10.  8. 29.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 4. 0. 6. 0.] 
adversary cards in discard: [6. 0. 8. 6. 8. 6.] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6] -> size -> 11 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.3332290649414






Player: 1 
cards in hand: [6. 4. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 0. 6. 0.] 
cards in discard: [6. 0. 8. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 6 4 0 6 0 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0. 11. 29.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 0. 6. 0.] 
cards in discard: [6. 0. 8. 6. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 6 4 0 6 0 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0. 11. 29.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 0. 6. 0.] 
cards in discard: [6. 0. 8. 6. 8. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0. 11. 29.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[ 98.625946]
 [102.251236]
 [102.251236]
 [103.05768 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11. 29.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.32337951660156



action possibilites: [-1. 11. 29.] 
expected returns: [[152.45724]
 [158.47827]
 [160.30835]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 94.30189514160156



action possibilites: [-1. 11.] 
expected returns: [[137.0122 ]
 [147.07751]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 8. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 140.32884216308594



action possibilites: [-1] 
expected returns: [[166.55681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 6. 8. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 135.1023712158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[144.25195]
 [156.11078]
 [127.33429]
 [167.15372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 6. 8. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.5568084716797






Player: 1 
cards in hand: [0. 6. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 8. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 0 6 4 0 6 0 6 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 4 0 6 0 6 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 4 0 6 0 6 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 0 6 4 0 6 0 6 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0. 10.] 
adversary cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  8. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 10.] 
expected returns: [[ 97.12683 ]
 [100.555176]
 [ 99.88483 ]
 [ 98.27883 ]
 [ 98.27883 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10.  0. 10.] 
cards in discard: [11. 11. 29.  0. 10. 10.  0.  0. 25.  3. 11.  8.  8. 10.  8. 25.  0. 11.
  8. 10.  8. 29.  3. 11.  0. 10. 15. 29. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [0. 8. 0. 8. 6.] 
adversary owned cards: [8 8 6 0 6 4 0 6 0 6 8 0] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.15374755859375



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[101.64299 ]
 [ 96.179306]
 [ 90.03595 ]
 [ 90.03595 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [0. 8. 0. 8. 6.] 
adversary owned cards: [8 8 6 0 6 4 0 6 0 6 8 0] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 100.6024169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 77.67141 ]
 [ 48.293056]
 [105.04667 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [0. 8. 0. 8. 6.] 
adversary owned cards: [8 8 6 0 6 4 0 6 0 6 8 0] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.64299011230469






Player: 1 
cards in hand: [6. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [0. 8. 0. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 0 6 4 0 6 0 6 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 25. 10.  8.  3.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [0. 8. 0. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 4 6 0 6 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 25. 10.  8.  3.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0. 8. 0. 8. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 6 4 6 0 6 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 25. 10.  8.  3.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.  8.] 
expected returns: [[46.692486]
 [52.72314 ]
 [72.66818 ]
 [49.00127 ]
 [52.72314 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10.  8.  3.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 4.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0] -> size -> 10 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.04667663574219



action possibilites: [-1] 
expected returns: [[54.62917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3. 11. 15.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 4.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.87632751464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.161373]
 [50.51656 ]
 [58.17243 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3. 11. 15.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 4.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.62916946411133



buy possibilites: [-1] 
expected returns: [[36.523617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3. 11. 15.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 4.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0   0   0] 
sum of rewards: 95 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 62.16134262084961






Player: 1 
cards in hand: [6. 8. 6. 6. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6. 4.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 29.  8. 29.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6. 4.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 29.  8. 29.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 29.] 
expected returns: [[67.605125]
 [76.94057 ]
 [77.65761 ]
 [73.50853 ]
 [77.65761 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  8. 29.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6. 6. 8. 6. 6. 4.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.523616790771484



action possibilites: [-1.  8. 29.] 
expected returns: [[112.310715]
 [112.515564]
 [118.25583 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6. 6. 8. 6. 6. 4.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 80.84813690185547



action possibilites: [-1.  8.] 
expected returns: [[130.5687 ]
 [132.36037]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6. 6. 8. 6. 6. 4.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 112.12577819824219



action possibilites: [-1] 
expected returns: [[113.61729]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6. 6. 8. 6. 6. 4.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 132.3603973388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[102.1586 ]
 [110.76524]
 [ 93.04086]
 [115.63097]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 0. 8.] 
adversary cards in discard: [6. 6. 8. 6. 6. 4.] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.6172866821289






Player: 1 
cards in hand: [6. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [6. 6. 8. 6. 6. 4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 29.  8. 10.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [6. 6. 8. 6. 6. 4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 29.  8. 10.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 8.] 
cards in discard: [6. 6. 8. 6. 6. 4. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10. 29.  8. 10.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8. 10.] 
expected returns: [[74.89689 ]
 [75.460594]
 [78.41554 ]
 [77.147354]
 [75.460594]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  8. 10.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6 3] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.63095092773438



action possibilites: [-1. 10. 10.] 
expected returns: [[132.34216]
 [131.0925 ]
 [131.0925 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6 3] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.67350006103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[123.360214]
 [129.80568 ]
 [116.938   ]
 [132.14572 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 0. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 6 4 6 0 6 8 0 6 3] -> size -> 12 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 132.3421630859375






Player: 1 
cards in hand: [6. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 6 4 6 0 6 8 0 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0. 25. 11.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 4 6 6 8 0 6 3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0. 25. 11.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 4 6 6 8 0 6 3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0. 25. 11.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 4 6 6 8 0 6 3 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0.  0. 25. 11.] 
adversary cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[66.132645]
 [53.17237 ]
 [72.251015]
 [68.930664]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25. 11.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 6. 3. 6.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [8 8 4 6 6 8 0 6 3 0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 132.14572143554688



Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 6 
Witch: 2 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  0.  0. 11. 11.  8.] 
cards in discard: [ 0. 29. 29.  8. 10. 10.  0. 25.  8. 10.  8.  3. 11. 15.  3. 11.  0.  0.
 29. 29.  8. 10.  8. 29.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 11 29 29 29 10  8 25 10 11 10 25  8  8 10  8
 10 29  8 11 10 10  8 11 11  0 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  0. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [8. 8. 6. 3. 6.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [8 8 4 6 6 8 0 6 3 0 6] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000045 

action type: take_action - action 25.0
Learning step: 119998.90625
desired expected reward: 120071.15625



