 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.684063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.409050941467285
desired expected reward: 29.10735321044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.15007 ]
 [20.963694]
 [20.593628]
 [19.13774 ]
 [22.125326]
 [21.681772]
 [21.311707]
 [21.919928]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.05473518371582



buy possibilites: [-1] 
expected returns: [[21.683905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 22.125329971313477






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.738726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.68390464782715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.696163]
 [23.509783]
 [23.139717]
 [21.683826]
 [23.068523]
 [24.671417]
 [24.22786 ]
 [24.760115]
 [23.204065]
 [23.857794]
 [24.017689]
 [24.466015]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.94301414489746



buy possibilites: [-1] 
expected returns: [[28.361032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.760114669799805






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.638762]
 [21.932861]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.361032485961914



action possibilites: [-1.] 
expected returns: [[26.928938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.19713020324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.196342]
 [26.009966]
 [25.639904]
 [24.184015]
 [25.56871 ]
 [27.1716  ]
 [26.72804 ]
 [27.260302]
 [25.704248]
 [26.35798 ]
 [26.517872]
 [26.966204]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.928937911987305



buy possibilites: [-1] 
expected returns: [[28.142038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.260299682617188






Player: 1 
cards in hand: [1. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.13754 ]
 [27.342943]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [4. 1. 3. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.142038345336914



action possibilites: [-1] 
expected returns: [[29.920443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [4. 1. 3. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.011533737182617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.592709]
 [29.40633 ]
 [29.036268]
 [27.58038 ]
 [30.567966]
 [30.124407]
 [29.754343]
 [30.362566]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [4. 1. 3. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.920442581176758



buy possibilites: [-1] 
expected returns: [[29.207026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [4. 1. 3. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.567964553833008






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [4. 1. 3. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [4. 1. 3. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.637283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.2070255279541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.103722]
 [25.917341]
 [25.547281]
 [24.091389]
 [25.476088]
 [27.07898 ]
 [26.63542 ]
 [27.167679]
 [25.61163 ]
 [26.265358]
 [26.425251]
 [26.873579]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.841571807861328



buy possibilites: [-1] 
expected returns: [[28.811214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.16767692565918






Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 4] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[33.8179]
 [34.0233]
 [34.0233]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 4. 3. 1.] 
adversary cards in discard: [22.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.811214447021484



action possibilites: [-1] 
expected returns: [[33.573433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 4. 3. 1.] 
adversary cards in discard: [22.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.527103424072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.819052]
 [32.26261 ]
 [30.806723]
 [33.35075 ]
 [33.58891 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 4. 3. 1.] 
adversary cards in discard: [22.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.57343292236328






Player: 1 
cards in hand: [0. 3. 4. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 3. 1.] 
cards in discard: [22.  0.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 3. 1.] 
cards in discard: [22.  0.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 3. 1.] 
cards in discard: [22.  0.  1.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 29. 29.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[28.24811 ]
 [27.64742 ]
 [28.538559]
 [28.538559]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29. 29.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10. 11. 11.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.58890914916992



action possibilites: [-1. 10. 29.] 
expected returns: [[29.698004]
 [29.08978 ]
 [29.992104]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.630361557006836



action possibilites: [-1. 10.] 
expected returns: [[35.478344]
 [34.870125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.992103576660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.74199 ]
 [34.555607]
 [34.18555 ]
 [32.729656]
 [34.114353]
 [35.717247]
 [35.273685]
 [35.805946]
 [34.249897]
 [34.903625]
 [35.063515]
 [35.511845]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.47835159301758



buy possibilites: [-1] 
expected returns: [[37.74031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 35.80594253540039






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[32.875862]
 [33.16996 ]
 [32.26764 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.74031066894531



action possibilites: [-1. 10.] 
expected returns: [[36.722298]
 [36.11408 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.277225494384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.09728 ]
 [35.9109  ]
 [35.540833]
 [34.084946]
 [35.469646]
 [37.072533]
 [36.62898 ]
 [37.161232]
 [35.605183]
 [36.25891 ]
 [36.418808]
 [36.867134]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [29. 29. 29.  0.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.72229766845703



buy possibilites: [-1] 
expected returns: [[32.42711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [29. 29. 29.  0.  3. 10.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.16123580932617






Player: 1 
cards in hand: [0. 0. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[35.447826]
 [35.65323 ]
 [35.65323 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 4. 22.  1.  3.  0.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.42710876464844



action possibilites: [-1] 
expected returns: [[35.42773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4. 22.  1.  3.  0.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.15703201293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.16137 ]
 [34.97499 ]
 [34.604927]
 [33.14904 ]
 [36.136627]
 [35.693066]
 [35.323006]
 [35.931225]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  8.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4. 22.  1.  3.  0.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.427730560302734



buy possibilites: [-1] 
expected returns: [[38.38148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  7.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4. 22.  1.  3.  0.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.13662338256836






Player: 1 
cards in hand: [ 4. 22.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 22.  1.  3.  0.] 
cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  7.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 22.  1.  3.  0.] 
cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  7.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 22.  1.  3.  0.] 
cards in discard: [16.  0.  0.  3.  0.  0. 15.  0.  0.  1.  8.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[31.70369 ]
 [31.997791]
 [31.997791]
 [31.997791]
 [31.997791]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.3814811706543



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[37.498646]
 [37.792747]
 [37.792747]
 [37.792747]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.07008361816406



action possibilites: [-1. 29. 29. 10.] 
expected returns: [[39.59043 ]
 [39.884533]
 [39.884533]
 [38.98221 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  3. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.792747497558594



action possibilites: [-1. 29. 10. 29.] 
expected returns: [[42.914684]
 [43.208782]
 [42.30646 ]
 [43.208782]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 10. 29.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.88452911376953



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[46.56618 ]
 [45.957954]
 [46.86028 ]
 [45.957954]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.20878219604492



action possibilites: [-1. 10. 10.] 
expected returns: [[51.795475]
 [51.187252]
 [51.187252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 5 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.86027908325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[50.050835]
 [50.86446 ]
 [49.68077 ]
 [50.494396]
 [49.397106]
 [49.0385  ]
 [50.42321 ]
 [52.026093]
 [51.582535]
 [52.768528]
 [52.11479 ]
 [50.558743]
 [50.21303 ]
 [51.212467]
 [49.399406]
 [51.372368]
 [51.82069 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9. 10.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.795475006103516



buy possibilites: [-1] 
expected returns: [[49.783936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 52.76852798461914






Player: 1 
cards in hand: [ 8.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  9.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 16.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[37.505283]
 [37.79938 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  1.  3.  0. 22.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.783935546875



action possibilites: [-1. 29.] 
expected returns: [[39.226357]
 [39.520454]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  1.  3.  0. 22.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.8759880065918



action possibilites: [-1.] 
expected returns: [[45.318363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  1.  3.  0. 22.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.52045822143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.46693 ]
 [44.280556]
 [43.09687 ]
 [43.91049 ]
 [42.8132  ]
 [42.454605]
 [43.8393  ]
 [45.44219 ]
 [44.998634]
 [46.184616]
 [45.53089 ]
 [43.974842]
 [43.62913 ]
 [44.628567]
 [42.81551 ]
 [44.78846 ]
 [45.23679 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  9.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  1.  3.  0. 22.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.318363189697266



buy possibilites: [-1] 
expected returns: [[49.369335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  1.  3.  0. 22.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 46.18461990356445






Player: 1 
cards in hand: [ 1.  1.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  0. 22.] 
cards in discard: [ 8.  8.  0.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  0. 22.] 
cards in discard: [ 8.  8.  0.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 29.  8. 10.  9.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  0. 22.] 
cards in discard: [ 8.  8.  0.  0.  0. 16. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29. 11. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 11.] 
expected returns: [[40.24821 ]
 [40.54231 ]
 [40.453613]
 [40.54231 ]
 [40.453613]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29.  3. 11.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.36933517456055



action possibilites: [-1. 11. 29. 11.] 
expected returns: [[43.017677]
 [43.22308 ]
 [43.311775]
 [43.22308 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 11.  3.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.59362030029297



action possibilites: [-1. 11. 11.] 
expected returns: [[47.139156]
 [47.344555]
 [47.344555]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  3.  0.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.3117790222168



action possibilites: [-1] 
expected returns: [[44.22527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.71168518066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.57476 ]
 [43.38838 ]
 [43.01832 ]
 [41.56243 ]
 [44.55002 ]
 [44.10646 ]
 [43.736393]
 [44.344616]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  6.  8.  8.  5. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.22526931762695



buy possibilites: [-1] 
expected returns: [[40.603485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  5.  8.  8.  5. 10. 10.  6.  9.  9.] 
adversary cards in hand: [ 4.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 18  0] 
sum of rewards: 73 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 44.55001449584961






Player: 1 
cards in hand: [ 4.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0. 11.  0.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  5.  8.  8.  5. 10. 10.  6.  9.  9.] 
adversary cards in hand: [11.  0. 10. 25. 10.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0. 11.  0.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  5.  8.  8.  5. 10. 10.  6.  9.  9.] 
adversary cards in hand: [11.  0. 10. 25. 10.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0. 11.  0.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 16. 16.  1.  1.  3.  0. 22. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11.  0. 10. 25. 10.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 10.] 
expected returns: [[38.046127]
 [38.25153 ]
 [37.43791 ]
 [38.993958]
 [37.43791 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 25. 10.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8. 10.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.603485107421875



action possibilites: [-1] 
expected returns: [[37.575108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.  0. 10.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.99395751953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.921696]
 [36.365253]
 [34.909367]
 [37.453392]
 [37.69155 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.  0. 10.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  0. 10. 11. 29. 29. 11.  3. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.57510757446289






Player: 1 
cards in hand: [ 0.  3. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29. 10. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29. 10. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  5.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29. 10. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 6. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  4.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [29. 10. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 10. 11. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 25. 29.] 
expected returns: [[37.41463 ]
 [37.708733]
 [36.806416]
 [37.620033]
 [38.362465]
 [37.708733]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 25. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  9.  8.  4.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16. 16. 22.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.691551208496094



action possibilites: [-1] 
expected returns: [[39.67496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16. 16. 22.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6 11  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.43407440185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.985996]
 [36.973663]
 [39.755856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [16. 16. 22.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6 11  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.67496109008789






Player: 1 
cards in hand: [16. 16. 22.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 22.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 22.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 16 15 11  8 16 10  6 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 25. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 10. 10.] 
expected returns: [[34.16291 ]
 [34.368305]
 [35.110737]
 [33.554688]
 [33.554688]
 [33.554688]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 10. 10.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  8.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8.  0.  0. 11.  0.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23  1] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.755855560302734



action possibilites: [-1] 
expected returns: [[42.54203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10.  3.  0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8.  0.  0. 11.  0.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23  1
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.1429328918457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.100376]
 [40.088043]
 [42.87023 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10. 10.  3.  0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 8.  0.  0. 11.  0.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23  1
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.542030334472656






Player: 1 
cards in hand: [ 8.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  0.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  4 22  8 15 11  8 16 10  6 11  6 23  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29. 11.] 
adversary cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[24.964796]
 [25.246145]
 [25.161335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.870235443115234



action possibilites: [-1. 11. 29.] 
expected returns: [[27.84654 ]
 [28.044113]
 [28.130053]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.246143341064453



action possibilites: [-1. 11.] 
expected returns: [[31.295496]
 [31.494558]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  5.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.13005256652832



action possibilites: [-1] 
expected returns: [[36.131466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.8531436920166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.525955]
 [35.314358]
 [34.16737 ]
 [34.95577 ]
 [33.892483]
 [33.545006]
 [34.886784]
 [36.43998 ]
 [36.010174]
 [37.159397]
 [36.52592 ]
 [35.018112]
 [34.68312 ]
 [35.651585]
 [33.894722]
 [35.80651 ]
 [36.24092 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  8.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.131465911865234



buy possibilites: [-1] 
expected returns: [[36.31141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 10. 11. 29.  3.  3. 25. 11. 10. 10. 10.  3.  0. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [ 4.  8. 10.  0.  1.] 
adversary cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 37.15939712524414






Player: 1 
cards in hand: [ 4.  8. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8. 10.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [25. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 10.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 30. 29.  8.  7.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [25. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 10.  0.  1.] 
cards in discard: [ 6. 11. 15.  3.  3.  3.  6. 23.  1. 16. 22.  0.  1.  6.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 29.  8.  7.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [25. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[40.959133]
 [41.90696 ]
 [41.16453 ]
 [41.25323 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  7.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10.  3.  1.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.31140899658203



action possibilites: [-1] 
expected returns: [[45.993053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10.  3.  1.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.95827102661133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.985924]
 [45.429478]
 [43.973587]
 [46.51762 ]
 [46.755775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [10.  3.  1.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.9930534362793






Player: 1 
cards in hand: [10.  3.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  1.  0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  4.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[45.41199 ]
 [45.70609 ]
 [44.803772]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  0.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [16.  8. 23.  0.  8.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.75577926635742



action possibilites: [-1. 10.] 
expected returns: [[47.21177]
 [46.60355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [16.  8. 23.  0.  8.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.70608901977539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[45.67741 ]
 [46.49103 ]
 [46.120968]
 [45.02368 ]
 [44.66508 ]
 [46.04978 ]
 [47.652668]
 [47.209103]
 [48.395096]
 [47.741367]
 [46.185318]
 [45.839603]
 [46.839046]
 [45.025986]
 [46.99894 ]
 [47.44727 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  7.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [16.  8. 23.  0.  8.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.21177291870117



buy possibilites: [-1] 
expected returns: [[45.664898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [16.  8. 23.  0.  8.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 48.39509582519531






Player: 1 
cards in hand: [16.  8. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 23.  0.  8.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6 23  1  6  3
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [25. 11. 10.  0. 29.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [25. 11. 10.  0. 29.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [25. 11. 10.  0. 29.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 29.] 
expected returns: [[32.217194]
 [33.13567 ]
 [32.416252]
 [31.631397]
 [32.502193]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  0. 29.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  6.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [11. 22.  3.  4.  0.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.66489791870117



action possibilites: [-1] 
expected returns: [[26.77738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 29. 25.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [11. 22.  3.  4.  0.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.13566970825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.209793]
 [24.276485]
 [26.860304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 29. 29. 25.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [11. 22.  3.  4.  0.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.777379989624023






Player: 1 
cards in hand: [11. 22.  3.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 22.  3.  4.  0.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [29. 11.  3. 10. 10.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  4.  0. 15.  3.  6.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [29. 11.  3. 10. 10.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  4.  0. 15.  3.  6.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [29. 11.  3. 10. 10.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  4.  0. 15.  3.  6.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [29. 11.  3. 10. 10.] 
adversary cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 11.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 10.] 
expected returns: [[38.504013]
 [38.78901 ]
 [38.70307 ]
 [37.914677]
 [37.914677]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10. 10.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 1. 6. 3.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.86030387878418



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[38.10583]
 [38.30489]
 [37.51649]
 [37.51649]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.  3.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 1. 6. 3.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.78901290893555



action possibilites: [-1] 
expected returns: [[37.20698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [6. 0. 1. 6. 3.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.66347885131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.507465]
 [34.539005]
 [37.200558]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25. 11. 29.  0.  0. 10. 11. 25. 29. 10.  0.  0.  0.  0. 25. 11. 10.  0.
 29. 29. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [6. 0. 1. 6. 3.] 
adversary cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.20698165893555






Player: 1 
cards in hand: [6. 0. 1. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 6. 3.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 3.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  8.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 3.] 
cards in discard: [ 6. 10. 10.  3.  1.  1.  0.  0.  8. 16.  8.  6.  0. 22. 11.  3.  4.  0.
 15.  3.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[40.45441 ]
 [39.846188]
 [40.65981 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.2005615234375



action possibilites: [-1] 
expected returns: [[40.43951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.06158447265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[38.954037]
 [39.397602]
 [37.941708]
 [40.485737]
 [40.7239  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  8. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0  8] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.439510345458984






Player: 1 
cards in hand: [ 6.  8. 10.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  8.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  1  4 22  8 15  8 16 10  6 11  6  1  6  3  6 10
  6  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  3. 29. 25. 25.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  3. 29. 25. 25.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  3. 29. 25. 25.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  3. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25. 25.] 
expected returns: [[42.046337]
 [41.438118]
 [42.34044 ]
 [42.99417 ]
 [42.99417 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 25. 25.] 
cards in discard: [10. 11. 10.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  5.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [22.  3.  0. 15.  3.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.72389602661133



action possibilites: [-1] 
expected returns: [[42.86835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 25. 10. 29.] 
cards in discard: [10. 11. 10.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [22.  3.  0. 15.  3.] 
adversary cards in discard: [8. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.994171142578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.17386 ]
 [40.161526]
 [42.943714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29. 25. 10. 29.] 
cards in discard: [10. 11. 10.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [22.  3.  0. 15.  3.] 
adversary cards in discard: [8. 8. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.868350982666016






Player: 1 
cards in hand: [22.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0. 15.  3.] 
cards in discard: [8. 8. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 25. 11. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0. 15.  3.] 
cards in discard: [8. 8. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 25. 11. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0. 15.  3.] 
cards in discard: [8. 8. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 25. 11. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25. 29. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 11. 10.] 
expected returns: [[41.729294]
 [42.677124]
 [42.023396]
 [42.677124]
 [41.934692]
 [41.12107 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 11. 10.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.9437141418457



action possibilites: [-1] 
expected returns: [[39.73293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 11. 10.  3. 11.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.677120208740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.089222]
 [37.10827 ]
 [39.804188]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 11. 10.  3. 11.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.73292922973633






Player: 1 
cards in hand: [ 3. 11.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  6.  0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  5. 10.  9.  1.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  4. 10.  9.  1.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  4. 10.  9.  1.  9.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[41.75809]
 [42.05219]
 [41.14987]
 [41.14987]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0. 10.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  4. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  4. 16.  0.  6.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 39.8041877746582



action possibilites: [-1. 10. 10.] 
expected returns: [[41.384907]
 [40.776684]
 [40.776684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  4. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  4. 16.  0.  6.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.052188873291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.592484]
 [40.40611 ]
 [40.036045]
 [38.580154]
 [39.96485 ]
 [41.56774 ]
 [41.124184]
 [41.656445]
 [40.100388]
 [40.754116]
 [40.914013]
 [41.36234 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  4. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  4. 16.  0.  6.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.38490676879883



buy possibilites: [-1] 
expected returns: [[44.873165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [10. 11. 10.  0.  0.  3. 25. 10.  3. 29. 25. 10. 29. 25. 29. 25. 11. 10.
  3. 11. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10.  4. 16.  0.  6.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.65644073486328






Player: 1 
cards in hand: [10.  4. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4. 16.  0.  6.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  6  1  6  3  6 10  6  0  8
  6  0  6 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  7.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4.  0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[41.48505 ]
 [42.43288 ]
 [41.77915 ]
 [41.690453]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.873165130615234



action possibilites: [-1] 
expected returns: [[46.534565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.43288040161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.062725]
 [45.506283]
 [44.0504  ]
 [46.594425]
 [46.83258 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.53456497192383






Player: 1 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10. 10. 29. 10. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10. 10. 29. 10. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 8.  8.  6.  0. 22.  3.  0. 15.  3.  6. 29. 11.  3.  6.  6.  0.  8. 16.
 10.  4.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [10. 10. 29. 10. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 10. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10. 11.] 
expected returns: [[41.85094 ]
 [41.24272 ]
 [41.24272 ]
 [42.14504 ]
 [41.24272 ]
 [42.056343]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 10. 11.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [4. 3. 8. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.832584381103516



action possibilites: [-1. 10. 10. 10. 11. 11.] 
expected returns: [[40.607235]
 [39.999012]
 [39.999012]
 [39.999012]
 [40.812637]
 [40.812637]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11. 11.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  1.  9.  9.] 
adversary cards in hand: [4. 3. 8. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.14504623413086



action possibilites: [-1] 
expected returns: [[44.65971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [4. 3. 8. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.267948150634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.880592]
 [41.86826 ]
 [44.65045 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [4. 3. 8. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.65970993041992






Player: 1 
cards in hand: [4. 3. 8. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 8. 1. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29. 29.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 8. 1. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29. 29.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[27.644802]
 [27.923592]
 [27.923592]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 29.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10. 22.  6. 16. 15.] 
adversary cards in discard: [4. 3. 8. 1. 1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.65045166015625



action possibilites: [-1. 25.] 
expected returns: [[35.305904]
 [36.224377]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  2.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10. 22.  6. 16. 15.] 
adversary cards in discard: [4. 3. 8. 1. 1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.746252059936523



action possibilites: [-1] 
expected returns: [[34.005165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10. 22.  6. 16. 15.] 
adversary cards in discard: [4. 3. 8. 1. 1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.22437286376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[32.455658]
 [33.234005]
 [32.879993]
 [31.487202]
 [32.811874]
 [34.345287]
 [33.92095 ]
 [34.4301  ]
 [32.94153 ]
 [33.719875]
 [34.14875 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  3. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10. 22.  6. 16. 15.] 
adversary cards in discard: [4. 3. 8. 1. 1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.005165100097656



buy possibilites: [-1] 
expected returns: [[34.366764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10. 22.  6. 16. 15.] 
adversary cards in discard: [4. 3. 8. 1. 1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 34.43009948730469






Player: 1 
cards in hand: [10. 22.  6. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 22.  6. 16. 15.] 
cards in discard: [4. 3. 8. 1. 1. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 22.  6. 16.] 
cards in discard: [4. 3. 8. 1. 1. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 22.  6. 16.] 
cards in discard: [4. 3. 8. 1. 1. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[26.222956]
 [25.64115 ]
 [25.64115 ]
 [25.64115 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.366764068603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.508753]
 [24.93309 ]
 [23.54242 ]
 [25.97405 ]
 [26.201847]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.22295570373535



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6
  0  6 29  8  6  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29. 25.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 11.] 
expected returns: [[20.229563]
 [20.50563 ]
 [21.119316]
 [20.50563 ]
 [20.42241 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 29. 11.] 
cards in discard: [25. 29. 11.  0.  0.  3. 25. 10. 29. 11. 10. 10. 10. 11. 29. 29. 29. 25.
  3.  0.  0.  0. 10. 10.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  1.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 8. 29.  8.  3.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.201847076416016



action possibilites: [-1] 
expected returns: [[48.326065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 8. 29.  8.  3.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.119314193725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.596115]
 [48.36597 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 8. 29.  8.  3.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.32606506347656






Player: 1 
cards in hand: [ 8. 29.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.  3.  0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[34.332996]
 [34.627094]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.36597442626953



action possibilites: [-1. 10.] 
expected returns: [[39.150448]
 [38.54223 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.37675857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[37.482597]
 [38.296215]
 [37.92616 ]
 [39.45785 ]
 [39.014297]
 [39.252453]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  4.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.150447845458984



buy possibilites: [-1] 
expected returns: [[31.449957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.457855224609375






Player: 1 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  9.] 
adversary cards in hand: [ 3. 29. 11. 29. 25.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 3. 29. 11. 29. 25.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 3. 29. 11. 29. 25.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 4.  3.  8.  1.  1.  6. 15. 10. 22.  6. 16.  0.  8.  6.  6.  6.  6.  8.
  8. 29.  3.  0.  6. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 3. 29. 11. 29. 25.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 25.] 
expected returns: [[28.509424]
 [28.79442 ]
 [28.708483]
 [28.79442 ]
 [29.427895]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 29. 25.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.4499568939209



action possibilites: [-1] 
expected returns: [[23.644869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 29. 10.  0.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.42789649963379





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.044401]
 [23.737494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11. 29. 10.  0.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.644868850708008






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  3.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25. 10.] 
expected returns: [[30.987642]
 [30.40583 ]
 [31.18418 ]
 [30.40583 ]
 [31.897356]
 [30.40583 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 25. 10.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [8. 3. 6. 3. 6.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.73749351501465



action possibilites: [-1] 
expected returns: [[29.528528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10. 10.  0.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [8. 3. 6. 3. 6.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.897354125976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.802   ]
 [29.571857]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 10. 10.  0.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [8. 3. 6. 3. 6.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.528528213500977






Player: 1 
cards in hand: [8. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 3. 6.] 
cards in discard: [11.  0.  0.  6.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 10. 10. 25. 29.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0. 25. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 6.] 
cards in discard: [11.  0.  0.  6.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 10. 10. 25. 29.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0. 25. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 3. 6.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 10. 10. 25. 29.] 
adversary cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0. 25. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 25. 29.] 
expected returns: [[24.58018 ]
 [24.85625 ]
 [24.009275]
 [24.009275]
 [25.4724  ]
 [24.85625 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 25. 29.] 
cards in discard: [25. 29.  3. 29. 11.  3. 11.  0.  0. 11. 29.  0.  0. 10. 25.  3. 29. 11.
 29. 10.  0. 25. 10. 11. 10. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11  0] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.571855545043945



action possibilites: [-1] 
expected returns: [[47.339363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11  0] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.47239875793457





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.70255 ]
 [47.472404]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11  0] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.33936309814453






Player: 1 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  4 22  8 15  8 16 11  1  6  3  6 10  6  0  8  6  0
  6 29  8  6  0  6  0  6 15  0 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[33.133965]
 [34.081795]
 [33.339367]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11.  0.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 6.  1. 10.  8. 11.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.47240447998047



action possibilites: [-1] 
expected returns: [[39.78149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.  3.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 6.  1. 10.  8. 11.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.08179473876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[38.124157]
 [38.93778 ]
 [38.567715]
 [40.09941 ]
 [39.655857]
 [39.894012]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 10.  3.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  2.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 6.  1. 10.  8. 11.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.781490325927734



buy possibilites: [-1] 
expected returns: [[37.525158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 10.  3.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 6.  1. 10.  8. 11.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.09941482543945






Player: 1 
cards in hand: [ 6.  1. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10.  8. 11.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6 10  6  0  8  6  0  6 29  8
  6  0  6  0  6 15  0 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 25.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 11.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 25.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 11.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [10.  0. 29. 11. 25.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 25.] 
expected returns: [[18.03668 ]
 [17.48187 ]
 [18.304958]
 [18.22405 ]
 [18.901274]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11. 25.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [22.  8.  6.  0.  1.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.5251579284668



action possibilites: [-1] 
expected returns: [[31.944233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11. 10. 29.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [22.  8.  6.  0.  1.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.901275634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.285627]
 [32.00059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29. 11. 10. 29.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [22.  8.  6.  0.  1.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.944232940673828






Player: 1 
cards in hand: [22.  8.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  6.  0.  1.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 29. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3. 25. 10.  0.
 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  1.  4. 15.  6.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 29. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3. 25. 10.  0.
 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  1.  4. 15.  6.] 
cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  1.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [29. 29. 29. 10. 10.] 
adversary cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3. 25. 10.  0.
 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 4 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 29. 29. 10. 10.] 
cards in discard: [25. 29. 10. 10. 29.  3.  0. 11. 25.  0.  0. 11.  0. 10.  3. 25. 10.  0.
 29. 11. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 29 29 10 11 25 25 10
 11 10 25 25 10 10 29 10 29 11 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 29.  8.  0.  8.  0.  6.  6.  2. 10.  9.  0.  9.  8.] 
adversary cards in hand: [ 8.  6.  0.  1.  4. 15.  6.] 
adversary cards in discard: [11.  0.  0.  6.  0.  0.  0.  8.  3.  6.  3.  6.  8.  0.  8.  6.  1. 11.
 11.] 
adversary owned cards: [ 0  3  3  3  1  4 22  8 15  8 16 11  1  3  6  6  0  8  6  0  6 29  8  6
  0  6  0  6 15  0 11  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1.0
Learning step: 13.889982223510742
desired expected reward: 45.89057159423828



