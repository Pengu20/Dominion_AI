 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.391938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000155 

action type: buy - action 0.0
Learning step: -120005.046875
desired expected reward: -120033.8515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 3.14936  ]
 [ 5.4690056]
 [-3.4572923]
 [ 4.5614214]
 [ 4.3633604]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.672785758972168



buy possibilites: [-1] 
expected returns: [[7.3956757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 5.469005584716797






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[5.774769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.3956756591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 6.480858  ]
 [11.886045  ]
 [ 8.900436  ]
 [ 3.6987145 ]
 [-0.10782385]
 [11.024955  ]
 [11.043593  ]
 [ 7.915288  ]
 [15.066439  ]
 [14.995726  ]
 [ 4.5967436 ]
 [10.995918  ]
 [ 7.1422644 ]
 [ 4.918847  ]
 [10.436489  ]
 [ 7.6453485 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.594944953918457



buy possibilites: [-1] 
expected returns: [[-0.27688432]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.066438674926758






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 5.915819]
 [13.323658]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 0.  0.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.2768843173980713



action possibilites: [-1] 
expected returns: [[-0.15429187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 0.  0.  3. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.556453704833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.03957796]
 [ 5.3170347 ]
 [ 2.3883712 ]
 [-2.6914444 ]
 [-6.3951674 ]
 [ 4.4781837 ]
 [ 4.523777  ]
 [ 1.4998591 ]
 [ 8.558572  ]
 [ 8.472403  ]
 [-1.8130475 ]
 [ 4.4256525 ]
 [ 0.7073126 ]
 [-1.5146468 ]
 [ 3.8946679 ]
 [ 1.1921546 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 0.  0.  3. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.15429186820983887



buy possibilites: [-1] 
expected returns: [[2.3453677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 0.  0.  3. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 8.558572769165039






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3. 15.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3. 15.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3. 15.  3.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.684935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.345367670059204





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.222158 ]
 [12.641739 ]
 [ 3.6334784]
 [11.656589 ]
 [11.38665  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.20238971710205



buy possibilites: [-1] 
expected returns: [[1.0294628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  0.  0.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 12.641738891601562






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  9. 10. 10. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.1610756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  6. 15.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.0294628143310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -4.036453 ]
 [  1.3495114]
 [ -1.6995983]
 [-10.565518 ]
 [  0.6328049]
 [ -2.361294 ]
 [ -3.2138376]
 [ -2.889603 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  6. 15.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.289879322052002



buy possibilites: [-1] 
expected returns: [[-1.7985386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  6. 15.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 1.3495142459869385






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6. 15.  0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3. 25.  3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3. 25.  3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3. 25.  3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [11.  0.  0.  3.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3. 25.  3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-7.684416  ]
 [-0.47086477]
 [-0.47086477]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  3.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14] -> size -> 15 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.7985385656356812



action possibilites: [-1] 
expected returns: [[0.08242178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.  0.  0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -1.7965495586395264





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.32296443]
 [ 5.3552895 ]
 [ 2.2521322 ]
 [-7.006591  ]
 [ 4.292618  ]
 [ 0.8646574 ]
 [ 0.16109872]
 [ 1.0177245 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  3.  0.  0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.08242177963256836



buy possibilites: [-1] 
expected returns: [[7.0530767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  3.  0.  0.] 
cards in discard: [1. 0. 3. 3. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 5.355291366577148






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 27. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.25135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3. 11.  0.  0.] 
adversary cards in discard: [6. 3. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.05307674407959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -4.4763107]
 [ -1.9492238]
 [-11.757636 ]
 [ -2.6810389]
 [ -3.2337058]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3. 11.  0.  0.] 
adversary cards in discard: [6. 3. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.0667572021484375



buy possibilites: [-1] 
expected returns: [[-6.9564886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3. 11.  0.  0.] 
adversary cards in discard: [6. 3. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -1.9492182731628418






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [15.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.  0.  0.] 
cards in discard: [6. 3. 6. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3] -> size -> 17 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 11.  0.  0.] 
cards in discard: [6. 3. 6. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3] -> size -> 17 
adversary victory points: 6
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.6485705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 14.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.956488609313965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-1.9760282 ]
 [ 3.8011944 ]
 [-5.242831  ]
 [ 0.6890271 ]
 [-4.689899  ]
 [-8.632285  ]
 [ 2.8818085 ]
 [ 2.7373922 ]
 [-0.76990867]
 [ 7.1629124 ]
 [ 7.1112013 ]
 [-3.7949533 ]
 [ 2.9417074 ]
 [-1.4867566 ]
 [-3.4077616 ]
 [ 2.2915456 ]
 [-0.6832757 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 14.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.109614372253418



buy possibilites: [-1] 
expected returns: [[-2.3277032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  7. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 14.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 147.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.162910461425781






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  0.  0.] 
cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  7. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [ 3.  3.  3.  0.  3.  0. 25.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.  0.  0.] 
cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  7. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [ 3.  3.  3.  0.  3.  0. 25.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.  0.  0.] 
cards in discard: [ 6.  3.  6.  3.  3.  0.  0. 15.  3. 11.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  7. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 25.  3.] 
adversary cards in discard: [ 3.  3.  3.  0.  3.  0. 25.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [ 0.  1.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-0.18131948]
 [ 6.481413  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 25.  3.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 25.  0.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  8. 10.  9. 10.  7. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14] -> size -> 18 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.3277032375335693



action possibilites: [-1] 
expected returns: [[-0.6223564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3.  1. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  7. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 6.017361640930176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.83057237]
 [ 4.928931  ]
 [ 1.7477167 ]
 [-3.7537205 ]
 [-7.8189545 ]
 [ 4.0251236 ]
 [ 3.9598277 ]
 [ 0.56647897]
 [ 8.255164  ]
 [ 8.1872835 ]
 [-2.7944772 ]
 [ 3.9375575 ]
 [-0.21262383]
 [-2.4918644 ]
 [ 3.3833501 ]
 [ 0.48914623]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3.  1. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  7. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6223564147949219



buy possibilites: [-1] 
expected returns: [[-4.955189]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3.  1. 25.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 8.255167007446289






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3. 15.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.16353464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 15.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.955189228057861





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-1.193676  ]
 [ 3.8364341 ]
 [ 1.0299785 ]
 [-7.306367  ]
 [ 2.9630897 ]
 [ 0.04867435]
 [-0.6359172 ]
 [-0.0418179 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 15.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.5027749538421631



buy possibilites: [-1] 
expected returns: [[-3.0955791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 15.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 3.8364365100860596






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6. 15.  3. 14.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6. 15.  3. 14.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6. 15.  3. 14.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.28705597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14] -> size -> 19 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.095579147338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-2.2317734e+00]
 [ 2.7981517e+00]
 [-7.4648857e-03]
 [-8.3424625e+00]
 [ 1.9244387e+00]
 [-9.9112308e-01]
 [-1.6751721e+00]
 [-1.0799192e+00]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14] -> size -> 19 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.5918862819671631



buy possibilites: [-1] 
expected returns: [[-3.808244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 25.  0.  1.  3.  3.  1. 25.  1.  0.  0.  3.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14] -> size -> 19 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 2.7981555461883545






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  3. 11.] 
cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  7. 10.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  3.] 
cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  7.  9.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.  3.] 
cards in discard: [ 6. 15.  3. 14.  3. 14.  0.  0.  0.  0.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 25. 30. 25. 30.  8.  7.  9.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 1.  0.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-11.412952 ]
 [ -4.6821833]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  7.  9.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16] -> size -> 20 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.808243989944458



action possibilites: [-1] 
expected returns: [[5.2612457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.734785556793213





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 7.987873 ]
 [13.224907 ]
 [ 4.972229 ]
 [10.323698 ]
 [ 5.5067673]
 [ 1.8169878]
 [12.4067335]
 [12.149013 ]
 [ 8.988184 ]
 [16.120813 ]
 [16.120588 ]
 [ 6.3192244]
 [12.3019   ]
 [ 8.37541  ]
 [ 6.5540266]
 [11.814369 ]
 [ 9.312136 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9. 10.  6. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.2612457275390625



buy possibilites: [-1] 
expected returns: [[9.980577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9. 10.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 16.120820999145508






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9. 10.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9. 10.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  0.  3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[0.6092894]
 [7.8885345]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.  3.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  6.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  1.] 
adversary cards in discard: [6. 8. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.98057746887207



action possibilites: [-1] 
expected returns: [[1.3727243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  1.] 
adversary cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.219566345214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-1.1756907 ]
 [ 4.003829  ]
 [ 1.139863  ]
 [-7.331275  ]
 [ 3.0311067 ]
 [-0.0375154 ]
 [-0.6949682 ]
 [ 0.04484415]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  1.] 
adversary cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.3727242946624756



buy possibilites: [-1] 
expected returns: [[-10.267217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  1.] 
adversary cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.003828048706055






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  1.] 
cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  1.  3. 25.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [6. 8. 3. 0. 6. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.280291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.  1. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 15. 16.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -7.2056121826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.758026]
 [-21.085144]
 [-13.53913 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [25. 25.  1.  0.  1.  0.  0.  3.  1. 25.  3.  0.  0.  3.  0. 25.  1. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 15. 16.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -13.280290603637695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  0. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 15. 16.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.604763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  6. 14. 11.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -13.539129257202148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 5.152173 ]
 [10.6502   ]
 [ 2.0711396]
 [ 7.667989 ]
 [ 2.6274726]
 [-1.1456019]
 [ 9.775399 ]
 [ 9.552152 ]
 [ 6.204913 ]
 [13.772211 ]
 [13.75831  ]
 [ 3.4533646]
 [ 9.807289 ]
 [ 5.55791  ]
 [ 3.794525 ]
 [ 9.202831 ]
 [ 6.442274 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  5. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  6. 14. 11.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.802248239517212



buy possibilites: [-1] 
expected returns: [[5.875575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 3.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  6. 14. 11.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 13.772211074829102






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6. 14. 11.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  9.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6. 14.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  8.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6. 14.] 
cards in discard: [ 6.  8.  3.  0.  6.  3.  0.  6. 23. 14.  3.  0.  0.  1.  2. 16.  6.  3.
  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  8.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 1. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-6.492544 ]
 [ 0.5369687]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  0.  0.] 
cards in discard: [25.  1.  0.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  5.  8.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 2.  3.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.875575065612793



action possibilites: [-1] 
expected returns: [[8.182916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0.  0. 25.] 
cards in discard: [25.  1.  0.  0.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  4.  8.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 2.  3.  0.  3. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6] -> size -> 26 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.2828028202056885





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 6.9980726]
 [12.165336 ]
 [ 3.9075873]
 [ 9.295501 ]
 [ 4.390234 ]
 [ 0.7379124]
 [11.34021  ]
 [11.291299 ]
 [ 8.296936 ]
 [15.157251 ]
 [15.119064 ]
 [ 5.223954 ]
 [11.301728 ]
 [ 7.5850325]
 [ 5.5154095]
 [10.771532 ]
 [ 8.152947 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0.  0. 25.] 
cards in discard: [25.  1.  0.  0.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 24. 29. 25. 30.  8.  4.  8.  9.  9.  4. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 2.  3.  0.  3. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6] -> size -> 26 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.182915687561035



buy possibilites: [-1] 
expected returns: [[5.9648046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0.  0. 25.] 
cards in discard: [25.  1.  0.  0.  1.  3. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 24. 29. 25. 30.  8.  4.  8.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 2.  3.  0.  3. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6] -> size -> 26 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.15725326538086






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 2.  3.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3.  0.  3. 16.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  4.  8.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 25. 25.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3.  0.  3. 16.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 24. 29. 25. 30.  8.  4.  8.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 25. 25.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3.  0.  3. 16.] 
cards in discard: [ 6. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  4.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 25. 25.  0.] 
adversary cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 3.  1. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[1.9598477]
 [8.800537 ]
 [8.800537 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25. 25.  0.] 
cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  4.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16] -> size -> 27 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.964804649353027



action possibilites: [-1] 
expected returns: [[-3.1711082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  0.  3.  3.] 
cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 29. 25. 30.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 8.800539016723633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -4.307707  ]
 [  0.4307356 ]
 [ -2.2230723 ]
 [-10.1111765 ]
 [ -0.45792198]
 [ -3.2826593 ]
 [ -3.8792872 ]
 [ -3.098521  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 25.  0.  3.  3.] 
cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 24. 29. 25. 30.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.1711082458496094



buy possibilites: [-1] 
expected returns: [[-9.489937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 25.  0.  3.  3.] 
cards in discard: [25.  1.  0.  0.  1.  3. 25. 25.  1.  0.  0.  0.  0. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 30.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6] -> size -> 28 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 0.4307377338409424






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 6. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 30.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 23. 29. 25. 30.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 29.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 1.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 1.  1. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-6.2341595]
 [ 0.6982939]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25.  3.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 29.  8.  3.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  8. 14.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.489936828613281



action possibilites: [-1] 
expected returns: [[3.5591981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  8. 14.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.14575910568237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 1.9123924]
 [ 7.2565594]
 [ 4.334465 ]
 [-4.339059 ]
 [ 6.4032965]
 [ 6.2603493]
 [ 3.0703294]
 [10.298507 ]
 [ 0.18926  ]
 [ 2.396024 ]
 [ 5.838194 ]
 [ 3.1318967]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3. 10.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  8. 14.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.5591981410980225



buy possibilites: [-1] 
expected returns: [[-5.5088997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  3. 25.  3.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  8. 14.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 10.298505783081055






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 14.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  8. 14.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3. 25.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 14.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 14.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8. 14.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.1612122]
 [9.798925 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 29. 25. 29.  8.  2.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.  3.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -16.037067413330078



action possibilites: [-1] 
expected returns: [[-2.2288547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 29. 25. 29.  8.  1.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.  3.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.798928260803223





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -4.5490155 ]
 [  0.6535778 ]
 [ -2.3033495 ]
 [ -7.3871946 ]
 [-11.209156  ]
 [ -0.13791513]
 [ -0.18294907]
 [ -3.187996  ]
 [  3.5931008 ]
 [  3.519488  ]
 [ -6.447238  ]
 [ -0.4202919 ]
 [ -3.923709  ]
 [ -6.2959414 ]
 [ -0.78643394]
 [ -3.2592442 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 23. 29. 25. 29.  8.  1.  7.  9.  9.  3.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.  3.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.2288546562194824



buy possibilites: [-1] 
expected returns: [[-4.9555387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 29. 25. 29.  8.  1.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.  3.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 3.5931007862091064






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 6. 14.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.  3.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 29. 25. 29.  8.  1.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 25.  0.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  3.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 23. 29. 25. 29.  8.  1.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 25.  0.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  3.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  1.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 25.  0.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 0. 25.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-18.096195]
 [-12.028025]
 [-12.028025]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 25.  0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  1.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [16. 11.  6. 23.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0] -> size -> 33 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.955538749694824



action possibilites: [-1] 
expected returns: [[-12.821656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  0.  0.  0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [16. 11.  6. 23.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0  6] -> size -> 34 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -12.028020858764648





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.913845 ]
 [-11.090511 ]
 [-18.796665 ]
 [-13.784254 ]
 [-18.342081 ]
 [-11.834116 ]
 [-11.995913 ]
 [-14.876028 ]
 [ -8.268909 ]
 [ -8.3081875]
 [-17.533255 ]
 [-11.988373 ]
 [-15.4817   ]
 [-17.353214 ]
 [-12.403451 ]
 [-14.695079 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  0.  0.  0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  2.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [16. 11.  6. 23.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0  6] -> size -> 34 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.821656227111816



buy possibilites: [-1] 
expected returns: [[-18.58403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  0.  0.  0.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [16. 11.  6. 23.  3.] 
adversary cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0  6] -> size -> 34 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -8.268903732299805






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [16. 11.  6. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 23.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  6. 23.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6 23  2
 16  6 16  6  4  6  0  6  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  9. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  3. 25.  1.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0. 25. 25.
  0.  1. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  3. 25.  1.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0. 25. 25.
  0.  1. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.] 
cards in discard: [ 6. 16.  2.  3.  0.  3. 16.  6.  4.  0.  6.  1.  0.  0.  6.  0. 14.  6.
  0.  8. 14.  6.  0.  6. 14.  6.  3.  3.  6. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  3. 25.  1.] 
adversary cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0. 25. 25.
  0.  1. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [ 3.  1.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-19.65558]
 [-13.7713 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 25.  1.] 
cards in discard: [29. 25.  1.  1.  3.  3. 25.  3. 25.  3. 25. 25.  0.  0.  1.  0. 25. 25.
  0.  1. 25.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 16. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.584030151367188



action possibilites: [-1] 
expected returns: [[2.4555752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  1.  1. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 16. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -13.7712984085083





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 3.4131463 ]
 [ 8.838739  ]
 [ 0.07188821]
 [ 5.799124  ]
 [ 0.5479009 ]
 [ 7.9991884 ]
 [ 7.957946  ]
 [ 4.7992773 ]
 [11.94722   ]
 [11.8742075 ]
 [ 1.4915698 ]
 [ 7.816127  ]
 [ 4.0422783 ]
 [ 1.7175729 ]
 [ 7.360302  ]
 [ 4.6970863 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  1.  1. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  1.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 16. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.4555752277374268



buy possibilites: [-1] 
expected returns: [[2.9689238]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  1.  1. 25.] 
cards in discard: [25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 16. 16.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 11.947223663330078






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 16. 16.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16. 16.  4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16
  6 16  6  4  6  0  6  0  6 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 25. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  3.  0.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  4.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  3.  0.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  4.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  3.  0.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  4.] 
cards in discard: [3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  3.  0.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [25.  3.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[23.69646 ]
 [31.113422]
 [31.113422]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  1. 25.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  6. 14.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.968923807144165



action possibilites: [-1] 
expected returns: [[13.636192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 25. 25.  1.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  6. 14.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.113441467285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[11.008195]
 [16.054903]
 [13.164023]
 [ 8.241158]
 [15.294638]
 [15.212145]
 [12.295045]
 [18.800247]
 [ 9.160128]
 [14.962584]
 [11.593915]
 [ 9.267086]
 [14.645994]
 [12.311183]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 25. 25.  1.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  9.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  6. 14.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.636192321777344



buy possibilites: [-1] 
expected returns: [[-1.8557009]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 25. 25.  1.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  6. 14.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0. 240.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 287.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 18.80025291442871






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  6. 14.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  0. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  6. 14.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  9.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  0. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  6. 14.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  0. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-13.830802]
 [ -7.771699]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 25.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 1. 6. 3. 3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.8557008504867554



action possibilites: [-1] 
expected returns: [[-12.413139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0. 0.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 1. 6. 3. 3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.771697998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-13.424946 ]
 [ -8.968026 ]
 [-16.046963 ]
 [-11.479502 ]
 [-15.586522 ]
 [ -9.651284 ]
 [ -9.920528 ]
 [-12.604673 ]
 [ -6.4358883]
 [-14.872907 ]
 [ -9.8368025]
 [-13.113764 ]
 [-14.74294  ]
 [-10.191505 ]
 [-12.214923 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0. 0.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  8.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 1. 6. 3. 3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.413139343261719



buy possibilites: [-1] 
expected returns: [[-3.030172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0. 0.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 1. 6. 3. 3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0. 240.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 287.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -6.43588924407959






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 1. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 3. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  0.  3. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 3. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 29. 24. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  0.  3. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 3. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  0.  3. 25.] 
adversary cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [25. 25.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-16.947126]
 [-11.14622 ]
 [-11.14622 ]
 [-11.14622 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  3. 25.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 0. 2. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.030172109603882



action possibilites: [-1] 
expected returns: [[-20.414045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 25. 29.  3.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 0. 2. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -11.146219253540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.689758]
 [-20.479641]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3. 25. 29.  3.] 
cards in discard: [25. 25.  3.  1.  3.  1.  1. 25. 29. 25.  3.  0.  1. 25. 25.  1. 29. 25.
  3.  0.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 0. 2. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.414045333862305






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 0. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 2. 0. 0.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 2. 0. 0.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 2. 0. 0.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 6 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [25.  1.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-5.786351 ]
 [ 1.3759887]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -20.479637145996094



action possibilites: [-1] 
expected returns: [[14.177568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.3759868144989014





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[12.460235]
 [18.201614]
 [ 8.942692]
 [14.93194 ]
 [ 9.381875]
 [17.304157]
 [17.374605]
 [14.138121]
 [21.544256]
 [10.379284]
 [17.08391 ]
 [13.278334]
 [10.601688]
 [16.610968]
 [13.755182]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  7.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.177568435668945



buy possibilites: [-1] 
expected returns: [[37.72387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3. 16.  6.  6.  3.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0. 210.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 257.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 21.54425811767578






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  6.  3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  6  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6
 16  6  4  6  0  6  0  6 23  3  0  8  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  8.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 29.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 29.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 29.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 29. 29.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 3.  1.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[20.449055]
 [27.185387]
 [27.185387]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29. 29.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [14.  6. 23.  6.  6.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.72386932373047



action possibilites: [-1.] 
expected returns: [[29.87756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [14.  6. 23.  6.  6.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.32257080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[28.117474]
 [32.967773]
 [30.223595]
 [32.099163]
 [29.218887]
 [28.589561]
 [29.397114]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [14.  6. 23.  6.  6.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.877559661865234



buy possibilites: [-1] 
expected returns: [[26.455902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [14.  6. 23.  6.  6.] 
adversary cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 32.9677848815918






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [14.  6. 23.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 23.  6.  6.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 23.  6.  6.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 23.  6.  6.] 
cards in discard: [ 3.  0. 16.  8. 16.  4.  8.  6.  0.  0.  6. 14.  3.  6.  1.  6.  3.  3.
  0.  6.  0.  2.  0.  0.  8.  0. 16.  3.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0. 25.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [29. 25. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 25.] 
expected returns: [[-15.132275]
 [ -9.66083 ]
 [ -9.655418]
 [ -9.655418]
 [ -9.655418]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.455902099609375



action possibilites: [-1] 
expected returns: [[-1.5517796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25. 25. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -9.65541934967041





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.693164 ]
 [-1.4772674]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0. 25. 25. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.5517796277999878






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  1.  3.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  1.  3.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  1.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-9.389774 ]
 [-3.3219764]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  1.  3.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  3.  6. 23.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.477266550064087



action possibilites: [-1] 
expected returns: [[-2.0055156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  3.  0. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  3.  6. 23.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -3.3219780921936035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.4190495 ]
 [ 2.7784832 ]
 [-5.319312  ]
 [-0.05843949]
 [-4.77423   ]
 [ 1.9578631 ]
 [ 1.6718023 ]
 [-1.5127493 ]
 [ 5.6757956 ]
 [-4.001863  ]
 [ 1.9404466 ]
 [-2.092445  ]
 [-3.7169623 ]
 [ 1.4006083 ]
 [-1.1328989 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  3.  0. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  6.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  3.  6. 23.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.0055155754089355



buy possibilites: [-1] 
expected returns: [[-4.918826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  3.  0. 25.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  3.  6. 23.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0. 180.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 227.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 5.675797462463379






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  3.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3.  6. 23.] 
cards in discard: [ 6.  0.  0. 14. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  3.  1.  0.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 6. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  3.  1.  0.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0] -> size -> 40 
action values: 0 
buys: 2 
player value: 4 
card supply: [24. 22. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  3.  1.  0.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
adversary victory points: 6
player victory points: 0 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 21. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  3.  1.  0.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 25.  3.  1.  0.] 
adversary cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [25. 25.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-14.774044]
 [ -8.206024]
 [ -8.206024]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3.  1.  0.] 
cards in discard: [29. 25.  1.  1.  0.  0.  3.  3.  0. 29.  1. 29.  3.  1.  3. 25. 29. 25.
  0. 25. 25. 25. 29. 25.  0.  1.  1.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.918826103210449



action possibilites: [-1] 
expected returns: [[48.12819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.206022262573242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[44.26775 ]
 [50.329308]
 [46.784668]
 [49.596992]
 [46.315853]
 [45.30302 ]
 [45.690525]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  1.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.12818908691406



buy possibilites: [-1] 
expected returns: [[49.66866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  1.  0.  3. 25.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 50.32930374145508






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16
  6  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  9.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [25. 29. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[11.193602]
 [17.388256]
 [17.316769]
 [17.388256]
 [17.388256]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  3. 25.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 2. 3. 4. 0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.66865921020508



action possibilites: [-1] 
expected returns: [[3.2838113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 25. 25.  1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 2. 3. 4. 0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.388273239135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[0.9342692]
 [3.0967438]
 [2.0696433]
 [2.1601121]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 25. 25.  1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 19. 29. 23. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 2. 3. 4. 0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.283811330795288



buy possibilites: [-1] 
expected returns: [[-18.999668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 25. 25.  1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [6. 2. 3. 4. 0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 251 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 3.0967400074005127






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [6. 2. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 2. 3. 4. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 3. 4. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8. 10. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 3. 4. 0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-5.3205366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8.  9. 10.  9.] 
adversary cards in hand: [14. 16.  8.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.99966812133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -8.43584   ]
 [ -3.4551206 ]
 [-11.404284  ]
 [ -6.2520466 ]
 [-10.922542  ]
 [ -4.2185    ]
 [ -4.433339  ]
 [ -7.409768  ]
 [ -0.67355657]
 [-10.09857   ]
 [ -4.424741  ]
 [ -8.018055  ]
 [ -9.933892  ]
 [ -4.816674  ]
 [ -7.1382027 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  5.  7.  8.  9. 10.  9.] 
adversary cards in hand: [14. 16.  8.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.3205366134643555



buy possibilites: [-1] 
expected returns: [[-2.4803593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [14. 16.  8.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 240.   0.   0.   0.   0.   0.   0.   0. -30.   0.   0.
  32.   0.] 
sum of rewards: 237.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -0.6735522747039795






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [14. 16.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  8.  0.  6.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  8.  0.  6.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  8.  0.  6.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [1. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.189437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.4803593158721924





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.093919]
 [-10.560517]
 [-13.103044]
 [-17.281902]
 [-11.260151]
 [-11.516809]
 [-14.24831 ]
 [ -7.9636  ]
 [-16.560112]
 [-11.411976]
 [-14.770567]
 [-16.407875]
 [-11.799316]
 [-13.888266]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  4.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -13.189436912536621



buy possibilites: [-1] 
expected returns: [[-15.377146]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 240.   0.   0.   0.   0.   0.   0.   0. -40.   0.   0.
  32.   0.] 
sum of rewards: 227.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -7.96359920501709






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.  6.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.  6.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29. 25.] 
adversary cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
adversary victory points: 7
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  0. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[-27.504671]
 [-21.698147]
 [-21.710413]
 [-21.710413]
 [-21.698147]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 29. 25.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.  8.  0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.377145767211914



action possibilites: [-1] 
expected returns: [[-30.238312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 25.  0.  0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.  8.  0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -21.698148727416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-30.238312]
 [-27.110523]
 [-29.572756]
 [-28.020596]
 [-30.238312]
 [-30.238312]
 [-30.238312]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 25.  0.  0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 19. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.  8.  0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.238311767578125



buy possibilites: [-1] 
expected returns: [[-30.238312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 25.  0.  0.] 
cards in discard: [ 1. 25. 25.  3.  1.  0.  3. 25.  3. 25. 29. 25.  3. 25. 25.  1. 29.  0.
  3.  1.  1.  0. 29.  1.  0.  3.  3.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.  8.  0.] 
adversary cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 259 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -27.110519409179688






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 14.  8.  0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 14.  8.  0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 14.  8.  0.] 
cards in discard: [ 6.  0.  0. 14. 11.  1.  0. 23.  1.  3.  3.  6.  0.  1. 11. 16.  0.  0.
  0. 10.  6.  2.  3.  4.  0.  0. 14. 16.  8.  0.  6.  6. 16.  3.  0.  6.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 0.  1. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[25.393894]
 [32.233826]
 [32.233826]
 [32.352753]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29. 25.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.238311767578125



action possibilites: [-1] 
expected returns: [[25.94141]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.352745056152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.097727]
 [28.940067]
 [25.653841]
 [28.041819]
 [28.032772]
 [24.650637]
 [32.201656]
 [20.98596 ]
 [23.814394]
 [27.341137]
 [24.48155 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  3.  7.  8.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.941410064697266



buy possibilites: [-1] 
expected returns: [[30.938362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 29.  0. 29.] 
cards in discard: [29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.20164489746094






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 11 14  6  3 14  6 14 16  6  8  6  2 16  6 16  6
  4  6  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 25. 25. 25.  0.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 25. 25. 25.  0.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 25. 25. 25.  0.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 3. 25. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-11.185783 ]
 [ -4.8067684]
 [ -4.8067684]
 [ -4.8067684]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25. 25.  0.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.93836212158203



action possibilites: [-1] 
expected returns: [[-0.9222671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  0. 25. 29.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.806763648986816





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6165564]
 [-1.3220971]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 25.  0. 25. 29.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.9222670793533325






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 22. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [8. 3. 6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [8. 3. 6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [25. 25.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-22.560215]
 [-16.682545]
 [-16.682545]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  1.  1.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  6.  0.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.3220932483673096



action possibilites: [-1] 
expected returns: [[-12.942301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  1.  0.  3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  6.  0.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.68254280090332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.121319 ]
 [ -9.662021 ]
 [-16.743168 ]
 [-12.176117 ]
 [-16.282724 ]
 [-10.34796  ]
 [-10.617204 ]
 [-13.301056 ]
 [ -7.123293 ]
 [-15.569145 ]
 [-10.526022 ]
 [-13.810119 ]
 [-15.4391985]
 [-10.888182 ]
 [-12.91148  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1.  0.  3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  2.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  6.  0.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.942300796508789



buy possibilites: [-1] 
expected returns: [[-12.586914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1.  0.  3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  6.  0.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0. 180.   0.   0.  20.   0.   0.   0.   0. -70.   0.   0.
  32.   0.] 
sum of rewards: 157.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -7.123290061950684






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3. 16. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 11.  6.  0.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  3 11 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6
  0  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  8.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  1.  3.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  1.  3.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  1.  3.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-30.238312]
 [-24.707857]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  1.  3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [4. 6. 0. 1. 8.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.5869140625



action possibilites: [-1.] 
expected returns: [[-28.834404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [4. 6. 0. 1. 8.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.331436157226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-29.871498]
 [-28.116638]
 [-29.158463]
 [-28.84023 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 18. 29. 21. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [4. 6. 0. 1. 8.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -28.83440399169922



buy possibilites: [-1] 
expected returns: [[-27.597473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [4. 6. 0. 1. 8.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 161 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -28.11663818359375






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [4. 6. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 0. 1. 8.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  4  6  0
  6  0  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 25. 25.] 
adversary cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
adversary victory points: 8
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-29.64777 ]
 [-23.830223]
 [-23.830223]
 [-23.830223]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 25. 25.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 23.  6.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -27.59747314453125



action possibilites: [-1] 
expected returns: [[-26.642475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 25.  1.  0.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 23.  6.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -23.830223083496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-27.757044]
 [-23.347538]
 [-25.828342]
 [-24.048512]
 [-24.260368]
 [-26.915684]
 [-20.856018]
 [-29.083378]
 [-27.424833]
 [-24.553476]
 [-26.642473]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 25.  1.  0.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  1.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 23.  6.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.642475128173828



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 9 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  0. 25. 25.  1.  0.] 
cards in discard: [29. 25.  0.  1. 29. 29.  0. 29. 25.  3. 25. 25.  0. 25. 29. 29. 25. 25.
  1.  1.  1.  0.  3.  1.  1.  3. 29.  0.  3.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25 25  3  1  1  3 25 25  1  1 25  1 25
 25  1 29 25 25 25 29 29 29  1 29  1  3 29 29  1 29 29  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 18. 29. 20. 29.  8.  0.  7.  7.  7.  0.  0.  7.  8.  9. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 23.  6.] 
adversary cards in discard: [ 8.  3.  6.  3. 11.  0.  8.  0.  0. 11. 16.  3.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  3 14  6 14 16  6  8  6  2 16  6 16  6  6  0  6  0
  6 23  3  0  8  3  0  8  0  0  1  0  1 11 10  0  0  3 11] -> size -> 43 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[     -5 3000000       0     300       0       0      20       0       0
       0       0     -90       0       0      64       0] 
sum of rewards: 3000289 

action type: buy - action 29.0
Learning step: 120012.390625
desired expected reward: 119991.53125



