 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.427506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       8       0] 
sum of rewards: 3000033 

action type: buy - action 8.0
Learning step: 120008.3671875
desired expected reward: 119832.1171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  3.3413563]
 [ 19.29106  ]
 [  7.5155926]
 [-75.00292  ]
 [ 12.807846 ]
 [ 13.39728  ]
 [  4.821229 ]
 [ 26.235958 ]
 [ 11.5081625]
 [ 10.832296 ]
 [ 16.756826 ]
 [  1.4764175]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.6550703048706055



buy possibilites: [-1] 
expected returns: [[-4.316227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.2359619140625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-11.795434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.316226959228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.823011  ]
 [  5.0424347 ]
 [ -6.492038  ]
 [-81.69817   ]
 [ -0.64386964]
 [ -9.446798  ]
 [ -3.144299  ]
 [-11.926333  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -12.063053131103516



buy possibilites: [-1] 
expected returns: [[-11.229116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 5.0424394607543945






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-0.68604445]
 [21.75636   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.229116439819336



action possibilites: [-1.] 
expected returns: [[-15.213434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.36604118347168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-13.045816  ]
 [  2.6814656 ]
 [ -9.009956  ]
 [-84.18311   ]
 [ -3.5752556 ]
 [ -3.0524988 ]
 [-11.245716  ]
 [  9.335762  ]
 [ -4.8434114 ]
 [ -5.4841547 ]
 [  0.18878531]
 [-14.318323  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -15.213434219360352



buy possibilites: [-1] 
expected returns: [[24.755373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.33576774597168






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.229277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.755373001098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-12.342312  ]
 [  2.3744898 ]
 [ -8.05614   ]
 [-42.567936  ]
 [-85.9417    ]
 [ -3.264632  ]
 [ -2.7781572 ]
 [-11.516596  ]
 [  2.835402  ]
 [  8.478439  ]
 [ -4.4134336 ]
 [  0.96386385]
 [ -4.998494  ]
 [ -4.7270927 ]
 [  0.16713047]
 [-13.097248  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -12.424797058105469



buy possibilites: [-1] 
expected returns: [[7.4312763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -3.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 8.478443145751953






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.629164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.431276321411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -3.2522635]
 [ 11.345545 ]
 [  0.7687068]
 [-33.823227 ]
 [-78.24758  ]
 [  5.6955433]
 [  6.0066442]
 [ -2.366229 ]
 [ 11.578607 ]
 [ 17.273325 ]
 [  4.491911 ]
 [  9.793709 ]
 [  3.9499855]
 [  4.2013774]
 [  8.953046 ]
 [ -3.551753 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.6150269508361816



buy possibilites: [-1] 
expected returns: [[4.964631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6. 10.  9. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -3.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 17.27332878112793






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [23.  0.  0.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [23.  0.  0.  0.  1.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [23.  0.  0.  0.  1.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [23.  0.  0.  0.  1.  3. 14. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-0.5157068]
 [22.345371 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  3.] 
cards in discard: [29.  0.  0.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.964631080627441



action possibilites: [-1.] 
expected returns: [[2.5053496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.1683292388916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  4.8309784]
 [ 19.980885 ]
 [  9.00699  ]
 [-70.13822  ]
 [ 14.095335 ]
 [ 14.702343 ]
 [  6.3645   ]
 [ 26.389263 ]
 [ 12.933813 ]
 [ 12.301085 ]
 [ 17.761108 ]
 [  3.579783 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  6.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.505349636077881



buy possibilites: [-1] 
expected returns: [[8.106271]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  1.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.389263153076172






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [23.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  3.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-2.9039404]
 [16.218987 ]
 [16.218987 ]
 [16.218987 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.106270790100098



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-14.621417 ]
 [  7.0916157]
 [  7.0916157]
 [  7.0916157]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.785993576049805



action possibilites: [-1. 29. 29.] 
expected returns: [[-4.916712]
 [18.273226]
 [18.273226]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 7.0916032791137695



action possibilites: [-1. 29.] 
expected returns: [[25.904503]
 [47.98646 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.273223876953125



action possibilites: [-1.] 
expected returns: [[52.130745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.98645782470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 56.298542]
 [ 71.678856]
 [ 20.668722]
 [ 61.107994]
 [ 21.61238 ]
 [ 66.49697 ]
 [-24.76607 ]
 [ 66.18924 ]
 [ 66.959984]
 [ 57.758003]
 [ 72.51474 ]
 [ 77.94118 ]
 [ 65.15919 ]
 [ 70.540215]
 [ 64.514915]
 [ 64.81379 ]
 [ 69.83579 ]
 [ 55.596416]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  5.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.13074493408203



buy possibilites: [-1] 
expected returns: [[20.166761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 77.94116973876953






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-3.7567647]
 [18.235302 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14. 11.  1.  0.  3.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.16676139831543



action possibilites: [-1.] 
expected returns: [[27.601604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14. 11.  1.  0.  3.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.244342803955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 34.228935  ]
 [ 49.1648    ]
 [ -1.6996421 ]
 [ 38.542286  ]
 [ -0.60429025]
 [-44.12313   ]
 [ 43.674828  ]
 [ 44.27347   ]
 [ 35.813953  ]
 [ 49.76229   ]
 [ 55.122833  ]
 [ 42.570496  ]
 [ 47.907764  ]
 [ 41.96122   ]
 [ 42.24386   ]
 [ 47.17799   ]
 [ 33.527237  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  4.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14. 11.  1.  0.  3.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.601604461669922



buy possibilites: [-1] 
expected returns: [[46.998856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [14. 11.  1.  0.  3.] 
adversary cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -13.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.122833251953125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [14. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  1.  0.  3.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  3.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3.] 
cards in discard: [ 0. 23.  0.  3.  3.  0.  3.  3.  0.  0.  0. 10. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.165741]
 [43.507236]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.99885559082031



action possibilites: [-1. 29.] 
expected returns: [[21.962482]
 [43.97682 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.946495056152344



action possibilites: [-1. 29.] 
expected returns: [[38.511665]
 [60.193237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.976829528808594



action possibilites: [-1. 29.] 
expected returns: [[34.262463]
 [56.259674]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.193241119384766



action possibilites: [-1.] 
expected returns: [[27.31292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.259681701660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 30.073795 ]
 [ 45.179058 ]
 [ -3.4983869]
 [ 34.686783 ]
 [ -2.8501172]
 [ 40.026646 ]
 [-42.628445 ]
 [ 39.749485 ]
 [ 40.48825  ]
 [ 31.58517  ]
 [ 45.97184  ]
 [ 51.340805 ]
 [ 38.724464 ]
 [ 44.031982 ]
 [ 38.093426 ]
 [ 38.38617  ]
 [ 43.33016  ]
 [ 29.358253 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  3.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.31291961669922



buy possibilites: [-1] 
expected returns: [[30.69526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 51.340789794921875






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.07439 ]
 [48.001015]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.69525909423828



action possibilites: [-1.] 
expected returns: [[39.087395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.06108856201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 42.313675]
 [ 56.9675  ]
 [ 46.578712]
 [-33.389946]
 [ 51.568733]
 [ 52.16375 ]
 [ 43.861984]
 [ 62.925552]
 [ 50.510193]
 [ 49.918602]
 [ 54.9807  ]
 [ 41.811172]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  2.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.08739471435547



buy possibilites: [-1] 
expected returns: [[61.33165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.92554473876953






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  3.  0.] 
cards in discard: [11.  0.  0.  8. 23.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [11.  0.  0.  8. 23.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [11.  0.  0.  8. 23.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  9. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 3.] 
cards in discard: [11.  0.  0.  8. 23.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-4.6409473]
 [18.251266 ]
 [18.251266 ]
 [18.251266 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.33164978027344



action possibilites: [-1. 29. 29.] 
expected returns: [[-12.722137]
 [  9.935143]
 [  9.935143]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.481372833251953



action possibilites: [-1. 29.] 
expected returns: [[ 3.8771334]
 [22.649963 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.935144424438477



action possibilites: [-1. 29.] 
expected returns: [[40.920166]
 [58.117805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.649978637695312



action possibilites: [-1.] 
expected returns: [[30.506004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.117801666259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 31.855488 ]
 [ 45.507183 ]
 [  1.0976863]
 [ 36.496475 ]
 [  1.5343676]
 [ 40.75081  ]
 [-36.24542  ]
 [ 40.99853  ]
 [ 41.502907 ]
 [ 32.508995 ]
 [ 46.070927 ]
 [ 50.606663 ]
 [ 40.099224 ]
 [ 44.507896 ]
 [ 39.59704  ]
 [ 39.83     ]
 [ 43.88823  ]
 [ 32.645287 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 10 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  1.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.506004333496094



buy possibilites: [-1] 
expected returns: [[31.75592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 6 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.60664749145508






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [11.  0.  0.  8. 23.  0.  8. 10.  1.  3.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[66.861885]
 [85.98363 ]
 [85.98363 ]
 [85.98363 ]
 [85.98363 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.75592041015625



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 82.66254]
 [100.77536]
 [100.77536]
 [100.77536]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 78.54373168945312



action possibilites: [-1. 29.] 
expected returns: [[70.29628]
 [89.05908]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 95.57691955566406



action possibilites: [-1.] 
expected returns: [[112.57117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 83.50157165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[112.26351 ]
 [126.332825]
 [116.57699 ]
 [ 77.13097 ]
 [ 34.82898 ]
 [121.59774 ]
 [122.08182 ]
 [113.87781 ]
 [126.84129 ]
 [120.65014 ]
 [125.22414 ]
 [120.13791 ]
 [120.37553 ]
 [124.5694  ]
 [113.12285 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8. 10.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 112.5711669921875



buy possibilites: [-1] 
expected returns: [[161.1049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  0.  0.  0. 29. 29.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 126.84126281738281






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.5226665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 11. 10.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 47.98228454589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.7016513]
 [-72.01811  ]
 [ -2.9238398]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 11. 10.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.103390216827393



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11. 10.] 
cards in discard: [10. 14.  3.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.  8. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11.  0.] 
cards in discard: [10. 14.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 11.  0.] 
cards in discard: [10. 14.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  1.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[12.198701]
 [32.324127]
 [32.324127]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 29.] 
cards in discard: [29. 29.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 23.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.9238433837890625



action possibilites: [-1. 29. 29.] 
expected returns: [[ 2.469984]
 [22.233477]
 [22.233477]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.] 
cards in discard: [29. 29.  3.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 23.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.549650192260742



action possibilites: [-1.] 
expected returns: [[21.442677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 23.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.586986541748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.524046 ]
 [ 38.827675 ]
 [ 28.903694 ]
 [ -8.9224205]
 [-50.6246   ]
 [ 33.820374 ]
 [ 34.3603   ]
 [ 25.900599 ]
 [ 39.392513 ]
 [ 32.828827 ]
 [ 37.670803 ]
 [ 32.28091  ]
 [ 32.53508  ]
 [ 36.98671  ]
 [ 24.696257 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  9.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 23.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.442676544189453



buy possibilites: [-1] 
expected returns: [[70.10495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 23.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 39.392513275146484






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 23.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 23.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 23.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[79.01572]
 [95.26831]
 [95.26831]
 [95.26831]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.10494995117188



action possibilites: [-1. 29.] 
expected returns: [[112.77179]
 [127.90979]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 90.61666870117188



action possibilites: [-1. 25.] 
expected returns: [[124.85214]
 [136.54439]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 123.3542251586914



action possibilites: [-1] 
expected returns: [[86.088425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.5443878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[83.21913 ]
 [97.37689 ]
 [88.01848 ]
 [51.173088]
 [11.108066]
 [92.76316 ]
 [93.209076]
 [83.89292 ]
 [97.884735]
 [91.82133 ]
 [96.30863 ]
 [91.32482 ]
 [91.55514 ]
 [95.65684 ]
 [84.4519  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  7.  8.  8.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.08842468261719



buy possibilites: [-1] 
expected returns: [[97.32161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0. 29.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 97.88471984863281






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 14.  3.  0.  3.  0. 10.  8.  0. 11. 11.  0.  3.  0.  8.  0.  3. 23.
  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29. 25. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[13.061415]
 [29.80146 ]
 [25.443079]
 [29.80146 ]
 [29.80146 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  1. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.32160949707031



action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[-4.1445794]
 [ 7.885968 ]
 [12.103863 ]
 [12.103863 ]
 [ 7.885968 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 25.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.974042892456055



action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-1.3049247]
 [17.080826 ]
 [12.189959 ]
 [17.080826 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.] 
cards in discard: [ 1. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.413334846496582



action possibilites: [-1. 25. 29.] 
expected returns: [[29.368813]
 [44.30154 ]
 [49.232643]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.] 
cards in discard: [ 1. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.823698043823242



action possibilites: [-1. 25.] 
expected returns: [[27.849472]
 [42.691902]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 1. 25.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 29.432220458984375



action possibilites: [-1] 
expected returns: [[27.834019]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [ 1. 25.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.69191360473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.575193 ]
 [ 39.63099  ]
 [ 29.787357 ]
 [ -4.0740933]
 [-42.935802 ]
 [ 34.40027  ]
 [ 34.876904 ]
 [ 26.405972 ]
 [ 40.101788 ]
 [ 33.339806 ]
 [ 38.349724 ]
 [ 32.78987  ]
 [ 33.044975 ]
 [ 37.61508  ]
 [ 25.177309 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [ 1. 25.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  7.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.83401870727539



buy possibilites: [-1] 
expected returns: [[31.798588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [ 1. 25.  3. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 11.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0  6] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0 100   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 40.101776123046875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 11.  1.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11  8 11  8  0 10
  3  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[80.04367]
 [94.65986]
 [94.65986]
 [94.65986]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 29.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 11.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.798587799072266



action possibilites: [-1. 29. 29.] 
expected returns: [[149.05284]
 [162.50252]
 [162.50252]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 11.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 90.40704345703125



action possibilites: [-1.] 
expected returns: [[173.22598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 11.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.5252227783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[168.6882 ]
 [182.06287]
 [173.93869]
 [ 98.06026]
 [178.5375 ]
 [178.80466]
 [168.83655]
 [177.77223]
 [177.40286]
 [180.72678]
 [172.28969]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 11.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 173.22598266601562



buy possibilites: [-1] 
expected returns: [[112.29227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [23. 11.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 18.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 182.0628204345703






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [23. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11. 11.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 11.  0.  0. 11.] 
cards in discard: [ 6.  8.  3. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  3.] 
cards in discard: [ 6.  8.  3. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  3.] 
cards in discard: [ 6.  8.  3. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6] -> size -> 27 
action values: 0 
buys: 2 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  3.] 
cards in discard: [ 6.  8.  3. 11.  1. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[19.51649 ]
 [36.544014]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.29226684570312



action possibilites: [-1.] 
expected returns: [[33.596153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.602264404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 32.85596  ]
 [ 46.732113 ]
 [ 37.822918 ]
 [  3.9906168]
 [-32.714638 ]
 [ 42.296383 ]
 [ 42.60874  ]
 [ 32.733498 ]
 [ 47.108368 ]
 [ 41.34693  ]
 [ 45.641087 ]
 [ 40.8955   ]
 [ 41.104904 ]
 [ 44.97994  ]
 [ 34.64634  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  6.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.596153259277344



buy possibilites: [-1] 
expected returns: [[39.035744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 25.  3. 25. 25. 29. 29. 29. 29. 25.  0. 29. 29. 29.  1. 29. 29.  0.
  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 47.108367919921875






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  3.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-4.8849096]
 [10.265596 ]
 [10.265596 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  8. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.035743713378906



action possibilites: [-1] 
expected returns: [[9.70032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.655227661132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  9.368096]
 [ 23.444246]
 [ 13.924351]
 [-56.973114]
 [ 18.935917]
 [  9.836372]
 [ 16.990988]
 [  9.964369]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.70032024383545



buy possibilites: [-1] 
expected returns: [[-8.019615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  0.  3.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 23.444250106811523






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 6.  8.  3. 11.  1. 10. 23. 11.  0.  0. 11.  3.  1. 10. 10.  3.  0.  3.
  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[75.05583]
 [92.23027]
 [92.23027]
 [92.23027]
 [92.23027]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29. 29.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.019615173339844



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[32.006172]
 [50.69574 ]
 [50.69574 ]
 [50.69574 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.27421569824219



action possibilites: [-1. 29. 29.] 
expected returns: [[25.169289]
 [40.60368 ]
 [40.60368 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.383567810058594



action possibilites: [-1. 29.] 
expected returns: [[41.260254]
 [58.36408 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.09344482421875



action possibilites: [-1.] 
expected returns: [[38.800148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.43659973144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 37.668114]
 [ 51.47597 ]
 [ 42.33207 ]
 [  6.235982]
 [-32.982918]
 [ 46.98111 ]
 [ 47.402454]
 [ 38.34569 ]
 [ 51.95408 ]
 [ 46.05956 ]
 [ 50.425186]
 [ 45.5791  ]
 [ 45.801983]
 [ 49.786987]
 [ 38.928314]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  5.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.800148010253906



buy possibilites: [-1] 
expected returns: [[65.33437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 51.954063415527344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 1. 25.  1. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -85.54188537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[77.9256   ]
 [91.5639   ]
 [82.90823  ]
 [46.264095 ]
 [ 7.1808033]
 [87.572754 ]
 [87.79921  ]
 [78.10684  ]
 [91.86239  ]
 [86.694885 ]
 [90.560974 ]
 [86.29981  ]
 [86.48309  ]
 [89.94784  ]
 [80.83066  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  4.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.66600036621094



buy possibilites: [-1] 
expected returns: [[48.816734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 91.86238098144531






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  8.] 
cards in discard: [ 0. 14.  6.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  7.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[40.997562]
 [58.049484]
 [53.49261 ]
 [58.049484]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 29.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0. 10.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.816734313964844



action possibilites: [-1. 25.] 
expected returns: [[25.293612]
 [38.011032]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  0.] 
cards in discard: [ 1. 25.  0.  3. 25.  0.  0.  3. 29. 29. 29. 25. 25. 29. 29. 29. 29.  0.
 25. 29. 25.  1.  1.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 30.  8.  7. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0. 10.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.10979080200195



action possibilites: [-1] 
expected returns: [[29.134918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0. 10.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.01104736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 31.263275]
 [ 44.632565]
 [ 35.942356]
 [-39.765617]
 [ 40.992363]
 [ 32.141792]
 [ 39.237125]
 [ 32.83482 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0. 10.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.134918212890625



buy possibilites: [-1] 
expected returns: [[49.639496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25. 29.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 23.  0. 10.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.63256072998047






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 23.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23.  0. 10.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6] -> size -> 34 
action values: 0 
buys: 2 
player value: 4 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[41.14138 ]
 [55.491356]
 [55.491356]
 [51.469707]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 25.  0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 3. 1. 6.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.639495849609375



action possibilites: [-1. 25.] 
expected returns: [[46.412865]
 [60.247032]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 27. 30.  8.  6. 10.  6.  8.  3.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 3. 1. 6.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.266876220703125



action possibilites: [-1] 
expected returns: [[77.308685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  3.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 3. 1. 6.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.24702072143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[75.129654 ]
 [88.47965  ]
 [80.152695 ]
 [44.228348 ]
 [ 6.3857384]
 [84.61108  ]
 [85.008736 ]
 [75.36988  ]
 [88.85597  ]
 [83.89899  ]
 [87.54614  ]
 [83.50195  ]
 [83.68612  ]
 [86.96227  ]
 [77.965935 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  3.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 3. 1. 6.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.30868530273438



buy possibilites: [-1] 
expected returns: [[73.287506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 3. 1. 6.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 88.85597229003906






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 1. 3. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 1. 6.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 25. 29.  1.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 1. 6.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  9.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 25. 29.  1.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 1. 6.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 25. 29.  1.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 25. 25. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[75.47641 ]
 [89.693565]
 [86.01293 ]
 [86.01293 ]
 [89.693565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25. 29.  1.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.28750610351562



action possibilites: [-1. 25. 25. 29.] 
expected returns: [[ 8.7189455]
 [20.530064 ]
 [20.530064 ]
 [24.808277 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  1.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.52693176269531



action possibilites: [-1. 25. 29.] 
expected returns: [[-3.3997998]
 [ 8.488087 ]
 [12.766315 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.135719299316406



action possibilites: [-1. 29.] 
expected returns: [[-2.6549697]
 [14.147617 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.075166702270508



action possibilites: [-1.] 
expected returns: [[15.563248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 4 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.262998580932617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.715122]
 [ 26.1156  ]
 [ 17.498623]
 [-17.470377]
 [-54.769344]
 [ 22.005354]
 [ 22.29401 ]
 [ 12.91515 ]
 [ 26.474335]
 [ 21.1191  ]
 [ 25.108246]
 [ 20.70385 ]
 [ 20.896515]
 [ 24.496017]
 [ 14.953732]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  2.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.563247680664062



buy possibilites: [-1] 
expected returns: [[22.866804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 26.474308013916016






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  8.  9.  7. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 0. 14.  6.  0.  0.  3. 11. 10. 10.  0. 11.  0.  8.  0.  6. 15. 23.  0.
  3.  0. 10.  0.  6. 14.  6.  1.  3.  1.  6. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29.  0.] 
adversary cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [25. 29. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 29.] 
expected returns: [[17.30812 ]
 [29.613594]
 [34.178913]
 [29.613594]
 [34.178913]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 29.  0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.866804122924805



action possibilites: [-1. 25. 25.] 
expected returns: [[11.705207]
 [24.010677]
 [24.010677]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0.] 
cards in discard: [ 1. 29. 25.  3.  0.  0. 25. 29. 29. 25. 29. 25.  3.  0.  0.  1.  3.  1.
 25. 25.  1. 25. 29. 29. 29. 29.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  5. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.2952880859375



action possibilites: [-1] 
expected returns: [[51.36762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  4. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.01068687438965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 51.307503]
 [ 65.54681 ]
 [ 55.69612 ]
 [-23.71476 ]
 [ 61.11699 ]
 [ 52.632202]
 [ 59.08397 ]
 [ 51.668407]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 27. 30.  8.  4. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.367618560791016



buy possibilites: [-1] 
expected returns: [[45.862003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29. 29.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6] -> size -> 40 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 65.54680633544922






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  8.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [6. 8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29.  0.  1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[26.544655]
 [37.719585]
 [41.907658]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0.  1.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0. 15.] 
adversary cards in discard: [6. 8. 6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8] -> size -> 41 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.862003326416016



action possibilites: [-1. 25. 25.] 
expected returns: [[50.606937]
 [64.12717 ]
 [64.12717 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 25.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 27. 30.  8.  4. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0. 15.] 
adversary cards in discard: [6. 8. 6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8] -> size -> 41 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.427818298339844



action possibilites: [-1] 
expected returns: [[87.137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0. 15.] 
adversary cards in discard: [6. 8. 6. 1. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.12715148925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[82.775345]
 [96.35216 ]
 [87.63727 ]
 [12.912611]
 [92.62528 ]
 [83.29793 ]
 [90.944786]
 [84.83559 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0. 15.] 
adversary cards in discard: [6. 8. 6. 1. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.13700103759766



buy possibilites: [-1] 
expected returns: [[117.99611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0. 15.] 
adversary cards in discard: [6. 8. 6. 1. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 96.35212707519531






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0. 15.] 
cards in discard: [6. 8. 6. 1. 0. 3. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 25. 25. 25. 25.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0. 15.] 
cards in discard: [6. 8. 6. 1. 0. 3. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 25. 25. 25. 25.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 25. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 25.] 
expected returns: [[73.74758]
 [85.05945]
 [85.05945]
 [85.05945]
 [85.05945]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 25. 25.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  3. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [14. 10.  0. 11.  0.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6] -> size -> 42 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.99610900878906



action possibilites: [-1] 
expected returns: [[16.600557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 25. 29. 25.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [14. 10.  0. 11.  0.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.05945587158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 12.567938]
 [ 17.375666]
 [-54.972294]
 [ 12.715124]
 [ 14.82    ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 25. 29. 25.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 27. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [14. 10.  0. 11.  0.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.600557327270508



buy possibilites: [-1] 
expected returns: [[4.7800236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 25. 29. 25.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [14. 10.  0. 11.  0.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 17.375642776489258






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0. 11.  0.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  1. 29. 29.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  0.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  1. 29. 29.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 22. 30. 26. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 30. 26. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.700424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  6. 10.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: -150.18084716796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 26.711632 ]
 [ 40.03624  ]
 [ 31.304638 ]
 [ -0.4018898]
 [-35.71761  ]
 [ 35.587627 ]
 [ 35.870373 ]
 [ 26.617487 ]
 [ 40.354534 ]
 [ 34.63092  ]
 [ 38.904385 ]
 [ 34.18748  ]
 [ 34.393185 ]
 [ 38.237236 ]
 [ 28.049067 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  1.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  6. 10.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.700424194335938



buy possibilites: [-1] 
expected returns: [[46.949677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  6. 10.  0. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0 -20   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 40.354522705078125






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [11.  6. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10.  0. 14.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 10.  0. 14.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 10.  0. 14.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 0.1678667]
 [17.811958 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  3.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.949676513671875



action possibilites: [-1.] 
expected returns: [[26.550255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.719755172729492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 25.212843]
 [ 38.53743 ]
 [ 29.805859]
 [-37.163998]
 [ 34.37159 ]
 [ 25.185701]
 [ 32.688675]
 [ 26.55026 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.550254821777344



buy possibilites: [-1] 
expected returns: [[7.954816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 29. 25. 25.  0.  0. 29. 29.  1.  1. 29. 25.  0.  0. 25. 29. 29.  3.
 25.  1. 25. 25. 25. 29. 25. 29. 29. 25.  0.  1.  1.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 38.537418365478516






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 1. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-6.6619043]
 [13.0918865]
 [13.0918865]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.954815864562988



action possibilites: [-1.] 
expected returns: [[-11.736229]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 20. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.357363700866699





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-13.698742  ]
 [  0.3515153 ]
 [ -9.283476  ]
 [-44.506824  ]
 [-85.4774    ]
 [ -4.4585714 ]
 [ -3.9908369 ]
 [-12.560054  ]
 [ -5.4306087 ]
 [ -0.78686094]
 [ -5.945717  ]
 [ -5.706764  ]
 [ -1.459331  ]
 [-12.966291  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 20. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -11.736228942871094



buy possibilites: [-1] 
expected returns: [[26.737724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.  1.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: 138.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 0.3515186309814453






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29.  3. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  7.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29.  3. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29.  3. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [29. 25. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[52.439278]
 [70.92496 ]
 [66.178024]
 [70.92496 ]
 [70.92496 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  3. 29.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.73772430419922



action possibilites: [-1. 29. 29.] 
expected returns: [[63.985596]
 [81.44695 ]
 [81.44695 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 65.6621322631836



action possibilites: [-1. 29.] 
expected returns: [[33.40081 ]
 [51.721684]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.447509765625



action possibilites: [-1.] 
expected returns: [[50.467323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 32.5244026184082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 49.648327]
 [ 63.77469 ]
 [ 54.460434]
 [-21.053629]
 [ 59.604683]
 [ 50.24839 ]
 [ 57.681793]
 [ 50.66797 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1] -> size -> 39 
action values: 1 
buys: 1 
player value: 3 
card supply: [22. 19. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.467323303222656



buy possibilites: [-1] 
expected returns: [[53.31237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 23.  6.  3. 14.] 
adversary cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 63.77466583251953






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 23.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  6.  3. 14.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  0. 25. 25.  1.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  6.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 18. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  6.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 18. 30. 25. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  6.  3.] 
cards in discard: [ 6.  8.  6.  1.  0.  3.  3.  6.  1. 10.  0.  0. 15.  6.  3. 10. 14.  0.
 11.  0.  3.  0. 11.  6. 10.  0. 14.  0.  1. 11.  0.  0.  0. 11.  8.  0.
  6.  8.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.245583]
 [45.365852]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: -155.7375946044922



action possibilites: [-1.] 
expected returns: [[28.382364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 18. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.41058349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 25.057022]
 [ 38.31687 ]
 [ 29.966995]
 [-41.971786]
 [ 34.765663]
 [ 25.349836]
 [ 33.10307 ]
 [ 27.038658]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 18. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.38236427307129



buy possibilites: [-1] 
expected returns: [[-23.937183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 38.31685256958008






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  1.  1. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 17. 30. 24. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  1.  1. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29.  1.  1. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [29.  1.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[20.607134]
 [37.37194 ]
 [32.847042]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 25.  0.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.937183380126953



action possibilites: [-1.] 
expected returns: [[32.95299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 17. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.5057258605957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 30.719574 ]
 [ 44.236423 ]
 [  1.5286627]
 [ 35.756866 ]
 [  1.5386715]
 [-34.878883 ]
 [ 40.124935 ]
 [ 40.525265 ]
 [ 30.745731 ]
 [ 39.27492  ]
 [ 43.321205 ]
 [ 38.82757  ]
 [ 39.035095 ]
 [ 42.732883 ]
 [ 32.635193 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 17. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.9529914855957



buy possibilites: [-1] 
expected returns: [[24.856747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 16. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.   90.    0.    0.   20.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: 48.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.23642349243164






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 3.] 
cards in discard: [3. 0. 3. 0. 0. 6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 3.] 
cards in discard: [3. 0. 3. 0. 0. 6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3] -> size -> 50 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 16. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 3.] 
cards in discard: [3. 0. 3. 0. 0. 6. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 3.4103894]
 [16.494614 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 23. 30.  8.  2. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.856746673583984



action possibilites: [-1] 
expected returns: [[3.166368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1. 1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.494611740112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  1.8289318]
 [ 15.153528 ]
 [-26.101393 ]
 [  6.4219475]
 [-25.284592 ]
 [-60.338108 ]
 [ 10.704933 ]
 [ 10.987679 ]
 [  1.7347841]
 [  9.748221 ]
 [ 14.021683 ]
 [  9.304781 ]
 [  9.510494 ]
 [ 13.3545265]
 [  3.1663651]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1. 1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 16. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.166368007659912



buy possibilites: [-1] 
expected returns: [[-27.345253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1. 1.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 15. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14.  0.  3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.   90.    0.    0.   20.    0.    0.    0.    0.  -80.
   0.    0.   13.5   0. ] 
sum of rewards: 38.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 15.153539657592773






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10.  6. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 14.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 25. 25. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1. 25.  0.  3.  0.  0.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 15. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1. 25.  0.  3.  0.  0.
  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 15. 30. 23. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1. 25.  0.  3.  0.  0.
  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  3.] 
cards in discard: [3. 0. 3. 0. 0. 6. 0. 6. 6. 8. 3. 3. 6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1. 25.  0.  3.  0.  0.
  1.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[-63.532654]
 [-59.914978]
 [-59.914978]
 [-56.616287]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.] 
cards in discard: [29.  1.  1. 29.  0.  0.  1. 25.  3.  3. 25. 25.  1. 29. 29. 29. 25. 25.
  0.  3.  1. 29.  1. 25. 29.  1. 29.  1.  1.  0.  1. 25.  0.  3.  0.  0.
  1.  1. 25. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -137.8029327392578



action possibilites: [-1.] 
expected returns: [[-18.14256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -58.400856018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-17.916094 ]
 [ -3.3846893]
 [-13.1993885]
 [-82.8171   ]
 [ -7.9618263]
 [-17.282774 ]
 [-10.050364 ]
 [-17.669981 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 15. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -18.142559051513672



buy possibilites: [-1] 
expected returns: [[-37.805386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 25.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  6.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -3.3846752643585205






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  6.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 10.  6.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14. 10.  6.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29. 25. 25.] 
adversary cards in discard: [25. 25.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [29. 29. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25. 25.] 
expected returns: [[46.579956]
 [65.76209 ]
 [65.76209 ]
 [65.76209 ]
 [60.829323]
 [60.829323]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25. 25.] 
cards in discard: [25. 25.  1. 29.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -37.80538558959961



action possibilites: [-1. 29. 25. 25.] 
expected returns: [[36.34674 ]
 [54.13903 ]
 [49.227463]
 [49.227463]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.32996368408203



action possibilites: [-1.] 
expected returns: [[2.3522453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.68629455566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  0.77481365]
 [ 14.108019  ]
 [  5.3464365 ]
 [-75.19786   ]
 [  9.829591  ]
 [ 10.196639  ]
 [  1.289144  ]
 [  8.939429  ]
 [  8.489632  ]
 [ 12.471899  ]
 [  2.263206  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 14. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.352245330810547



buy possibilites: [-1] 
expected returns: [[40.961906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 13. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5.     0.     0.    90.     0.     0.    40.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: 38.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 14.10799789428711






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [10.  0. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 25.  1.] 
adversary cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 13. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.] 
adversary cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 13. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.] 
adversary cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 12. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.] 
adversary cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[57.020798]
 [69.14467 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 22. 30.  8.  1. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.  1. 14. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0  1] -> size -> 55 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -167.0299835205078



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 14 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  1.  1. 25.] 
cards in discard: [25. 25.  1. 29.  1. 29.  0. 25. 25.  1. 29. 29.  1.  1.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29 29 29 29 29 29 29 29 29 25 25 25
 25  1 25  1 25 25  1 25 25  1  1  3 25  1  1  1  1  1  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 22. 30.  8.  0. 10.  6.  6.  0.  0.  7.  9.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6.  0.  6.  6.  8.  3.  3.  6.  3. 14. 10.  6.  0.
  3.  0.  0.  0. 14. 10.  6.  1. 14. 10.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 23 14 10  0  3 11 11  8  0 10  3
  6  0  6 10  1  6  0  0 11  6 15  6 14 14  0  6  8  6  6  3  0  0  1  8
  3  3  0  6  3  0  1  6] -> size -> 56 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000105 

action type: take_action - action 25.0
Learning step: 120001.4296875
desired expected reward: 120070.578125



