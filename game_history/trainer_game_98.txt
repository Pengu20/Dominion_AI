 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.5641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   4  60   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: 608 

action type: buy - action 11.0
Learning step: 30.246267318725586
desired expected reward: 33.3209342956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[242.85571]
 [264.25854]
 [256.15775]
 [202.07228]
 [275.2796 ]
 [257.18347]
 [253.67   ]
 [278.32803]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.152876853942871
desired expected reward: 272.73345947265625



buy possibilites: [-1] 
expected returns: [[281.3562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.412270545959473
desired expected reward: 235.44342041015625






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.63367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.924346923828125
desired expected reward: 274.4318542480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.85938]
 [315.8203 ]
 [306.13882]
 [250.08716]
 [304.21432]
 [324.40994]
 [308.29987]
 [306.4957 ]
 [272.0737 ]
 [302.4653 ]
 [290.6118 ]
 [326.9703 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.135443687438965
desired expected reward: 312.7962646484375



buy possibilites: [-1] 
expected returns: [[296.2627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  0.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -7.044804573059082
desired expected reward: 297.16949462890625






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.76816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.3482084274292
desired expected reward: 287.91448974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[264.51053]
 [279.79004]
 [273.31256]
 [226.13373]
 [286.21432]
 [274.66785]
 [270.70938]
 [287.94672]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.403046607971191
desired expected reward: 283.3714904785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.2972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.035600662231445
desired expected reward: 278.9111022949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[284.71994]
 [304.18222]
 [295.47272]
 [244.16034]
 [293.71805]
 [311.8714 ]
 [297.90344]
 [296.26526]
 [264.5742 ]
 [292.74582]
 [282.17422]
 [313.5047 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.274333953857422
desired expected reward: 299.13616943359375



buy possibilites: [-1] 
expected returns: [[323.10052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 0 

action type: buy - action 16.0
Learning step: -7.416143894195557
desired expected reward: 286.3019714355469






Player: 1 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 16] -> size -> 13 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 16] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 16] -> size -> 13 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [16.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[268.9158 ]
 [254.49928]
 [254.49928]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -11.77879810333252
desired expected reward: 311.32171630859375



action possibilites: [-1] 
expected returns: [[318.4247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 13 

action type: gain_card_n - action 9
Learning step: -7.19802188873291
desired expected reward: 293.05352783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[290.47415]
 [308.46536]
 [301.93723]
 [254.56392]
 [316.48962]
 [302.2037 ]
 [299.10986]
 [319.15088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -9.561714172363281
desired expected reward: 308.8630065917969






Player: 1 
cards in hand: [4. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.27332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [4. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -10.141921043395996
desired expected reward: 309.0089111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[284.48862]
 [305.97546]
 [295.76596]
 [238.92642]
 [314.25427]
 [299.59796]
 [292.84415]
 [313.79114]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [4. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.796847343444824
desired expected reward: 309.9184265136719



buy possibilites: [-1] 
expected returns: [[262.10394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 16.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [4. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 11.0
Learning step: -10.515372276306152
desired expected reward: 303.73883056640625






Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [4. 3. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [4. 3. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [4. 3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.25348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -7.646639347076416
desired expected reward: 254.45730590820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[287.36548]
 [304.77316]
 [297.61377]
 [250.21143]
 [295.56128]
 [311.81613]
 [298.95886]
 [297.51447]
 [269.89508]
 [295.37946]
 [285.75726]
 [315.6301 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.4382963180542
desired expected reward: 303.275390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [4. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[355.8025 ]
 [352.13846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.400723457336426
desired expected reward: 306.2294006347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[335.7213 ]
 [352.509  ]
 [345.48553]
 [300.11044]
 [360.03577]
 [346.73233]
 [343.03098]
 [361.59473]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.444174766540527
desired expected reward: 344.0949401855469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  4.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  4.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  4.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[313.51456]
 [324.7496 ]
 [295.7558 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -12.996779441833496
desired expected reward: 348.59796142578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[289.75705]
 [255.4485 ]
 [315.29434]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -11.066267013549805
desired expected reward: 303.8728332519531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3. 25. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3. 25. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3. 25. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3. 25. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[210.80594]
 [209.29822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 3. 25. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 4.  0.  0. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -13.154627799987793
desired expected reward: 302.1396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[189.29626]
 [205.74556]
 [199.32834]
 [156.59215]
 [212.59467]
 [199.75688]
 [196.31683]
 [214.10237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 3. 25. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 4.  0.  0. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -7.959468841552734
desired expected reward: 201.74667358398438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 4.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  0. 14.  0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  0. 14.  0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  0. 14.  0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.83237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -5.519329071044922
desired expected reward: 208.58306884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[295.19553]
 [312.84625]
 [306.1549 ]
 [271.2383 ]
 [259.239  ]
 [303.39554]
 [321.69363]
 [306.43436]
 [333.66083]
 [305.13162]
 [278.51294]
 [287.7819 ]
 [303.90717]
 [268.5517 ]
 [294.3825 ]
 [325.95764]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -11.171814918518066
desired expected reward: 312.6411437988281



buy possibilites: [-1] 
expected returns: [[295.32706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 8 

action type: buy - action 25.0
Learning step: -9.638181686401367
desired expected reward: 324.0226135253906






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 29.  8. 10.  8.  8. 10.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 11.  4.  0.  0. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8. 10.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[372.56735]
 [391.75748]
 [372.8254 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8. 10.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -8.165637016296387
desired expected reward: 287.1614074707031



action possibilites: [-1] 
expected returns: [[232.3498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -18 

action type: gain_card_n - action 6
Learning step: -9.251788139343262
desired expected reward: 268.51605224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[210.70862]
 [172.81546]
 [240.22214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -7.668277740478516
desired expected reward: 224.6815185546875






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[284.5964 ]
 [263.87244]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 25 11 25  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 11. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -8.273658752441406
desired expected reward: 231.948486328125



action possibilites: [-1] 
expected returns: [[227.70142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 11. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -34 

action type: gain_card_n - action 1
Learning step: -6.915713787078857
desired expected reward: 199.86419677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[203.61552]
 [220.06744]
 [212.37988]
 [171.80191]
 [224.92122]
 [214.31049]
 [208.80936]
 [225.4261 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 11. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -8.631033897399902
desired expected reward: 219.0703887939453



buy possibilites: [-1] 
expected returns: [[221.8941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 11. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -41.0 

action type: buy - action 8.0
Learning step: -7.7729082107543945
desired expected reward: 206.53759765625






Player: 1 
cards in hand: [ 1.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11. 29.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0. 11.  0.] 
adversary cards in discard: [ 1.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11.  3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0. 11.  0.] 
adversary cards in discard: [ 1.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11.  3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0. 11.  0.] 
adversary cards in discard: [ 1.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[223.13266]
 [229.66779]
 [220.57466]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 11.  0.] 
cards in discard: [ 1.  8. 16.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -9.186601638793945
desired expected reward: 212.70750427246094



action possibilites: [-1] 
expected returns: [[259.61008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.  8.] 
cards in discard: [ 1.  8. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -42 

action type: take_action - action 25.0
Learning step: -7.626756191253662
desired expected reward: 219.73291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[223.67728]
 [239.29887]
 [233.92763]
 [193.08391]
 [230.75523]
 [247.97734]
 [233.77469]
 [232.59898]
 [209.9206 ]
 [232.18599]
 [223.77118]
 [250.9113 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  8.] 
cards in discard: [ 1.  8. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -9.722740173339844
desired expected reward: 249.8873291015625



buy possibilites: [-1] 
expected returns: [[217.4507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  8.] 
cards in discard: [ 1.  8. 16.  0.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -11 

action type: buy - action 15.0
Learning step: -6.845916748046875
desired expected reward: 216.92523193359375






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15. 25.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15. 25.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 29.  1.  3.  0. 11.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15. 25.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [15. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[170.79478]
 [150.0111 ]
 [181.63884]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  9.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3] -> size -> 22 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -10.131134033203125
desired expected reward: 207.31956481933594



action possibilites: [-1] 
expected returns: [[182.10696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  4.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -42 

action type: take_action - action 25.0
Learning step: -7.000311374664307
desired expected reward: 172.9540557861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[153.5932 ]
 [162.93466]
 [117.24133]
 [163.9485 ]
 [175.42812]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  4.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -7.537269592285156
desired expected reward: 174.5697021484375



buy possibilites: [-1] 
expected returns: [[203.20183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  8.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  4.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -24 

action type: buy - action 3.0
Learning step: -4.774692058563232
desired expected reward: 158.15997314453125






Player: 1 
cards in hand: [ 0.  3.  0. 14.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  4.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0. 16.  8.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 4.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[140.59924]
 [131.12123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: discard_down_to_3_cards - action 4
Learning step: -3.178804874420166
desired expected reward: 79.17289733886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.29217]
 [131.56721]
 [103.50669]
 [132.66785]
 [139.89078]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -5.970455169677734
desired expected reward: 131.4588165283203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[57.361984]
 [56.000282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  0.] 
cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -8.376795768737793
desired expected reward: 131.51402282714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.038918]
 [45.772903]
 [41.65196 ]
 [30.642248]
 [27.671232]
 [39.28366 ]
 [51.147255]
 [40.71889 ]
 [64.21374 ]
 [39.70851 ]
 [32.397366]
 [35.318176]
 [39.055916]
 [30.063807]
 [36.561115]
 [52.577404]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  0.] 
cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  8.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -4.142420291900635
desired expected reward: 50.32159423828125



buy possibilites: [-1] 
expected returns: [[62.780006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  0.] 
cards in discard: [ 3. 25. 15.  0.  3.  3.  8.  0. 25.  8.  0.  0. 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -2 

action type: buy - action 25.0
Learning step: -1.8981369733810425
desired expected reward: 62.31560134887695






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  8.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  7.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[104.562515]
 [ 94.294525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  7.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -3.5071685314178467
desired expected reward: 59.2728385925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.91042 ]
 [100.785515]
 [ 93.64129 ]
 [ 55.16906 ]
 [ 93.032326]
 [105.03094 ]
 [ 95.99907 ]
 [ 94.31787 ]
 [ 69.63373 ]
 [ 90.99087 ]
 [ 82.981064]
 [104.79275 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  7.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -5.487058639526367
desired expected reward: 96.06578063964844



buy possibilites: [-1] 
expected returns: [[168.6097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -47.5 

action type: buy - action 11.0
Learning step: -3.832828998565674
desired expected reward: 101.19810485839844






Player: 1 
cards in hand: [29.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  1.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11] -> size -> 21 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  1.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11] -> size -> 21 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  1.] 
cards in discard: [ 6. 14.  0.  3.  0.  4.  3.  3.  0.  6.  3.  0. 11.  0.  0.  3.  0. 11.
 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11] -> size -> 21 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[170.65501]
 [159.59924]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [11.  0.  8.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -7.325374126434326
desired expected reward: 161.28431701660156



action possibilites: [-1] 
expected returns: [[128.9784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: gain_card_n - action 0
Learning step: -2.8804798126220703
desired expected reward: 50.76939392089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.07275]
 [ 91.19632]
 [133.18062]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1
Learning step: -5.27294921875
desired expected reward: 123.7054443359375






Player: 1 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 15.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 15.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 15.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 25.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 15.] 
expected returns: [[70.41208 ]
 [58.596138]
 [76.92459 ]
 [51.162014]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  0. 15.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 25 11 25  8  1  8 15  3 25 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0. 10.] 
adversary cards in discard: [0. 6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -7.667549133300781
desired expected reward: 125.51306915283203



action possibilites: [-1] 
expected returns: [[145.91974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0. 10.] 
adversary cards in discard: [0. 6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.7635151147842407
desired expected reward: 69.7435302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.53282]
 [135.78407]
 [110.08948]
 [136.99457]
 [143.56458]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0. 10.] 
adversary cards in discard: [0. 6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1
Learning step: -5.799825191497803
desired expected reward: 140.1199188232422



buy possibilites: [-1] 
expected returns: [[193.7893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0. 10.] 
adversary cards in discard: [0. 6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -5.266380310058594
desired expected reward: 125.26641082763672






Player: 1 
cards in hand: [ 0.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 10.] 
cards in discard: [0. 6. 3. 0. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 11.  3.  1. 25.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [0. 6. 3. 0. 3. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 11.  3.  1. 25.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 6. 3. 0. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 11.  3.  1. 25.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 6. 3. 0. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 25. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 11.  3.  1. 25.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 6. 3. 0. 3. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 24. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 11.  3.  1. 25.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25. 11.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25.] 
expected returns: [[106.154396]
 [115.42897 ]
 [106.205864]
 [115.42897 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  3.  1. 25.] 
cards in discard: [11.  0.  8.  0.  0.  0.  0. 16.  3.  3.  0.  0.  8.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  8.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3] -> size -> 28 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -10.243241310119629
desired expected reward: 183.5460662841797



action possibilites: [-1] 
expected returns: [[73.376305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1. 25.  0. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6] -> size -> 29 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -41 

action type: take_action - action 25.0
Learning step: -6.170481204986572
desired expected reward: 109.25848388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.423717]
 [67.05375 ]
 [63.828907]
 [41.74584 ]
 [69.95234 ]
 [63.408024]
 [61.610485]
 [70.64036 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1. 25.  0. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6] -> size -> 29 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1
Learning step: -4.273648262023926
desired expected reward: 69.10265350341797






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.74268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  6.  0.  1. 11.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -4.71393346786499
desired expected reward: 65.92642974853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[52.11285 ]
 [60.64519 ]
 [57.152763]
 [41.134697]
 [36.665966]
 [55.83192 ]
 [63.643223]
 [57.191994]
 [69.791626]
 [56.321934]
 [43.482   ]
 [48.39028 ]
 [55.006504]
 [39.887436]
 [50.676304]
 [63.43369 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 30. 24. 29.  8.  7.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  6.  0.  1. 11.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -4.363591194152832
desired expected reward: 58.662391662597656



buy possibilites: [-1] 
expected returns: [[34.55488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  6.  0.  1. 11.] 
adversary cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -363.0 

action type: buy - action 6.0
Learning step: -19.205814361572266
desired expected reward: 17.460155487060547






Player: 1 
cards in hand: [11.  6.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  1. 11.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 16.  8.  3.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  1. 11.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 16.  8.  3.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  1. 11.] 
cards in discard: [ 0.  6.  3.  0.  3.  0.  3. 10. 29.  0.  0.  0.  3.  3.  6. 15.  0.  0.
  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 16.  8.  3.] 
adversary cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[73.8331 ]
 [67.40641]
 [68.33756]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8.  3.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  3. 14.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0] -> size -> 31 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -3.2602646350860596
desired expected reward: 31.294612884521484



action possibilites: [-1] 
expected returns: [[82.70073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  3. 14.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.6577677726745605
desired expected reward: 71.7129135131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.95147 ]
 [65.11667 ]
 [83.368805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [25. 11.  3.  1. 25.  0. 15.  6.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  3. 14.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0] -> size -> 31 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -5.049798011779785
desired expected reward: 77.65093231201172






Player: 1 
cards in hand: [11.  3.  3. 14.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 14.  4.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  4.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  4.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  4.] 
cards in discard: [14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[45.363037]
 [40.82245 ]
 [28.975266]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -6.943864345550537
desired expected reward: 76.42495727539062



action possibilites: [-1] 
expected returns: [[68.05829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.7268149852752686
desired expected reward: 36.43571090698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.42705 ]
 [42.710293]
 [69.159355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -5.222306251525879
desired expected reward: 62.83598327636719






Player: 1 
cards in hand: [6. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 15.] 
adversary cards in discard: [ 8. 11.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 15.] 
adversary cards in discard: [ 8. 11.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[26.55404 ]
 [21.234932]
 [13.413145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  1. 15.] 
cards in discard: [ 8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -6.719917297363281
desired expected reward: 52.13155746459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.819312]
 [21.498995]
 [17.495693]
 [-7.437622]
 [23.948282]
 [17.978533]
 [13.986849]
 [22.920849]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  1. 15.] 
cards in discard: [ 8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  6.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.008571147918701
desired expected reward: 19.00200653076172



buy possibilites: [-1] 
expected returns: [[-13.155403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  1. 15.] 
cards in discard: [ 8. 11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  5.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -67 

action type: buy - action 11.0
Learning step: -4.843410968780518
desired expected reward: 19.104875564575195






Player: 1 
cards in hand: [ 0.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3
 11 10  0  3  6 15  0 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  5.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  5.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  5.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  4.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[55.50757 ]
 [56.366665]
 [67.12948 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 25.] 
cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  6.  8.  4.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -2.170304536819458
desired expected reward: -15.32570743560791



action possibilites: [-1] 
expected returns: [[21.59872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 16.  0.] 
cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  4.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -64 

action type: take_action - action 25.0
Learning step: -6.056382179260254
desired expected reward: 60.790679931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.791533]
 [22.199827]
 [20.634449]
 [13.913095]
 [22.334612]
 [21.46308 ]
 [20.037365]
 [21.939226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 16.  0.] 
cards in discard: [ 8. 11. 11.  0.  3.  8.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  4.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -3.849933624267578
desired expected reward: 17.74878692626953






Player: 1 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  4.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [25. 16.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [25. 16.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [25. 16.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25. 16.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 25.] 
expected returns: [[17.890726]
 [23.663435]
 [11.605149]
 [23.663435]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  5.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11] -> size -> 35 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -4.399799346923828
desired expected reward: 17.5394287109375



action possibilites: [-1] 
expected returns: [[23.200636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 25. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 25.0
Learning step: -3.3348190784454346
desired expected reward: 18.801843643188477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.696245]
 [29.330437]
 [17.94567 ]
 [29.152092]
 [33.99804 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 25. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -3.217468738555908
desired expected reward: 19.98316764831543






Player: 1 
cards in hand: [ 0.  0.  6.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  1. 10.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  1. 29.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 28. 30. 24. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [14.  0. 11.  3.  3. 14.  4.  6.  0.  3.  3.  0. 11. 15.  0.  0.  6.  6.
 11. 11.  0.  3.  3.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 28. 30. 23. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[10.722903]
 [ 8.293289]
 [11.658167]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 11.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -5.203378200531006
desired expected reward: 28.794652938842773



action possibilites: [-1] 
expected returns: [[31.944008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -40 

action type: gain_card_n - action 2
Learning step: -1.4126375913619995
desired expected reward: 1.2149168252944946





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.428127]
 [28.698341]
 [27.84919 ]
 [11.006427]
 [25.609898]
 [30.948948]
 [25.00184 ]
 [24.762644]
 [17.989635]
 [26.418995]
 [23.907133]
 [31.903534]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  8.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -3.1585872173309326
desired expected reward: 28.78542137145996



buy possibilites: [-1] 
expected returns: [[4.6750135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  7.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -42.0 

action type: buy - action 8.0
Learning step: -3.244903564453125
desired expected reward: 21.756925582885742






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  7.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11.  0. 11.  6.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  7.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11.  0. 11.  6.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11.  0. 11.  6.] 
adversary cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[ 3.3195972]
 [-1.7913032]
 [ 2.8285027]
 [ 2.8285027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 11.  6.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -3.3758351802825928
desired expected reward: 1.2991783618927002





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.4368334]
 [-25.295153 ]
 [  3.9489026]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 11.  6.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 22. 29.  8.  4.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -3.415264844894409
desired expected reward: -0.09567666053771973



buy possibilites: [-1] 
expected returns: [[7.074643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 11.  6.] 
cards in discard: [25. 16.  0.  0. 25. 15.  3.  3.  8. 11.  0.  1.  8.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 1. 6. 0. 3.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: -17.136547088623047
desired expected reward: -46.222023010253906






Player: 1 
cards in hand: [3. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 0. 3.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0. 3.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  6.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0. 3.] 
cards in discard: [8. 3. 3. 0. 0. 3. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[3.7185564]
 [3.6330113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  0.  6. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -4.020535945892334
desired expected reward: 3.054107189178467





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -1.1762409 ]
 [  2.0801005 ]
 [  1.5770078 ]
 [-11.23724   ]
 [  0.18002129]
 [  3.1054478 ]
 [ -0.23426199]
 [ -0.2672329 ]
 [ -4.247616  ]
 [  0.39807415]
 [ -0.66428614]
 [  3.7858362 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  0.  6. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.8985886573791504
desired expected reward: -0.18002557754516602



buy possibilites: [-1] 
expected returns: [[-24.102074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  1.] 
cards in discard: [15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [14.  0.  0.  6. 29.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -43 

action type: buy - action 15.0
Learning step: -2.6590828895568848
desired expected reward: -3.3233590126037598






Player: 1 
cards in hand: [14.  0.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6. 29.] 
cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0. 11. 16.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6. 29.] 
cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  5.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0. 11. 16.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6. 29.] 
cards in discard: [8. 3. 3. 0. 0. 3. 8. 3. 1. 6. 0. 3. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 15.  0. 11. 16.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16.] 
expected returns: [[-12.7015505]
 [-16.52678  ]
 [-15.744567 ]
 [-18.491741 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 11. 16.] 
cards in discard: [15. 11.  0.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -2.865532398223877
desired expected reward: -26.967605590820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-18.772621]
 [-14.343265]
 [-31.408003]
 [-19.63117 ]
 [-12.60874 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 11. 16.] 
cards in discard: [15. 11.  0.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.4728894233703613
desired expected reward: -16.174442291259766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 25.  8.  6. 11.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 25.  8.  6. 11.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
adversary victory points: 0
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[-18.128155]
 [-16.8779  ]
 [-20.746902]
 [-18.225616]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  6. 11.] 
cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -3.517120361328125
desired expected reward: -16.12586212158203



action possibilites: [-1] 
expected returns: [[-7.71507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  6.] 
cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: gain_card_n - action 0
Learning step: -3.235532760620117
desired expected reward: -26.99665641784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.137974]
 [-13.56111 ]
 [ -7.482068]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8.  6.] 
cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -2.5646584033966064
desired expected reward: -10.279727935791016






Player: 1 
cards in hand: [ 0. 11.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  6. 25.  3.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0. 11.  0. 25.  8.  6.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  6. 25.  3.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0. 11.  0. 25.  8.  6.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 21. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  6. 25.  3.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0. 11.  0. 25.  8.  6.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 8.  8.  6. 25.  3.] 
adversary cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0. 11.  0. 25.  8.  6.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  6. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[-10.577509]
 [ -8.213779]
 [ -8.213779]
 [ -9.274886]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6. 25.  3.] 
cards in discard: [15. 11.  0.  3.  0.  1.  0. 15.  0. 11. 16.  0. 11.  0. 25.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  3.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  4.  3.  6. 14.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3] -> size -> 42 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -4.570136070251465
desired expected reward: -12.052205085754395



action possibilites: [-1] 
expected returns: [[2.5369983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  4.  3.  6. 14.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: -3.229172945022583
desired expected reward: -12.50406551361084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.68049765]
 [-4.2679777 ]
 [ 3.4595242 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6.  4.  3.  6. 14.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -3.8375790119171143
desired expected reward: -1.3005807399749756






Player: 1 
cards in hand: [ 6.  4.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  4.  3.  6. 14.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [16.  0.  0.  6.  0.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 3. 6.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [16.  6.  0.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 6.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [16.  6.  0.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-13.0471735]
 [-14.077044 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  2.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: discard_down_to_3_cards - action 1
Learning step: -3.6708199977874756
desired expected reward: -21.23906707763672



action possibilites: [-1] 
expected returns: [[-17.513971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  1.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -90    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -376 

action type: gain_card_n - action 2
Learning step: -19.360952377319336
desired expected reward: -16.023216247558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-26.026812]
 [-48.43195 ]
 [-16.775852]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  1.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -3.4519245624542236
desired expected reward: -20.965896606445312






Player: 1 
cards in hand: [ 0.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  1.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  1.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.
  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.
  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3.  3.  0.  0.  3.  8.  3.  1.  6.  0.  3.  8. 14.  0.  0.  6. 29.
 11.  0.  0.  3.  0.  3.  3. 11.  0.  6.  3.  0.  6. 14.  6.  4.  3.  6.
  6. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 11. 25. 15.  1.] 
adversary cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 15.] 
expected returns: [[-34.667934]
 [-34.978508]
 [-33.063217]
 [-45.965042]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 15.  1.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.250341892242432
desired expected reward: -21.02619743347168



action possibilites: [-1] 
expected returns: [[-41.427666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  1. 11.  0.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -65 

action type: take_action - action 25.0
Learning step: -2.528961181640625
desired expected reward: -35.592185974121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-36.68719 ]
 [-37.56496 ]
 [-35.822407]
 [-37.46205 ]
 [-38.1177  ]
 [-38.441456]
 [-37.81595 ]
 [-33.929047]
 [-36.895668]
 [-35.408607]
 [-38.47098 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15.  1. 11.  0.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  8. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.0254554748535156
desired expected reward: -43.453121185302734



buy possibilites: [-1] 
expected returns: [[18.861614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15.  1. 11.  0.] 
cards in discard: [25.  8.  8.  6.  3.  8.  3.  0.  0.  6. 16.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -34 

action type: buy - action 14.0
Learning step: 0.42083826661109924
desired expected reward: -33.508201599121094






Player: 1 
cards in hand: [11.  0.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0. 15.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14] -> size -> 23 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0. 15.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14] -> size -> 23 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0. 15.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14] -> size -> 23 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[-22.509584]
 [-21.112822]
 [-19.306345]
 [-21.112822]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 29.  8.  0.  8.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -5.696239471435547
desired expected reward: 13.165374755859375



action possibilites: [-1] 
expected returns: [[-12.962802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 11.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -50 

action type: gain_card_n - action 3
Learning step: -1.8926887512207031
desired expected reward: -19.872175216674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.281588]
 [-12.58596 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 11.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.9298715591430664
desired expected reward: -15.89267349243164



buy possibilites: [-1] 
expected returns: [[-13.706021]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 11.] 
cards in discard: [16.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -4.4943060874938965
desired expected reward: -16.775894165039062






Player: 1 
cards in hand: [ 8. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  6. 15. 25.  0.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 6. 15. 25.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  4.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 6. 15. 25.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 6. 15. 25.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-34.4175  ]
 [-48.98499 ]
 [-29.000647]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 25.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: discard_down_to_3_cards - action 3
Learning step: -4.121027946472168
desired expected reward: -22.615680694580078



action possibilites: [-1] 
expected returns: [[9.299398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  8.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 25.0
Learning step: -1.6407310962677002
desired expected reward: -30.641380310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 2.2283328]
 [10.06131  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  8.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8] -> size -> 48 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.5817220211029053
desired expected reward: 5.717676162719727






Player: 1 
cards in hand: [ 0.  6.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 11.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  6.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 25.  8.  0.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ -4.146772 ]
 [ -0.6351352]
 [-11.714595 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.570109844207764
desired expected reward: -0.5249800682067871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-14.450108]
 [ -9.388121]
 [-12.99931 ]
 [ -5.792407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 25.  8.  0.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.276568412780762
desired expected reward: -8.423344612121582



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [11. 14.  0. 16.  1.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.  6.  0. 25.  8.
  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [11. 14.  0. 16.  1.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.  6.  0. 25.  8.
  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [11. 14.  0. 16.  1.] 
adversary cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.  6.  0. 25.  8.
  0.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11. 14.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16.] 
expected returns: [[ -9.201055]
 [-11.700868]
 [-11.57508 ]
 [-14.582026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0. 16.  1.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.  6.  0. 25.  8.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [11.  6.  0.  4.  0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.245636940002441
desired expected reward: -10.038043975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-14.218241]
 [-14.384709]
 [-12.085452]
 [-12.260954]
 [-16.516838]
 [-13.449965]
 [ -9.943964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0. 16.  1.] 
cards in discard: [16.  0. 11.  3.  0. 15. 11.  3.  0. 25.  6. 15.  6.  8.  6.  0. 25.  8.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [11.  6.  0.  4.  0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.100268840789795
desired expected reward: -13.301313400268555



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  6.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  4.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  4.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  3.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  4.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-10.36904 ]
 [-10.448831]
 [-10.448831]
 [-11.780343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.040430545806885
desired expected reward: -13.98438835144043





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.61669]
 [-10.36904]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.002066135406494
desired expected reward: -14.37110710144043



buy possibilites: [-1] 
expected returns: [[-8.187226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 11.  8.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [8. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -116.0 

action type: buy - action 0.0
Learning step: -5.503377914428711
desired expected reward: -15.12006664276123






Player: 1 
cards in hand: [8. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 15.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 15.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 6.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  1.  3. 15.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8.] 
adversary owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-21.195251]
 [-20.627321]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 15.] 
cards in discard: [ 0.  3. 11.  0. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15. 14. 29.  0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.35788106918335
desired expected reward: -12.545106887817383



action possibilites: [-1] 
expected returns: [[1.6271627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [ 0.  3. 11.  0. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15. 14. 29.  0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 15.0
Learning step: -2.232022523880005
desired expected reward: -22.85934829711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.348299  ]
 [ 0.46112323]
 [-2.7227402 ]
 [-0.22470379]
 [-3.8647652 ]
 [-1.3068559 ]
 [ 1.2365468 ]
 [-1.2781358 ]
 [ 1.6714051 ]
 [-1.5282955 ]
 [-3.371768  ]
 [-2.5043583 ]
 [-1.3274589 ]
 [-3.7447422 ]
 [-2.341628  ]
 [ 1.7816598 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 0.  3. 11.  0. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15. 14. 29.  0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.3756301403045654
desired expected reward: -1.7484674453735352






Player: 1 
cards in hand: [ 6. 15. 14. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 14. 29.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14. 11.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 14. 29.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14. 11.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 14. 29.  0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14. 11.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 11.] 
expected returns: [[-11.164839]
 [ -8.600364]
 [ -7.467227]
 [-10.371526]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 14. 11.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.578392028808594
desired expected reward: -2.7967259883880615



action possibilites: [-1] 
expected returns: [[-10.317853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 11.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 14.0
Learning step: -3.1587905883789062
desired expected reward: -10.626016616821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-10.360307 ]
 [ -9.279264 ]
 [ -7.7365026]
 [ -8.341009 ]
 [-12.389158 ]
 [ -8.997134 ]
 [ -7.0607843]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0. 11.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.96616268157959
desired expected reward: -13.284015655517578



buy possibilites: [-1] 
expected returns: [[-15.036511]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0. 11.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -48 

action type: buy - action 1.0
Learning step: -2.2743585109710693
desired expected reward: -11.553617477416992






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [25.  8.  6.  0. 16.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  2.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [25.  8.  6.  0. 16.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  1.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [25.  8.  6.  0. 16.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.] 
adversary owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [25.  8.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 16.] 
expected returns: [[-21.502647]
 [-22.322243]
 [-21.604872]
 [-21.211533]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  0. 16.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  1.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.030375957489014
desired expected reward: -19.06688690185547



action possibilites: [-1] 
expected returns: [[-16.378277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -62 

action type: gain_card_n - action 2
Learning step: -3.021313190460205
desired expected reward: -11.965276718139648





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.584416]
 [-16.854631]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.8387296199798584
desired expected reward: -19.21700668334961



buy possibilites: [-1] 
expected returns: [[-31.227829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  8.  3.] 
adversary cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action 0.0
Learning step: -4.723405361175537
desired expected reward: -20.30781364440918






Player: 1 
cards in hand: [ 6.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  8.  3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [16. 25.  0.  6.  8.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.  0.
 16. 25.  8.  6.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  8.  3.] 
cards in discard: [ 1. 11.  0.  1.  0. 15.  8. 14.  8.  0.  0.  3. 15.  0. 11.  0.  6.  3.
  6. 10.  0.  3.  3.  3.  6.  8. 11.  6.  0.  4.  0.  0.  8.  3.  3.  3.
  6.  0.  6. 15. 14. 29.  0.  3.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [16. 25.  0.  6.  8.] 
adversary cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.  0.
 16. 25.  8.  6.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [16. 25.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.  8.] 
expected returns: [[-12.191828]
 [-13.722378]
 [-12.19024 ]
 [-14.033937]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25.  0.  6.  8.] 
cards in discard: [ 0.  3. 11.  0. 11.  8. 15.  0.  1.  3.  1. 14.  6. 15.  0. 11.  8.  0.
 16. 25.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -3.0221879482269287
desired expected reward: -34.25001525878906



action possibilites: [-1] 
expected returns: [[-11.237155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  8. 25. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 25.0
Learning step: -2.943323850631714
desired expected reward: -15.133564949035645





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.648918]
 [ -9.914652]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  8. 25. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -2.9817843437194824
desired expected reward: -14.218938827514648



buy possibilites: [-1] 
expected returns: [[-25.83002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  8. 25. 11.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 6.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -4.698729991912842
desired expected reward: -18.347644805908203






Player: 1 
cards in hand: [ 6.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  1.  0.  0. 14.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  1.  0.  0. 14.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  1.  0.  0. 14.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-74.19244]
 [-79.46094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 14.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 4.  0.  3.  3. 11.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.706839084625244
desired expected reward: -30.5368595123291





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-75.71852 ]
 [-75.93214 ]
 [-73.07259 ]
 [-81.87047 ]
 [-76.072525]
 [-74.86916 ]
 [-77.44841 ]
 [-76.7317  ]
 [-77.86194 ]
 [-71.03197 ]
 [-74.12297 ]
 [-81.349884]
 [-72.45739 ]
 [-72.09868 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 14.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9. 10.  5.] 
adversary cards in hand: [ 4.  0.  3.  3. 11.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -2.2406654357910156
desired expected reward: -76.43309020996094



buy possibilites: [-1] 
expected returns: [[-15.0118265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 14.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9.  9.  5.] 
adversary cards in hand: [ 4.  0.  3.  3. 11.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -36 

action type: buy - action 22.0
Learning step: 1.9297274351119995
desired expected reward: -79.4201431274414






Player: 1 
cards in hand: [ 4.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  3.  3. 11.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9.  9.  5.] 
adversary cards in hand: [ 8. 11. 11.  0.  6.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22] -> size -> 29 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  3.  3. 11.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9.  9.  5.] 
adversary cards in hand: [ 8. 11. 11.  0.  6.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22] -> size -> 29 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  3.  3. 11.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9.  9.  5.] 
adversary cards in hand: [ 8. 11. 11.  0.  6.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22] -> size -> 29 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[-21.474243]
 [-22.844383]
 [-22.673077]
 [-22.673077]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  0.  6.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  7. 10.  9.  9.  5.] 
adversary cards in hand: [ 0. 14.  6.  0.  8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.042953014373779
desired expected reward: -19.054779052734375



action possibilites: [-1] 
expected returns: [[6.376542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  6.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 0. 14.  6.  0.  8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -50 

action type: gain_card_n - action 6
Learning step: -1.707388162612915
desired expected reward: -14.690178871154785





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.9900942]
 [6.750124 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  6.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 0. 14.  6.  0.  8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.4931600093841553
desired expected reward: 2.8833820819854736



buy possibilites: [-1] 
expected returns: [[-11.723388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  6.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 0. 14.  6.  0.  8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -5.114638805389404
desired expected reward: -3.1245360374450684






Player: 1 
cards in hand: [ 0. 14.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.  0.  8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 6.  0. 15. 16.  8.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.  0.  8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 6.  0. 15. 16.  8.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  6.  0.  8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 6.  0. 15. 16.  8.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
adversary owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 15. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.  8.] 
expected returns: [[-21.363647]
 [-18.157578]
 [-19.059805]
 [-19.827291]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15. 16.  8.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 11 25  8  1  8 15  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0
  1  8  0  0 22 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [11.  1.  6. 11.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0] -> size -> 57 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.138284206390381
desired expected reward: -15.861671447753906



action possibilites: [-1] 
expected returns: [[-3.5603743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [11.  1.  6. 11.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0] -> size -> 57 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.6078896522521973
desired expected reward: -18.052265167236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.8629727]
 [-2.8138518]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [11.  1.  6. 11.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0] -> size -> 57 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.202082872390747
desired expected reward: -6.762456893920898






Player: 1 
cards in hand: [11.  1.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6. 11.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  5.] 
adversary cards in hand: [ 1.  3.  8. 15.  3.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 11.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3.  8. 15.  3.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 11.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3.  8. 15.  3.] 
adversary cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[-18.14037 ]
 [-17.27925 ]
 [-13.467584]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 15.  3.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3. 15.  8. 15.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.493474006652832
desired expected reward: -7.307326793670654



action possibilites: [-1] 
expected returns: [[-2.5219707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3. 15.  8. 15.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 15.0
Learning step: -2.6833653450012207
desired expected reward: -16.150949478149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-5.3027687]
 [-2.322877 ]
 [-2.6310298]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3. 15.  8. 15.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -3.23823618888855
desired expected reward: -5.760207176208496



buy possibilites: [-1] 
expected returns: [[20.311392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 3.] 
cards in discard: [ 0. 25. 16.  0.  6.  8. 25. 11. 22.  0.  1.  0.  0. 14. 14.  0. 11.  8.
 11.  0.  6.  8.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 1.  3. 15.  8. 15.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -4.077855110168457
desired expected reward: -9.380626678466797






Player: 1 
cards in hand: [ 1.  3. 15.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.  8. 15.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 8. 16.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0  0] -> size -> 30 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 15.  8. 15.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 8. 16.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0  0] -> size -> 30 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8. 16.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[-22.0496  ]
 [-27.90705 ]
 [-27.197374]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0  6 11  3  8  6 15  0  6 14 16  0  0  1  8
  0  0 22 14  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 20. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -5.852085113525391
desired expected reward: 14.459306716918945



action possibilites: [-1] 
expected returns: [[18.839346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -40 

action type: gain_card_n - action 1
Learning step: -0.984762966632843
desired expected reward: -12.811799049377441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.114503]
 [17.168974]
 [18.805954]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -2.738393545150757
desired expected reward: 16.1009521484375






Player: 1 
cards in hand: [ 0.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [15. 11. 25.  0.  0.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  4.] 
adversary cards in hand: [15. 11. 25.  0.  0.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15 15] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [15. 11. 25.  0.  0.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15. 11. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25.] 
expected returns: [[-31.61928 ]
 [-27.519302]
 [-31.06137 ]
 [-33.000145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 25.  0.  0.] 
cards in discard: [ 3. 16.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15 15] -> size -> 59 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -4.79561185836792
desired expected reward: 14.010343551635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-27.933714]
 [-27.792202]
 [-30.935114]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 25.  0.  0.] 
cards in discard: [ 3. 16.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 19. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15 15] -> size -> 59 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -2.2564175128936768
desired expected reward: -33.87569808959961



buy possibilites: [-1] 
expected returns: [[-62.735275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 25.  0.  0.] 
cards in discard: [ 3. 16.  8.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15 15] -> size -> 59 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -45 

action type: buy - action 3.0
Learning step: -2.2444443702697754
desired expected reward: -30.03664779663086






Player: 1 
cards in hand: [0. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11
 10  0  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8
 15  0  8  0  0  8  0  0  0 15 15] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 8. 11.  0.  3.  6.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-18.409586]
 [-20.192797]
 [-18.61677 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  6.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  3. 10. 29.  6.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0] -> size -> 58 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: 0.5652416348457336
desired expected reward: -62.1700325012207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.821932]
 [-17.792442]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  3.  6.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  3. 10. 29.  6.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0] -> size -> 58 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -1.6355193853378296
desired expected reward: -20.04510498046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.  6.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [14.  0.  3. 14.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 29.  6.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0] -> size -> 58 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [14.  0.  3. 14.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 29.  6.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [14.  0.  3. 14.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [14.  0.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
expected returns: [[9.553663 ]
 [4.1469812]
 [4.1469812]
 [6.6959333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 14.  8.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0] -> size -> 59 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -1.0830596685409546
desired expected reward: -18.875499725341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.339591]
 [9.124647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3. 14.  8.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0] -> size -> 59 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -2.443220615386963
desired expected reward: 7.110439777374268



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 22.  1.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0] -> size -> 59 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 22.  1.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 22.  1.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[-16.327763]
 [-15.6996  ]
 [-12.313601]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 22.  1.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  6. 10.  9.  9.  3.] 
adversary cards in hand: [ 3.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -2.9104537963867188
desired expected reward: 6.214193344116211



action possibilites: [-1] 
expected returns: [[-3.7682226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  1.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [ 3.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -7 

action type: gain_card_n - action 6
Learning step: 0.1879875659942627
desired expected reward: -12.267463684082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ -8.00302  ]
 [  4.3803205]
 [ -0.5213251]
 [ -2.652855 ]
 [  7.7040253]
 [ -2.3621635]
 [-16.858995 ]
 [ -3.9380784]
 [-11.290822 ]
 [  4.901496 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  1.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 18. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [ 3.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -0.9046328663825989
desired expected reward: -4.672855377197266



buy possibilites: [-1] 
expected returns: [[-4.235255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  1.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [ 3.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: -0.5692278742790222
desired expected reward: -1.0905351638793945






Player: 1 
cards in hand: [ 3.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  8.  0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6 15  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0
  8  0  0  8  0  0  0 15 15  0  0  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [25.  0.  6.  1.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3. 11.  0.  0. 22.  1.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [25.  0.  6.  1.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3. 11.  0.  0. 22.  1.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0] -> size -> 59 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [25.  0.  6.  1.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3. 11.  0.  0. 22.  1.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.  6.  3.  0.  8.  0.  4.  0.  3.  3. 11.  0.  0. 14.  6.  0.  8.
 15. 11.  1.  6. 11.  0.  1.  3. 15.  8. 15. 15.  0.  0. 14.  0.  0.  0.
  8.  0.  8.  0.  0.  3. 10. 29.  6.  0.  3.  6.  6.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [25.  0.  6.  1.  8.] 
adversary cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3. 11.  0.  0. 22.  1.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [25.  0.  6.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[-13.230106]
 [-16.868862]
 [-16.60711 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6.  1.  8.] 
cards in discard: [ 3. 16.  8.  0.  0.  3. 15. 11. 25.  0.  0.  8. 11.  0.  3.  6. 14.  0.
  3. 14.  8. 14.  3. 11.  0.  0. 22.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -1.711668848991394
desired expected reward: -5.946923732757568



action possibilites: [-1] 
expected returns: [[-17.05998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1.  8.  0. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -11 

action type: take_action - action 25.0
Learning step: -0.09040641784667969
desired expected reward: -16.95926856994629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-15.946533]
 [-17.249968]
 [-15.779416]
 [-16.637516]
 [-17.033674]
 [-16.874676]
 [-13.430854]
 [-15.762577]
 [-14.720746]
 [-16.235132]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1.  8.  0. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  5. 10.  9.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -0.07712631672620773
desired expected reward: -17.13710594177246



buy possibilites: [-1] 
expected returns: [[-18.154598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1.  8.  0. 15.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 20 

action type: buy - action 14.0
Learning step: 1.2630642652511597
desired expected reward: -12.167787551879883






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3 14] -> size -> 34 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 26. 30. 17. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3 14] -> size -> 34 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
adversary owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3 14] -> size -> 34 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-18.242844]
 [-21.724272]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11  0  0 11  3  8  6 15  0  6 14 16  0  0  1  8  0
  0 22 14  0  0  3  3 14  3 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 29.  0.  0.  4.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -1.6219042539596558
desired expected reward: -19.77650260925293



action possibilites: [-1] 
expected returns: [[-3.6725898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 22
 14  0  0  3  3 14  3 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 29.  0.  0.  4.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.19638405740261078
desired expected reward: -19.52592658996582





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.8148637]
 [-3.7644048]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 22
 14  0  0  3  3 14  3 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 29.  0.  0.  4.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -1.017866611480713
desired expected reward: -4.690456390380859






Player: 1 
cards in hand: [ 3. 29.  0.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  4.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 8.  3.  3. 22.  0.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 22
 14  0  0  3  3 14  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  4.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 8.  3.  3. 22.  0.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 22
 14  0  0  3  3 14  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[-27.384434]
 [-28.872604]
 [-22.915665]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 22.  0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 22
 14  0  0  3  3 14  3 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -2.465654134750366
desired expected reward: -6.230059623718262



action possibilites: [-1] 
expected returns: [[-21.905266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.3561386168003082
desired expected reward: -25.090734481811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.730843]
 [-21.37817 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -0.4237642288208008
desired expected reward: -22.329029083251953



buy possibilites: [-1] 
expected returns: [[-15.462469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -52.0 

action type: buy - action 0.0
Learning step: -2.0613629817962646
desired expected reward: -19.792213439941406






Player: 1 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [14.  3. 11.  3.  0.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [14.  3. 11.  3.  0.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [14.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[-16.328999]
 [-12.354891]
 [-16.444176]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  3.  0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 8.  0. 15.  6. 11.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -1.6344616413116455
desired expected reward: -17.09693145751953



action possibilites: [-1] 
expected returns: [[-40.343704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 15.  6.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action 14.0
Learning step: -1.389988899230957
desired expected reward: -13.744877815246582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-43.052883]
 [-40.23134 ]
 [-37.106113]
 [-39.114594]
 [-39.944572]
 [-38.67791 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 16. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 15.  6.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: 0.05386505275964737
desired expected reward: -40.28984069824219



buy possibilites: [-1] 
expected returns: [[-7.589088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 15.  6.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 3.0
Learning step: 1.2345507144927979
desired expected reward: -35.871551513671875






Player: 1 
cards in hand: [ 0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  8. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3] -> size -> 33 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  8. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3] -> size -> 33 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 15. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 0.  0. 14.  8. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3] -> size -> 33 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
expected returns: [[-4.2047114]
 [-5.2447906]
 [-7.043356 ]
 [-5.51766  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8. 11.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -1.2794452905654907
desired expected reward: -8.86853313446045



action possibilites: [-1] 
expected returns: [[-26.512714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 14. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 4 

action type: gain_card_n - action 2
Learning step: -0.10879939049482346
desired expected reward: -5.863533020019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-31.354511]
 [-25.677044]
 [-26.337273]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 14. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: 0.7246370911598206
desired expected reward: -25.788076400756836



buy possibilites: [-1] 
expected returns: [[-79.04062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 19 

action type: buy - action 3.0
Learning step: 0.4554382264614105
desired expected reward: -25.22160530090332






Player: 1 
cards in hand: [ 3. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  3.  0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0
  3  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8
  0  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0] -> size -> 61 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  9.  4. 10.  9.  9.  3.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  8.  4. 10.  9.  9.  3.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8.] 
adversary owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [16.  0.  1. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 11.] 
expected returns: [[-20.250355]
 [-18.647816]
 [-13.075936]
 [-20.045452]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 14. 11.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14
  0  0  3  3 14  3 14  0  3  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  8.  4. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 1. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1
Learning step: 3.153541326522827
desired expected reward: -75.88707733154297



action possibilites: [-1] 
expected returns: [[10.955948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 1. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 27 

action type: gain_card_n - action 7
Learning step: 2.062816858291626
desired expected reward: -7.263343811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 7.8361816]
 [11.294436 ]
 [ 9.507108 ]
 [11.954638 ]
 [ 8.686035 ]
 [10.829505 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 1. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1
Learning step: 0.24985404312610626
desired expected reward: 11.205801963806152



buy possibilites: [-1] 
expected returns: [[-18.600916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.] 
cards in discard: [14. 25.  0.  6.  1.  8.  0. 15.  8.  6.  3.  0.  8.  3.  3.  0.  3. 14.
  3. 11.  3.  0.  3.  3. 11.  0.  0. 14.  8. 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  8.  9.  3.] 
adversary cards in hand: [0. 8. 1. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0  -1   0   0  18   0] 
sum of rewards: 28 

action type: buy - action 10.0
Learning step: 0.5471774339675903
desired expected reward: 9.2332181930542






Player: 1 
cards in hand: [0. 8. 1. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 6. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  8.  9.  3.] 
adversary cards in hand: [ 0.  8.  0. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 6. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  8.  9.  3.] 
adversary cards in hand: [ 0.  8.  0. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 6. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 0.  8.  0. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[8.189233 ]
 [4.169875 ]
 [6.0020113]
 [6.0020113]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 63 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: buy - action -1
Learning step: 0.6411938071250916
desired expected reward: -17.9597225189209



action possibilites: [-1] 
expected returns: [[-11.514135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 25.  6.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 63 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action 25.0
Learning step: -0.009168649092316628
desired expected reward: 5.9928436279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.512811]
 [-10.941903]
 [-11.451276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 25.  6.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 63 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 11 

action type: take_action - action -1
Learning step: 0.8755483627319336
desired expected reward: -10.63858699798584






Player: 1 
cards in hand: [15. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  8.  0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11 10  0  3
  6  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6 15  0  1  8 15  0  8  0
  0  8  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [10. 16.  3.  0.  3.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [10. 16.  3.  0.  3.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 13. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [10. 16.  3.  0.  3.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [10. 16.  3.  0.  3.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 8 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [10. 16.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[-30.911688]
 [-31.577133]
 [-33.07281 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  0.  3.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3] -> size -> 62 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: buy - action -1.0
Learning step: -1.083325982093811
desired expected reward: -12.534589767456055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-31.342163]
 [-29.460865]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  0.  3.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3] -> size -> 62 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1.0
Learning step: -0.07764387130737305
desired expected reward: -30.98933982849121



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 1.  3.  6. 14. 15.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 1.  3.  6. 14. 15.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 1.  3.  6. 14. 15.] 
adversary cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
adversary owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
adversary victory points: 6
player victory points: 8 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  6. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[-18.571901]
 [-17.619648]
 [-17.31639 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 14. 15.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 0. 11.  6.  1. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.  1.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3  1] -> size -> 63 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: buy - action -1.0
Learning step: 0.12770281732082367
desired expected reward: -29.333171844482422



action possibilites: [-1] 
expected returns: [[-16.754913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 14.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 0. 11.  6.  1. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.  1.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3  1] -> size -> 63 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 1 

action type: take_action - action 15.0
Learning step: 0.5388342142105103
desired expected reward: -16.77756118774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-18.521038]
 [-15.722494]
 [-17.525925]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 14.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 0. 11.  6.  1. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.  1.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3  1] -> size -> 63 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 1 

action type: take_action - action -1
Learning step: 0.5170960426330566
desired expected reward: -16.237817764282227



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 2 

Remodel: 2 
Workshop: 3 
Chapel: 2 
Witch: 2 
Poacher: 0 
Militia: 2 
Market: 0 
Village: 1 
Library: 1 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  3.  6. 14.] 
cards in discard: [25.  0.  8.  0. 25.  6.  3. 10. 16.  3.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [25  8  1  8  3 25 11 11  3  8  6 15  0  6 14 16  0  0  1  8  0  0 14  0
  0  3  3 14  3 14  0  3  3  3 29 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 12. 29.  8.  0.  7.  3.  0.  7.  7.  4. 10.  7.  9.  3.] 
adversary cards in hand: [ 0. 11.  6.  1. 14.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3. 29.  0.  0.  4.  0.  0. 14.  3.  0.  8. 11.
  0.  0. 15.  6. 29. 15.  3.  3.  0. 10.  0.  8.  1.  6.  3.  3.  8.  0.
  0.  1.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  0  4  0 14  3  1 11  0  3  6  3  6  3 11  0  3  6
  0 14  0 11  6 11  6  3  8  8  8  3  3  6  6  0  1  8 15  0  8  0  0  8
  0  0  0 15 15  0  0  0  0  3  0 29 10  3  1] -> size -> 63 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[  -5 -500    6  -20    0    0   20  -30    0    0    0   -2    0    0
    0    0] 
sum of rewards: -531 

action type: buy - action 0.0
Learning step: -25.623947143554688
desired expected reward: -44.144996643066406



