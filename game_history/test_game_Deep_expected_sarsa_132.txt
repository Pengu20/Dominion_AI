 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.665405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0       20        0
        0        0        0     -240        0        0       27        0] 
sum of rewards: -3000408 

action type: gain_card_n - action 4
Learning step: -120006.5703125
desired expected reward: -120250.2421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[6.3739914e+01]
 [1.0341939e+02]
 [7.7570061e+01]
 [4.8538208e-02]
 [9.4037270e+01]
 [1.0172057e+02]
 [8.7519157e+01]
 [1.1727702e+02]
 [2.3478842e+01]
 [6.2023262e+01]
 [6.0592865e+01]
 [7.1107651e+01]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.90729522705078



buy possibilites: [-1] 
expected returns: [[74.32256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.27702331542969






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.603294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.32256317138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.67633 ]
 [92.466255]
 [67.54653 ]
 [-7.786727]
 [91.0927  ]
 [77.16005 ]
 [52.383667]
 [62.37626 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.806251525878906



buy possibilites: [-1] 
expected returns: [[79.517166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 92.46626281738281






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[37.96904]
 [83.26293]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.51716613769531



action possibilites: [-1.] 
expected returns: [[69.588615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.79356384277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 57.047913]
 [ 97.14917 ]
 [ 31.997175]
 [ 70.95702 ]
 [ 16.908958]
 [ -7.962757]
 [ 87.716324]
 [ 95.43569 ]
 [ 81.02694 ]
 [153.48961 ]
 [110.86388 ]
 [ 15.263132]
 [ 60.371017]
 [ 55.40206 ]
 [ 21.62712 ]
 [ 54.006996]
 [ 64.78906 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.58861541748047



buy possibilites: [-1] 
expected returns: [[66.43593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 153.4895782470703






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  0.  0. 15. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[59.842125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25. 29.  3.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.43592834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.39054 ]
 [88.006386]
 [64.54568 ]
 [-9.419758]
 [86.80354 ]
 [73.514084]
 [50.215218]
 [59.962425]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25. 29.  3.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.639251708984375



buy possibilites: [-1] 
expected returns: [[38.362297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25. 29.  3.  1.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.00640106201172






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[49.086456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.36229705810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 39.767395]
 [ 80.72714 ]
 [ 54.25686 ]
 [-28.253798]
 [ 71.24111 ]
 [ 79.003746]
 [ 64.514275]
 [ 94.52263 ]
 [ -4.38108 ]
 [ 38.044014]
 [ 36.57863 ]
 [ 47.73278 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.18290710449219



buy possibilites: [-1] 
expected returns: [[49.26619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.52262878417969






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  3.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  3.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  3.  0.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 25.] 
adversary cards in discard: [29.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 1.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 54.386406]
 [138.50356 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [29.  0.  3.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.26618957519531



action possibilites: [-1] 
expected returns: [[47.2172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 138.56568908691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 47.084335 ]
 [ 76.63892  ]
 [ 30.1214   ]
 [ 57.10051  ]
 [ 19.40732  ]
 [  1.0175376]
 [ 68.41599  ]
 [ 75.58837  ]
 [ 63.63127  ]
 [126.150345 ]
 [ 89.171776 ]
 [ 18.449623 ]
 [ 50.25717  ]
 [ 46.521805 ]
 [ 23.14599  ]
 [ 45.874146 ]
 [ 54.770226 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 26. 30. 30. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.217201232910156



buy possibilites: [-1] 
expected returns: [[58.09977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  9. 10. 10. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 126.15036010742188






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9. 10. 10. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 30. 30.  8.  9. 10. 10. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9. 10.  9. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 1.6109886]
 [83.14077  ]
 [43.6332   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9. 10.  9. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.099769592285156



action possibilites: [-1] 
expected returns: [[4.3561935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.10284423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -0.30469513]
 [ 31.439695  ]
 [ 10.53673   ]
 [-48.606354  ]
 [ 23.242983  ]
 [ 30.30762   ]
 [ 17.639687  ]
 [ 43.798508  ]
 [-30.943846  ]
 [ -0.9429488 ]
 [ -1.6423149 ]
 [  8.068764  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.356193542480469



buy possibilites: [-1] 
expected returns: [[16.598072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0. 25.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.79851531982422






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 1. 15. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10.  1.  3.] 
cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.  3.  0.] 
cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  3.  0.] 
cards in discard: [ 6. 11.  0.  3.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  3.] 
adversary cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-4.243552]
 [23.051336]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.598072052001953



action possibilites: [-1.] 
expected returns: [[15.1809025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.96427345275879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.983492 ]
 [ 39.758705 ]
 [ 22.55782  ]
 [-14.217832 ]
 [-30.329775 ]
 [ 33.377388 ]
 [ 39.351982 ]
 [ 29.045126 ]
 [ 79.84989  ]
 [ 50.23416  ]
 [-15.019368 ]
 [ 15.708017 ]
 [ 12.1813545]
 [-10.720936 ]
 [ 11.407742 ]
 [ 20.21761  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [29. 25.  0.  0. 29.  0. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  8.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.180902481079102



buy possibilites: [-1] 
expected returns: [[69.7173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [29. 25.  0.  0. 29.  0. 25.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 79.84991455078125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 30. 30.  8.  8. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 30. 30.  8.  8. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[20.401312]
 [91.08418 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  8. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.71730041503906



action possibilites: [-1] 
expected returns: [[58.242775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  7. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.15679931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.14102 ]
 [83.581604]
 [65.96112 ]
 [10.933634]
 [77.15456 ]
 [83.438324]
 [72.618256]
 [94.20479 ]
 [27.510332]
 [54.997787]
 [54.57081 ]
 [65.09735 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8.  7. 10.  9. 10.  7.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.242774963378906



buy possibilites: [-1] 
expected returns: [[90.28501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 25. 29.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  7. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.2048110961914






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [1. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  7. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 30. 30.  8.  7. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8.  7. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 6.132512]
 [33.6361  ]
 [61.406242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 25.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  7. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.2850112915039



action possibilites: [-1] 
expected returns: [[91.54704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.  1.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.24848175048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.9304  ]
 [114.85273 ]
 [ 98.13857 ]
 [ 64.11712 ]
 [ 48.960175]
 [108.73943 ]
 [114.632614]
 [104.42008 ]
 [153.20148 ]
 [124.8497  ]
 [ 63.891647]
 [ 92.18758 ]
 [ 88.704926]
 [ 67.79821 ]
 [ 88.281006]
 [ 97.0147  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.  1.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  7.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.54704284667969



buy possibilites: [-1] 
expected returns: [[100.402916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.  1.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 153.20147705078125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0.  3. 10.  0.  0.  0.  6.  3.  1.  6.  6.  0.  3.  6. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[33.145172]
 [65.57269 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.40291595458984



action possibilites: [-1.] 
expected returns: [[72.838776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.17407989501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 66.12447 ]
 [ 95.742134]
 [ 77.43891 ]
 [ 17.824505]
 [ 89.05896 ]
 [ 95.65794 ]
 [ 84.34353 ]
 [106.86947 ]
 [ 36.01409 ]
 [ 66.0403  ]
 [ 65.63177 ]
 [ 76.765205]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.83877563476562



buy possibilites: [-1] 
expected returns: [[142.57973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 106.86946105957031






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0.  1.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 15.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0.  1.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 15.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0.  1.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25. 29. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 73.023865]
 [139.19075 ]
 [106.41995 ]
 [139.19075 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  0.  1.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  6. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.57972717285156



action possibilites: [-1] 
expected returns: [[66.145134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  1. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.7023162841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[54.638016]
 [78.84086 ]
 [63.922485]
 [15.234156]
 [73.38664 ]
 [78.81969 ]
 [69.53522 ]
 [88.243645]
 [30.107336]
 [54.61685 ]
 [54.310196]
 [63.512054]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  1. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  5.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.14513397216797



buy possibilites: [-1] 
expected returns: [[102.52069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  1. 29.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  4.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 88.24363708496094






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  0.  6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  4.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25. 25.  0.  0.  3.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  4.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  4.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  3.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 84.104996]
 [135.49135 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  5. 10.  9. 10.  6.  3.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 7.424073219299316



action possibilites: [-1] 
expected returns: [[17.313206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  4. 10.  9. 10.  6.  3.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.49130249023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 13.572054]
 [ 37.867798]
 [ 22.426123]
 [-26.232733]
 [ 32.296875]
 [ 37.204796]
 [ 28.350752]
 [ 46.408905]
 [-11.912609]
 [ 12.909048]
 [ 12.24502 ]
 [ 19.797432]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  1.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 29. 30.  8.  4. 10.  9. 10.  6.  3.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.31320571899414



buy possibilites: [-1] 
expected returns: [[44.58248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  1.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29. 25. 29. 25.  0.  1. 29.  0. 25.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 46.40888214111328






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 1. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 73.60708]
 [103.12547]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.582481384277344



action possibilites: [-1. 25.] 
expected returns: [[108.81311]
 [164.65434]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  4. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.00816345214844



action possibilites: [-1] 
expected returns: [[100.82181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  3. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 164.6543426513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 94.67394 ]
 [122.27594 ]
 [105.10959 ]
 [ 67.34312 ]
 [ 51.075737]
 [116.025345]
 [122.04785 ]
 [111.61219 ]
 [160.56566 ]
 [132.49927 ]
 [ 67.11431 ]
 [ 98.394615]
 [ 94.44581 ]
 [ 71.3029  ]
 [ 93.98147 ]
 [103.96472 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 30.  8.  3. 10.  9. 10.  6.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.82180786132812



buy possibilites: [-1] 
expected returns: [[141.77637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 25. 29.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  3. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 405 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 160.56564331054688






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  3. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 30.  8.  3. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [ 0. 11.  0.  0.  1. 15.  6. 29. 14.  0. 10.  0.  6.  6.  3.  6. 10.  3.
  0.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  3. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  0. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[40.185036]
 [90.13231 ]
 [65.18703 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 29.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  3. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.7763671875



action possibilites: [-1] 
expected returns: [[92.568985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.13229370117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.46367 ]
 [111.701866]
 [ 95.626   ]
 [ 50.640793]
 [111.02848 ]
 [101.80339 ]
 [ 85.72756 ]
 [ 92.7396  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.56898498535156



buy possibilites: [-1] 
expected returns: [[94.77617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 111.70182800292969






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 1.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [29.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[36.171005]
 [59.151627]
 [59.151627]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  3.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.77616882324219



action possibilites: [-1. 29.] 
expected returns: [[54.41826 ]
 [78.186745]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.15160369873047



action possibilites: [-1.] 
expected returns: [[60.403214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.18672943115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 53.466873]
 [ 75.599174]
 [ 40.600647]
 [ 61.086395]
 [ 32.537834]
 [ 19.984846]
 [ 70.08671 ]
 [ 75.04166 ]
 [ 66.18628 ]
 [109.196014]
 [ 84.177505]
 [ 32.192078]
 [ 55.977547]
 [ 53.121086]
 [ 35.491806]
 [ 52.67781 ]
 [ 59.61123 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  5.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.40321350097656



buy possibilites: [-1] 
expected returns: [[93.57579]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [25. 29. 25.  1.  0.  3.  0. 25. 29.  1. 25.  0.  0.  0. 29. 29. 25. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 247.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.19599914550781






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [6. 0. 0. 3. 6. 0. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0.  3.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 80.470795]
 [105.98716 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [14.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.57579040527344



action possibilites: [-1. 25.] 
expected returns: [[100.68897]
 [151.72328]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  2. 10.  9. 10.  4.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [14.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 105.9871826171875



action possibilites: [-1] 
expected returns: [[130.31836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  1. 10.  9. 10.  4.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [14.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 151.72325134277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.996155]
 [149.02705 ]
 [108.56595 ]
 [133.54456 ]
 [ 98.67507 ]
 [ 83.2697  ]
 [143.33849 ]
 [148.91997 ]
 [139.3611  ]
 [184.13214 ]
 [158.48553 ]
 [ 98.60985 ]
 [127.56583 ]
 [123.93094 ]
 [102.58723 ]
 [123.588425]
 [132.97983 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 25. 30. 27. 30.  8.  1. 10.  9. 10.  4.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [14.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.318359375



buy possibilites: [-1] 
expected returns: [[105.10521]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 25.  0.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  1. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [14.  3.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 247.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 184.1321563720703






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [14.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 10.  0.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  1. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 25. 25. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10.  0.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 27. 30.  8.  1. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 25. 25. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10.  0.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 30.  8.  1. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 25. 25. 29.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0.  1. 25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[42.486427]
 [85.70297 ]
 [85.70297 ]
 [62.95632 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 25. 29.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  1. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.10520935058594



action possibilites: [-1] 
expected returns: [[78.10596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 29. 29.  3.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.7029800415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[70.57273 ]
 [95.833336]
 [80.01944 ]
 [95.4765  ]
 [86.02978 ]
 [70.21588 ]
 [78.44025 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25. 29. 29.  3.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.10595703125



buy possibilites: [-1] 
expected returns: [[54.007156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25. 29. 29.  3.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 95.83331298828125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [29.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  0.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0
  0  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [ 0. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[32.8216  ]
 [74.74718 ]
 [53.262047]
 [53.262047]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 29.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.00715637207031



action possibilites: [-1] 
expected returns: [[19.951231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.7471923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.076981]
 [32.286835]
 [20.816538]
 [31.934347]
 [25.194815]
 [13.724489]
 [19.353052]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0.  0. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.951231002807617



buy possibilites: [-1] 
expected returns: [[57.89424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0.  0. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  1. 25.  0.  1. 25.  0.  1. 25. 29. 29.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 32.286834716796875






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [25.  1. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [25.  1. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 80.52203]
 [122.44122]
 [100.4593 ]
 [100.4593 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.89424133300781



action possibilites: [-1] 
expected returns: [[51.209785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.44120788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[45.94216 ]
 [66.86299 ]
 [53.97824 ]
 [66.86339 ]
 [58.827316]
 [45.942574]
 [53.702507]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  9. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.20978546142578



buy possibilites: [-1] 
expected returns: [[48.082993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3.  0.  3.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.86338806152344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [ 6.  0.  0.  3.  6.  0.  1. 22.  0.  1.  0.  0. 10.  6.  0. 14.  3.  3.
 10.  0.  6. 15. 29.  0.  6.  0.  6.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[31.400175]
 [56.199463]
 [80.96181 ]
 [56.199463]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 29.  0.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.08299255371094



action possibilites: [-1] 
expected returns: [[38.870728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 25.  3.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.96180725097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[32.375755]
 [40.937546]
 [46.647774]
 [39.119675]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0. 25.  3.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8. 10.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.8707275390625



buy possibilites: [-1] 
expected returns: [[75.23235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0. 25.  3.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 46.64778137207031






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 15. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0
  6 29  6  3  6  3  6  0 22  6  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 29.  1.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 29.  1.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 29.  1.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [ 0. 25. 25. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[45.64112]
 [89.35549]
 [89.35549]
 [67.90993]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 29.  1.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 1. 6. 6.] 
adversary cards in discard: [15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.23235321044922



action possibilites: [-1] 
expected returns: [[46.515205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  1.  0.  0.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 1. 6. 6.] 
adversary cards in discard: [15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.35549926757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.91407 ]
 [59.76117 ]
 [47.722946]
 [22.266203]
 [55.17257 ]
 [59.468452]
 [52.08864 ]
 [89.74109 ]
 [67.21326 ]
 [21.97903 ]
 [43.183617]
 [40.626892]
 [24.918766]
 [40.243866]
 [46.480072]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  1.  0.  0.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  3.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 1. 6. 6.] 
adversary cards in discard: [15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.51520538330078



buy possibilites: [-1] 
expected returns: [[56.366226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  1.  0.  0.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 1. 6. 6.] 
adversary cards in discard: [15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 475 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 89.74111938476562






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 6.] 
cards in discard: [15.  3.  6. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29. 25.  1.  0.  1.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 6.] 
cards in discard: [15.  3.  6. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29. 25.  1.  0.  1.] 
adversary cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[40.636513]
 [61.242867]
 [80.629745]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  0.  1.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0. 10. 14.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.36622619628906



action possibilites: [-1] 
expected returns: [[34.85486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  1. 25.  1.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0. 10. 14.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.62971496582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.01837 ]
 [49.341644]
 [19.806189]
 [37.26899 ]
 [14.98489 ]
 [45.18953 ]
 [48.999023]
 [42.210144]
 [74.51609 ]
 [55.894363]
 [14.922346]
 [32.04418 ]
 [29.375319]
 [16.861504]
 [28.77075 ]
 [34.772324]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1. 25.  1.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  2.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0. 10. 14.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.8548583984375



buy possibilites: [-1] 
expected returns: [[70.331184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1. 25.  1.] 
cards in discard: [11. 25.  1. 29. 29.  3.  0.  3.  8. 25. 29.  0. 29.  0. 25.  3. 25. 25.
  0. 25. 29.  1.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6.  0. 10. 14.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 74.51605987548828






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10. 14.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  1. 25.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 29.] 
adversary cards in discard: [ 1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 27. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 29.] 
adversary cards in discard: [ 1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 29.] 
adversary cards in discard: [ 1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[69.35109]
 [90.13167]
 [90.13167]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.] 
cards in discard: [ 1. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [10. 29.  6.  3.  6.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -113.20221710205078



action possibilites: [-1.] 
expected returns: [[94.110275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 1. 25. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [10. 29.  6.  3.  6.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.24252319335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 86.06512 ]
 [ 94.923645]
 [100.26602 ]
 [ 94.65049 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 1. 25. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  9.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [10. 29.  6.  3.  6.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.11027526855469



buy possibilites: [-1] 
expected returns: [[77.34236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 1. 25. 29.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [10. 29.  6.  3.  6.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 100.26600646972656






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [10. 29.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  6.  3.  6.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  8.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6.  0.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  8.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  8.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  8.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  8.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0.  1. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[60.038025]
 [75.58566 ]
 [66.67162 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  8.  1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.34236145019531



action possibilites: [-1] 
expected returns: [[56.234344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.68257141113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 52.843834]
 [ 78.256714]
 [ 62.12468 ]
 [ 27.989313]
 [ 72.40755 ]
 [ 77.831024]
 [ 68.27106 ]
 [113.805885]
 [ 87.56351 ]
 [ 27.562952]
 [ 55.801956]
 [ 52.417435]
 [ 31.481993]
 [ 51.88292 ]
 [ 60.31315 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  1.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.234344482421875



buy possibilites: [-1] 
expected returns: [[55.85695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 113.8058853149414






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29.  0. 25. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29.  0. 25. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29.  0. 25. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [29.  0. 25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[102.36426 ]
 [124.856125]
 [146.02982 ]
 [146.02982 ]
 [124.856125]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 25. 29.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.85694885253906



action possibilites: [-1] 
expected returns: [[93.296234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29.  0. 29.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.0298309326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[89.44135 ]
 [95.48772 ]
 [99.768715]
 [94.620636]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25. 29.  0. 29.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  8.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.29623413085938



buy possibilites: [-1] 
expected returns: [[91.09518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25. 29.  0. 29.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 99.76871490478516






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [1. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 25.  3. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 25.  3. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [15.  3.  6. 11.  3.  0.  1.  6.  6.  3. 14.  0.  6.  0. 10.  6.  0. 10.
 29.  3.  6.  0.  3.  0.  6.  0.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 25.  3. 25. 29.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0. 25.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[110.82385]
 [153.442  ]
 [153.442  ]
 [132.46957]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25. 29.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.09517669677734



action possibilites: [-1] 
expected returns: [[65.91714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 29. 25.  3.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.4420623779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[59.697777]
 [65.3144  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 29. 25.  3.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.9171371459961






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 22.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 22.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 22.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [29. 25.  0. 25.  1.] 
adversary cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [29. 25.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 80.38584]
 [103.40587]
 [125.64473]
 [125.64473]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25.  1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [14. 11.  1.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.31437683105469



action possibilites: [-1] 
expected returns: [[80.478516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1. 25.  1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [14. 11.  1.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.64471435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[73.23094 ]
 [91.88437 ]
 [80.46001 ]
 [54.39583 ]
 [87.69501 ]
 [91.96789 ]
 [84.7388  ]
 [99.02123 ]
 [54.4793  ]
 [76.08895 ]
 [73.31443 ]
 [57.43553 ]
 [73.132744]
 [80.47852 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1. 25.  1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  2.  9. 10.  8.  9.  8.] 
adversary cards in hand: [14. 11.  1.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.478515625



buy possibilites: [-1] 
expected returns: [[96.62337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1. 25.  1.] 
cards in discard: [ 1. 25. 29.  8. 29.  0.  3. 15. 25. 11.  0.  1.  8.  1.  8. 25. 29.  0.
 25. 29.  0. 29. 25.  0.  3. 25. 29. 25.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [14. 11.  1.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. 180.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
  32.   0.] 
sum of rewards: 197.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 99.02117919921875






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14. 11.  1.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  1.  6.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 22.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  1.  6.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 22.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  8.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  1.  6.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 22. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  7.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 1. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[115.36864]
 [136.51227]
 [158.97255]
 [158.97255]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  7.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  1.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22. 11. 14. 11.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0 11] -> size -> 41 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.62336730957031



action possibilites: [-1] 
expected returns: [[119.82146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  7.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  1.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22. 11. 14. 11.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0 11] -> size -> 41 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.97254943847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.213486]
 [133.16225 ]
 [120.957954]
 [128.68709 ]
 [133.27588 ]
 [125.53145 ]
 [141.63336 ]
 [ 93.19909 ]
 [113.327126]
 [113.147865]
 [121.08806 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 25.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  7.  7.  0.  1.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  1.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22. 11. 14. 11.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0 11] -> size -> 41 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.82145690917969



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 5 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 29. 25.  0. 29.  0.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25  1 29 25 29 25 29 25 29 29 29 25
  1 25 25  1  1 11  8 25 25  8 15 25  8 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  0. 10.  7.  7.  0.  0.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  6. 10.  1.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 22. 11. 14. 11.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  1 10  1 10  6 11  6  0  6  3  6 14  0  0  6
 29  6  3  6  3  6  0 22  6  0  6  3  0  0  0  0 11] -> size -> 41 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0     -40       0       0      64       0] 
sum of rewards: 3000219 

action type: buy - action 29.0
Learning step: 120003.0859375
desired expected reward: 120144.71875



