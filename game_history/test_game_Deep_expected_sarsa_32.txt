 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.04063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0       60        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000275 

action type: buy - action 0.0
Learning step: -120010.140625
desired expected reward: -120031.7578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[71.608284]
 [81.82742 ]
 [77.03012 ]
 [60.94534 ]
 [85.45243 ]
 [79.63887 ]
 [74.93017 ]
 [82.43259 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.3484878540039



buy possibilites: [-1] 
expected returns: [[82.146545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.45242309570312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.845825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.14654541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 80.22505]
 [ 92.63532]
 [ 86.64483]
 [ 66.22726]
 [ 89.13073]
 [ 96.97631]
 [ 89.93175]
 [103.40944]
 [ 75.71199]
 [ 84.17958]
 [ 87.69327]
 [ 93.38923]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.07426452636719



buy possibilites: [-1] 
expected returns: [[76.24572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.409423828125






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.77392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.24571990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 76.25669 ]
 [ 87.25812 ]
 [ 82.16949 ]
 [ 68.621254]
 [ 63.794018]
 [ 84.31583 ]
 [ 90.9131  ]
 [ 84.989334]
 [104.32938 ]
 [ 96.3286  ]
 [ 72.15016 ]
 [ 82.43748 ]
 [ 79.900696]
 [ 71.49522 ]
 [ 83.11097 ]
 [ 87.89553 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.44290161132812



buy possibilites: [-1] 
expected returns: [[79.29401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 104.3293685913086






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[107.28415]
 [110.7045 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 11.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.29400634765625



action possibilites: [-1] 
expected returns: [[85.94768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.00445556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.33036 ]
 [63.585506]
 [86.5654  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.94767761230469






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 16. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 16. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 16. 11.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[75.271454]
 [83.50097 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.56539916992188



action possibilites: [-1.] 
expected returns: [[85.6722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.25483703613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[75.73529 ]
 [85.47278 ]
 [80.96832 ]
 [64.51949 ]
 [82.86012 ]
 [88.70384 ]
 [83.46321 ]
 [93.657555]
 [72.12386 ]
 [78.958755]
 [81.80533 ]
 [86.059296]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.67220306396484



buy possibilites: [-1] 
expected returns: [[86.95261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.65756225585938






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 94.363686]
 [111.00411 ]
 [ 97.25589 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0.  3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.95260620117188



action possibilites: [-1] 
expected returns: [[73.76654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.7255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[67.46136 ]
 [77.16692 ]
 [72.19511 ]
 [59.707897]
 [80.94299 ]
 [74.816   ]
 [70.17385 ]
 [77.83424 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.76654052734375



buy possibilites: [-1] 
expected returns: [[92.56822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0. 10.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.94300842285156






Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11.  0.  0.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11.  0.  0.  0.  0.  3.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[76.042564]
 [78.916725]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.56822204589844



action possibilites: [-1] 
expected returns: [[72.69481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.67277526855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.96329 ]
 [74.366165]
 [69.84372 ]
 [55.17278 ]
 [71.70857 ]
 [77.6507  ]
 [72.32697 ]
 [82.46061 ]
 [61.70516 ]
 [67.87473 ]
 [70.67209 ]
 [74.98075 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.69480895996094



buy possibilites: [-1] 
expected returns: [[92.72455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.46060180664062






Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 86.6188  ]
 [102.215225]
 [ 94.58729 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 29.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9.  5.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.72454833984375



action possibilites: [-1] 
expected returns: [[93.45188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8.  9.  5.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.06611633300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.79774 ]
 [ 97.395096]
 [ 93.658165]
 [ 82.22121 ]
 [100.06615 ]
 [ 95.729675]
 [ 92.109085]
 [ 97.83395 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  8.  9.  5.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.4518814086914



buy possibilites: [-1] 
expected returns: [[109.18918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 100.066162109375






Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 8.  0. 16.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 8.  0. 16.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[61.41663 ]
 [54.424545]
 [68.85996 ]
 [54.424545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  3. 11.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.18917846679688



action possibilites: [-1. 10. 10.] 
expected returns: [[70.183395]
 [63.41679 ]
 [63.41679 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  3. 11.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 67.58750915527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.36272 ]
 [66.97245 ]
 [52.664745]
 [69.202255]
 [71.54806 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  3. 11.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.18340301513672






Player: 1 
cards in hand: [ 0.  6. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  3. 11.] 
cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  3. 11.] 
cards in discard: [ 8.  0. 16.  0.  0.  3.  6.  0.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 93.14582]
 [108.23416]
 [ 95.93457]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 11.  0.] 
cards in discard: [29. 10. 10.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.54804992675781



action possibilites: [-1] 
expected returns: [[105.89815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.  0.] 
cards in discard: [29. 10. 10.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.11141967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.54341 ]
 [113.895355]
 [109.13254 ]
 [ 98.97732 ]
 [ 95.34501 ]
 [111.12152 ]
 [117.41823 ]
 [111.77057 ]
 [130.15118 ]
 [122.59674 ]
 [101.590866]
 [109.37458 ]
 [107.160965]
 [101.098206]
 [110.02363 ]
 [114.568726]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  0.] 
cards in discard: [29. 10. 10.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.89814758300781



buy possibilites: [-1] 
expected returns: [[103.46997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  0.] 
cards in discard: [29. 10. 10.  3.  3.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 130.1511688232422






Player: 1 
cards in hand: [ 0.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  4.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 6. 15. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[43.83051 ]
 [46.059483]
 [46.059483]
 [50.958   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 29.] 
cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.469970703125



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[63.6266 ]
 [66.6328 ]
 [66.6328 ]
 [71.95085]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 29.] 
cards in discard: [29. 10. 10.  3.  3.  0. 25. 25.  0.  0. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.706382751464844



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[103.03143 ]
 [105.47815 ]
 [105.47815 ]
 [ 96.362686]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.95086669921875



action possibilites: [-1] 
expected returns: [[92.89908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.79772186279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[89.76758 ]
 [95.06676 ]
 [92.52276 ]
 [83.780716]
 [96.96738 ]
 [93.88957 ]
 [91.46829 ]
 [95.40814 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  3.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.89907836914062



buy possibilites: [-1] 
expected returns: [[115.19203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 96.96737670898438






Player: 1 
cards in hand: [ 6.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 87.32986]
 [102.98814]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  7.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  3. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.19203186035156



action possibilites: [-1] 
expected returns: [[88.14289]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  3. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 100.63407897949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[75.05343 ]
 [84.39165 ]
 [80.07404 ]
 [64.12467 ]
 [87.487366]
 [82.46675 ]
 [78.14915 ]
 [84.93993 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  2.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  3. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.14289093017578



buy possibilites: [-1] 
expected returns: [[69.816925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 25.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  1.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  3. 11.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.48735809326172






Player: 1 
cards in hand: [ 0. 16. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  3. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  1.  9.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[67.72461 ]
 [62.039837]
 [74.07932 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.81692504882812



action possibilites: [-1. 10. 11.] 
expected returns: [[93.68303]
 [88.2161 ]
 [95.84482]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.0793228149414



action possibilites: [-1] 
expected returns: [[69.47644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.39309692382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[61.906933]
 [68.81237 ]
 [65.47376 ]
 [54.450302]
 [66.86162 ]
 [71.24122 ]
 [67.29969 ]
 [74.82605 ]
 [59.398067]
 [64.10507 ]
 [66.04208 ]
 [69.209724]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.4764404296875



buy possibilites: [-1] 
expected returns: [[83.00409]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0.  3. 11. 10. 11. 25.  3.  0.  0.  3.  0. 25. 10.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 74.82605743408203






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11. 11.  0.  6.  0.  0.  6.  3.  3.  0. 11.  6.  8.  0. 16. 10.
  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[87.309586]
 [83.16583 ]
 [91.61621 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.00408935546875



action possibilites: [-1. 10. 25.] 
expected returns: [[108.095024]
 [103.31015 ]
 [117.67255 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  6.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.89482116699219



action possibilites: [-1] 
expected returns: [[107.31509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 29. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.67253875732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.139565]
 [100.464714]
 [ 86.79744 ]
 [102.57974 ]
 [104.78072 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3. 29. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.3150863647461






Player: 1 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  1.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[44.295807]
 [46.329433]
 [46.329433]
 [39.195095]
 [39.195095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10. 10.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6 11] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.78073120117188



action possibilites: [-1] 
expected returns: [[56.392536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6 11] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.7591438293457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.36034 ]
 [40.080772]
 [56.677094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6 11] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.39253616333008






Player: 1 
cards in hand: [11. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  6. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[52.626385]
 [54.669422]
 [54.669422]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.67708969116211



action possibilites: [-1] 
expected returns: [[75.328064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 58.06829833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[67.771454]
 [75.96989 ]
 [72.174866]
 [58.364723]
 [74.279594]
 [70.48459 ]
 [76.41325 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.32806396484375






Player: 1 
cards in hand: [11.  6.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3.  3.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 10. 25.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15. 11.  0.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  3.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 10. 25.] 
adversary cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15. 11.  0.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[50.957085]
 [56.06889 ]
 [46.129314]
 [60.90704 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10. 25.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15. 11.  0.  0.
 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  5.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 16. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.41325378417969



action possibilites: [-1] 
expected returns: [[41.661053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10. 29.  0.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15. 11.  0.  0.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  4.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 16. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.907047271728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.36596 ]
 [38.80653 ]
 [31.053402]
 [39.978756]
 [41.13205 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 10. 29.  0.] 
cards in discard: [29. 25.  3.  0. 10.  3. 29. 11. 15. 11. 11.  0. 10. 10. 15. 11.  0.  0.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  4.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 16. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.66105270385742






Player: 1 
cards in hand: [ 0.  0.  6. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 16. 11.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6
 11 29  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  4.  9.  0.  8.  8.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  3. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.
 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  4.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  3. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.
 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  4.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  3. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  6.  0. 29. 15. 11.  0. 11. 11.  6.  0.  3.  3.  6.
 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  4.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  3. 11. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  3. 11. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 29.] 
expected returns: [[70.430115]
 [66.72787 ]
 [71.85465 ]
 [78.1745  ]
 [74.41481 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 25. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  4.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.13206100463867



action possibilites: [-1] 
expected returns: [[75.367325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 29.  0. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 76.78852081298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.95903 ]
 [60.962536]
 [75.30203 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 29.  0. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.36732482910156






Player: 1 
cards in hand: [11.  8.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8. 10.  3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25. 15. 11.  3.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  3.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  0  0 16 10 11  6 11  8  6  0  6 15 11  6  8  0  0  6 11
 29  6 25  0  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25. 15. 11.  3.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6
 25  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25. 15. 11.  3.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25. 15. 11.  3.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25. 15. 11.  3.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 11.] 
expected returns: [[39.036385]
 [50.68382 ]
 [35.621746]
 [41.182514]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 11.  3.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  3.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 25. 15.] 
adversary cards in discard: [ 6. 10.  8.  8.] 
adversary owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.3020248413086



action possibilites: [-1] 
expected returns: [[29.153835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3. 29. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 25. 15.] 
adversary cards in discard: [ 6. 10.  8.  8.  6.] 
adversary owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6  6] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.683815002441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.21228 ]
 [16.114956]
 [29.843327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.  3. 29. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 16. 25. 15.] 
adversary cards in discard: [ 6. 10.  8.  8.  6.] 
adversary owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6  6] -> size -> 27 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.15383529663086






Player: 1 
cards in hand: [ 0.  0. 16. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 25. 15.] 
cards in discard: [ 6. 10.  8.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25
  0  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0. 11. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 25.] 
cards in discard: [ 6. 10.  8.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0. 11. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 25.] 
cards in discard: [ 6. 10.  8.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  5. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0. 11. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 25.] 
cards in discard: [ 6. 10.  8.  8.  6. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  0. 11. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[46.958378]
 [49.026848]
 [49.026848]
 [41.894417]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  6.  6. 29. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29] -> size -> 27 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.843341827392578



action possibilites: [-1] 
expected returns: [[68.417786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 6.  6.  6. 29. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29] -> size -> 27 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.525489807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.989193]
 [64.29558 ]
 [50.714462]
 [66.39209 ]
 [68.52317 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 6.  6.  6. 29. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29] -> size -> 27 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.41778564453125






Player: 1 
cards in hand: [ 6.  6.  6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 29. 11.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 30. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [29.  0. 29.  0. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 29.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [29.  0. 29.  0. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 29.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [29.  0. 29.  0. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 29.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [29.  0. 29.  0. 10.] 
adversary cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[47.08563 ]
 [53.244633]
 [53.244633]
 [41.900936]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 10.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.52317810058594



action possibilites: [-1. 10.] 
expected returns: [[32.97183]
 [28.21075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.679866790771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[26.413624]
 [32.27108 ]
 [29.443565]
 [20.563309]
 [31.003166]
 [28.199429]
 [32.75835 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [25. 10.  3. 11. 29.  0. 15. 25.  0. 15. 11.  3. 29. 10. 15. 11.  0.  0.
 11. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.971832275390625






Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 29. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[67.15013 ]
 [62.75561 ]
 [62.75561 ]
 [68.790146]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.75835037231445



action possibilites: [-1] 
expected returns: [[49.462715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.26689910888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.156864]
 [48.225796]
 [41.638443]
 [49.217747]
 [50.37636 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.46271514892578






Player: 1 
cards in hand: [11.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 11.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [15.  0.  0. 15. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [15.  0.  0. 15. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [15.  0.  0. 15. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6. 10.  8.  8.  6. 29. 15.  0. 16. 25.  3.  0. 11.  6.  6.  6. 29.  3.
  6.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [15.  0.  0. 15. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11.] 
expected returns: [[83.32015]
 [79.63834]
 [79.63834]
 [85.60715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15. 11.] 
cards in discard: [15. 11. 10. 10.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  5.] 
adversary cards in hand: [29. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.37636947631836



action possibilites: [-1] 
expected returns: [[64.95173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [29. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.51094818115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.442196]
 [60.684933]
 [47.386192]
 [62.705387]
 [64.836105]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [29. 29.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.95172882080078






Player: 1 
cards in hand: [29. 29.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 25.] 
cards in discard: [0. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  2.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  6.] 
cards in discard: [0. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6] -> size -> 31 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  6.] 
cards in discard: [0. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  8.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6] -> size -> 31 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  6.] 
cards in discard: [0. 3. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  7.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [11.  0. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6] -> size -> 31 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[55.025585]
 [57.33601 ]
 [49.077175]
 [51.467766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 15.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  7.  7.  4. 10. 10.  5. 10.  4.] 
adversary cards in hand: [ 6. 11.  3. 11. 15.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  180    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.83612060546875



action possibilites: [-1] 
expected returns: [[51.44887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 6. 11.  3. 11. 15.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.72488021850586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.358624]
 [37.218937]
 [52.224445]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 6. 11.  3. 11. 15.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.44887161254883






Player: 1 
cards in hand: [ 6. 11.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3. 11. 15.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  1.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11. 15.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11. 15.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11. 15.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 25. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[41.72079 ]
 [47.84583 ]
 [53.552452]
 [53.552452]
 [47.84583 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  3. 29.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.224449157714844



action possibilites: [-1] 
expected returns: [[42.989826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 29.  0. 29.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.55244827270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.341656]
 [42.676975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 29.  0. 29.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.98982620239258






Player: 1 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[61.103878]
 [67.99187 ]
 [56.74986 ]
 [63.575184]
 [63.575184]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11. 11.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [16.  8.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.67698287963867



action possibilites: [-1. 11. 11.] 
expected returns: [[45.50768 ]
 [47.610577]
 [47.610577]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [16.  8.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.68001937866211



action possibilites: [-1] 
expected returns: [[50.649853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [16.  8.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 45.03357696533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.676105]
 [50.410442]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [15. 11. 10. 10.  0.  0. 15. 11. 15.  0.  0. 15.  6. 15. 11.  0. 10. 15.
  3. 25. 29. 25.  3. 29.  0. 29.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [16.  8.  0.  3.  3.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.64985275268555






Player: 1 
cards in hand: [16.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  3.  3.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0
  6  6 29  3  0  3  0  0  8  6  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  3.] 
adversary cards in hand: [ 6.  3.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 6.  3.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 6.  3.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[47.156612]
 [55.615208]
 [51.339085]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1. 25. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.41043472290039



action possibilites: [-1] 
expected returns: [[85.88869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.61520004272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[79.06746 ]
 [85.07492 ]
 [82.29785 ]
 [83.83821 ]
 [81.061134]
 [85.432335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.88868713378906






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25.  3. 10. 11. 15.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  4. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25.  3. 10. 11. 15.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  8. 29. 29. 25.  6.  6. 10.  6.  6.  0. 11.  6.  3. 11. 15.  3.
  8.  0.  6.  6.  0. 15. 16.  8.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25.  3. 10. 11. 15.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25.  3. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 15.] 
expected returns: [[44.71127 ]
 [56.219837]
 [39.89125 ]
 [46.72857 ]
 [41.722702]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 11. 15.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [29. 15.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.43233489990234



action possibilites: [-1] 
expected returns: [[84.55291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 15. 11. 29.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [29. 15.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.21982192993164





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[74.458885]
 [84.08949 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 15. 11. 29.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [29. 15.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.55290985107422






Player: 1 
cards in hand: [29. 15.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 10.  0. 15. 15.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 10.  0. 15. 15.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[60.140232]
 [56.372005]
 [57.895557]
 [57.895557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15. 15.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [29. 15.  0.  6. 11.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.08949279785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[54.224613]
 [57.030132]
 [58.374157]
 [59.722042]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15. 15.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [29. 15.  0.  6. 11.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.14022445678711



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [29. 15.  0.  6. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [15. 11. 15.  0. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [29. 15.  0.  6. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [15. 11. 15.  0. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [29. 15.  0.  6. 11.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [15. 11. 15.  0. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 11. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15. 11.] 
expected returns: [[49.87357 ]
 [46.073563]
 [52.32869 ]
 [46.073563]
 [52.32869 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.  0. 11.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25. 29.  0.  0.  8.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.722042083740234



action possibilites: [-1] 
expected returns: [[58.40716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0. 11.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25. 29.  0.  0.  8.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 49.36349105834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.97095 ]
 [58.916737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0. 11.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [25. 29.  0.  0.  8.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.407161712646484






Player: 1 
cards in hand: [25. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  0.  8.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11 29  6 25  0  6
  6 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 10. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 10. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 10. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 10. 11.] 
adversary cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[20.408363]
 [17.62146 ]
 [15.741818]
 [22.237751]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 10. 11.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.9167366027832



action possibilites: [-1] 
expected returns: [[20.216728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 10.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 20.04962921142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.220843]
 [17.497066]
 [18.588848]
 [19.776463]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10.] 
cards in discard: [25.  6.  3.  1. 29. 10.  0. 25.  3. 10. 11. 15. 11. 29.  0. 10.  0. 15.
 15.  1. 11. 15. 15.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.21672821044922






Player: 1 
cards in hand: [0. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  7.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[54.974873]
 [50.460884]
 [59.70264 ]
 [59.70264 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 6.  6.  3. 16.  0.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.776458740234375



action possibilites: [-1. 10.] 
expected returns: [[94.4786 ]
 [90.57711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [29.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 6.  6.  3. 16.  0.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 54.612361907958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[88.8719 ]
 [91.71587]
 [93.09798]
 [94.52658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [29.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 6.  6.  3. 16.  0.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.47860717773438






Player: 1 
cards in hand: [ 6.  6.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 16.  0.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  1. 11.  6. 10.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 16.  0.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  1. 11.  6. 10.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
adversary victory points: 2
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[97.166565]
 [99.55614 ]
 [91.05612 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  6. 10.] 
cards in discard: [29.  0. 29. 10.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 8.  3. 15.  3. 10.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.52657318115234



action possibilites: [-1] 
expected returns: [[90.32662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 10.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 8.  3. 15.  3. 10.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 96.64009094238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[81.47397 ]
 [89.921745]
 [86.01443 ]
 [88.1802  ]
 [84.2729  ]
 [90.44523 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 8.  3. 15.  3. 10.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
adversary owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.32662200927734






Player: 1 
cards in hand: [ 8.  3. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.  3. 10.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16 10  6 11  8  6  0  6 15 11  6  8  0  0  6 11  6 25  0  6  6
 29  3  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 11. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 11. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 11. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  3.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[62.684597]
 [57.035748]
 [64.99798 ]
 [59.191196]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 11. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 11. 11. 29.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.44523620605469



action possibilites: [-1] 
expected returns: [[63.656048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 11. 11. 29.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 62.23380661010742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[54.927227]
 [59.66479 ]
 [61.93095 ]
 [64.251274]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 11. 11. 29.] 
adversary cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.65604782104492






Player: 1 
cards in hand: [ 0.  0. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 29.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15. 11. 29.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  6.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15. 11. 29.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15. 11. 29.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15. 11. 29.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.] 
cards in discard: [29. 15.  0.  6. 11.  3.  6.  0.  3.  0.  6.  0.  8. 25.  0.  0.  8.  0.
  0.  6.  8.  6.  6.  6.  3. 16.  0.  8.  3.  3.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15. 11. 29.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 11. 29.] 
expected returns: [[58.420242]
 [71.38697 ]
 [54.97958 ]
 [60.84833 ]
 [65.14731 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15. 11. 29.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.25127410888672



action possibilites: [-1] 
expected returns: [[66.585846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 11. 29. 25.  0.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.38697052001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[58.065315]
 [66.38696 ]
 [62.530003]
 [64.66215 ]
 [60.816265]
 [66.86606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 11. 29. 25.  0.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.58584594726562






Player: 1 
cards in hand: [3. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0 16  6 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3
  0  3  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[67.69173 ]
 [70.33446 ]
 [63.553448]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [0. 8. 3. 6.] 
adversary owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.86608123779297



action possibilites: [-1] 
expected returns: [[40.131443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [0. 8. 3. 6.] 
adversary owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 67.1437759399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.862072]
 [34.27862 ]
 [35.985718]
 [37.858772]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [0. 8. 3. 6.] 
adversary owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.13144302368164






Player: 1 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [0. 8. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  8  6  0  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3
  0  0  8  6  0  3 15 29  3  0  8  8  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 29. 11. 10. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 29. 11. 10. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 29. 11. 10. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 6. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 29. 11. 10. 15.] 
adversary cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 15.] 
expected returns: [[20.357758]
 [23.180683]
 [21.385033]
 [17.74094 ]
 [18.803719]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15. 16. 29.  0.] 
adversary cards in discard: [0. 8. 3. 6. 0. 8. 0.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.8587760925293



action possibilites: [-1. 15. 15.] 
expected returns: [[34.11861 ]
 [31.963123]
 [31.963123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15. 16. 29.  0.] 
adversary cards in discard: [0. 8. 3. 6. 0. 8. 0.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.17816925048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.876701]
 [31.533504]
 [32.799656]
 [34.11861 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.] 
cards in discard: [29.  0. 29. 10.  3.  0.  1. 11.  0.  1.  6. 10.  1. 11. 10.  3.  1. 15.
 25.  1. 15. 11. 29. 25.  0.  1. 11.  0.  3.  0. 15. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 0. 15. 16. 29.  0.] 
adversary cards in discard: [0. 8. 3. 6. 0. 8. 0.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.118595123291016






Player: 1 
cards in hand: [ 0. 15. 16. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 16. 29.  0.] 
cards in discard: [0. 8. 3. 6. 0. 8. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6 29  3  0  3  0  0  8
  6  0  3 15 29  3  0  8  8  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10. 10.  5. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 26. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1.  0. 10. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[92.747116]
 [87.950226]
 [89.87086 ]
 [89.87086 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 15. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 6.  3. 25.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.118595123291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[85.73194]
 [92.29558]
 [89.26413]
 [90.94502]
 [87.91357]
 [92.71045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 15. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 6.  3. 25.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.74710083007812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  3. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.  3. 29.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [11. 15. 15. 11.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 29.  0. 11.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [11. 15. 15. 11.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 29.  0. 11.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [11. 15. 15. 11.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 29.  0. 11.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [11. 15. 15. 11.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11. 15. 15. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 11.] 
expected returns: [[70.49605]
 [72.53627]
 [67.21958]
 [67.21958]
 [72.53627]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15. 11.  1.] 
cards in discard: [ 1.  0. 10. 15. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.71044921875



action possibilites: [-1] 
expected returns: [[78.76016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11.  1.] 
cards in discard: [ 1.  0. 10. 15. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 69.91319274902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.97333 ]
 [74.47449 ]
 [76.61583 ]
 [78.914276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 11.  1.] 
cards in discard: [ 1.  0. 10. 15. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.76016235351562






Player: 1 
cards in hand: [0. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  5.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[79.72903 ]
 [87.374466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.91427612304688



action possibilites: [-1. 11.] 
expected returns: [[41.261246]
 [44.46551 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.13677978515625



action possibilites: [-1] 
expected returns: [[58.929096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 40.58063507080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[49.85342 ]
 [58.62367 ]
 [54.509068]
 [56.77424 ]
 [52.689266]
 [59.169277]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
adversary owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.92909622192383






Player: 1 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  8  6  6 11  6  8  0  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6
  0  3 15 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 15. 15.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 15. 15.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 15. 15.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10.  3.  1. 15. 15.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [10.  3.  1. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[58.945312]
 [53.496357]
 [55.27638 ]
 [55.27638 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 15. 15.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 6.  3.  8.  6. 11.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.16927719116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[50.52798 ]
 [53.76432 ]
 [55.343967]
 [57.57466 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1. 15. 15.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 6.  3.  8.  6. 11.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.945316314697266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  3.  8.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8.  6. 11.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 11. 29.  3. 25.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 11. 29.  3. 25.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 11. 29.  3. 25.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 0.  8.  3.  6.  0.  8.  0. 23.  3. 16.  0. 15.  0.  0. 25.  6.  3.  3.
 29.  0. 11.  8.  0.  6.  0.  0.  8.  0.  8.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 11. 29.  3. 25.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[52.047874]
 [54.46898 ]
 [58.98504 ]
 [65.93974 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  3. 25.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.57466506958008



action possibilites: [-1] 
expected returns: [[21.063892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  3. 11. 10.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.93973541259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[12.219121]
 [15.351598]
 [16.851097]
 [18.354992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  3. 11. 10.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.063892364501953






Player: 1 
cards in hand: [1. 3. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  1.  0.  0.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  1.  0.  0.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  1.  0.  0.  1.] 
adversary cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [25.  1.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.61607 ]
 [37.934765]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  0.  1.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [0. 1. 3. 3. 6. 6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.354995727539062



action possibilites: [-1] 
expected returns: [[17.985294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 0. 6.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [0. 1. 3. 3. 6. 6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.93476486206055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[11.892289]
 [17.645473]
 [ 9.367132]
 [14.985944]
 [ 8.086762]
 [16.109718]
 [16.461052]
 [27.003948]
 [22.439583]
 [ 9.816219]
 [15.131152]
 [13.801526]
 [ 9.501096]
 [15.48249 ]
 [17.98529 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 0. 6.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 7 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  7.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [0. 1. 3. 3. 6. 6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.985294342041016



buy possibilites: [-1] 
expected returns: [[24.914127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 0. 6.] 
cards in discard: [ 1.  0. 10. 15. 15.  1. 11. 15. 15. 11.  1.  0.  3.  1. 29. 11.  0.  0.
 10.  3.  1. 15. 15. 25.  1. 11. 29.  3. 11. 10. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [0. 1. 3. 3. 6. 6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   20.    0.    0.    0.    0.  -60.
   0.    0.   62.5   0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 27.003952026367188






Player: 1 
cards in hand: [ 0.  3. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [0. 1. 3. 3. 6. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  0. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [0. 1. 3. 3. 6. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  4.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  0. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [0. 1. 3. 3. 6. 6. 8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [25.  0. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 29.] 
expected returns: [[ 95.22364 ]
 [104.820755]
 [100.176865]
 [ 90.41946 ]
 [100.176865]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.914127349853516



action possibilites: [-1] 
expected returns: [[87.87103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29.  3. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.82075500488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.38328]
 [87.95386]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10. 29.  3. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.87103271484375






Player: 1 
cards in hand: [ 0.  8.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 1. 25. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[36.386856]
 [44.698143]
 [34.420452]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15.  1.  0.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.953857421875



action possibilites: [-1] 
expected returns: [[78.24783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.  0. 10.  3.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.6981315612793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[74.07893 ]
 [81.066246]
 [77.608154]
 [69.749054]
 [79.055565]
 [79.49746 ]
 [92.71656 ]
 [87.31917 ]
 [71.715126]
 [77.78843 ]
 [76.250656]
 [71.380905]
 [78.1866  ]
 [81.44624 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  0. 10.  3.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  6.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.24783325195312



buy possibilites: [-1] 
expected returns: [[95.97828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  0. 10.  3.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -70   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 92.71654510498047






Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 11.  0. 25. 29.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  3. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 11.  0. 25. 29.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 11.  0. 25. 29.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 29.] 
expected returns: [[30.12418 ]
 [34.55966 ]
 [31.744339]
 [38.623146]
 [34.55966 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 25. 29.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 25.  0.  8.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 43 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.97827911376953



action possibilites: [-1] 
expected returns: [[86.59652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  3.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 25.  0.  8.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 43 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.62314987182617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[80.31447 ]
 [86.291245]
 [83.509926]
 [85.053894]
 [82.27258 ]
 [86.608505]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 29.  3.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [29. 25.  0.  8.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 43 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.59651947021484






Player: 1 
cards in hand: [29. 25.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  8.  8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6 25  0  6  6  3  0  3  0  0  8  6  0  3 15
 29  3  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10. 15. 11.  1. 11.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10. 15. 11.  1. 11.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [10. 15. 11.  1. 11.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10. 15. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 11.] 
expected returns: [[19.709538]
 [16.805984]
 [17.986435]
 [20.924759]
 [20.924759]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11.  1. 11.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  8.  6.  0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.60848999023438



action possibilites: [-1] 
expected returns: [[36.340366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  1. 11.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  8.  6.  0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 19.52214813232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[32.073887]
 [34.050724]
 [35.005344]
 [35.934113]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  1. 11.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  8.  6.  0.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
adversary owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.34036636352539






Player: 1 
cards in hand: [ 0. 15.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  6.  0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  0  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3
  0  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 11. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 11. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  2.] 
adversary cards in hand: [ 0. 11. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  1.] 
adversary cards in hand: [ 0. 11. 15.  1.  0.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[8.224382]
 [9.453849]
 [6.472516]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  1.  0.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  1.] 
adversary cards in hand: [ 0.  8. 11. 23.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.934104919433594



action possibilites: [-1] 
expected returns: [[17.411125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  0.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  1.] 
adversary cards in hand: [ 0.  8. 11. 23.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 7.976630210876465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.859172]
 [17.200626]
 [15.188537]
 [16.05738 ]
 [16.306889]
 [20.768608]
 [11.272948]
 [14.294791]
 [15.558307]
 [17.411129]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  0.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  2. 10.  9.  5. 10.  1.] 
adversary cards in hand: [ 0.  8. 11. 23.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.41112518310547



buy possibilites: [-1] 
expected returns: [[28.89394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  0.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [ 0.  8. 11. 23.  8.] 
adversary cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -100    0    0
  128    0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.76860809326172






Player: 1 
cards in hand: [ 0.  8. 11. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 23.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 23.  8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [10.  6.  1. 11.  1.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29] -> size -> 45 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 23.  8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [10.  6.  1. 11.  1.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29] -> size -> 45 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11. 23.  8.] 
cards in discard: [ 0.  1.  3.  3.  6.  6.  8.  0.  3. 11.  0.  6.  0.  0.  8.  0. 16.  6.
 29.  0.  6.  0.  0.  0.  8.  0.  8. 15. 15.  8.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [10.  6.  1. 11.  1.] 
adversary cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29] -> size -> 45 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10.  6.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[6.235839 ]
 [4.1475058]
 [7.110574 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1. 11.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.893939971923828



action possibilites: [-1] 
expected returns: [[14.62795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 6.095664024353027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[11.074005 ]
 [14.480367 ]
 [12.885781 ]
 [13.583484 ]
 [13.773894 ]
 [17.311207 ]
 [ 9.8273735]
 [12.179303 ]
 [13.177733 ]
 [14.627955 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 18. 30. 25. 30.  8.  0.  9.  0.  3.  5.  1. 10.  9.  5. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.627949714660645



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 4 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  6.  1.  1.] 
cards in discard: [25.  0. 29. 10. 29.  3. 15. 25. 25.  1. 15.  1.  0. 10.  3. 25. 29. 11.
  0. 29.  3.  1.  1. 11. 10. 15.  1. 11.  1. 29. 11.  0. 15.  1.  0.  1.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 29 11 10 29 11 25 10 11 11 10
 29 15 15 15 15 15  6 15  1  1  1  1  1  1  1  1 25 25  1  1 29  1 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 25. 30.  8.  0.  9.  0.  3.  5.  0. 10.  9.  5. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  6 11  6  8  6 11  6  0  6  6  3  0  3  0  0  8  6  0  3 15  3  0
  8  8  0  0  0 23  3  0  8  0  1  0  0  8  0 29 15  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0    -120       0       0      64       0] 
sum of rewards: 3000079 

action type: buy - action 29.0
Learning step: 120002.46875
desired expected reward: 120019.78125



