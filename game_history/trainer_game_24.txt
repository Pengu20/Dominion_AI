 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.61514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -595 

action type: buy - action -1.0
Learning step: -33.991703033447266
desired expected reward: 50.842342376708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[294.63327]
 [298.98236]
 [299.37885]
 [292.09912]
 [305.35883]
 [300.22202]
 [300.64377]
 [315.58124]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.81873607635498
desired expected reward: 304.5108947753906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.43732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.980188846588135
desired expected reward: 307.6010437011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[322.76642]
 [327.66238]
 [328.12878]
 [319.92493]
 [327.92892]
 [334.00244]
 [329.04068]
 [335.36255]
 [326.19168]
 [329.46335]
 [331.00482]
 [344.62753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.05418872833252
desired expected reward: 341.0068664550781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.55392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.14487075805664
desired expected reward: 334.482666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[299.30237]
 [303.77255]
 [304.18375]
 [296.70038]
 [310.09464]
 [305.0191 ]
 [305.4342 ]
 [320.30515]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.015822410583496
desired expected reward: 310.38446044921875



buy possibilites: [-1] 
expected returns: [[299.19]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.519183158874512
desired expected reward: 296.4999694824219






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.9275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.68344259262085
desired expected reward: 291.5065612792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[304.80438]
 [309.51175]
 [309.97144]
 [302.2027 ]
 [309.7794 ]
 [316.13574]
 [310.8482 ]
 [317.57962]
 [308.116  ]
 [311.30792]
 [312.94385]
 [326.7565 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.295939445495605
desired expected reward: 318.5288391113281



buy possibilites: [-1] 
expected returns: [[307.39365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 29.0
Learning step: -7.462624549865723
desired expected reward: 310.11700439453125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[321.36493]
 [307.75677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.24454402923584
desired expected reward: 299.14910888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[304.7694 ]
 [308.20605]
 [308.5016 ]
 [302.69717]
 [308.3709 ]
 [313.56912]
 [309.2163 ]
 [314.77625]
 [307.12354]
 [309.56967]
 [310.93103]
 [322.31284]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.191160202026367
desired expected reward: 315.1165771484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  0.] 
cards in discard: [ 8. 11.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 11.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 11.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 11.  0.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[267.6161 ]
 [259.80692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.686540603637695
desired expected reward: 311.62628173828125



action possibilites: [-1.] 
expected returns: [[325.62146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 9 

action type: take_action - action 29.0
Learning step: -5.309497833251953
desired expected reward: 256.41009521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[303.5926 ]
 [307.61545]
 [308.00983]
 [301.26483]
 [307.84576]
 [313.5656 ]
 [308.80988]
 [314.8862 ]
 [306.37115]
 [309.20428]
 [310.68893]
 [323.10443]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.751654624938965
desired expected reward: 316.86981201171875



buy possibilites: [-1] 
expected returns: [[355.96967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 8. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 10.0 

action type: buy - action 8.0
Learning step: -6.931180000305176
desired expected reward: 301.8787536621094






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.22003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -11.477376937866211
desired expected reward: 344.4922790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[280.7585 ]
 [284.95758]
 [278.50436]
 [285.74582]
 [299.70462]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.321279525756836
desired expected reward: 297.1116943359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[328.7557 ]
 [322.4443 ]
 [318.06085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [3. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  3.] 
adversary cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.281829833984375
desired expected reward: 291.42279052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[314.0125 ]
 [317.12372]
 [317.29633]
 [312.1363 ]
 [321.34302]
 [317.9062 ]
 [318.07874]
 [329.0689 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [3. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  9.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  3.] 
adversary cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.661015510559082
desired expected reward: 317.4186096191406



buy possibilites: [-1] 
expected returns: [[339.89078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [ 3.  0.  3.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  0.  3.] 
adversary cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 11.0
Learning step: -8.119609832763672
desired expected reward: 313.22344970703125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [16.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  0.  3.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 16  8  0  3 29  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  8  0  3 29  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0. 11.  0.  3.  0.  1.  8.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  8  0  3 29  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[292.1107 ]
 [279.83627]
 [279.83627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  8  0  3 29  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -11.118081092834473
desired expected reward: 328.772705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.9758 ]
 [277.07434]
 [277.30756]
 [272.14288]
 [281.30173]
 [277.9009 ]
 [278.13412]
 [289.31198]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  8  0  3 29  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.784794807434082
desired expected reward: 282.8341064453125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  8  0  3 29  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  6. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[351.88437]
 [343.12198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [8. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -6.693997859954834
desired expected reward: 282.6180114746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[333.24512]
 [336.95065]
 [331.26654]
 [337.61774]
 [351.29953]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [8. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.9312744140625
desired expected reward: 342.0328674316406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  8.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [ 8.  8.  0.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[333.6528 ]
 [324.17184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  0. 11.  0.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.174773216247559
desired expected reward: 341.1247863769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[314.25925]
 [319.59918]
 [311.4116 ]
 [320.50854]
 [336.98648]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  0. 11.  0.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.442720413208008
desired expected reward: 325.64288330078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  3.  0. 11.  0.  0.  8. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  3.  0. 11.  0.  0.  8. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  3.  0. 11.  0.  0.  8. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[362.74454]
 [353.12646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 29.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.860663414001465
desired expected reward: 328.1258239746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[346.08444]
 [349.01794]
 [349.199  ]
 [344.325  ]
 [349.1167 ]
 [352.9413 ]
 [349.76703]
 [353.90765]
 [348.00345]
 [349.94803]
 [350.99667]
 [359.33987]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 29.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  7.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.195307731628418
desired expected reward: 351.5199890136719



buy possibilites: [-1] 
expected returns: [[395.1299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 29.  3.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -8.631644248962402
desired expected reward: 344.3096618652344






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[283.7871 ]
 [277.18045]
 [277.18045]
 [273.91946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29. 10.] 
adversary cards in discard: [ 3. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -14.012377738952637
desired expected reward: 381.1175231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[270.4514 ]
 [268.68323]
 [284.08566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29. 10.] 
adversary cards in discard: [ 3. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.539756774902344
desired expected reward: 276.08392333984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29. 10.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 11.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 11.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  5. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 11.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 11.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[372.49442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 11.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 3. 8.] 
adversary cards in discard: [ 3. 11.  3.  0. 11.  0.  8. 10.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.414714813232422
desired expected reward: 277.67095947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[351.009  ]
 [356.1405 ]
 [356.63263]
 [348.2017 ]
 [363.47028]
 [357.6126 ]
 [358.10477]
 [374.12042]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 11.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 1. 0. 3. 8.] 
adversary cards in discard: [ 3. 11.  3.  0. 11.  0.  8. 10.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.95023250579834
desired expected reward: 361.09442138671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3. 8.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.  8. 10.  0.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  8  0  3 29  0  8  8 11 10  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [11. 11.  8.  3.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.  8. 10.  0.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [11. 11.  8.  3.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 11.  3.  0. 11.  0.  8. 10.  0.  8.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [11. 11.  8.  3.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[287.27374]
 [277.12418]
 [270.45297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [11. 11.  8.  3.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -13.003107070922852
desired expected reward: 361.1173400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.78098]
 [270.3317 ]
 [270.79697]
 [263.1891 ]
 [276.77362]
 [271.6396 ]
 [272.10486]
 [287.91904]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [11. 11.  8.  3.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.500685691833496
desired expected reward: 275.8365478515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[292.1751 ]
 [278.22876]
 [284.39246]
 [278.22876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.500633239746094
desired expected reward: 279.4183654785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[269.98294]
 [267.98648]
 [289.7204 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.871026992797852
desired expected reward: 284.05291748046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [ 0. 29.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [ 8. 29.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 0. 29.  8.  3.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [ 8. 29.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 0. 29.  8.  3.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [ 8. 29.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[308.48944]
 [298.7752 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [ 8. 29.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.242045402526855
desired expected reward: 281.4783935546875



action possibilites: [-1] 
expected returns: [[358.223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 17 

action type: gain_card_n - action 9
Learning step: -5.9171576499938965
desired expected reward: 290.6263427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[339.4102 ]
 [342.63693]
 [337.63422]
 [343.2105 ]
 [353.189  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -9.667949676513672
desired expected reward: 348.5550537109375



buy possibilites: [-1] 
expected returns: [[344.7004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -10.314750671386719
desired expected reward: 329.0954284667969






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  8.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  0.  3.] 
cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 0.] 
cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29.  8.  3.  3. 14. 11.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[236.59761]
 [227.11719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 14. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -12.100932121276855
desired expected reward: 332.5994873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[213.60017]
 [217.94576]
 [218.38033]
 [210.96922]
 [218.21088]
 [223.79657]
 [219.13843]
 [225.07661]
 [216.79892]
 [219.57301]
 [221.02252]
 [233.55669]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 14. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.727284908294678
desired expected reward: 228.07020568847656



buy possibilites: [-1] 
expected returns: [[255.83554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 8. 29.  0.  3.  8. 10.  0. 11.  0.  3.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 14. 11.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -3.6542441844940186
desired expected reward: 214.55662536621094






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3. 14. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3. 11.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3. 11.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3. 11.] 
cards in discard: [16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  8. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 16.] 
expected returns: [[230.54306]
 [217.6517 ]
 [221.91498]
 [216.7946 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 29. 10.  0.] 
adversary cards in discard: [16.  0. 11.  3. 14.  3. 11.] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.829833984375
desired expected reward: 248.00570678710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.11899]
 [210.9028 ]
 [230.89867]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 29. 10.  0.] 
adversary cards in discard: [16.  0. 11.  3. 14.  3. 11.] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.487732887268066
desired expected reward: 222.556396484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29. 10.  0.] 
cards in discard: [16.  0. 11.  3. 14.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  0.  0.] 
cards in discard: [16.  0. 11.  3. 14.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  0.  0.] 
cards in discard: [16.  0. 11.  3. 14.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  4. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  0.  0.] 
cards in discard: [16.  0. 11.  3. 14.  3. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[318.7223 ]
 [313.46274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 3.  3.  8. 11. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -4.488795757293701
desired expected reward: 226.40985107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[304.94025]
 [307.99197]
 [308.2473 ]
 [303.15192]
 [308.15024]
 [312.1845 ]
 [308.83203]
 [313.14954]
 [307.05533]
 [309.0874 ]
 [310.1784 ]
 [318.7734 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 3.  3.  8. 11. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.87057113647461
desired expected reward: 308.02398681640625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [ 3.  3.  8. 11. 16.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[233.48694]
 [223.10667]
 [222.84492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [ 3.  3.  8. 11. 16.  0.  0. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [0. 3. 8. 0. 8.] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.922782897949219
desired expected reward: 307.85064697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[215.49991]
 [218.93094]
 [213.63722]
 [219.53928]
 [230.18132]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [ 3.  3.  8. 11. 16.  0.  0. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [0. 3. 8. 0. 8.] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.561564922332764
desired expected reward: 224.0451202392578



buy possibilites: [-1] 
expected returns: [[240.35802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [ 3.  3.  8. 11. 16.  0.  0. 29.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [0. 3. 8. 0. 8.] 
adversary owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.92380714416504
desired expected reward: 192.7134246826172






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8. 11.] 
cards in discard: [0. 3. 8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [0. 3. 8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.] 
cards in discard: [0. 3. 8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[260.6037 ]
 [248.94415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0. 14.] 
adversary cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.880374431610107
desired expected reward: 233.47764587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[237.79951]
 [242.52307]
 [243.11511]
 [235.16113]
 [242.89166]
 [250.37836]
 [244.13347]
 [252.09885]
 [241.09401]
 [244.72552]
 [246.66945]
 [262.52   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0. 14.] 
adversary cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.921116828918457
desired expected reward: 252.05068969726562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11. 16.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.  0. 14.] 
cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 14 16  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [ 0.  3.  8.  0.  8.  8. 10.  8. 11.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [29. 11. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[309.6889 ]
 [302.10626]
 [300.8618 ]
 [296.8692 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0.  6.] 
cards in discard: [ 0.  0.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -6.3942437171936035
desired expected reward: 256.125732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[293.67535]
 [291.4132 ]
 [312.35278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10.  0.  6.] 
cards in discard: [ 0.  0.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -8.72058391571045
desired expected reward: 300.5074462890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [ 0.  0.  0. 11.  0. 29. 11. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [ 0.  0.  0. 11.  0. 29. 11. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[269.94107]
 [257.97583]
 [257.97583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [ 0.  0.  0. 11.  0. 29. 11. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -9.783087730407715
desired expected reward: 302.5697021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[251.43707]
 [255.09642]
 [249.46423]
 [255.73993]
 [268.46884]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [ 0.  0.  0. 11.  0. 29. 11. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  3. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.7250213623046875
desired expected reward: 262.00555419921875



buy possibilites: [-1] 
expected returns: [[270.77454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [ 0.  0.  0. 11.  0. 29. 11. 10.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.] 
adversary owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -6.444568157196045
desired expected reward: 249.2953338623047






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 8.] 
cards in discard: [ 0.  6.  0.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  3 29  0  8  8 11 10  3  8 16  0  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  3. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 16.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[262.1494]
 [248.6954]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29  8 11 11 10  0 16  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  8. 10.  0.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -7.403752326965332
desired expected reward: 263.37078857421875



action possibilites: [-1] 
expected returns: [[201.3097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  8. 10.  0.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 25 

action type: gain_card_n - action 9
Learning step: -5.977694034576416
desired expected reward: 229.16554260253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.78967]
 [177.19783]
 [170.48743]
 [177.94704]
 [196.00291]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  8. 10.  0.] 
adversary cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -5.033162593841553
desired expected reward: 196.2765350341797






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11. 11.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 10.  0.] 
cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  0.] 
cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10.  0.] 
cards in discard: [ 0.  6.  0.  3. 29.  0.  8.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[282.25137]
 [271.5559 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [10. 16.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -3.5703747272491455
desired expected reward: 188.088134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[257.3401 ]
 [261.69202]
 [262.17648]
 [254.9147 ]
 [268.33105]
 [263.04724]
 [263.53168]
 [279.02652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [10. 16.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -8.009513854980469
desired expected reward: 270.57177734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  1.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  8. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 16.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 16.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[263.5039 ]
 [245.21402]
 [244.67342]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -8.439224243164062
desired expected reward: 270.5872802734375



action possibilites: [-1.  8.] 
expected returns: [[297.15314]
 [277.97293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: -4.6282057762146
desired expected reward: 236.6632537841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.24377]
 [278.8626 ]
 [279.4376 ]
 [270.00797]
 [286.827  ]
 [280.4868 ]
 [281.06174]
 [299.667  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  8.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -7.506906986236572
desired expected reward: 289.646240234375



buy possibilites: [-1] 
expected returns: [[293.97983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10. 16.  0.  0.  3.  0.  6. 11.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.] 
adversary owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -21.635854721069336
desired expected reward: 248.3721466064453






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [14. 11.  0.  1.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3 29  0  8 11 10  3  8 16  0  8  6  0  0  1 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [14. 11.  0.  1.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [14. 11.  0.  1.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [14. 11.  0.  1.  8. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [16.  8. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.  8. 29.] 
expected returns: [[239.58276]
 [223.49939]
 [224.49405]
 [229.48648]
 [224.49405]
 [230.87311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
adversary owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -10.191139221191406
desired expected reward: 283.7886962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[216.98428]
 [214.45724]
 [237.7678 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  7.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
adversary owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -7.4871826171875
desired expected reward: 231.19967651367188



buy possibilites: [-1] 
expected returns: [[241.27217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 11.  8. 29.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
adversary owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14  0] -> size -> 16 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -326 

action type: buy - action 6.0
Learning step: -21.59423828125
desired expected reward: 192.8629913330078






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [11.  8.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 29.  3.] 
cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8 11 10  3  8 16  8  6  0  0  1 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [14. 11.  0.  1.  8. 16.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0.  3.  3.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [10.  6.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[251.7498 ]
 [242.98695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  3.  3.] 
cards in discard: [ 6. 16.  8. 11.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -7.797595977783203
desired expected reward: 233.47457885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[236.853  ]
 [235.29497]
 [249.26302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  3.  3.] 
cards in discard: [ 6. 16.  8. 11.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0] -> size -> 14 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -8.252899169921875
desired expected reward: 241.1474609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [1. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[170.86893]
 [162.5989 ]
 [158.98456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16.  1.  3. 10.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
adversary owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -10.585345268249512
desired expected reward: 238.6776885986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[157.04248]
 [160.27194]
 [160.57654]
 [155.16852]
 [165.0373 ]
 [161.18771]
 [161.49232]
 [173.74759]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16.  1.  3. 10.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
adversary owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.3465375900268555
desired expected reward: 160.29270935058594



buy possibilites: [-1] 
expected returns: [[180.9695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16.  1.  3. 10.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
adversary owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -23.0 

action type: buy - action 3.0
Learning step: -5.1070146560668945
desired expected reward: 155.46954345703125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  1.  3. 10.] 
cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  1.  3.  8.] 
cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  3  8 11 10  3  8 16  8  6  0  1 14  0  1  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  3. 11.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[173.35797]
 [159.71855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -6.500720500946045
desired expected reward: 174.46878051757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[158.02072]
 [161.72743]
 [162.12419]
 [155.89642]
 [161.97691]
 [167.0181 ]
 [162.81462]
 [168.18835]
 [160.72215]
 [163.21136]
 [164.5289 ]
 [175.6102 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  6.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -6.019105434417725
desired expected reward: 165.86990356445312



buy possibilites: [-1] 
expected returns: [[240.52483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 6. 16.  8. 11.  8. 29. 10.  6.  0.  3.  3.  3.  0. 11.  0.  8.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -20.5 

action type: buy - action 11.0
Learning step: -3.538965940475464
desired expected reward: 154.9765167236328






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  3. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 14.  8. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 14.  8. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 14.  8. 11.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[160.43987]
 [150.06233]
 [150.06233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 0. 10.  3. 14.  8. 11.] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -9.75699520111084
desired expected reward: 230.76783752441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.96838]
 [135.36378]
 [159.33235]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 0. 10.  3. 14.  8. 11.] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.8021087646484375
desired expected reward: 153.80157470703125



buy possibilites: [-1] 
expected returns: [[199.30064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 0. 10.  3. 14.  8. 11.] 
adversary owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -5.16415548324585
desired expected reward: 132.8042449951172






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [ 0. 10.  3. 14.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6  0 14  0  1  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  3. 14.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  3. 14.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 3. 29.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[241.74947]
 [236.73436]
 [232.98836]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  8.  3.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 29  8 11 11 10  0 16  6  8 10  6  6  3 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -5.87170934677124
desired expected reward: 193.42893981933594



action possibilites: [-1] 
expected returns: [[204.10228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 11
Learning step: -7.775210857391357
desired expected reward: 223.5750274658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[178.79758]
 [175.73323]
 [203.90533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -6.601653575897217
desired expected reward: 197.50062561035156






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 6.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 6.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 6.] 
cards in discard: [16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
expected returns: [[200.74213]
 [188.2452 ]
 [188.56288]
 [187.52266]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 16.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  8 11 11 10  0 16  6  8 10  6  6  3 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11. 10.] 
adversary cards in discard: [16.  0. 11.  3.  8.  3.  6.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -7.613383769989014
desired expected reward: 196.29196166992188



action possibilites: [-1] 
expected returns: [[153.06688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11. 10.] 
adversary cards in discard: [16.  0. 11.  3.  8.  3.  6.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.6938958168029785
desired expected reward: 180.06411743164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.3438 ]
 [132.63086]
 [149.43365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11. 10.] 
adversary cards in discard: [16.  0. 11.  3.  8.  3.  6.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -5.201472282409668
desired expected reward: 147.8654022216797






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11. 10.] 
cards in discard: [16.  0. 11.  3.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11. 10.] 
cards in discard: [16.  0. 11.  3.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[178.9343 ]
 [166.56578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.364367961883545
desired expected reward: 144.06930541992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[158.28656]
 [161.47493]
 [161.78093]
 [156.54253]
 [166.181  ]
 [162.42395]
 [162.72993]
 [175.94688]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 11.  6.  0. 11.  6.  8.  3.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.785745143890381
desired expected reward: 169.45205688476562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6 14  0  3  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 8.  0. 11.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[159.73686]
 [148.50943]
 [152.17004]
 [148.80792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 16. 11.  8.] 
adversary cards in discard: [ 8.  3.  0. 14.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -7.104092597961426
desired expected reward: 168.8427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.0132 ]
 [144.11145]
 [161.45033]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 16. 11.  8.] 
adversary cards in discard: [ 8.  3.  0. 14.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.219905376434326
desired expected reward: 152.56199645996094



buy possibilites: [-1] 
expected returns: [[177.9252]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6. 10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 16. 11.  8.] 
adversary cards in discard: [ 8.  3.  0. 14.] 
adversary owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -6.236505508422852
desired expected reward: 132.5599365234375






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [10.  0. 16. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16. 11.  8.] 
cards in discard: [ 8.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.] 
cards in discard: [ 8.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.] 
cards in discard: [ 8.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.] 
cards in discard: [ 8.  3.  0. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 10.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 8.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[179.97739]
 [167.56557]
 [167.9183 ]
 [167.56557]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  8.  0.] 
cards in discard: [ 0.  8.  0. 11.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8 11 11 10  0  6  8 10  6  6  3 11  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -6.8014726638793945
desired expected reward: 171.1237335205078



action possibilites: [-1] 
expected returns: [[188.65067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0. 11.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 11
Learning step: -4.858120441436768
desired expected reward: 161.19708251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[174.13211]
 [172.3984 ]
 [189.61923]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0. 11.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -6.079308032989502
desired expected reward: 182.57135009765625






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [16.  3.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  6.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6. 11. 11.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  3.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6. 11. 11.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  3.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6. 11. 11.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  3.] 
cards in discard: [16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6. 11. 11.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6.  6. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[215.60182]
 [209.68161]
 [209.68161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11. 11.  0.] 
cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [16.  0. 11. 16.  3.  6.  3.] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -6.4959869384765625
desired expected reward: 183.1232452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[201.14432]
 [200.01956]
 [213.56525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11. 11.  0.] 
cards in discard: [ 0.  8.  0. 11.  6. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [16.  0. 11. 16.  3.  6.  3.] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -7.815651893615723
desired expected reward: 206.8042449951172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [16.  0. 11. 16.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [16.  0. 11. 16.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [16.  0. 11. 16.  3.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[167.2792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -8.682100296020508
desired expected reward: 204.8831329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.79106]
 [151.54286]
 [151.93034]
 [145.63544]
 [157.06218]
 [152.68806]
 [153.07555]
 [165.87393]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  5.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.635350704193115
desired expected reward: 162.08294677734375



buy possibilites: [-1] 
expected returns: [[185.60324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  4.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -18 

action type: buy - action 11.0
Learning step: -4.577037811279297
desired expected reward: 152.48516845703125






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  4.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  6. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11] -> size -> 18 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  4.  2. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  6. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11] -> size -> 18 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  4.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  6. 10. 11.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11] -> size -> 18 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 8. 11.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 11.] 
expected returns: [[144.57489]
 [132.7729 ]
 [136.67119]
 [133.11038]
 [136.67119]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6. 10. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  4.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  8.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0  8] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -7.944908142089844
desired expected reward: 177.6583251953125



action possibilites: [-1] 
expected returns: [[162.52844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  8.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0  8] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -7 

action type: gain_card_n - action 5
Learning step: -3.087007999420166
desired expected reward: 124.79094696044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.0473 ]
 [141.46025]
 [164.19278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10. 11.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  8.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.] 
adversary owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0  8] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -5.380491256713867
desired expected reward: 157.14794921875






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [16. 11.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  8.  0.  6.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  3  8  8  6 14  3  0 16  0  0 16  0  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  6.  8.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[123.58646]
 [115.11975]
 [110.94808]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  8.  0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 11 11  0  6  8 10  6  6  3 11  0  0 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.] 
adversary owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -7.398301601409912
desired expected reward: 156.7944793701172



action possibilites: [-1] 
expected returns: [[154.05193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.] 
adversary owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.257991075515747
desired expected reward: 99.22518920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.73347]
 [132.33536]
 [154.32541]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  3.  0.  0.  3.  0. 11. 11.  8.  6. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.] 
adversary owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -4.074195861816406
desired expected reward: 149.97772216796875






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [16.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  0.  0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  8  6 14  3  0  0 16  0  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  6.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 26. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 14.  8.  0.  8.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[108.16156]
 [ 97.61716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -5.517168998718262
desired expected reward: 148.80824279785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.47383 ]
 [ 89.88232 ]
 [ 90.1801  ]
 [ 84.4892  ]
 [ 94.964874]
 [ 90.84096 ]
 [ 91.13874 ]
 [104.632256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -3.450002670288086
desired expected reward: 105.92304229736328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 30. 25. 30.  8.  5.  5.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[202.11337]
 [187.60896]
 [187.9403 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  0.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  3. 16.  6.] 
adversary cards in discard: [16. 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -0.9745628237724304
desired expected reward: 103.65767669677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.55733]
 [183.78647]
 [178.8341 ]
 [184.36111]
 [196.09906]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10.  0.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  3. 16.  6.] 
adversary cards in discard: [16. 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -6.03638219833374
desired expected reward: 196.5743408203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 16.  6.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  6. 11. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  6. 11. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  6. 11. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  6. 11. 11.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [11. 11.  6. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 11.] 
expected returns: [[169.90788]
 [161.4059 ]
 [161.4059 ]
 [161.4059 ]
 [161.4059 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  6. 11. 11.] 
cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  8.] 
adversary cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.] 
adversary owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.783390522003174
desired expected reward: 190.31565856933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.06818]
 [149.16214]
 [168.36356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  6. 11. 11.] 
cards in discard: [ 3.  0.  8.  0.  0.  3.  0.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 14.  8.] 
adversary cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.] 
adversary owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0  0] -> size -> 18 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.456806182861328
desired expected reward: 163.91650390625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 14.  8.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6 14  3  0  0 16  0  0  8  0  6  3 16  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [16. 10.  0.  0.  6.  0.  0.  0.  0. 16.  8.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[123.049  ]
 [115.6949 ]
 [112.20768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 16.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0  0] -> size -> 16 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.436460018157959
desired expected reward: 162.92710876464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.023865]
 [107.34873 ]
 [103.725044]
 [107.78233 ]
 [116.82344 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 16.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0  0] -> size -> 16 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -3.2618629932403564
desired expected reward: 118.74281311035156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 16.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0 16  0  0  8  0  6  3 16  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  8.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  8.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  8.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  8.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.] 
expected returns: [[176.87593]
 [164.24236]
 [167.98055]
 [167.98055]
 [163.89198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  8.] 
cards in discard: [ 6.  0. 11.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [14.  0. 16.  3.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -1.697024941444397
desired expected reward: 115.12642669677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.55196]
 [155.47154]
 [174.31616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.  8.] 
cards in discard: [ 6.  0. 11.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [14.  0. 16.  3.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.647413730621338
desired expected reward: 170.27818298339844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [14.  0. 16.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.  0. 10. 11. 11.  8.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [14.  0. 16.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 25. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.  0. 10. 11. 11.  8.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [14.  0. 16.  3.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 6.  0. 11.  8.  0.  0. 10. 11. 11.  8.] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[162.34293]
 [154.36627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 6.  0. 11.  8.  0.  0. 10. 11. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [14.  0. 16.  3.  0.  6.  3. 10.  0.  0.  0.  8.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -5.360114574432373
desired expected reward: 168.9560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.91045]
 [148.48686]
 [143.11107]
 [149.16415]
 [161.31718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 6.  0. 11.  8.  0.  0. 10. 11. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [14.  0. 16.  3.  0.  6.  3. 10.  0.  0.  0.  8.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.68961763381958
desired expected reward: 155.22021484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [14.  0. 16.  3.  0.  6.  3. 10.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [14.  0. 16.  3.  0.  6.  3. 10.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[129.57819]
 [122.96581]
 [122.96581]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -5.387234687805176
desired expected reward: 155.92996215820312



action possibilites: [-1] 
expected returns: [[131.33878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 11
Learning step: -2.323686361312866
desired expected reward: 108.25248718261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.47501 ]
 [112.100006]
 [127.7858  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -3.5455806255340576
desired expected reward: 127.79319763183594






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [16. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  3.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
adversary victory points: 0
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[111.62816 ]
 [101.834946]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3.  0.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [16. 14.  0.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -4.702353000640869
desired expected reward: 123.08345794677734



action possibilites: [-1. 11.] 
expected returns: [[108.28082]
 [101.79623]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  4.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [16. 14.  0.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -2.3905904293060303
desired expected reward: 98.4742660522461



action possibilites: [-1.] 
expected returns: [[102.80507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  5.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [16. 14.  0.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 41 

action type: gain_card_n - action 4
Learning step: -0.4376201629638672
desired expected reward: 95.57706451416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.8653 ]
 [ 97.68551]
 [ 94.83232]
 [ 98.03261]
 [104.96533]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 24. 30.  8.  5.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [16. 14.  0.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: -1.5979896783828735
desired expected reward: 101.20707702636719



buy possibilites: [-1] 
expected returns: [[100.59769]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 8.  8. 16.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 24. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [16. 14.  0.  0.  6.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -286.0 

action type: buy - action 6.0
Learning step: -16.778167724609375
desired expected reward: 78.05415344238281






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [16. 14.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 24. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[138.64719]
 [134.08282]
 [134.08282]
 [134.08282]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 6. 0.] 
adversary cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -3.7678215503692627
desired expected reward: 96.82986450195312



action possibilites: [-1] 
expected returns: [[111.92401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 6. 0.] 
adversary cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -7 

action type: gain_card_n - action 9
Learning step: -4.454948425292969
desired expected reward: 128.00982666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.64168]
 [ 98.28524]
 [ 94.20313]
 [ 98.76638]
 [107.46492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 8. 0. 6. 0.] 
adversary cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -4.067461013793945
desired expected reward: 107.85655212402344






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 6. 0.] 
cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 10. 11.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6. 0.] 
cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 23. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 10. 11.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6. 0.] 
cards in discard: [16. 14.  0.  0.  6.  3. 10.  0.  3.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 10. 11.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8.  3. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[83.51077 ]
 [74.132645]
 [74.39671 ]
 [77.22925 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 11.  6.] 
cards in discard: [10. 11.  0. 11.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  3.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.902159214019775
desired expected reward: 101.56275939941406



action possibilites: [-1] 
expected returns: [[78.090675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  6.] 
cards in discard: [10. 11.  0. 11.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -17 

action type: gain_card_n - action 5
Learning step: -2.573678970336914
desired expected reward: 67.04070281982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.48332]
 [65.98192]
 [80.50753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  6.] 
cards in discard: [10. 11.  0. 11.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -3.4884681701660156
desired expected reward: 74.60220336914062






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 22. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 21. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [10.  6. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
expected returns: [[111.129875]
 [107.44671 ]
 [107.15911 ]
 [107.41213 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.0999650955200195
desired expected reward: 70.37852478027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.79061]
 [ 99.079  ]
 [104.94532]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 21. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.] 
adversary owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -5.929051876068115
desired expected reward: 103.11447143554688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3.  0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 30.  8.  4.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 11.] 
adversary cards in discard: [10.  6. 16.  0.  8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 11.] 
adversary cards in discard: [10.  6. 16.  0.  8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 11.] 
adversary cards in discard: [10.  6. 16.  0.  8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 11.] 
adversary cards in discard: [10.  6. 16.  0.  8.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  8. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 11.] 
expected returns: [[38.422543]
 [32.11153 ]
 [33.83313 ]
 [33.83313 ]
 [33.83313 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11. 11.] 
cards in discard: [10.  6. 16.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.] 
adversary owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -6.733348369598389
desired expected reward: 98.21198272705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.679264]
 [29.779776]
 [39.358673]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 11. 11.] 
cards in discard: [10.  6. 16.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.] 
adversary owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.3763961791992188
desired expected reward: 34.599037170410156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  6  3  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  6. 11.  0. 10.] 
adversary cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  6. 11.  0. 10.] 
adversary cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 21. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  6. 11.  0. 10.] 
adversary cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  6. 11.  0. 10.] 
adversary cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [11.  6. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[46.95894 ]
 [44.024002]
 [44.024002]
 [42.6465  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11.  0. 10.] 
cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14.  6.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -3.765697956085205
desired expected reward: 35.59297561645508



action possibilites: [-1] 
expected returns: [[57.29134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10.] 
cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14.  6.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: gain_card_n - action 0
Learning step: -4.071051120758057
desired expected reward: 37.131065368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.099358]
 [53.473743]
 [59.5742  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 10.] 
cards in discard: [10.  6. 16.  0.  8.  3.  8. 11. 11. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14.  6.  0.  8.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -3.364211320877075
desired expected reward: 53.927127838134766






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [14.  6.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  8.  3.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  8.  3.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  8.  3.] 
cards in discard: [ 3.  0. 10.  0.  3.  0.  6.  0. 16.  3.  3.  0.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[74.37671 ]
 [69.243935]
 [69.243935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.1826372146606445
desired expected reward: 55.39155960083008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.042236]
 [63.28768 ]
 [63.48387 ]
 [59.73692 ]
 [66.41625 ]
 [63.919685]
 [64.115875]
 [71.500496]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.893570899963379
desired expected reward: 67.63446044921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  6.] 
adversary cards in discard: [ 0.  0. 11. 11.  0.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  6.] 
adversary cards in discard: [ 0.  0. 11. 11.  0.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[90.57018]
 [83.16448]
 [83.16448]
 [80.33668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10.  6.] 
cards in discard: [ 0.  0. 11. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.43579626083374
desired expected reward: 67.064697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.20283]
 [71.84946]
 [87.09629]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0. 10.  6.] 
cards in discard: [ 0.  0. 11. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.] 
adversary owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -5.380614757537842
desired expected reward: 83.40782928466797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 14.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [16.  6.  8. 11.  3.] 
adversary cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 14.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [16.  6.  8. 11.  3.] 
adversary cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 14.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [16.  6.  8. 11.  3.] 
adversary cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [16.  6.  8. 11.  3.] 
adversary cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6.] 
adversary owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [16.  6.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
expected returns: [[69.29319 ]
 [60.243095]
 [60.79911 ]
 [63.596077]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8. 11.  3.] 
cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
adversary owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -5.713974952697754
desired expected reward: 81.3823013305664



action possibilites: [-1] 
expected returns: [[75.83053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3.] 
cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
adversary owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -20 

action type: gain_card_n - action 14
Learning step: -3.282238721847534
desired expected reward: 78.87039947509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.419876]
 [71.722534]
 [77.85967 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  3.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
adversary owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -3.8797531127929688
desired expected reward: 71.95077514648438



buy possibilites: [-1] 
expected returns: [[73.0072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [ 0.  0. 11. 11.  0. 11. 11.  0. 10.  6. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
adversary owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: buy - action 6.0
Learning step: -19.29346466064453
desired expected reward: 52.42906951904297






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 6.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  6  3 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [11. 11.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.  8.] 
expected returns: [[42.04358]
 [37.77979]
 [37.77979]
 [35.85818]
 [35.72011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  6. 10.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  6. 16.  3.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.  8.  3.] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -6.098807334899902
desired expected reward: 66.90839385986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.179043]
 [30.195387]
 [39.735306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  6. 10.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  6. 16.  3.] 
adversary cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.  8.  3.] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.620216369628906
desired expected reward: 37.412330627441406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  6. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6. 16.  3.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 15.  0.] 
adversary cards in discard: [11. 11.  6. 10.  8.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6. 16.  3.] 
cards in discard: [ 3.  0. 14.  3.  3.  0.  8.  0.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 15.  0.] 
adversary cards in discard: [11. 11.  6. 10.  8.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[34.150055]
 [31.197008]
 [30.308514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 15.  0.] 
cards in discard: [11. 11.  6. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -4.635827541351318
desired expected reward: 35.099464416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.199276]
 [26.104889]
 [26.136196]
 [24.647043]
 [27.35912 ]
 [26.326033]
 [26.357342]
 [30.373018]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 15.  0.] 
cards in discard: [11. 11.  6. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.316067695617676
desired expected reward: 27.88189697265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  6.] 
adversary cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  6.] 
adversary cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  6.  6.] 
adversary cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [ 8. 11.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[99.889984]
 [96.133675]
 [97.263115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  6.  6.] 
cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0 15] -> size -> 19 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -2.692035675048828
desired expected reward: 27.680988311767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[93.60998]
 [93.0156 ]
 [98.46457]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  6.  6.] 
cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  2.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0 15] -> size -> 19 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -6.055449962615967
desired expected reward: 91.64935302734375



buy possibilites: [-1] 
expected returns: [[44.796513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  6.  6.] 
cards in discard: [11. 11.  6. 10.  8.  0.  0. 11. 15.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0 15] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -378 

action type: buy - action 6.0
Learning step: -22.54286003112793
desired expected reward: 70.47274780273438






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0  0 14  0  3  3  3  3  6  0  3  0  0 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6] -> size -> 19 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6] -> size -> 19 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 20. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6] -> size -> 19 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 6. 11.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16.] 
expected returns: [[47.541992]
 [42.865143]
 [40.75477 ]
 [40.122498]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -4.63698148727417
desired expected reward: 40.15953063964844



action possibilites: [-1] 
expected returns: [[29.791613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 16.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -33 

action type: gain_card_n - action 2
Learning step: -2.8447794914245605
desired expected reward: 34.45703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.568785]
 [16.527979]
 [26.952232]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 16.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 19. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -2.80171275138855
desired expected reward: 26.989900588989258






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  6.  0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  6  0  3  0  0 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  1.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  3.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  3.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  8.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  3.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16.] 
adversary owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[35.058   ]
 [31.696161]
 [31.213602]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  8.  3.] 
cards in discard: [ 3. 11.  6.  0. 10. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 14.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -3.4611618518829346
desired expected reward: 23.491060256958008



action possibilites: [-1] 
expected returns: [[44.78162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3.] 
cards in discard: [ 3. 11.  6.  0. 10. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 14.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -2.365750551223755
desired expected reward: 28.100984573364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[38.884533]
 [40.01299 ]
 [40.108265]
 [41.97951 ]
 [40.37452 ]
 [40.50422 ]
 [45.384342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [ 3. 11.  6.  0. 10. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 14.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.1130893230438232
desired expected reward: 41.66852951049805






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 14.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.  8. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0. 11.  6.  6.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.  8. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0. 11.  6.  6.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.  8. 10.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0. 11.  6.  6.] 
adversary cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[35.54103 ]
 [32.312176]
 [32.312176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  6.  6.] 
cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.06325626373291
desired expected reward: 35.62290573120117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[29.923338]
 [35.8658  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  6.  6.] 
cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.8336174488067627
desired expected reward: 31.36130142211914



buy possibilites: [-1] 
expected returns: [[42.403248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  6.  6.] 
cards in discard: [ 3. 11.  6.  0. 10. 16. 15.  6.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.] 
adversary owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -4.892093658447266
desired expected reward: 25.031240463256836






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 15. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 16.  0.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 16  0  0 14  0  3  3  3  0  3  0  0 15  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[36.708984]
 [32.54532 ]
 [30.694267]
 [30.54305 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.239673137664795
desired expected reward: 38.16357421875



action possibilites: [-1. 11.  8. 11.] 
expected returns: [[39.245655]
 [33.605503]
 [31.263403]
 [33.605503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -2.4358534812927246
desired expected reward: 25.941701889038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.27698 ]
 [40.727497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -2.9501700401306152
desired expected reward: 36.29548263549805






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10.  3.  0.] 
adversary cards in discard: [10.  3.  0. 11.  8. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10.  3.  0.] 
adversary cards in discard: [10.  3.  0. 11.  8. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  3. 14.  8. 10.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10.  3.  0.] 
adversary cards in discard: [10.  3.  0. 11.  8. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[39.289135]
 [36.66724 ]
 [36.665554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  3.  0.] 
cards in discard: [10.  3.  0. 11.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.046402454376221
desired expected reward: 36.681087493896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.412712]
 [38.57059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  3.  0.] 
cards in discard: [10.  3.  0. 11.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.9020843505859375
desired expected reward: 34.16847610473633



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11. 11.  6. 15.] 
adversary cards in discard: [10.  3.  0. 11.  8. 11.  6.  8. 10.  3.  0.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 11. 11.  6. 15.] 
adversary cards in discard: [10.  3.  0. 11.  8. 11.  6.  8. 10.  3.  0.] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 11. 11.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[63.2057 ]
 [60.05115]
 [60.05115]
 [59.23162]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 11.  6. 15.] 
cards in discard: [10.  3.  0. 11.  8. 11.  6.  8. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  2.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -3.4605648517608643
desired expected reward: 35.110023498535156



action possibilites: [-1] 
expected returns: [[41.935894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6. 15.] 
cards in discard: [10.  3.  0. 11.  8. 11.  6.  8. 10.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -28 

action type: gain_card_n - action 4
Learning step: -3.1166200637817383
desired expected reward: 50.08693313598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.896774]
 [43.596764]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6. 15.] 
cards in discard: [10.  3.  0. 11.  8. 11.  6.  8. 10.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -3.0006520748138428
desired expected reward: 38.93524169921875






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 8.] 
cards in discard: [ 8.  0. 14.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 8.] 
cards in discard: [ 8.  0. 14.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 8.] 
cards in discard: [ 8.  0. 14.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [15.  0.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[30.950869]
 [24.466698]
 [23.13303 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0  0 11 11 16  6 10 11  0 15  6  6  3  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 19. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.  0.  6.  0.  3.  3.  8.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.427724361419678
desired expected reward: 39.169036865234375



action possibilites: [-1] 
expected returns: [[30.963598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.  0.  6.  0.  3.  3.  8.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -22 

action type: gain_card_n - action 1
Learning step: -1.2850592136383057
desired expected reward: 18.915157318115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.81846 ]
 [31.860935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 8.  0. 14.  0.  0.  0.  6.  0.  3.  3.  8.] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -2.173063039779663
desired expected reward: 28.79053497314453






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 8.  0. 14.  0.  0.  0.  6.  0.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11. 11.  3. 11.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 8.  0. 14.  0.  0.  0.  6.  0.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11. 11.  3. 11.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 11.] 
expected returns: [[41.038235]
 [37.372513]
 [38.548744]
 [38.548744]
 [38.548744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  3. 11.] 
cards in discard: [ 3. 16. 15.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.0369908809661865
desired expected reward: 28.82394027709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.86676 ]
 [39.801704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 11.  3. 11.] 
cards in discard: [ 3. 16. 15.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.3839504718780518
desired expected reward: 35.69340896606445



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  6. 11.  3.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  6. 11.  3.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  6. 11.  3.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  6. 11.  3.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[12.381392]
 [10.374273]
 [ 9.624528]
 [10.374273]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6. 11.  3.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.029208660125732
desired expected reward: 35.772499084472656



action possibilites: [-1] 
expected returns: [[-1.407021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  3.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -10 

action type: gain_card_n - action 9
Learning step: -1.050614595413208
desired expected reward: 9.32851791381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.407021]
 [-1.407021]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.  3.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -1.2613070011138916
desired expected reward: -2.668328046798706






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  1. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.] 
adversary owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-1.407021]
 [-1.407021]
 [-1.407021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0.  0.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0  8] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -2.2613070011138916
desired expected reward: -3.668328046798706





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-1.407021]
 [-1.407021]
 [-1.407021]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  0.  0.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 18. 30.  8.  0.  3.  1.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0  8] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -2.2613070011138916
desired expected reward: -3.668328046798706



Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  8. 10.  0.  0.] 
cards in discard: [ 3. 16. 15.  6.  0.  8. 11. 11.  3. 11. 15. 11. 10.  6. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  6  3 11  0 11 11 16  6 10 11  0 15  6  6  3  0 11  3 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 27. 30. 18. 30.  8.  0.  3.  1.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  3.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  8 14  0  3  3  3  0  3  0  0  6  0  0  0  0  0  8] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -40    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -576 

action type: buy - action 0.0
Learning step: -28.72964859008789
desired expected reward: -30.136669158935547



