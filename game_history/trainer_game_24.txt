 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.136173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.851018905639648
desired expected reward: 7.516304016113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.27808 ]
 [19.684072]
 [18.966885]
 [16.310534]
 [21.543839]
 [20.855032]
 [20.137844]
 [20.420269]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5565118789672852
desired expected reward: 19.968833923339844



buy possibilites: [-1] 
expected returns: [[19.712477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.43233585357666
desired expected reward: 6.87819766998291






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.808142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5205217003822327
desired expected reward: 19.19195556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.443714]
 [20.849707]
 [20.132517]
 [17.476168]
 [19.833921]
 [22.709469]
 [22.020666]
 [22.557125]
 [20.043737]
 [21.303476]
 [21.449728]
 [21.585901]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5587332844734192
desired expected reward: 20.4748477935791



buy possibilites: [-1] 
expected returns: [[22.424986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.46082162857055664
desired expected reward: 22.248645782470703






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.87002 ]
 [22.993587]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5829071998596191
desired expected reward: 21.842079162597656



action possibilites: [-1] 
expected returns: [[22.736668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.6196008324623108
desired expected reward: 18.924070358276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.604418]
 [21.293222]
 [18.636877]
 [23.18137 ]
 [22.746607]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.004562187008559704
desired expected reward: 22.732105255126953



buy possibilites: [-1] 
expected returns: [[23.153982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.07498425990343094
desired expected reward: 20.679401397705078






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [16.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [16.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [16.  0. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.74419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [16.  0. 11.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5941408276557922
desired expected reward: 22.55984115600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.15163 ]
 [23.557623]
 [22.840435]
 [20.184084]
 [25.417387]
 [24.728582]
 [24.011396]
 [24.29382 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [16.  0. 11.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6157323122024536
desired expected reward: 23.239370346069336



buy possibilites: [-1] 
expected returns: [[22.265764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [16.  0. 11.  3.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.08293813467025757
desired expected reward: 23.474685668945312






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.583376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5679803490638733
desired expected reward: 21.697784423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.750708]
 [23.156698]
 [22.439512]
 [20.490969]
 [19.783161]
 [22.140917]
 [25.016462]
 [24.32766 ]
 [26.123856]
 [24.864119]
 [22.350733]
 [21.569979]
 [23.610472]
 [20.163988]
 [23.756723]
 [23.892895]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.617548942565918
desired expected reward: 23.191265106201172



buy possibilites: [-1] 
expected returns: [[22.611378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.499205589294434
desired expected reward: 10.283955574035645






Player: 1 
cards in hand: [ 8.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 14.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [6. 1. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.26759 ]
 [22.375992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [6. 1. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5968733429908752
desired expected reward: 22.014503479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.558401]
 [20.236488]
 [17.620804]
 [22.091051]
 [21.660736]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [6. 1. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5750332474708557
desired expected reward: 20.804494857788086



buy possibilites: [-1] 
expected returns: [[22.881062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [6. 1. 0. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.438373565673828
desired expected reward: 8.182432174682617






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 14.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[20.523703]
 [18.803501]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6272012591362
desired expected reward: 22.253860473632812



action possibilites: [-1] 
expected returns: [[21.566319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.23976241052150726
desired expected reward: 18.795894622802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.99076 ]
 [20.668846]
 [18.053164]
 [22.523409]
 [22.093092]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.02390281669795513
desired expected reward: 21.590221405029297



buy possibilites: [-1] 
expected returns: [[21.97816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  1.  0.  3.  0.  0.  6. 11.  3.  3.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.860823631286621
desired expected reward: 9.192339897155762






Player: 1 
cards in hand: [ 8. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8 14  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.11827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5962579846382141
desired expected reward: 21.38190269470215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.27296 ]
 [19.655844]
 [18.951048]
 [16.33948 ]
 [18.655092]
 [21.483696]
 [20.80561 ]
 [21.333197]
 [18.86339 ]
 [20.100811]
 [20.24627 ]
 [20.375294]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5491457581520081
desired expected reward: 19.74483299255371



buy possibilites: [-1] 
expected returns: [[19.701378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.433320045471191
desired expected reward: 6.906161308288574






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 16.  6.  6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 16.  6.  6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 16.  6.  6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0. 16.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[17.921764]
 [19.03017 ]
 [16.214256]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  6.  6.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5516323447227478
desired expected reward: 19.14974594116211



action possibilites: [-1] 
expected returns: [[20.628876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 10
Learning step: 0.6155890226364136
desired expected reward: 18.316062927246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.634766]
 [16.697166]
 [20.737097]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03167489916086197
desired expected reward: 20.660551071166992



buy possibilites: [-1] 
expected returns: [[21.536789]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.799458503723145
desired expected reward: 7.053699493408203






Player: 1 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 6.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6] -> size -> 21 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8.  0. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 6.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6] -> size -> 21 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 3. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.052723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6. 11.  0. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5639430284500122
desired expected reward: 20.97284507751465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.163803]
 [21.522526]
 [20.831692]
 [18.259735]
 [23.317366]
 [22.649479]
 [21.958643]
 [22.228098]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6. 11.  0. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  9. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5848716497421265
desired expected reward: 21.525663375854492



buy possibilites: [-1] 
expected returns: [[21.48646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 15.  6. 11.  0. 16.  6.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5438765287399292
desired expected reward: 22.105602264404297






Player: 1 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [16.  3.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[17.435345]
 [15.770233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10  0] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6174444556236267
desired expected reward: 20.869014739990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.653565]
 [13.784928]
 [17.688673]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10  0] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5070397257804871
desired expected reward: 17.03102684020996



buy possibilites: [-1] 
expected returns: [[16.827606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  3.  0.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10  0] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4429170787334442
desired expected reward: 15.210648536682129






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0.  0.  0. 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14  0 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  0. 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  0. 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.202661]
 [14.617613]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 8. 0.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 16  0  1  6  6  3  6  6 15  6  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.502525269985199
desired expected reward: 16.32508087158203



action possibilites: [-1] 
expected returns: [[17.543104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.2859308421611786
desired expected reward: 11.894989013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.82691 ]
 [13.95031 ]
 [17.886063]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09472475200891495
desired expected reward: 17.637828826904297



buy possibilites: [-1] 
expected returns: [[17.734417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.78229808807373
desired expected reward: 5.168010711669922






Player: 1 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  6.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.76773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [29. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0 29] -> size -> 11 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -2100    45     0] 
sum of rewards: -2060 

action type: discard_down_to_3_cards - action 8
Learning step: -62.06797790527344
desired expected reward: -47.253692626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.919889]
 [13.161625]
 [16.892353]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [29. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0 29] -> size -> 11 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4927271902561188
desired expected reward: 16.311538696289062



buy possibilites: [-1] 
expected returns: [[11.6156845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [29. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  8 14  0 10  0 29] -> size -> 11 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.46613696217536926
desired expected reward: 14.453751564025879






Player: 1 
cards in hand: [ 0.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  3.] 
cards in discard: [29. 14.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 14  0 10  0 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [29. 14.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 14  0 10  0 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [29. 14.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 14  0 10  0 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [29. 14.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8 14  0 10  0 29  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.088327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 14  0 10  0 29  0] -> size -> 10 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3395345211029053
desired expected reward: 11.27614974975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.283772]
 [13.902487]
 [11.544801]
 [15.592843]
 [15.20783 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 14  0 10  0 29  0] -> size -> 10 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4545445144176483
desired expected reward: 14.68221664428711



buy possibilites: [-1] 
expected returns: [[15.632961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [ 0. 16.  3.  6.  3.  0.  6.  8.  6.  3. 15.  0.  0.  3.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 14  0 10  0 29  0] -> size -> 10 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.162928506731987
desired expected reward: 13.739558219909668






Player: 1 
cards in hand: [10.  8. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 14  0 10  0 29  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3] -> size -> 23 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3] -> size -> 23 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3] -> size -> 23 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[13.7176895]
 [14.710716 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46729108691215515
desired expected reward: 15.165670394897461



action possibilites: [-1] 
expected returns: [[14.73718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.2449980229139328
desired expected reward: 12.236409187316895





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.999515]
 [13.623967]
 [11.293285]
 [15.323851]
 [14.939013]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  8. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15460644662380219
desired expected reward: 14.891786575317383



buy possibilites: [-1] 
expected returns: [[18.18967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 14.] 
adversary owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.4212760031223297
desired expected reward: 15.745126724243164






Player: 1 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [ 8. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  8 14  0 10  0 29  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.602745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5206897258758545
desired expected reward: 17.668981552124023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.767628]
 [12.991535]
 [16.744164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.49022895097732544
desired expected reward: 16.176471710205078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10. 14.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  6.  3.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10. 14.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  6.  3.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [16.  3.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[13.471237]
 [11.958357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  6.  3.] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5164458155632019
desired expected reward: 16.22771644592285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.727643]
 [10.072103]
 [13.571718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  6.  3.] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.42889320850372314
desired expected reward: 13.118904113769531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14. 29.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1.  8. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  8 14 10 29  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.521881]
 [17.92178 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -2100    61     0] 
sum of rewards: -2044 

action type: discard_down_to_3_cards - action 2
Learning step: -61.378028869628906
desired expected reward: -53.20563888549805



action possibilites: [-1] 
expected returns: [[14.177859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.15923257172107697
desired expected reward: 14.994111061096191





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.459285 ]
 [10.790498 ]
 [14.3529005]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1600928008556366
desired expected reward: 14.33795166015625



buy possibilites: [-1] 
expected returns: [[13.740673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.  0.  6.  0.  6.  3.  3.  6.  0. 16.  3.  0.  6.  3.  0.
  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  1.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.2204984873533249
desired expected reward: 12.67978286743164






Player: 1 
cards in hand: [10.  3.  1.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  8. 14.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 14 10 29  0  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0  1] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  0  1] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[9.806015]
 [9.690865]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  1] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4577611982822418
desired expected reward: 13.282912254333496



action possibilites: [-1] 
expected returns: [[11.015649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  1] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.2692910134792328
desired expected reward: 10.14840030670166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 9.544404]
 [10.616823]
 [10.075848]
 [ 8.593441]
 [ 8.052467]
 [ 9.840021]
 [12.056902]
 [11.504387]
 [12.952281]
 [11.93695 ]
 [10.005645]
 [ 9.420506]
 [10.956607]
 [ 8.348085]
 [11.078065]
 [11.187808]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  1] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23396973311901093
desired expected reward: 11.249618530273438



buy possibilites: [-1] 
expected returns: [[11.64535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  1] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: 1.6837077140808105
desired expected reward: 14.635988235473633






Player: 1 
cards in hand: [ 1.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  0  1] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [25. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29  0  1] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [25. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [25. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29  0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  7.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [25. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29  0  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  6.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [25. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.679137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [25. 15.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  6.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3443194031715393
desired expected reward: 11.301031112670898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.287086 ]
 [13.855319 ]
 [11.716114 ]
 [15.385023 ]
 [15.0490675]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [25. 15.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  6.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44425442814826965
desired expected reward: 14.321563720703125



buy possibilites: [-1] 
expected returns: [[15.244574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [25. 15.  0.  0.  6.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  0  8] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.21148262917995453
desired expected reward: 15.173539161682129






Player: 1 
cards in hand: [ 8.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  0  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[11.865677]
 [10.460313]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4882528483867645
desired expected reward: 14.75632095336914



action possibilites: [-1] 
expected returns: [[14.508464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.26774659752845764
desired expected reward: 15.420823097229004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.762832]
 [11.238133]
 [14.574138]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15336206555366516
desired expected reward: 14.661826133728027



buy possibilites: [-1] 
expected returns: [[14.631785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.22074876725673676
desired expected reward: 12.983580589294434






Player: 1 
cards in hand: [8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[14.800694 ]
 [15.1476965]
 [15.1476965]
 [15.755459 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  8. 11.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0. 16.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4272557497024536
desired expected reward: 14.204529762268066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.968945]
 [11.399541]
 [14.766824]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  8.  8. 11.] 
cards in discard: [25. 15.  0.  0.  6.  8.  3.  6.  3.  0.  0.  3.  0. 16.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4532603621482849
desired expected reward: 14.34172534942627



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.909463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49756598472595215
desired expected reward: 14.269258499145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.4048433]
 [5.886425 ]
 [9.140942 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  3.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.340675950050354
desired expected reward: 8.748727798461914



buy possibilites: [-1] 
expected returns: [[11.224264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.20873737335205
desired expected reward: -3.322312355041504






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  8.  3.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  8.  3.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[11.297014]
 [11.178719]
 [11.637094]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  8.  3.] 
cards in discard: [6. 3. 0. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  0  6  3  6  6 15  6  8  0  6  0  3  0  8  0 25  8
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.366107702255249
desired expected reward: 10.858156204223633



action possibilites: [-1] 
expected returns: [[8.2528515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6. 3. 0. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.21108180284500122
desired expected reward: 11.063519477844238





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[6.3958426]
 [5.08168  ]
 [7.9456086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 3. 0. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.273485004901886
desired expected reward: 8.526336669921875






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25.  6. 11.  3.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 8.] 
adversary owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [25.  6. 11.  3.  0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 6. 8.] 
adversary owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25.  6. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 9.159287]
 [10.931689]
 [10.037653]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 11.  3.  0.] 
cards in discard: [6. 3. 0. 3. 3. 6. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.279996395111084
desired expected reward: 7.665612697601318



action possibilites: [-1] 
expected returns: [[12.944109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  3.  0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.8502379655838013
desired expected reward: 8.039408683776855





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.385988]
 [ 9.893272]
 [13.0401  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  3.  0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18515515327453613
desired expected reward: 13.129263877868652






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 8. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
adversary owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 8. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
adversary owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 8. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
adversary owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[12.7157135]
 [13.060951 ]
 [13.060951 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 8. 0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 16  0  6  3  6  6  6  8  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.40454089641571045
desired expected reward: 12.635560035705566



action possibilites: [-1] 
expected returns: [[11.857606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.14418911933898926
desired expected reward: 14.488046646118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.227978]
 [ 8.768369]
 [11.852554]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20553912222385406
desired expected reward: 12.06314468383789






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[14.212449]
 [12.80275 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  0.  0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  2.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3543812930583954
desired expected reward: 11.249882698059082



action possibilites: [-1] 
expected returns: [[13.301702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  1.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 2
Learning step: -8.763940811157227
desired expected reward: 3.02304744720459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.826096]
 [12.900794]
 [12.35252 ]
 [10.375109]
 [14.406358]
 [13.829222]
 [13.245473]
 [13.482707]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 26. 30.  8.  1.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18874147534370422
desired expected reward: 13.490443229675293



buy possibilites: [-1] 
expected returns: [[10.83875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  3.  6.  8. 29. 11. 25.  6.  3.  0.  8.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.74744701385498
desired expected reward: 1.6276617050170898






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  8.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[5.214482]
 [5.842734]
 [5.483896]
 [5.483896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  8.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.41472598910331726
desired expected reward: 10.424023628234863



action possibilites: [-1.  8.] 
expected returns: [[8.1177435]
 [8.447528 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.3881453275680542
desired expected reward: 5.3604326248168945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[6.406381 ]
 [6.9245667]
 [8.341233 ]
 [8.014807 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 26. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2863270044326782
desired expected reward: 8.404069900512695



buy possibilites: [-1] 
expected returns: [[9.912805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [8. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.5863474607467651
desired expected reward: 7.510913372039795






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  3. 25.  6.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  3. 25.  6.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[5.7129917]
 [7.213447 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 25.  6.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3768818974494934
desired expected reward: 9.53592300415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[4.440756 ]
 [5.8337193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 25.  6.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.26888754963874817
desired expected reward: 5.540817737579346



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[12.616384]
 [13.559   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11.  0.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.18584799766540527
desired expected reward: 5.647871971130371



action possibilites: [-1] 
expected returns: [[13.457109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.6482782363891602
desired expected reward: 14.884910583496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[11.88557 ]
 [12.444743]
 [13.958416]
 [13.601074]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18456795811653137
desired expected reward: 13.641677856445312






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[13.973816]
 [12.596026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4164317846298218
desired expected reward: 13.184642791748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[12.484508]
 [13.606898]
 [13.02788 ]
 [15.103948]
 [14.534515]
 [13.953082]
 [14.180984]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  9.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.42304760217666626
desired expected reward: 13.611488342285156



buy possibilites: [-1] 
expected returns: [[16.430204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [ 8.  3. 29.  6.  8.  0.  6.  6.  3.  3. 25.  6. 15. 11.  0.  3.  6.  0.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.10939870774745941
desired expected reward: 15.213347434997559






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 25. 16.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 25. 16.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 25. 16.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 16.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 16.  8.] 
expected returns: [[7.295178 ]
 [7.5924783]
 [8.894281 ]
 [6.1517143]
 [7.5924783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 16.  8.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5593162178993225
desired expected reward: 15.870887756347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.9463124]
 [7.345632 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25. 16.  8.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.30249151587486267
desired expected reward: 7.155625343322754



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6. 11.  3.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 9.527862]
 [10.349469]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  3.  6.] 
cards in discard: [ 8. 25. 16.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2640593647956848
desired expected reward: 7.081572532653809



action possibilites: [-1] 
expected returns: [[10.717779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.8102095127105713
desired expected reward: 8.55444622039795





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.251902]
 [10.770999]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23518191277980804
desired expected reward: 10.952960968017578



buy possibilites: [-1] 
expected returns: [[6.023111]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.23568566143512726
desired expected reward: 9.48758602142334






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[9.324682]
 [9.234365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2330491989850998
desired expected reward: 5.7900614738464355





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 7.8544555]
 [ 8.8919525]
 [ 8.3618765]
 [10.2606125]
 [ 9.743228 ]
 [ 9.210009 ]
 [ 9.419741 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  8.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3320294916629791
desired expected reward: 9.003538131713867



buy possibilites: [-1] 
expected returns: [[11.636816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  7.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.20436818897724152
desired expected reward: 10.464981079101562






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  7.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  7.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  7.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11] -> size -> 28 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.171001]
 [11.006459]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  7.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3865935504436493
desired expected reward: 11.250222206115723



action possibilites: [-1] 
expected returns: [[10.296614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 4
Learning step: 0.6023468971252441
desired expected reward: 8.127931594848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.687557]
 [ 9.162524]
 [10.435381]
 [10.126567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2436811625957489
desired expected reward: 10.540294647216797






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 29.  3.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 29.  3.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 29.  3.] 
adversary cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[8.945009]
 [9.604956]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 29.  3.] 
cards in discard: [ 8. 25. 16.  8.  3. 14.  0. 11.  6.  6.  3.  6. 11.  0.  0.  0. 15.  6.
 11. 11.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.35541847348213196
desired expected reward: 9.771148681640625



action possibilites: [-1.] 
expected returns: [[9.691839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.32225102186203003
desired expected reward: 7.97269344329834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.145225 ]
 [ 8.6749525]
 [10.118008 ]
 [ 9.768042 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 25. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.25757572054862976
desired expected reward: 9.94941520690918



buy possibilites: [-1] 
expected returns: [[11.906469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [6. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.5547693967819214
desired expected reward: 9.229722023010254






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 14.  0.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 14.  0.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 14.  0.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 25.  0. 14.  0.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[ 8.630333]
 [10.349598]
 [ 7.47579 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 14.  0.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4111148715019226
desired expected reward: 11.495354652404785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[7.125681 ]
 [7.6450453]
 [9.06045  ]
 [8.715345 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 14.  0.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.32230013608932495
desired expected reward: 8.333525657653809



buy possibilites: [-1] 
expected returns: [[10.508724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 14.  0.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.2534288465976715
desired expected reward: 6.872251987457275






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  3.  8.  0. 15.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 6.  3.  8.  0. 15.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.] 
adversary owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[13.458824]
 [13.815374]
 [13.372937]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8.  0. 15.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  0  3  6  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15
 11 14  0 11 11  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.321963369846344
desired expected reward: 10.186760902404785



action possibilites: [-1] 
expected returns: [[10.422222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: 0.16226117312908173
desired expected reward: 13.40133285522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.749777]
 [10.363226]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2393706887960434
desired expected reward: 10.661592483520508



buy possibilites: [-1] 
expected returns: [[10.79427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.30084651708602905
desired expected reward: 9.050622940063477






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 11. 16. 11.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 11. 16. 11.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 11. 16. 11.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16. 11.] 
expected returns: [[12.534166]
 [13.431975]
 [13.431975]
 [11.201009]
 [13.431975]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 16. 11.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.33758115768432617
desired expected reward: 10.456687927246094



action possibilites: [-1] 
expected returns: [[7.073836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16. 11.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.19970397651195526
desired expected reward: 11.018746376037598





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.622422 ]
 [7.0781713]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 16. 11.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.30599159002304077
desired expected reward: 7.379827499389648



buy possibilites: [-1] 
expected returns: [[7.4262147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 16. 11.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.3593025207519531
desired expected reward: 5.981725215911865






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.502732]
 [16.489056]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.20379574596881866
desired expected reward: 7.222418785095215



action possibilites: [-1] 
expected returns: [[9.083329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.13282203674316406
desired expected reward: 13.8845853805542





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[7.5029883]
 [8.017619 ]
 [9.443709 ]
 [9.07305  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 24. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26881036162376404
desired expected reward: 9.352139472961426



buy possibilites: [-1] 
expected returns: [[7.4511924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [ 6.  3. 29.  6.  0.  3.  6.  0.  3. 25.  0. 14.  0.  0.  8. 15.  0.  0.
 11.  0. 11. 16. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.5277089476585388
desired expected reward: 8.545327186584473






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11. 11.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11. 11.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[3.8234518]
 [4.4997497]
 [4.4997497]
 [4.094272 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  3  6  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 11 14  0
 11 11  3  0  0  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32790738344192505
desired expected reward: 7.123284816741943



action possibilites: [-1] 
expected returns: [[1.2112938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: 0.34788432717323303
desired expected reward: 4.175693035125732





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.64107615]
 [1.1747134 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.42375436425209045
desired expected reward: 1.6350481510162354



buy possibilites: [-1] 
expected returns: [[1.7999002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.4496666491031647
desired expected reward: 1.090742826461792






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0] -> size -> 30 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0] -> size -> 30 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.1693664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [0. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.15990525484085083
desired expected reward: 1.6399948596954346





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[2.9732683]
 [3.394438 ]
 [4.599543 ]
 [4.277217 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [0. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 23. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.23430396616458893
desired expected reward: 3.964909076690674



buy possibilites: [-1] 
expected returns: [[4.5855894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: 0.03537796437740326
desired expected reward: 3.461068630218506






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  8. 25.  0. 16.] 
adversary cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  8. 25.  0. 16.] 
adversary cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  8. 25.  0. 16.] 
adversary cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  8. 25.  0. 16.] 
adversary cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 25.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 16.] 
expected returns: [[2.478704 ]
 [2.7063603]
 [3.5732515]
 [1.768824 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.  0. 16.] 
cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.25774747133255005
desired expected reward: 4.327841758728027



action possibilites: [-1] 
expected returns: [[6.9937873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 16.  3. 11.] 
cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.41556644439697266
desired expected reward: 4.011178493499756





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.5659027]
 [7.0116253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 16.  3. 11.] 
cards in discard: [0. 8. 3. 3. 6. 0. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3077363669872284
desired expected reward: 7.301523685455322






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.56285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.26996567845344543
desired expected reward: 6.7416605949401855





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[7.3016014]
 [8.359519 ]
 [7.8183   ]
 [7.5803328]
 [9.73929  ]
 [9.210835 ]
 [9.616287 ]
 [7.7236333]
 [8.663871 ]
 [8.781549 ]
 [8.840733 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3162810504436493
desired expected reward: 8.291631698608398



buy possibilites: [-1] 
expected returns: [[5.2256913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.21091580390930176
desired expected reward: 8.148603439331055






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[4.3551664]
 [3.474475 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.26463010907173157
desired expected reward: 4.961061000823975



action possibilites: [-1] 
expected returns: [[8.901222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.4389260709285736
desired expected reward: 3.9234836101531982





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 7.7038507]
 [ 8.62228  ]
 [ 8.146678 ]
 [ 6.900283 ]
 [ 7.942808 ]
 [ 9.856697 ]
 [ 9.38576  ]
 [10.618384 ]
 [ 9.747053 ]
 [ 8.065541 ]
 [ 7.5797954]
 [ 8.897052 ]
 [ 6.6776705]
 [ 9.003335 ]
 [ 9.056855 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  9.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.27705618739128113
desired expected reward: 9.178277969360352



buy possibilites: [-1] 
expected returns: [[9.138219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: 1.7273998260498047
desired expected reward: 12.345784187316895






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11. 29. 15.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11. 29. 15.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11. 29. 15.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 11. 29. 15.] 
adversary cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0.] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[6.0075283]
 [6.7853284]
 [6.6783285]
 [5.9561157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 29. 15.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3565000593662262
desired expected reward: 8.781719207763672



action possibilites: [-1] 
expected returns: [[9.450686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 15.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.8111675977706909
desired expected reward: 8.079985618591309





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[8.159452]
 [9.478649]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29. 15.] 
cards in discard: [ 0.  8.  3.  3.  6.  0.  6.  0. 25.  3.  8.  0. 16.  3. 11.  1.  0.  0.
  3.  0.  0. 25. 14.  0.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2604645788669586
desired expected reward: 9.711151123046875






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[4.055856 ]
 [4.0119267]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0
  0  0  0  0  3  0  3  1 25 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3912622630596161
desired expected reward: 9.087387084960938



action possibilites: [-1] 
expected returns: [[7.417487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.4025614857673645
desired expected reward: 4.579965591430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[6.084061 ]
 [7.0667925]
 [6.5618105]
 [6.341366 ]
 [8.376306 ]
 [7.8755956]
 [8.257793 ]
 [6.4707465]
 [7.353479 ]
 [7.4643345]
 [7.5106487]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  6.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3056700527667999
desired expected reward: 7.7231574058532715



buy possibilites: [-1] 
expected returns: [[5.0662165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.38690614700317383
desired expected reward: 8.76321029663086






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [11. 15.  3.  0.  6.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [11. 15.  3.  0.  6.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [11. 15.  3.  0.  6.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[6.071286]
 [7.548109]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [11. 15.  3.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.22855940461158752
desired expected reward: 4.8376569747924805



action possibilites: [-1] 
expected returns: [[10.818719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16. 11.] 
cards in discard: [11. 15.  3.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.33608660101890564
desired expected reward: 7.919752597808838





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 9.460515]
 [10.500253]
 [ 9.965146]
 [11.844098]
 [11.335113]
 [10.79781 ]
 [10.959985]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 16. 11.] 
cards in discard: [11. 15.  3.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  5.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24014656245708466
desired expected reward: 11.058865547180176



buy possibilites: [-1] 
expected returns: [[7.941827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 16. 11.] 
cards in discard: [11. 15.  3.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.2533358335494995
desired expected reward: 11.588448524475098






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[7.2779756]
 [7.2369637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.  0.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.31117430329322815
desired expected reward: 7.63065242767334





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.860922]
 [7.150245]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.  0.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3010648488998413
desired expected reward: 7.0565104484558105



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[6.007987 ]
 [4.9915595]
 [6.3625436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3024129271507263
desired expected reward: 6.847832202911377





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[4.769395 ]
 [5.720084 ]
 [5.2261114]
 [6.995006 ]
 [6.50514  ]
 [5.998197 ]
 [6.1512227]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  4.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2663016617298126
desired expected reward: 5.754676818847656



buy possibilites: [-1] 
expected returns: [[7.616965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: -4.0 

action type: buy - action 8.0
Learning step: -0.23517605662345886
desired expected reward: 6.26996374130249






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
adversary owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[9.054037]
 [9.408269]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  0  3  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0
  0  0  0  3  0  3  1 25 15 11  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.28120988607406616
desired expected reward: 7.335754871368408



action possibilites: [-1] 
expected returns: [[8.115158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.2535049021244049
desired expected reward: 9.643646240234375





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[8.10929]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2916927933692932
desired expected reward: 8.406850814819336






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [25.  1. 11.  0.  6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.  8.  6.] 
adversary owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [25.  1. 11.  0.  6.] 
adversary cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.  8.  6.] 
adversary owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25.  1. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[10.663383]
 [12.232409]
 [11.486766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 11.  0.  6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2737540602684021
desired expected reward: 7.916687965393066



action possibilites: [-1] 
expected returns: [[12.302117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.  8.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 0
Learning step: 0.5698660612106323
desired expected reward: 9.880071640014648





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[11.9719715]
 [11.452828 ]
 [13.280498 ]
 [12.78396  ]
 [12.255782 ]
 [12.398794 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  6.] 
cards in discard: [11. 15.  3.  0.  6.  8. 25.  3.  0.  0.  0. 16. 11.  3. 15.  3.  3.  0.
  8.  0.  0.  0. 14.  8.  8.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.21262690424919128
desired expected reward: 12.51474380493164






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [15.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [15.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [15.  1.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[3.9123213]
 [3.8872707]
 [4.4811482]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4773578941822052
desired expected reward: 11.921435356140137



action possibilites: [-1. 15.] 
expected returns: [[4.6007967]
 [4.5731173]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.] 
cards in discard: [0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  0  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0
  3  0  3  1 25 15 11  8  8  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.39978376030921936
desired expected reward: 3.680060625076294



action possibilites: [-1] 
expected returns: [[4.9960184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.9652647376060486
desired expected reward: 5.538381576538086





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[4.754973 ]
 [3.5404754]
 [4.328236 ]
 [3.260723 ]
 [4.143366 ]
 [5.8592186]
 [5.436562 ]
 [6.5490193]
 [5.757082 ]
 [4.2488847]
 [3.8207114]
 [4.992648 ]
 [3.0779989]
 [5.084697 ]
 [5.11327  ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 26. 30. 22. 30.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.9530544281005859
desired expected reward: 5.94907283782959



buy possibilites: [-1] 
expected returns: [[3.479131]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 0. 4.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 22. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 47.5 

action type: buy - action 4.0
Learning step: 1.3637092113494873
desired expected reward: 4.62443208694458






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 22. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  3.  3. 15.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4] -> size -> 34 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 22. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  8.  3.  3. 15.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4] -> size -> 34 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[5.5313525]
 [5.8551106]
 [5.502983 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3.  3. 15.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 22. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.1942071169614792
desired expected reward: 3.284923791885376





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[4.7772236]
 [5.899118 ]
 [5.573982 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3.  3. 15.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 22. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.25968652963638306
desired expected reward: 5.326166152954102



buy possibilites: [-1] 
expected returns: [[4.277832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3.  3. 15.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.0083994772285223
desired expected reward: 4.768824100494385






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[6.5596647]
 [7.375784 ]
 [5.6026664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.20757132768630981
desired expected reward: 4.070260524749756





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[5.660375 ]
 [6.88598  ]
 [6.5327415]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  3.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.28046759963035583
desired expected reward: 6.331186771392822



buy possibilites: [-1] 
expected returns: [[5.729729]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  2.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 2 

action type: buy - action 8.0
Learning step: -0.08705466240644455
desired expected reward: 6.798925399780273






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  2.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [16.  8. 25.  3.  0.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  2.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [16.  8. 25.  3.  0.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  2.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [16.  8. 25.  3.  0.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.] 
adversary owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [16.  8. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 25.] 
expected returns: [[7.3042307]
 [6.2620196]
 [7.682942 ]
 [8.906693 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 25.  3.  0.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3
  0  3  1 25 15 11  8  8  1  4  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  2.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2396717667579651
desired expected reward: 5.490057468414307



action possibilites: [-1] 
expected returns: [[11.290683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  3.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  4  0] 
sum of rewards: 18 

action type: gain_card_n - action 1
Learning step: 0.33616185188293457
desired expected reward: 11.082504272460938





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[11.253587]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  3.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22944216430187225
desired expected reward: 11.520125389099121






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  6.  6.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  6.  6.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  6.  6.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[8.455377]
 [9.306201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  6.  6.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39346593618392944
desired expected reward: 10.86012077331543





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[8.423268]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  6.  6.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.31521695852279663
desired expected reward: 8.140159606933594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  8. 25.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.  0.  3. 11.  6.  6.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  8. 25.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.  0.  3. 11.  6.  6.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  8. 25.] 
adversary cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.  0.  3. 11.  6.  6.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 25.] 
expected returns: [[12.849578]
 [13.70103 ]
 [13.231066]
 [13.231066]
 [14.462407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8.  8. 25.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.  0.  3. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2589687407016754
desired expected reward: 8.164299964904785





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[12.840426]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.  8. 25.] 
cards in discard: [ 0.  0.  4. 29. 15.  1.  3.  1.  8.  3.  3. 15.  8.  0. 11.  3.  0. 14.
  8. 16.  8. 25.  3.  0.  3. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4006628394126892
desired expected reward: 12.448915481567383



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.4852445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5086143612861633
desired expected reward: 12.331811904907227





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[2.4698424]
 [1.5348552]
 [2.143263 ]
 [1.3227323]
 [2.0027087]
 [3.3230016]
 [2.9967248]
 [3.8785806]
 [3.2416675]
 [2.081756 ]
 [1.7464259]
 [2.6501043]
 [1.1796889]
 [2.7199106]
 [2.733453 ]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 26. 30. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.19767668843269348
desired expected reward: 2.3355085849761963



buy possibilites: [-1] 
expected returns: [[2.8920128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0 1700    0   -2    0    0
   72    0] 
sum of rewards: 1765 

action type: buy - action 2.0
Learning step: 52.93431854248047
desired expected reward: 54.469173431396484






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 15.  8.  8.] 
adversary cards in discard: [2. 1. 0. 0. 0. 0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 15.  8.  8.] 
adversary cards in discard: [2. 1. 0. 0. 0. 0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
expected returns: [[5.4399095]
 [5.421869 ]
 [5.792005 ]
 [5.792005 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  8.  8.] 
cards in discard: [2. 1. 0. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.17667841911315918
desired expected reward: 2.715334415435791



action possibilites: [-1] 
expected returns: [[7.021122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8.] 
cards in discard: [2. 1. 0. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.358842134475708
desired expected reward: 5.854831695556641





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[7.0026975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 8.] 
cards in discard: [2. 1. 0. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.31289467215538025
desired expected reward: 7.334016799926758






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  1.  8.  0. 11.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[10.8507  ]
 [11.241952]
 [11.723307]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  0. 11.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  5.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.24014942348003387
desired expected reward: 6.762547969818115



action possibilites: [-1] 
expected returns: [[12.627079]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  9  0] 
sum of rewards: 21 

action type: gain_card_n - action 3
Learning step: 0.4658459722995758
desired expected reward: 10.357124328613281





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.369695]
 [11.818941]
 [11.582599]
 [13.760317]
 [13.230343]
 [13.622846]
 [11.713006]
 [12.666834]
 [12.777539]
 [12.780475]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20619529485702515
desired expected reward: 12.833273887634277



buy possibilites: [-1] 
expected returns: [[11.450951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 32  0] 
sum of rewards: 43 

action type: buy - action 15.0
Learning step: 1.0269087553024292
desired expected reward: 13.804448127746582






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 8. 25.  8.  8.  6.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 8. 25.  8.  8.  6.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 8. 25.  8.  8.  6.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  8.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.  8.] 
expected returns: [[ 9.339479]
 [ 9.732772]
 [10.923984]
 [ 9.732772]
 [ 9.732772]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  8.  6.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3874410092830658
desired expected reward: 11.063509941101074



action possibilites: [-1] 
expected returns: [[11.062369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8.  6. 29.  0.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.23829030990600586
desired expected reward: 11.167110443115234





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[11.078123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8.  6. 29.  0.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23444917798042297
desired expected reward: 11.296818733215332






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [25.  3. 11.  6. 16.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [25.  3. 11.  6. 16.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [25.  3. 11.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 16.] 
expected returns: [[15.647217]
 [17.56637 ]
 [16.670137]
 [14.397246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  6. 16.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3104642629623413
desired expected reward: 10.767659187316895





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[15.63632]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 11.  6. 16.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.45523515343666077
desired expected reward: 15.19198226928711



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 14.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0. 25.  3. 11.  6. 16.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 14.] 
adversary cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0. 25.  3. 11.  6. 16.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[17.190042]
 [18.228315]
 [16.070034]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3. 14.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0. 25.  3. 11.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4366426169872284
desired expected reward: 15.199677467346191



action possibilites: [-1] 
expected returns: [[19.938473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0. 25.  3. 11.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.17725296318531036
desired expected reward: 16.24728775024414





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[18.890718]
 [20.428988]
 [19.938475]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [ 2.  1.  0.  0.  0.  0. 15.  3.  3.  8.  8. 11. 15. 11.  0.  1.  8.  0.
 25.  8.  8.  8.  6. 29.  0. 25.  3. 11.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06066959351301193
desired expected reward: 19.999141693115234






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 3. 15.  4.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 3. 15.  4.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  4.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[3.102888]
 [3.100923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  4.  0.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7154213786125183
desired expected reward: 19.223051071166992





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[3.1061785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  4.  0.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2109309732913971
desired expected reward: 2.907263994216919



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 1.  3.  2. 11.  0.] 
adversary cards in discard: [ 3. 15.  4.  0.  6.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [ 1.  3.  2. 11.  0.] 
adversary cards in discard: [ 3. 15.  4.  0.  6.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  2. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[5.4620957]
 [6.21565  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  2. 11.  0.] 
cards in discard: [ 3. 15.  4.  0.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  9.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.18041884899139404
desired expected reward: 2.925759792327881



action possibilites: [-1] 
expected returns: [[7.2862267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 2. 0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 16  0] 
sum of rewards: 26 

action type: gain_card_n - action 2
Learning step: 0.7363299131393433
desired expected reward: 4.742178440093994





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[7.2843485]
 [5.937713 ]
 [6.819048 ]
 [5.610806 ]
 [6.617439 ]
 [8.471742 ]
 [8.020643 ]
 [9.205806 ]
 [8.350408 ]
 [6.726515 ]
 [6.244024 ]
 [7.535223 ]
 [5.378895 ]
 [7.6273103]
 [7.6114326]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 2. 0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.310912549495697
desired expected reward: 7.597139358520508



buy possibilites: [-1] 
expected returns: [[8.229553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 2. 0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -6.   0.   0.
 12.5  0. ] 
sum of rewards: 21.5 

action type: buy - action 22.0
Learning step: 0.5700435042381287
desired expected reward: 5.948938846588135






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 16.  3.  8.  0.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 16.  3.  8.  0.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.] 
adversary owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 41 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[7.313977 ]
 [6.2963414]
 [7.725083 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  8.  0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  0  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0
  3  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32068443298339844
desired expected reward: 7.908868789672852



action possibilites: [-1] 
expected returns: [[6.2352905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.33258143067359924
desired expected reward: 6.4288859367370605





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[6.2446656]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.32851025462150574
desired expected reward: 6.563800811767578






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29.  3.  0. 11. 15.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0.] 
adversary owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29.  3.  0. 11. 15.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0.] 
adversary owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [29.  3.  0. 11. 15.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0.] 
adversary owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[8.778313]
 [9.487958]
 [9.604211]
 [8.793063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 11. 15.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2399626523256302
desired expected reward: 6.004703044891357





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[8.7950115]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11. 15.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3217785358428955
desired expected reward: 8.482426643371582



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.] 
adversary owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 14.  8.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.] 
adversary owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[10.433406]
 [ 9.521675]
 [10.848906]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  8.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  3  6 29  6  6  3 15 14  0 11 11  3  0  0  0  0  0  3  0  3
  1 25 15 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30481645464897156
desired expected reward: 8.490195274353027



action possibilites: [-1] 
expected returns: [[11.116697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.22568517923355103
desired expected reward: 11.593689918518066





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[11.177084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23385846614837646
desired expected reward: 11.350555419921875






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 11.  1.  6. 25.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 11.  1.  6. 25.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  1.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[10.72491 ]
 [11.140416]
 [11.595703]
 [12.349798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1.  6. 25.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3631752133369446
desired expected reward: 10.813908576965332





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[10.043626 ]
 [11.276443 ]
 [10.8602705]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  1.  6. 25.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.35796183347702026
desired expected reward: 10.366949081420898



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  3. 25.  8.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  3. 25.  8.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  6.  3. 25.  8.] 
adversary cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[12.376062]
 [14.065668]
 [12.815158]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 25.  8.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3363509476184845
desired expected reward: 10.523920059204102



action possibilites: [-1] 
expected returns: [[12.699024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  8.  8. 15.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.1659826934337616
desired expected reward: 14.07788372039795





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[12.699024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  8.  8. 15.] 
cards in discard: [ 3. 15.  4.  0.  6. 16. 22. 11.  1.  3.  2.  0.  8. 16.  3.  0. 29.  3.
  0. 11. 15.  8.  0.  8. 11.  1.  6. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20236901938915253
desired expected reward: 12.901392936706543






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  4. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  4. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [ 0.  4. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[6.7419543]
 [7.582811 ]
 [7.582811 ]
 [7.154863 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 11. 11.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 21. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.453681617975235
desired expected reward: 12.245342254638672



action possibilites: [-1] 
expected returns: [[8.604098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 11.  8.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  4  0] 
sum of rewards: 16 

action type: gain_card_n - action 1
Learning step: 0.37616321444511414
desired expected reward: 6.848822593688965





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[8.653701]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 11.  8.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.28274089097976685
desired expected reward: 8.886838912963867






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  8. 15. 11. 25.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  8. 15. 11. 25.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 0.  8. 15. 11. 25.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 15. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11. 25.] 
expected returns: [[5.370375 ]
 [5.7200727]
 [5.3968406]
 [6.084739 ]
 [6.689859 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 11. 25.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3458271026611328
desired expected reward: 8.307873725891113





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[5.406644]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15. 11. 25.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2559219300746918
desired expected reward: 5.167134761810303



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 29.  1.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 29.  1.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 29.  1.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[7.997534]
 [8.401864]
 [8.702704]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 29.  1.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2229338437318802
desired expected reward: 5.183710098266602



action possibilites: [-1. 11.] 
expected returns: [[7.1353707]
 [7.9293675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.32299482822418213
desired expected reward: 7.2206196784973145





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[6.9686885]
 [6.5342355]
 [8.050432 ]
 [7.6395903]
 [7.1978   ]
 [7.249229 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.31394073367118835
desired expected reward: 7.449312210083008






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.] 
adversary owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[11.861257 ]
 [12.3738165]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8  6 29  6  6  3 15 11 11  3  0  0  0  0  0  3  0  3  1 25 15
 11  8  8  1  4  3  8  8  2 11 15 16 22  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2396470308303833
desired expected reward: 7.009582996368408



action possibilites: [-1] 
expected returns: [[11.546998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.16803646087646484
desired expected reward: 13.608269691467285





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[11.380338]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22308360040187836
desired expected reward: 11.770081520080566






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3.] 
adversary owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [ 1. 15.  0.  0.  3.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3.] 
adversary owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [ 1. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[12.02737 ]
 [12.081741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.36403700709342957
desired expected reward: 10.994266510009766





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[11.725031]
 [11.152744]
 [10.901955]
 [13.111553]
 [12.593378]
 [12.963167]
 [11.033365]
 [12.021095]
 [12.123825]
 [12.069454]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3829772174358368
desired expected reward: 11.652215003967285



buy possibilites: [-1] 
expected returns: [[13.894951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  3.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 26 

action type: buy - action 15.0
Learning step: 0.5621821284294128
desired expected reward: 12.686009407043457






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  5.] 
adversary cards in hand: [ 2. 16.  6. 16. 22.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3. 15.  1. 15.  0.  0.  3.] 
adversary owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  5.] 
adversary cards in hand: [ 2. 16.  6. 16. 22.] 
adversary cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3. 15.  1. 15.  0.  0.  3.] 
adversary owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [ 2. 16.  6. 16. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 22.] 
expected returns: [[11.611731]
 [10.568424]
 [10.568424]
 [ 9.179354]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 16.  6. 16. 22.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3. 15.  1. 15.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 25  8 29  6  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8
  1  4  3  8  8  2 11 15 16 22  3 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  1.  8.  8.  8. 10.  8.  9.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4544152319431305
desired expected reward: 13.440535545349121



Player 0 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 1 
Estate: 6 
Duchy: 1 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 4 
Chapel: 6 
Witch: 2 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 1 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 2. 16. 22.] 
cards in discard: [ 3. 11.  0.  4. 11.  8.  0.  8. 15. 11. 25.  3.  8. 29.  3.  1. 11.  8.
  3. 15.  1. 15.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8 25  8 29  6 15 11 11  3  0  0  0  0  3  0  3  1 25 15 11  8  8  1
  4  3  8  8  2 11 15 16 22  3 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 29. 20. 29.  8.  0.  8.  4.  0.  8.  8.  8. 10.  8.  9.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0  -1   0   0   4   0] 
sum of rewards: 518 

action type: gain_card_n - action 1
Learning step: 15.245696067810059
desired expected reward: 25.055824279785156



