 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.20392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action 25.0
Learning step: 26.51969337463379
desired expected reward: 11.125833511352539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[275.8198 ]
 [294.79745]
 [287.43265]
 [236.71434]
 [305.68   ]
 [290.22333]
 [285.9279 ]
 [309.03113]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.391256332397461
desired expected reward: 295.04632568359375



buy possibilites: [-1] 
expected returns: [[277.2138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -8.084319114685059
desired expected reward: 279.3482666015625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.24094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.970439910888672
desired expected reward: 270.2433776855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[279.71082]
 [299.4806 ]
 [291.1533 ]
 [243.64308]
 [287.45203]
 [310.0182 ]
 [294.16696]
 [291.95807]
 [260.44907]
 [288.15015]
 [277.78122]
 [312.04944]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.02772045135498
desired expected reward: 299.4278869628906



buy possibilites: [-1] 
expected returns: [[281.1195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 14.0
Learning step: -5.1472625732421875
desired expected reward: 255.30177307128906






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[275.96774]
 [236.82538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.881552696228027
desired expected reward: 272.2379455566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[254.5525 ]
 [260.8617 ]
 [220.59358]
 [266.02808]
 [274.37936]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.493008613586426
desired expected reward: 265.28216552734375



buy possibilites: [-1] 
expected returns: [[284.99524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -8.365234375
desired expected reward: 246.1873016357422






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[307.4339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.398487091064453
desired expected reward: 277.59674072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[285.3595 ]
 [303.30164]
 [296.68805]
 [247.32802]
 [292.8146 ]
 [312.15646]
 [298.63733]
 [296.83655]
 [266.43127]
 [294.11575]
 [284.4832 ]
 [314.22867]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.835665702819824
desired expected reward: 297.8876647949219



buy possibilites: [-1] 
expected returns: [[316.25674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 3.5 

action type: buy - action 1.0
Learning step: -7.874305248260498
desired expected reward: 295.4273376464844






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.08344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.479996681213379
desired expected reward: 306.7767333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.74126]
 [267.90845]
 [258.53406]
 [209.99315]
 [276.79935]
 [263.9791 ]
 [256.55145]
 [277.89075]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.434417724609375
desired expected reward: 275.2474060058594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [6. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [6. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 6.  0.  0.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.13364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.131852149963379
desired expected reward: 270.7589111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.53085]
 [289.4786 ]
 [280.99286]
 [238.66882]
 [280.1536 ]
 [297.70236]
 [286.76968]
 [284.9597 ]
 [255.18636]
 [280.70554]
 [271.66998]
 [299.77585]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.925448417663574
desired expected reward: 293.86065673828125



buy possibilites: [-1] 
expected returns: [[261.6226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 16.0
Learning step: -6.261044979095459
desired expected reward: 273.8926086425781






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  3.  3. 10.  0. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [16.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[245.64189]
 [226.25467]
 [203.89214]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.024637222290039
desired expected reward: 253.5979461669922



action possibilites: [-1] 
expected returns: [[259.85187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -3.4736459255218506
desired expected reward: 201.93260192871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[234.24316]
 [248.6755 ]
 [241.26405]
 [213.99089]
 [202.32932]
 [240.22295]
 [254.75723]
 [245.3146 ]
 [267.2981 ]
 [243.40315]
 [217.31798]
 [224.99704]
 [239.21292]
 [209.46088]
 [231.3213 ]
 [255.4834 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -6.738899230957031
desired expected reward: 253.11297607421875



buy possibilites: [-1] 
expected returns: [[222.03064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 11.0
Learning step: -6.567172527313232
desired expected reward: 248.1900634765625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [11. 14. 16.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -6.322742462158203
desired expected reward: 215.70790100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[212.3952 ]
 [228.24887]
 [222.35484]
 [176.33797]
 [238.4339 ]
 [224.14563]
 [220.81909]
 [242.12865]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [11. 14. 16.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.4259538650512695
desired expected reward: 229.40914916992188



buy possibilites: [-1] 
expected returns: [[183.46419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [11. 14. 16.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 8.0
Learning step: -7.529338359832764
desired expected reward: 216.61630249023438






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [3. 0. 3. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[202.50589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  0. 10.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -5.317716121673584
desired expected reward: 178.14646911621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[182.22458]
 [195.05856]
 [190.28854]
 [153.09738]
 [187.86179]
 [201.05534]
 [191.55695]
 [190.16191]
 [166.88408]
 [188.03192]
 [180.64337]
 [202.40437]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  0. 10.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -6.158466815948486
desired expected reward: 189.6412353515625



buy possibilites: [-1] 
expected returns: [[201.51086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 14. 16.  0.  0.  0.  8.  0.  3.  1.  3.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  0. 10.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 21 

action type: buy - action 15.0
Learning step: -3.448176622390747
desired expected reward: 177.1952362060547






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  0. 10.  3. 11.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15] -> size -> 18 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  0. 10.  3. 11.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15] -> size -> 18 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[177.09637]
 [176.64442]
 [160.78358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -6.776217937469482
desired expected reward: 194.73464965820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[150.60571]
 [122.55291]
 [173.08878]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  9.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -6.032992362976074
desired expected reward: 170.61195373535156



buy possibilites: [-1] 
expected returns: [[188.32332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 16.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -17.990371704101562
desired expected reward: 104.56253814697266






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [ 6. 11.  3.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [ 6. 11.  3.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [ 6. 11.  3.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[160.58743]
 [139.86758]
 [151.06589]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  8.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  0  1 16 11  8 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -7.229672431945801
desired expected reward: 181.09364318847656



action possibilites: [-1] 
expected returns: [[138.56999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: trash_cards_n_from_hand - action 8
Learning step: -4.526007175445557
desired expected reward: 138.7581329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.932396]
 [ 85.26955 ]
 [135.05627 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -5.069232940673828
desired expected reward: 133.50076293945312






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 14.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[158.55296]
 [120.5556 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  1.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -5.289288520812988
desired expected reward: 129.76699829101562



action possibilites: [-1] 
expected returns: [[212.82254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 14.0
Learning step: -1.8358558416366577
desired expected reward: 117.65140533447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[194.57402]
 [207.54555]
 [188.03278]
 [201.65483]
 [177.23727]
 [167.85222]
 [199.85553]
 [214.03056]
 [204.26926]
 [223.94391]
 [202.6523 ]
 [180.7921 ]
 [187.51067]
 [199.89752]
 [173.99606]
 [193.03293]
 [215.17871]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -6.878299236297607
desired expected reward: 205.94424438476562



buy possibilites: [-1] 
expected returns: [[165.31616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 6. 11.  3.  0. 16.  3.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -5.0 

action type: buy - action 14.0
Learning step: -5.569993019104004
desired expected reward: 175.22213745117188






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  9. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [14.  0.  0.  0.  0.  0.  3.  0.  0.  0.  3.  3.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[155.02579]
 [122.87788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.825305461883545
desired expected reward: 158.49085998535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.14241]
 [152.94211]
 [146.9097 ]
 [115.42893]
 [158.56096]
 [150.16205]
 [145.495  ]
 [158.98131]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.0318603515625
desired expected reward: 147.4217987060547



buy possibilites: [-1] 
expected returns: [[174.05678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 10.0
Learning step: -4.108473300933838
desired expected reward: 141.38653564453125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  1. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[173.33852]
 [173.20601]
 [144.95636]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 14.  0.] 
cards in discard: [10.  3. 14.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.714582920074463
desired expected reward: 167.34219360351562



action possibilites: [-1] 
expected returns: [[144.03586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -324 

action type: gain_card_n - action 3
Learning step: -20.99315071105957
desired expected reward: 139.6859893798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[127.02365 ]
 [138.33377 ]
 [133.3848  ]
 [101.55844 ]
 [131.4914  ]
 [144.22665 ]
 [135.54366 ]
 [134.0619  ]
 [114.75988 ]
 [131.82564 ]
 [125.666534]
 [144.80794 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  7.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -5.470322608947754
desired expected reward: 138.56553649902344



buy possibilites: [-1] 
expected returns: [[159.67912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -18.235143661499023
desired expected reward: 83.32328796386719






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [ 0.  3.  6.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 16.] 
adversary cards in discard: [10.  3. 14.  0.  0.  0.  6.  6. 11.  0.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [ 0.  3.  6.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 16.] 
adversary cards in discard: [10.  3. 14.  0.  0.  0.  6.  6. 11.  0.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[128.96349]
 [116.25863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 16.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.  6. 11.  0.  1. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -8.046775817871094
desired expected reward: 151.63235473632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.780975]
 [119.142136]
 [ 84.608505]
 [119.99292 ]
 [129.4907  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 16.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.  6. 11.  0.  1. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -6.486614227294922
desired expected reward: 119.03993225097656



buy possibilites: [-1] 
expected returns: [[117.95818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 16.] 
cards in discard: [10.  3. 14.  0.  0.  0.  6.  6. 11.  0.  1. 14.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -6.932966709136963
desired expected reward: 103.84799194335938






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0. 14.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[100.83927]
 [ 69.38252]
 [ 93.0718 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  0  1 16 11  8  6 14 10  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.78557825088501
desired expected reward: 111.172607421875



action possibilites: [-1] 
expected returns: [[143.04591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.9550548791885376
desired expected reward: 66.51670837402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.50641]
 [ 90.40878]
 [145.57858]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -6.211021423339844
desired expected reward: 136.83489990234375



buy possibilites: [-1] 
expected returns: [[140.70244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -6.209514617919922
desired expected reward: 116.296875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6. 14.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 29. 30. 26. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  3. 11. 10.  3.  8.  0.  0.  0.  0.  3.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[126.17403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 1
Learning step: -6.255143642425537
desired expected reward: 108.30781555175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.76106]
 [ 74.99084]
 [126.06354]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -6.997659206390381
desired expected reward: 114.02474975585938



buy possibilites: [-1] 
expected returns: [[134.41528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -7.013710021972656
desired expected reward: 98.74736785888672






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 25. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.3653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -8.645153999328613
desired expected reward: 125.77012634277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.44902 ]
 [82.3585  ]
 [78.30657 ]
 [49.43488 ]
 [76.565834]
 [86.37464 ]
 [79.426025]
 [78.12723 ]
 [60.72259 ]
 [75.91993 ]
 [70.4857  ]
 [86.03862 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  8. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -6.125366687774658
desired expected reward: 75.01287078857422



buy possibilites: [-1] 
expected returns: [[91.545784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -73.0 

action type: buy - action 8.0
Learning step: -5.561521530151367
desired expected reward: 73.86450958251953






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[68.56043 ]
 [57.430035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.409348011016846
desired expected reward: 86.13643646240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.937546]
 [60.537735]
 [54.284157]
 [24.894466]
 [53.043583]
 [65.18886 ]
 [57.155525]
 [55.295574]
 [34.55882 ]
 [51.76871 ]
 [44.963253]
 [64.41906 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.525300979614258
desired expected reward: 64.0351333618164



buy possibilites: [-1] 
expected returns: [[51.90644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 10. 14.  0.  0.  6.  6.  8.  6.  0.  3.  1.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -40.5 

action type: buy - action 10.0
Learning step: -3.4455411434173584
desired expected reward: 48.323177337646484






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [20. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.60076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -40    0    0    0    0    0    0    0    0    0 -600
   38    0] 
sum of rewards: -607 

action type: discard_down_to_3_cards - action 6
Learning step: -32.31803512573242
desired expected reward: 47.2443733215332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.70092]
 [48.34932]
 [93.95705]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -5.072228908538818
desired expected reward: 84.26475524902344



buy possibilites: [-1] 
expected returns: [[114.63383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 0. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -5.005785942077637
desired expected reward: 71.69515228271484






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  7. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 3.  3.  0.  6. 11.  0.  0.  8.  0. 14.  0.  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[97.77003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.869999885559082
desired expected reward: 108.76382446289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.835625]
 [88.23941 ]
 [84.429695]
 [52.972897]
 [94.51515 ]
 [84.47756 ]
 [82.02956 ]
 [96.19341 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 24. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -5.085907936096191
desired expected reward: 88.7670669555664



buy possibilites: [-1] 
expected returns: [[82.144226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -32.0 

action type: buy - action 3.0
Learning step: -3.973240613937378
desired expected reward: 80.45646667480469






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0  3] -> size -> 26 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [14.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[100.488174]
 [ 76.35387 ]
 [ 94.793144]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  0.  0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16 11  8  6 14 10  6  6  0  0  0  8 10
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.768967390060425
desired expected reward: 78.37525939941406



action possibilites: [-1] 
expected returns: [[99.90109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 5
Learning step: -2.541273593902588
desired expected reward: 79.23968505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.44557 ]
 [58.271816]
 [98.61329 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.9056851863861084
desired expected reward: 95.99540710449219



buy possibilites: [-1] 
expected returns: [[78.50025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 23. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -17.397336959838867
desired expected reward: 40.87449645996094






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 22. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  0. 10.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[64.593735]
 [58.54998 ]
 [54.6646  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  0. 10.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -5.840925693511963
desired expected reward: 72.6593246459961



action possibilites: [-1.  8.] 
expected returns: [[79.13924]
 [71.36338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -44 

action type: take_action - action 10.0
Learning step: -3.239691972732544
desired expected reward: 51.424903869628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.098957]
 [72.96069 ]
 [67.46061 ]
 [39.850906]
 [77.45527 ]
 [69.35721 ]
 [64.781075]
 [77.05434 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.715179443359375
desired expected reward: 74.42406463623047



buy possibilites: [-1] 
expected returns: [[54.0543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0. 11.  0.  6.  3.  0.  3.  6.  3.  3.  0.  1.  6.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -5.588726997375488
desired expected reward: 55.51023864746094






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6
  0] -> size -> 25 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6
  0] -> size -> 25 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[76.585144]
 [69.054054]
 [69.03871 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6 10  6  6  0  0  0  8 10  0  3  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -4.413805961608887
desired expected reward: 49.6404914855957



action possibilites: [-1] 
expected returns: [[65.89939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -30 

action type: gain_card_n - action 2
Learning step: -1.886227011680603
desired expected reward: 35.493038177490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.068184]
 [32.605236]
 [65.07185 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -3.8629188537597656
desired expected reward: 62.03647232055664



buy possibilites: [-1] 
expected returns: [[43.932236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -4.864933967590332
desired expected reward: 48.203250885009766






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.  3.  3. 11.  3.  0.  0.  6.  8.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[44.06047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -3.4291484355926514
desired expected reward: 40.50308609008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.852585]
 [37.651466]
 [15.098598]
 [38.158527]
 [44.01639 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  5. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -3.5938880443573
desired expected reward: 39.404483795166016



buy possibilites: [-1] 
expected returns: [[23.535692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -36 

action type: buy - action 8.0
Learning step: -3.178373336791992
desired expected reward: 34.98015594482422






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  1.  3.  8.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  1.  3.  8.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  1.  3.  8.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  1.  3.  8.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 8. 10.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[ 6.627882  ]
 [ 1.3584092 ]
 [-0.01582718]
 [ 1.3584092 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  3.  8.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  1 16 11  8  6  6  6  0  0  0  8 10  0  3  6  0
  3  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -3.3238861560821533
desired expected reward: 20.21180534362793



action possibilites: [-1] 
expected returns: [[39.928658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 14
Learning step: -0.6167857050895691
desired expected reward: -5.313175201416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.650547]
 [15.226579]
 [40.27794 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -3.099130392074585
desired expected reward: 36.82952880859375






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  6.  0.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6.  0.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 20. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6.  0.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.819817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  3.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -4.885451793670654
desired expected reward: 35.392494201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -3.0564885]
 [  6.6240416]
 [  4.288247 ]
 [-17.40294  ]
 [  0.8506892]
 [ 12.577843 ]
 [  3.31168  ]
 [  1.9532363]
 [-11.987526 ]
 [  2.1013186]
 [ -3.2347565]
 [ 13.662158 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  3.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.071559429168701
desired expected reward: 12.74825668334961



buy possibilites: [-1] 
expected returns: [[64.31604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  3.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -3.150064706802368
desired expected reward: -6.20655632019043






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  8.  3.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 19. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.692863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3  3] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_down_to_3_cards - action 1
Learning step: -4.091903209686279
desired expected reward: 19.70794105529785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.621355]
 [34.516895]
 [32.945988]
 [15.695454]
 [38.33331 ]
 [32.20967 ]
 [31.46742 ]
 [39.05439 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  4. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3  3] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -4.922783851623535
desired expected reward: 32.77008056640625



buy possibilites: [-1] 
expected returns: [[42.615295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  3.  0.  8.  0.  3.  3.  6.  0.  8.  0.  6.  0.  0.  0.
  0.  6. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3  3] -> size -> 27 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -73.0 

action type: buy - action 8.0
Learning step: -4.301639556884766
desired expected reward: 27.908035278320312






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  3  6  0 10  0  3  0 14  8  0  3  3  0  0  8  8  3  3
 29  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8] -> size -> 25 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8] -> size -> 25 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 10.  0.  3.  0.  0.  0.  3.  3.  0. 11.  6.  0.  3. 14.  0.  3.  8.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8] -> size -> 25 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [ 6.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.147743]
 [13.75754 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -5.605197429656982
desired expected reward: 37.01009750366211



action possibilites: [-1] 
expected returns: [[31.336199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: gain_card_n - action 8
Learning step: -1.7217832803726196
desired expected reward: 7.815169811248779





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.350906]
 [27.096079]
 [23.625128]
 [12.793949]
 [28.966635]
 [25.886166]
 [22.822514]
 [27.729393]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -3.781162738800049
desired expected reward: 27.555036544799805



buy possibilites: [-1] 
expected returns: [[65.64311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [14. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -37 

action type: buy - action 11.0
Learning step: -1.8213618993759155
desired expected reward: 27.14527702331543






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.405668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  8.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -6.865528106689453
desired expected reward: 58.777584075927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 6.799764 ]
 [11.957077 ]
 [10.813709 ]
 [ 1.541985 ]
 [-1.6940749]
 [ 8.7831955]
 [13.602886 ]
 [10.30393  ]
 [15.924149 ]
 [ 9.380751 ]
 [ 2.9010587]
 [ 5.544994 ]
 [ 9.124851 ]
 [ 1.12047  ]
 [ 6.7340503]
 [12.425251 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 29. 30. 18. 30.  8.  5.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  8.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.943333148956299
desired expected reward: 3.462334632873535



buy possibilites: [-1] 
expected returns: [[29.997728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [15. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  8.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0] -> size -> 25 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -386.0 

action type: buy - action 6.0
Learning step: -18.54034996032715
desired expected reward: -20.23441505432129






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  8.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [0. 0. 0. 3. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [0. 0. 0. 3. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [0. 0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [8. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[45.96729 ]
 [37.797867]
 [37.797867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 3.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -4.887626647949219
desired expected reward: 25.1101016998291





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.155987]
 [21.945742]
 [46.133095]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 3.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  4.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -5.8378825187683105
desired expected reward: 40.12940979003906



buy possibilites: [-1] 
expected returns: [[56.159496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 3.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 10.  0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -397.0 

action type: buy - action 6.0
Learning step: -19.683698654174805
desired expected reward: 2.2620391845703125






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 10.  0.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  8.  6.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3. 10.  0.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  8.  6.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3. 10.  0.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  8.  6.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [16.  0.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[-14.236624]
 [-13.72864 ]
 [-12.524242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  8.  6.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -7.961550235748291
desired expected reward: 48.19794464111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.8284855]
 [-21.039076 ]
 [-13.467686 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  8.  6.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 18. 30.  8.  3.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.492892265319824
desired expected reward: -18.72951889038086



buy possibilites: [-1] 
expected returns: [[1.2877042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  8.  6.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  0.  3.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -408.0 

action type: buy - action 6.0
Learning step: -19.287412643432617
desired expected reward: -40.959716796875






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  3.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6. 16.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  3.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6. 16.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  3.] 
cards in discard: [ 0.  0.  0.  3.  3.  0.  0.  0. 11.  3.  0.  3.  8.  0.  3. 29.  3. 10.
  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6. 16.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.970243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6. 16.  0.  6.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -5.015054702758789
desired expected reward: -3.7273504734039307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.226943]
 [17.146763]
 [ 9.771721]
 [16.936539]
 [20.096228]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [14. 11. 11.  6.  0.  0.  0.  6.  0.  0.  0.  0.  0.  6.  8.  6.  0.  8.
  3.  6. 16.  0.  6.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -6.04179048538208
desired expected reward: 13.92845344543457



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  8.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [11.  8.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[-11.440999]
 [-11.823057]
 [-12.826135]
 [-12.826135]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0
  8 14 11  6  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -6.6798882484436035
desired expected reward: 13.416337966918945



action possibilites: [-1] 
expected returns: [[10.828526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: trash_cards_n_from_hand - action 2
Learning step: -3.5785186290740967
desired expected reward: -15.135309219360352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -5.241231]
 [-10.265574]
 [ 10.207853]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  2.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -4.979988098144531
desired expected reward: 5.848537445068359



buy possibilites: [-1] 
expected returns: [[24.237154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -399 

action type: buy - action 6.0
Learning step: -18.891386032104492
desired expected reward: -29.156959533691406






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [8. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 3.] 
cards in discard: [14. 11.  0.  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  6  0 10  0  3  0 14  0  3  3  0  0  8  8  3  3 29  3  3
  0  0  0  0  8 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14. 11.  0.  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 11.  0.  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.675723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -6.492061614990234
desired expected reward: 17.745092391967773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-13.173824]
 [-13.584781]
 [-14.404053]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 18. 30.  8.  1.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -4.5248799324035645
desired expected reward: -19.200603485107422



buy possibilites: [-1] 
expected returns: [[-3.6085217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 18. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -19.901952743530273
desired expected reward: -33.48672866821289






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 18. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 29. 30. 18. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 17. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-16.801409]
 [-19.009163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.  6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 17. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 14.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: buy - action -1
Learning step: -6.222334384918213
desired expected reward: -9.830856323242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-18.195707]
 [-15.517291]
 [-16.8962  ]
 [-15.267587]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 14.  6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 17. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 14.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1.0
Learning step: -5.530367851257324
desired expected reward: -22.331783294677734



buy possibilites: [-1] 
expected returns: [[-6.3596363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 14.  6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 14.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -101 

action type: buy - action 3.0
Learning step: -4.417227268218994
desired expected reward: -19.934518814086914






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 14.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 14.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  2. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 14.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
adversary victory points: -4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-12.019885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -5.4024658203125
desired expected reward: -11.762102127075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.114092 ]
 [-11.093503 ]
 [-10.426664 ]
 [ -8.66278  ]
 [-10.676985 ]
 [-11.661698 ]
 [-11.329036 ]
 [-12.961032 ]
 [-11.10294  ]
 [ -8.481908 ]
 [ -8.9392605]
 [-10.649493 ]
 [ -8.204866 ]
 [ -9.865325 ]
 [-13.278446 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 29. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.084952354431152
desired expected reward: -17.10483741760254



buy possibilites: [-1] 
expected returns: [[-11.8131275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5.     0.    -4.  -100.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -104.5 

action type: buy - action 1.0
Learning step: -4.9179487228393555
desired expected reward: -16.374889373779297






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1] -> size -> 33 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 16. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1] -> size -> 33 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [14. 11.  0.  0.  3.  6.  0.  8.  3.  0.  0.  3.  3.  0.  8.  0.  3.  0.
 10. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 15. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1] -> size -> 33 
adversary victory points: -4
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-5.075813]
 [-5.039476]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 15. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -5.473138809204102
desired expected reward: -17.286266326904297



action possibilites: [-1] 
expected returns: [[-12.538754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 14. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -84 

action type: gain_card_n - action 2
Learning step: -4.0287766456604
desired expected reward: -13.095682144165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-16.461372 ]
 [-10.338294 ]
 [-16.382004 ]
 [-13.1221695]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 14. 30.  8.  0.  9.  7.  1. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -4.089402675628662
desired expected reward: -16.628156661987305



buy possibilites: [-1] 
expected returns: [[-18.993383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 14. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -80 

action type: buy - action 8.0
Learning step: -3.6082513332366943
desired expected reward: -19.990251541137695






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 14. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 14. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [ 3.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[-17.120447]
 [-18.933893]
 [-18.265842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 16.  0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -5.357635021209717
desired expected reward: -24.35101890563965





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-16.16681 ]
 [-16.117132]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 16.  0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -5.407169818878174
desired expected reward: -22.52761459350586



buy possibilites: [-1] 
expected returns: [[-9.1329365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 16.  0.] 
cards in discard: [ 6.  8. 11.  6.  8.  6.  6.  3.  3.  0.  6.  3.  0.  6.  0. 14.  6.  1.
  0.  0.  0.  0.  0.  3.  8. 11.  0.  6.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -110.    0.    0.    0.  -30.    0.    0.    0.   -1.
    0.    0.    0.    0.] 
sum of rewards: -149.0 

action type: buy - action 0.0
Learning step: -6.8471503257751465
desired expected reward: -23.013959884643555






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 14. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 14. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0. 14. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
expected returns: [[ 1.2531381]
 [ 2.2395263]
 [-5.2313766]
 [ 2.2395263]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14. 11.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -5.440328121185303
desired expected reward: -14.573265075683594



action possibilites: [-1] 
expected returns: [[-16.239399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action 14.0
Learning step: -5.003818035125732
desired expected reward: -10.235184669494629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-16.351572]
 [-15.865791]
 [-14.869992]
 [-16.049366]
 [-16.217306]
 [-16.474766]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 13. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1
Learning step: -4.447279453277588
desired expected reward: -20.686677932739258



buy possibilites: [-1] 
expected returns: [[11.795733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -100.    0.    0.   20.    0.    0.    0.    0.   -2.
    0.    0.    2.    0.] 
sum of rewards: -87.0 

action type: buy - action 3.0
Learning step: -3.3410966396331787
desired expected reward: -18.211088180541992






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 1. 6. 8.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 1. 6. 8.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 1. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-9.377919 ]
 [-8.3766365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 8.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -6.139476299285889
desired expected reward: 5.656257152557373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-11.050348]
 [-11.413393]
 [-10.901248]
 [-11.266109]
 [-10.865019]
 [-11.129627]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 8.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 11. 14.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -5.130927562713623
desired expected reward: -14.508840560913086



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 11. 14.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0 14  0  3  3  0  0  8  3  3 29  3  3  0  0  0  0
  8 14  0  3  8  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [16.  8.  0.  8.  0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [16.  8.  0.  8.  0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [16.  8.  0.  8.  0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [16.  8.  0.  8.  0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [16.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
expected returns: [[-13.613108]
 [-12.870147]
 [-13.636096]
 [-13.636096]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  8.  0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16 11  6  6  6  0  0  0  8  0  3  6  0  3  0  8  0  8
 14 11  6  6  6  6  6  3  1  3  8  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.595837116241455
desired expected reward: -15.725461959838867



action possibilites: [-1] 
expected returns: [[-18.594652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.5662357807159424
desired expected reward: -17.609115600585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.367657]
 [-18.760145]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.292738676071167
desired expected reward: -21.88739013671875



buy possibilites: [-1] 
expected returns: [[-5.1680355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -107 

action type: buy - action 0.0
Learning step: -4.747898101806641
desired expected reward: -19.115554809570312






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  3.  0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 12. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.6288571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3. 14.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2  -100     0     0     0     0     0     0     0     0
     0 -2400    34     0] 
sum of rewards: -2473 

action type: discard_down_to_3_cards - action 5
Learning step: -123.54576873779297
desired expected reward: -124.44747924804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.19679499]
 [3.167931  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3. 14.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -5.443443298339844
desired expected reward: -2.8145861625671387



buy possibilites: [-1] 
expected returns: [[-2.333458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3. 14.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -100.    0.    0.    0.  -30.    0.    0.    0.   -1.
    0.    0.    0.    0.] 
sum of rewards: -138.0 

action type: buy - action 0.0
Learning step: -6.962342262268066
desired expected reward: -6.765542984008789






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3. 14.  8.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0. 29.  0.  6.  8.  0.  3.  0.  0. 10.  0.  0.  0.  8.
  3. 11.  3. 14.  8.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-15.93758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -5.591922760009766
desired expected reward: -7.925380706787109





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.988333]
 [-15.720762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -4.8759636878967285
desired expected reward: -20.81354331970215



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  3  0  0  8  3  3 29  3  3  0  0  0  0  8 14
  0  3  8  3  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-17.73769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.463059902191162
desired expected reward: -20.183826446533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-14.191898 ]
 [-16.89316  ]
 [-14.8495655]
 [-17.566101 ]
 [-14.663706 ]
 [-17.489244 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.3216447830200195
desired expected reward: -22.05933380126953



buy possibilites: [-1] 
expected returns: [[-13.385685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  6.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0  -2   0   0  18   0] 
sum of rewards: -81 

action type: buy - action 1.0
Learning step: -3.5065200328826904
desired expected reward: -20.399675369262695






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  6.] 
cards in discard: [ 0.  8.  8. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 11. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-9.48971 ]
 [-8.927654]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16 11  6  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6
  6  6  6  6  3  1  3  8  0  3  0  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -4.88788366317749
desired expected reward: -18.273569107055664



action possibilites: [-1] 
expected returns: [[-13.732946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: trash_cards_n_from_hand - action 7
Learning step: -4.274422645568848
desired expected reward: -10.594321250915527





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.170057]
 [-14.573595]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -3.9415016174316406
desired expected reward: -17.674448013305664



buy possibilites: [-1] 
expected returns: [[-11.402979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 14. 11.  0. 11.  3.  3.  0.  1.  6.  8.  0.  8. 16.  3.  6.  0.  0.
  6.  3.  6.  3.  6.  6.  0.  1.  6.  0.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -117.0 

action type: buy - action 0.0
Learning step: -5.598064422607422
desired expected reward: -15.768115043640137






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  6  0 10  0  0  0  0  0  8  3  3 29  3  3  0  0  0  0  8 14  0
  3  8  3  3  0  3  0 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  1. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-15.018917]
 [-10.12619 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.562492370605469
desired expected reward: -15.965471267700195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-13.033308]
 [-14.681843]
 [-12.754772]
 [-13.937325]
 [-14.709373]
 [-14.460611]
 [-10.126191]
 [-13.186783]
 [-12.055765]
 [-15.018919]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  9.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.400152683258057
desired expected reward: -19.419071197509766



buy possibilites: [-1] 
expected returns: [[-15.6064415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0  -1   0   0  32   0] 
sum of rewards: -66 

action type: buy - action 16.0
Learning step: -2.9542787075042725
desired expected reward: -16.891603469848633






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  7.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-15.190416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [16.  0.  1. 14.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.411462306976318
desired expected reward: -20.01790428161621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.026363]
 [-10.103479]
 [-14.15324 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [16.  0.  1. 14.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.354938983917236
desired expected reward: -19.54535484313965



buy possibilites: [-1] 
expected returns: [[13.8622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -129.0 

action type: buy - action 0.0
Learning step: -5.586781978607178
desired expected reward: -16.61314582824707






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16  0] -> size -> 37 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16  0] -> size -> 37 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
adversary owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16  0] -> size -> 37 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-26.049189]
 [-30.80357 ]
 [-27.247528]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 16 11  6  6  0  0  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6
  6  3  1  3  8  0  3  0  0  1  0 16  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -6.173666477203369
desired expected reward: 7.688533306121826



action possibilites: [-1] 
expected returns: [[7.225023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.1167640686035156
desired expected reward: -33.53022766113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.2858481]
 [4.6722293]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -4.1440558433532715
desired expected reward: 3.0809669494628906



buy possibilites: [-1] 
expected returns: [[-21.50484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -107 

action type: buy - action 0.0
Learning step: -5.89815092086792
desired expected reward: -4.612309455871582






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8.] 
adversary owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 26. 30. 10. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8.] 
adversary owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  8. 10.  0.  0.  6. 10.  3. 29. 11.  0.  3.  8.  0. 11.  0.  0.
  3.  0.  3.  1.  3.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8.] 
adversary owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 0. 16.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[-22.999435]
 [-25.113018]
 [-25.93536 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3
  8  0  3  0  0  1  0 16  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -4.82995080947876
desired expected reward: -26.33479118347168



action possibilites: [-1] 
expected returns: [[-12.19975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -89 

action type: gain_card_n - action 7
Learning step: -4.353168487548828
desired expected reward: -11.779682159423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-15.173874 ]
 [-14.0140915]
 [-13.686834 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -98 

action type: take_action - action -1
Learning step: -4.611514091491699
desired expected reward: -16.811264038085938






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [0. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-19.49605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  8. 29.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3  0] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1.0
Learning step: -5.654319763183594
desired expected reward: -19.341148376464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.989722]
 [-20.008474]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  8. 29.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3  0] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1.0
Learning step: -5.3186798095703125
desired expected reward: -24.814729690551758



buy possibilites: [-1] 
expected returns: [[-9.623396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  8. 29.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3  0] -> size -> 34 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -148.0 

action type: buy - action 0.0
Learning step: -6.867041110992432
desired expected reward: -21.85676383972168






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8. 29.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0 10  0  0  0  0  0  8  3 29  3  3  0  0  0  0  8  0  3  8  3
  3  0  3  0 10  3 11  1  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3. 11.  1.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3. 11.  1.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  6.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3. 11.  1.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3. 11.  1.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
adversary owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [ 6.  3. 11.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-4.8973336]
 [-5.846927 ]
 [-7.359417 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  1.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  3  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8
  0  3  0  0  1  0 16  0  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -5.554495811462402
desired expected reward: -15.177891731262207



action possibilites: [-1] 
expected returns: [[-8.921736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.369392395019531
desired expected reward: -10.996321678161621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.059719 ]
 [-10.039352 ]
 [-10.3732395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1
Learning step: -5.239911079406738
desired expected reward: -14.161646842956543






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.  8.  6. 11.  1.] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30.  9. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.  8.  6. 11.  1.] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.  8.  6. 11.  1.] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 9 





Player: 0 
cards in hand: [0. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-26.57115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.  8.  6. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11  3] -> size -> 34 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: buy - action -1.0
Learning step: -7.029188632965088
desired expected reward: -17.402429580688477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-22.107231]
 [-21.969389]
 [-27.123186]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [16.  0.  1. 14.  3.  0.  0.  6.  0.  6.  3.  0.  0.  8. 10. 16.  0.  0.
  8.  0.  0.  3.  6.  3.  6.  8.  6. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11  3] -> size -> 34 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: take_action - action -1.0
Learning step: -6.155267238616943
desired expected reward: -32.726417541503906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 9 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  6  0 10  0  0  0  0  0  8  3  3  3  0  0  0  0  8  0  3  8  3  3  0
  3  0 10  3 11  1  3  0 11  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30.  8. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
adversary victory points: -4
player victory points: 10 





Player: 0 
cards in hand: [ 6.  6.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-16.398783]
 [-10.642147]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 14.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: buy - action -1.0
Learning step: -6.397767543792725
desired expected reward: -33.52095413208008



action possibilites: [-1] 
expected returns: [[-22.121542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 26. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action 14.0
Learning step: -6.415627479553223
desired expected reward: -17.05777359008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-15.006665]
 [-18.721542]
 [-16.735477]
 [-20.314457]
 [-16.224642]
 [-20.974274]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action -1
Learning step: -5.748542308807373
desired expected reward: -27.870084762573242



buy possibilites: [-1] 
expected returns: [[-6.4258456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -111 

action type: buy - action 1.0
Learning step: -4.758504390716553
desired expected reward: -23.48004722595215






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  1. 16.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  6.] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  1. 16.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  6.] 
adversary owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 10 


Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 4 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 2 
Workshop: 2 
Chapel: 5 
Witch: 0 
Poacher: 0 
Militia: 2 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  6.  8.  1. 16.] 
cards in discard: [ 1. 14.  6.  6.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  6  0  0  6  0  3  0  8  0  8 14 11  6  6  6  6  6  3  1  3  8  0
  3  0  0  1  0 16  0  0 10  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30.  7. 30.  8.  0.  8.  5.  0. 10.  9.  5. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0. 11.  8.  1.  0.  3.  0.  3.  6.  3.  0.  3. 10.
  8.  0.  3.  0.  0. 10.  0.] 
adversary owned cards: [11  6  0 10  0  0  0  0  0  3  3  3  0  0  0  0  8  0  3  8  3  3  0  3
  0 10  3 11  1  3  0 11  3  3  0] -> size -> 35 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -649 

action type: buy - action -1
Learning step: -32.12870788574219
desired expected reward: -38.5545539855957



