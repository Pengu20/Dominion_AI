 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.70043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0      -60        0        0        0        0] 
sum of rewards: -3000135 

action type: gain_card_n - action 0
Learning step: -120004.0859375
desired expected reward: -120036.8046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 84.059235]
 [ 98.354385]
 [ 90.99669 ]
 [ 67.171616]
 [102.05384 ]
 [ 95.04457 ]
 [ 87.702034]
 [ 98.5125  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.9098892211914



buy possibilites: [-1] 
expected returns: [[94.70031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 102.05384063720703






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.824104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.70030975341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.108765]
 [ 96.46235 ]
 [ 89.080986]
 [ 64.536285]
 [ 92.33914 ]
 [100.123726]
 [ 93.15152 ]
 [107.20932 ]
 [ 75.0726  ]
 [ 85.77016 ]
 [ 89.37492 ]
 [ 96.60466 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.54932403564453



buy possibilites: [-1] 
expected returns: [[74.80028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.2093276977539






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[102.1309 ]
 [105.71234]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.80027770996094



action possibilites: [-1] 
expected returns: [[94.9972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 115.0536880493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.91696 ]
 [92.496056]
 [86.02911 ]
 [64.5955  ]
 [95.77506 ]
 [89.593056]
 [83.126114]
 [92.6415  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.99720001220703



buy possibilites: [-1] 
expected returns: [[81.7124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 95.7750473022461






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  8.  1.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.592155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.71240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.32687 ]
 [90.490204]
 [83.16335 ]
 [59.927963]
 [94.38161 ]
 [87.14409 ]
 [79.922035]
 [90.696884]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.69793701171875



buy possibilites: [-1] 
expected returns: [[73.568115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.38162994384766






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[105.593765]
 [108.95896 ]
 [115.559364]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.568115234375



action possibilites: [-1. 11. 11.] 
expected returns: [[100.90114]
 [104.44743]
 [104.44743]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.02617645263672



action possibilites: [-1] 
expected returns: [[89.04361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.01954650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.074486]
 [89.71753 ]
 [83.69227 ]
 [64.46549 ]
 [86.33072 ]
 [92.71965 ]
 [87.01391 ]
 [98.38102 ]
 [72.71475 ]
 [80.98865 ]
 [83.94377 ]
 [89.90161 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.04360961914062



buy possibilites: [-1] 
expected returns: [[108.0422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.38101959228516






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  8.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  8.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  8.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[71.42942]
 [74.53495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.04219818115234



action possibilites: [-1] 
expected returns: [[74.40446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.49534606933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[67.20691 ]
 [72.82322 ]
 [55.538315]
 [76.33983 ]
 [79.39828 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.40445709228516






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[64.002174]
 [72.38883 ]
 [55.329407]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.39826965332031



action possibilites: [-1. 10.] 
expected returns: [[96.200615]
 [86.17495 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.95955657958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.69489]
 [ 98.84273]
 [ 92.05272]
 [ 70.29656]
 [ 95.01009]
 [102.23547]
 [ 95.79455]
 [108.53179]
 [ 79.4321 ]
 [ 89.04385]
 [ 92.34349]
 [ 99.09854]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.20061492919922



buy possibilites: [-1] 
expected returns: [[90.493515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 108.53179931640625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [10.  0.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11. 29.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11. 29.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11. 29.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11. 29.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[113.654495]
 [117.167046]
 [117.167046]
 [124.17739 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11. 29.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.49351501464844



action possibilites: [-1. 11. 11.] 
expected returns: [[118.304146]
 [121.48443 ]
 [121.48443 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.23444366455078



action possibilites: [-1] 
expected returns: [[155.17307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.47369384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[145.71674]
 [159.13426]
 [152.20229]
 [128.88399]
 [162.63821]
 [156.01634]
 [149.12773]
 [159.33186]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.17306518554688



buy possibilites: [-1] 
expected returns: [[150.03229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 162.63819885253906






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0. 1.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[69.18613 ]
 [61.774773]
 [61.774773]
 [71.94326 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.03228759765625



action possibilites: [-1] 
expected returns: [[83.17747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.63335418701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.39443 ]
 [76.904854]
 [57.175083]
 [80.122894]
 [82.84914 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [29. 29. 10.  3.  0.  0.  0. 10. 11. 29. 11.  0.  0. 11.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.1774673461914






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14. 25.  0.  0.  8.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14. 25.  0.  0.  8.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 97.07363 ]
 [ 88.95719 ]
 [104.797676]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.84915924072266



action possibilites: [-1. 10. 11.] 
expected returns: [[91.2566 ]
 [82.84059]
 [93.87556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.21092987060547



action possibilites: [-1] 
expected returns: [[99.02116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.5794906616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.3283  ]
 [ 97.755135]
 [ 82.364136]
 [100.35521 ]
 [102.65941 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.02115631103516






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 10.] 
cards in discard: [14. 25.  0.  0.  8.  3.  0.  1. 23.  0.  0.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[108.60915]
 [111.64841]
 [111.64841]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 102.65941619873047



action possibilites: [-1] 
expected returns: [[100.99442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.47447967529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.738335]
 [104.772575]
 [ 98.07568 ]
 [ 75.38194 ]
 [108.10693 ]
 [101.7696  ]
 [ 95.0727  ]
 [104.957085]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  6.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.99442291259766



buy possibilites: [-1] 
expected returns: [[49.710945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.10694122314453






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0.  0.  6. 10.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0.  0.  6. 10.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0.  0.  6. 10.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [29.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[41.186462]
 [47.41005 ]
 [35.044952]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  6. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.71094512939453



action possibilites: [-1. 10. 10.] 
expected returns: [[45.648094]
 [39.103573]
 [39.103573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.410057067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.89631 ]
 [46.535965]
 [42.005722]
 [27.212038]
 [49.031918]
 [44.406837]
 [40.05629 ]
 [46.632107]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  5.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.64810562133789



buy possibilites: [-1] 
expected returns: [[56.735783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.03192138671875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 23.  8.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14 23  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  3.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  3.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  3.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29.  0.  0.  0. 10.  0.  0.  0.  1.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  3.] 
adversary cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [29.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[32.07337 ]
 [40.554436]
 [23.47983 ]
 [34.943714]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11.  3.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.735782623291016



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[35.495636]
 [27.41152 ]
 [38.123085]
 [27.41152 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.554443359375



action possibilites: [-1] 
expected returns: [[71.056465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.67667770385742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.820793]
 [65.38951 ]
 [45.56984 ]
 [68.6718  ]
 [71.5099  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0.  3.  3. 10. 11. 11.  0.  0. 11.  0. 11. 29.  0.  0.
  6. 10. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.05646514892578






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  4.  9.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  9.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  9.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 14.  0.  1.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[72.32732]
 [78.66953]
 [65.62214]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.5099105834961



action possibilites: [-1. 10.] 
expected returns: [[100.10331]
 [ 93.22701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.18607330322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 93.88956 ]
 [103.3678  ]
 [ 98.43494 ]
 [ 82.87595 ]
 [100.601715]
 [105.83225 ]
 [101.15574 ]
 [110.519135]
 [ 89.45994 ]
 [ 96.22287 ]
 [ 98.639725]
 [103.50391 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  6.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.10330963134766



buy possibilites: [-1] 
expected returns: [[112.67625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 6. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 110.51912689208984






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 6. 11. 11. 11.  3.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29] -> size -> 30 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 6. 11. 11. 11.  3.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29] -> size -> 30 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 11. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[37.346085]
 [39.08831 ]
 [39.08831 ]
 [39.08831 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 11. 11.  3.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  1. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.6762466430664



action possibilites: [-1] 
expected returns: [[43.90056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 11.  3.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.852996826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.92273 ]
 [22.055536]
 [44.075928]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 11.  3.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.90055847167969






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 30. 30.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8. 25.  0.  0.  1. 14.  0.  1.  0.  0.  3.  0.  8.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10. 10. 29.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [11.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[23.195873]
 [25.24415 ]
 [17.676939]
 [17.676939]
 [29.25929 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10. 29.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.0759391784668



action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[27.57797 ]
 [29.605505]
 [21.424803]
 [21.424803]
 [21.424803]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.106313705444336



action possibilites: [-1] 
expected returns: [[48.059708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.81475830078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.118004]
 [26.328295]
 [47.898758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.05970764160156






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0. 11. 10.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0. 11. 10.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0. 11. 10.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 29.  0. 11. 10.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [10. 29.  0. 11. 10.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10. 29.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[30.203642]
 [22.446815]
 [37.559532]
 [32.668682]
 [22.446815]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 11. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [0. 4. 0. 0. 8.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.89876174926758



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[78.55832 ]
 [70.836296]
 [70.836296]
 [70.836296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [0. 4. 0. 0. 8.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.04692268371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.4703 ]
 [73.3485 ]
 [55.79255]
 [76.19527]
 [78.70229]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [0. 4. 0. 0. 8.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.55833435058594






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 4. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 8.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [11. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[39.765305]
 [41.101986]
 [35.777702]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3.  0.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  9.] 
adversary cards in hand: [ 1.  1.  8. 25.  0.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.70230865478516



action possibilites: [-1] 
expected returns: [[55.42103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 1.  1.  8. 25.  0.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.92018127441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.897457]
 [50.997177]
 [40.86036 ]
 [52.81606 ]
 [54.35732 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 6. 29. 29.  0.  0. 10.  3.  0. 10. 11.  6. 11. 11.  3.  0. 15. 29. 11.
 10. 10. 10. 11. 29. 10.  0. 10. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 1.  1.  8. 25.  0.] 
adversary cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.42102813720703






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1.  1.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  8. 25.  0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  8. 10.  4.  8.  9.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 11. 15. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15] -> size -> 33 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8. 0. 0. 0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 11. 15. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8. 0. 0. 0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  9.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 11. 15. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8. 0. 0. 0.] 
cards in discard: [ 0. 22. 29. 10.  1.  0.  3.  0.  8.  4.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 11. 15. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11. 15. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 29.] 
expected returns: [[82.24005 ]
 [84.43466 ]
 [77.67302 ]
 [88.793724]
 [88.793724]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 29. 29.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 22. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -455 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.35731506347656



action possibilites: [-1. 11. 15. 11.] 
expected returns: [[82.85646 ]
 [84.8895  ]
 [78.533356]
 [84.8895  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 11.] 
cards in discard: [ 6. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  8.] 
adversary cards in hand: [ 0. 22. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.94879150390625



action possibilites: [-1] 
expected returns: [[76.70002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.] 
cards in discard: [ 6. 29. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [ 0. 22. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.2926254272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.1342  ]
 [71.06077 ]
 [53.336044]
 [73.96549 ]
 [76.46775 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.] 
cards in discard: [ 6. 29. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [ 0. 22. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.70001983642578






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 22. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [10. 10. 10. 11. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  4.  8. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [10. 10. 10. 11. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  4.  8. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [10. 10. 10. 11. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  4.  8. 14.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [10. 10. 10. 11. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [10. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11. 10.] 
expected returns: [[58.425194]
 [54.1277  ]
 [54.1277  ]
 [54.1277  ]
 [59.983192]
 [54.1277  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  7.] 
adversary cards in hand: [ 0.  1. 25.  1. 10.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.46773529052734



action possibilites: [-1] 
expected returns: [[44.159203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  1. 25.  1. 10.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -10    0    0
   64    0] 
sum of rewards: -111 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.22808074951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.825874]
 [29.300066]
 [44.018044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  1. 25.  1. 10.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.159202575683594






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 25.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  1. 10.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29.  6. 10.  0. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  1. 10.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 29. 29.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29.  6. 10.  0. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  1. 10.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29.  6. 10.  0. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29.  6. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[58.631935]
 [65.2367  ]
 [51.65144 ]
 [51.65144 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10.  0. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.01805114746094



action possibilites: [-1. 10. 10.] 
expected returns: [[38.99392]
 [33.18195]
 [33.18195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 58.49159622192383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.2721  ]
 [34.902634]
 [21.923006]
 [37.11236 ]
 [38.98147 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 10.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.99394226074219






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29. 10.  6. 11.  0.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29. 10.  6. 11.  0.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3. 22.  0. 14.  0.  3.  4.  8. 14.  4.  0.  1. 25.  1. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [29. 10.  6. 11.  0.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29. 10.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[63.792336]
 [69.68577 ]
 [57.59834 ]
 [65.76826 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  6. 11.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 38.981483459472656



action possibilites: [-1. 10. 11.] 
expected returns: [[67.98735]
 [61.78324]
 [70.02357]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  6.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.66771697998047



action possibilites: [-1] 
expected returns: [[33.59525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -191 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.33332061767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.996984]
 [30.045706]
 [19.18156 ]
 [31.830496]
 [33.325245]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.59524917602539






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8  1 29  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4
  1] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  3. 10. 11. 11.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 3.  3. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[30.296698]
 [27.245108]
 [31.428122]
 [31.428122]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11. 11.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  5.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.325252532958984



action possibilites: [-1] 
expected returns: [[32.067955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0  -30    0    0
   64    0] 
sum of rewards: -221 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.75323486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.573656]
 [23.089891]
 [31.830252]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.067955017089844






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [ 0. 10.  8.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [15.  0.  0.  3. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [15.  3. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 29. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [15.  3. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [15.  3. 10.] 
adversary cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[16.881529]
 [14.915991]
 [13.919649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 4.  0.  0.  1. 14.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0  -30    0 -900
 1018    0] 
sum of rewards: -217 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 10.382081985473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.906002]
 [ 8.0065  ]
 [16.881529]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.] 
cards in discard: [ 6. 29. 15. 29. 11.  0. 15. 11. 15. 11. 10. 10. 10. 10.  0. 29.  6. 10.
 10.  0.  0. 15. 29. 11. 10.  6.  0. 15. 11.  3.  3. 10. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 4.  0.  0.  1. 14.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.88153076171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 4.  0.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  0.  1. 14.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 0. 29. 15.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 1.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 1.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 28. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 1.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 26. 30. 27. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[90.13633]
 [83.59507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [29. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 1.  3.  0. 25.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0  -30    0 -900
 1018    0] 
sum of rewards: -247 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -10.133584976196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.75305]
 [70.31414]
 [89.53059]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [29. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 1.  3.  0. 25.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.1363296508789



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 25.  0.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  7. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 6.  0. 10. 15. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15] -> size -> 38 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0.  1. 22.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 6.  0. 10. 15. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6] -> size -> 39 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0.  1. 22.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  8.  9.  0.  9.  4.] 
adversary cards in hand: [ 6.  0. 10. 15. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6] -> size -> 39 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0.  1. 22.] 
cards in discard: [ 0. 10.  8.  3.  0.  3. 14.  3.  8.  0.  0.  3. 14.  4.  0.  0.  1. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  4.] 
adversary cards in hand: [ 6.  0. 10. 15. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6] -> size -> 39 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 6.  0. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[ 96.45375]
 [ 85.52186]
 [ 89.01034]
 [100.06275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 15. 11.] 
cards in discard: [29. 15.  0.  3. 10.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  4.] 
adversary cards in hand: [ 1. 14.  0.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0    0    0    0    0    0  -40    0 -300
    0    0] 
sum of rewards: -705 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.53058624267578



action possibilites: [-1] 
expected returns: [[88.04887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 15.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [ 1. 14.  0.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0  -50    0    0
   64    0] 
sum of rewards: -331 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.80927276611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.284454]
 [65.42686 ]
 [88.635605]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 15.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [ 1. 14.  0.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.04886627197266






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0.  1.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  1.  4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [15. 10.  0. 29. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [15. 10. 29.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 4.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  8.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [15. 10. 29.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 4.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [15. 10. 29.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [15. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29.] 
expected returns: [[124.21775]
 [116.85464]
 [113.1906 ]
 [134.99463]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  1.  1.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[   -5     0     0  -360     0     0     0     0     0     0     0   -50
     0 -1200  1082     0] 
sum of rewards: -533 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -6.610625267028809



action possibilites: [-1. 15. 10.] 
expected returns: [[106.958115]
 [100.093575]
 [ 96.724556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  1.  1.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.03314971923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.1854 ]
 [ 76.40981]
 [106.83926]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [ 3. 10.  3.  1.  1.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 106.95812225341797






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  1.  1.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [11. 10. 10.  6.  3.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1.  1.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [11. 10. 10.  6.  3.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1.  1.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [11. 10. 10.  6.  3.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [11. 10. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[73.29185 ]
 [75.430786]
 [67.00407 ]
 [67.00407 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  6.  3.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  3.] 
adversary cards in hand: [14.  8.  3.  0. 25.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -365 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.83924865722656



action possibilites: [-1] 
expected returns: [[87.30787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.  3.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [14.  8.  3.  0. 25.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0  -60    0    0
   64    0] 
sum of rewards: -341 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.94916534423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.65072]
 [65.58628]
 [87.15472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.  3.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [14.  8.  3.  0. 25.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -360    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.30786895751953






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14.  8.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0. 25.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  6. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [10. 15. 11. 11. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15] -> size -> 41 
adversary victory points: -1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  4.  0.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [10. 15. 11. 11. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6] -> size -> 42 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  0.  4.  0.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [10. 15. 11. 11. 11.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6] -> size -> 42 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [10. 15. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 11. 11.] 
expected returns: [[34.40093 ]
 [31.531397]
 [32.493145]
 [35.3649  ]
 [35.3649  ]
 [35.3649  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 11. 11.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  2.] 
adversary cards in hand: [ 3.  0. 14.  0.  8.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0    0    0    0    0    0  -70    0 -300
    0    0] 
sum of rewards: -765 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.15470123291016



action possibilites: [-1] 
expected returns: [[32.53823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 11.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 14.  0.  8.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   20    0    0    0    0  -80    0    0
   64    0] 
sum of rewards: -391 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.338844299316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.567118]
 [24.510012]
 [32.53822 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 11. 11.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 3.  0. 14.  0.  8.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.538230895996094






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0.  8.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [29. 29.  0.  3.  0.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  4.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [29. 29.  0.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[26.707697]
 [29.7105  ]
 [29.7105  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0. 11. 14.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[   -5     0     0  -390     0     0     0     0     0     0     0   -80
     0 -1500  1210     0] 
sum of rewards: -765 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 1.513329029083252



action possibilites: [-1. 10.] 
expected returns: [[40.110962]
 [37.134415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0. 11. 14.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.69029426574707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.24164 ]
 [37.987736]
 [31.941889]
 [39.116512]
 [40.110966]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  0.  0.  3. 22.] 
adversary cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0. 11. 14.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -375 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.11095428466797






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 22.] 
cards in discard: [ 8. 14.  1.  0.  1.  4.  1.  3. 10.  3.  1.  1. 25. 14.  8.  3.  0.  4.
  0. 11. 14.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 15.  6. 10.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.  8. 14. 10.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 15.  6. 10.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.  8. 14. 10.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 25. 30. 27. 28.  8.  5. 10.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 15.  6. 10.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 1. 0.] 
cards in discard: [16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.  8. 14. 10.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 15.  6. 10.] 
adversary cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 0. 15. 15.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10.] 
expected returns: [[57.24198 ]
 [53.965443]
 [53.965443]
 [52.536472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.  6. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [14.  3.  4. 25.  0.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -395 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.11095428466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.084892]
 [44.038483]
 [57.24198 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.  6. 10.] 
cards in discard: [29. 15.  0.  3. 10.  6. 15. 11.  6.  0. 10. 15.  0. 11. 10. 29. 15. 10.
 15. 11. 10. 10.  6.  3.  6. 15. 11. 10. 15. 11. 11.  0.  3. 29. 29.  0.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [14.  3.  4. 25.  0.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.24198913574219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [14.  3.  4. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  4. 25.  0.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [11. 15. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4. 25.  0.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [15. 15.  0.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4. 25.  0.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [15. 15.  0.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[105.20883]
 [100.21557]
 [100.21557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.] 
cards in discard: [11.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [1. 3. 1. 8. 0.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[   -5     0     0  -390     0     0     0     0     0     0     0   -80
     0 -1500  1183     0] 
sum of rewards: -792 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -13.660511016845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 95.8365 ]
 [ 85.39468]
 [105.53333]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.] 
cards in discard: [11.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [1. 3. 1. 8. 0.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.20881652832031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [1. 3. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 8. 0.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0
  3  3 14  8  1 11 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 6. 15.  6.  6. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 6. 15.  6.  6. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  7.  9.  0.  9.  1.] 
adversary cards in hand: [ 6. 15.  6.  6. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [ 6. 15.  6.  6. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [ 6. 15.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[88.74565 ]
 [82.49089 ]
 [79.639244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  6. 10.] 
cards in discard: [11.  3. 15. 15.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  0.  3. 11.  1.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.
  8.  1.  1.] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14] -> size -> 30 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -360    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -365 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.53333282470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.196014]
 [65.05129 ]
 [88.950195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  6. 10.] 
cards in discard: [11.  3. 15. 15.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [ 0.  0.  3. 11.  1.] 
adversary cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.
  8.  1.  1.] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14] -> size -> 30 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -360    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -365 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.74565124511719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.
  8.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [10. 15. 29. 11. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.
  8.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 27. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [10. 15. 29. 11. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  1.] 
cards in discard: [16. 22.  8. 14. 10.  0.  0.  0.  3.  3.  1.  0. 14.  3.  4. 25.  0. 14.
  8.  1.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [10. 15. 29. 11. 10.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [10. 15. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29. 11. 10.] 
expected returns: [[57.537918]
 [50.148697]
 [52.48172 ]
 [64.78508 ]
 [59.97751 ]
 [50.148697]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 29. 11. 10.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [10. 14.  1.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -395 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.9501953125



action possibilites: [-1. 10. 15. 11. 10.] 
expected returns: [[83.192116]
 [75.51016 ]
 [78.05745 ]
 [85.72564 ]
 [75.51016 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 10.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  1.] 
adversary cards in hand: [10. 14.  1.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.406715393066406



action possibilites: [-1] 
expected returns: [[105.61452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 14.  1.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   40    0    0    0    0  -90    0    0
   64    0] 
sum of rewards: -381 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.43338775634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.98428]
 [ 79.15345]
 [105.66778]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 14.  1.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -390    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -355 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.61451721191406






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10. 14.  1.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  1.  8.  4.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10.  6. 10. 15.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  8.  4.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  1  0 25  0 10  1 14  1  0  0  8  4 22 14  3  4  1  0  3  3
 14  8  1 11 16 14  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10.  6. 10. 15.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10.  6. 10. 15.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[74.87437]
 [69.51877]
 [69.51877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [22.  3. 14.  1. 16.] 
adversary cards in discard: [ 0. 10.  8. 14.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[   -5     0     0  -270     0     0     0     0     0     0     0   -90
     0 -1500  1247     0] 
sum of rewards: -618 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 32.947349548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.270584]
 [58.805763]
 [74.70678 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [22.  3. 14.  1. 16.] 
adversary cards in discard: [ 0. 10.  8. 14.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.8743667602539



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [22.  3. 14.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 14.  1. 16.] 
cards in discard: [ 0. 10.  8. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6. 29. 11. 10.  3.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3. 14.  1. 16.] 
cards in discard: [ 0. 10.  8. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  7.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6. 29. 11. 10.  3.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3. 14.  1. 16.] 
cards in discard: [ 0. 10.  8. 14.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6. 29. 11. 10.  3.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 6. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[45.685925]
 [49.324173]
 [46.915   ]
 [42.15058 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 11. 10.  3.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 1.  8.  3. 25.  1.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 74.70677947998047



action possibilites: [-1. 11.] 
expected returns: [[57.049065]
 [58.292534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 1.  8.  3. 25.  1.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.66463851928711



action possibilites: [-1] 
expected returns: [[37.57394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 1.  8.  3. 25.  1.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -308 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 57.02507781982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.330776]
 [29.033628]
 [37.573944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 1.  8.  3. 25.  1.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.57394027709961






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 25.  1.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 15.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3. 25.  1.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 30. 26. 28.  8.  5.  9.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 15.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3. 25.  1.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 29. 10. 15.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0. 15. 29. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10. 15.] 
expected returns: [[40.556858]
 [38.59195 ]
 [43.56872 ]
 [37.595917]
 [38.59195 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 10. 15.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.57394027709961



action possibilites: [-1. 15. 15.] 
expected returns: [[32.381172]
 [30.43556 ]
 [30.43556 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.560909271240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.459402]
 [23.691818]
 [32.381172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.38116455078125






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 15. 10. 29.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  5.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 15. 10. 29.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 15. 10. 29.  0.] 
adversary cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [15. 15. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10. 29.] 
expected returns: [[31.868006]
 [30.057276]
 [30.057276]
 [29.13508 ]
 [35.352325]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 29.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [11.  4.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.38116455078125



action possibilites: [-1. 15.] 
expected returns: [[34.489136]
 [32.111053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3. 15.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [11.  4.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.886926651000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[29.710062]
 [34.441265]
 [32.008617]
 [23.74694 ]
 [35.651543]
 [33.35298 ]
 [34.489136]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3. 15.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  3.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [11.  4.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.48912811279297



buy possibilites: [-1] 
expected returns: [[53.73248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [11.  3. 15. 15.  0.  6. 15.  6.  6. 10.  0. 15. 29. 11. 10. 15. 10.  6.
 15. 10. 10.  0. 11. 10.  1. 29. 11.  6.  3.  0. 10. 29. 15. 15.  3. 15.
 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [11.  4.  0.  0. 14.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: -311 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 35.65154266357422






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [11.  4.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  0.  0. 14.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 11. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11] -> size -> 46 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  0.  0. 14.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 11. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11] -> size -> 46 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  0.  0. 14.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 11. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11] -> size -> 46 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 3. 11. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[83.56019]
 [85.62887]
 [77.09515]
 [85.62887]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.732479095458984



action possibilites: [-1] 
expected returns: [[121.61219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -348 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 83.40204620361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.81166 ]
 [ 99.22577 ]
 [121.955925]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  0.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.61219024658203






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 11.  1.  6. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  6.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 11.  1.  6. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [ 0. 10.  8. 14.  8. 22.  3. 14.  1. 16. 16.  1.  8.  3. 25.  1. 29.  0.
  8.  0.  1.  3.  0. 11.  4.  0.  0. 14.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15. 11.  1.  6. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [15. 11.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[102.00415 ]
 [ 96.89421 ]
 [104.406456]
 [104.406456]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  1.  6. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0  8] -> size -> 34 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.95592498779297



action possibilites: [-1] 
expected returns: [[99.876236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  6. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0  8] -> size -> 34 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -358 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 101.8307876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.63267]
 [91.40178]
 [74.28095]
 [95.0641 ]
 [98.26791]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  6. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0  8] -> size -> 34 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.87623596191406






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 29.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 29.  8. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1 14  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1
 11 16 14  3  0  8 16 29  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 11. 15. 15. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 11. 15. 15. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 11. 15. 15. 11.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0. 11. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 11.] 
expected returns: [[75.975464]
 [79.52688 ]
 [69.00931 ]
 [69.00931 ]
 [79.52688 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 15. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [14.  0.  8.  8.  1.] 
adversary cards in discard: [ 8.  8. 25.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.26789093017578



action possibilites: [-1] 
expected returns: [[112.03509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [14.  0.  8.  8.  1.] 
adversary cards in discard: [ 8.  8. 25.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -368 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.78120422363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.74049]
 [ 74.27859]
 [109.0035 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15. 11.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [14.  0.  8.  8.  1.] 
adversary cards in discard: [ 8.  8. 25.] 
adversary owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.03508758544922






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [14.  0.  8.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  8.  1.] 
cards in discard: [ 8.  8. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 25  0 10  1  1  0  0  8 22 14  3  4  1  0  3  3 14  8  1 11
 16 14  3  0  8 16  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8.  8. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  8. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  8. 25.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 10. 10. 15. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 3. 10. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 10.] 
expected returns: [[74.10108]
 [65.09777]
 [65.09777]
 [68.09227]
 [65.09777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 15. 10.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [16.  0.  0. 22.  3.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.] 
adversary owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 109.00350952148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.056244]
 [49.292892]
 [74.10109 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 15. 10.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [16.  0.  0. 22.  3.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.] 
adversary owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.10108184814453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [16.  0.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 22.  3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 29. 15. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 22.  3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 29. 15. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 22.  3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3. 29. 15. 11. 10.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 3. 29. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 10.] 
expected returns: [[23.898617]
 [27.184969]
 [21.679453]
 [25.02902 ]
 [20.562168]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 15. 11. 10.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14.  0. 10.  1.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
adversary owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 74.10108184814453



action possibilites: [-1. 10. 15.] 
expected returns: [[23.842024]
 [21.77967 ]
 [22.473967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14.  0. 10.  1.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
adversary owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.891313552856445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.07459 ]
 [17.554632]
 [23.842024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 8. 14.  0. 10.  1.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
adversary owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.842023849487305






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8. 14.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 10.  1.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 10.  6.  0.  0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  1.  0.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 10.  6.  0.  0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  8  0 25  0 10  1  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3
  0  8 16  0  8  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.48147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [14.  3.  0.  4.  1.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[   -5     0     0  -270     0     0     0     0     0     0     0  -140
     0 -1500  1301     0] 
sum of rewards: -614 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -24.306432723999023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.650534]
 [19.513203]
 [12.989361]
 [20.611355]
 [21.481482]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [14.  3.  0.  4.  1.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.481470108032227



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  4.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  4.  1.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [29.  0.  0. 15. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 1.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 1.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  9.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 1.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 15. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [ 0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[30.243345]
 [27.514372]
 [27.514372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[   -5     0     0  -270     0     0     0     0     0     0     0  -140
     0 -1500  1328     0] 
sum of rewards: -587 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -20.970922470092773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.772367]
 [18.312284]
 [30.243345]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  1.  0.  3. 11.] 
adversary cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.243337631225586



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 11.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  8.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 29. 15.  6. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 29. 15.  6. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 21. 30. 26. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 29. 15.  6. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [ 8.  8. 25.  0.  8.  8.  0. 16.  0.  0. 22.  3. 10. 14.  8.  0. 25. 14.
  3.  0.  4.  1. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [10. 29. 15.  6. 15.] 
adversary cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [10. 29. 15.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15. 15.] 
expected returns: [[34.763462]
 [29.886347]
 [39.609505]
 [31.5263  ]
 [31.5263  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 15.  6. 15.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  4. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.243337631225586



action possibilites: [-1. 10. 15.] 
expected returns: [[27.377378]
 [22.902857]
 [24.405401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  4. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.77901077270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.525305]
 [24.291525]
 [14.77714 ]
 [26.017796]
 [27.377378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.] 
cards in discard: [ 1. 11.  3. 10. 11.  0.  1. 11. 15.  1.  6. 11.  1. 11.  0. 15. 15. 11.
  3. 10. 10. 15. 10. 15. 11. 29.  3. 10. 15. 10. 10.  6.  0.  0. 29.  0.
  0. 15. 15.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  4. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.377355575561523






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3.  4. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  6.  6. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  6.  6. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4. 16.  0.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 3.  6.  6. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 3.  6.  6. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[85.64803]
 [80.08976]
 [91.31681]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 10. 29.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [16. 22.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.377355575561523



action possibilites: [-1. 10.] 
expected returns: [[94.731224]
 [88.58831 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.] 
cards in discard: [ 6. 15.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [16. 22.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.5118179321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[87.031  ]
 [78.36577]
 [94.79836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.] 
cards in discard: [ 6. 15.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [16. 22.  8.  0.  3.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.73121643066406






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [16. 22.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 22.  8.  0.  3.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6.  6. 10. 15. 15.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0.  8. 16.  1.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22. 11. 16.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6.  6. 10. 15. 15.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  8. 16.  1.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22. 11. 16.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 21. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6.  6. 10. 15. 15.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  8. 16.  1.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22. 11. 16.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 6.  6. 10. 15. 15.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 6.  6. 10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[75.29698]
 [68.28668]
 [70.61657]
 [70.61657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 15. 15.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1] -> size -> 34 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.7983627319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.97223 ]
 [55.283253]
 [75.214035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 15. 15.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 20. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1] -> size -> 34 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.2969741821289



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  1. 11.  0. 11.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 30. 25. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  1. 11.  0. 11.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 24. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  1. 11.  0. 11.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [15.  1. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
expected returns: [[71.48054]
 [65.52102]
 [74.30824]
 [74.30824]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 11.  0. 11.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 24. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.21401977539062



action possibilites: [-1] 
expected returns: [[110.32003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0. 11.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: -438 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 71.30130767822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 94.59526 ]
 [105.03783 ]
 [ 99.51777 ]
 [ 82.315   ]
 [107.92768 ]
 [102.51519 ]
 [105.218254]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 11.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  2.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.32003021240234



buy possibilites: [-1] 
expected returns: [[102.64318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0. 11.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0.  1.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0 -160    0    0
   54    0] 
sum of rewards: -421 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 107.92766571044922






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 14.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  1  0  3  3 14  8  1 11 16 14  3  0  8
 16  0  8  0  0 25 16  3  0  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  0.  0. 10.  0.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
adversary victory points: -2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  0  3  3 14  8  1 11 16 14  3  0  8 16
  0  8  0  0 25 16  3  0  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  0.  0. 10.  0.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  0  3  3 14  8  1 11 16 14  3  0  8 16
  0  8  0  0 25 16  3  0  1  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [15.  0.  0. 10.  0.] 
adversary cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [15.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[64.02236 ]
 [60.44979 ]
 [58.653305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 10.  0.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 25. 25.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.  8.  0.  0. 14.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  0  3  3 14  8  1 11 16 14  3  0  8 16
  0  8  0  0 25 16  3  0  1  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.64318084716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[56.82873 ]
 [63.990128]
 [60.303566]
 [47.776535]
 [65.814316]
 [62.340164]
 [64.02237 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 10.  0.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  1.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 25. 25.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.  8.  0.  0. 14.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  0  3  3 14  8  1 11 16 14  3  0  8 16
  0  8  0  0 25 16  3  0  1  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.0223388671875



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 0 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  0.  0. 10.  0.] 
cards in discard: [ 6. 15. 29.  3.  6. 10.  6.  6. 10. 15. 15.  1. 11. 11. 15.  1.  0. 11.
 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 29 10 11  6 10 10
 10 11 11 10  6 29 10 15 15  6 15 15 15 15  6 15 15  6 15 15  1 11  1  1
  1  1 11 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 28.  8.  5.  7.  0.  5.  8.  4.  6.  9.  0.  9.  0.] 
adversary cards in hand: [ 0. 25. 25.  8. 14.] 
adversary cards in discard: [ 0.  3.  4. 16.  0.  0.  1. 22. 11. 16.  8.  0.  3.  0.  8. 16.  1.  3.
  0.  0.  8.  3. 10.  8.  0.  0. 14.] 
adversary owned cards: [ 8  0 25  0 10  0  0  8 22  3  4  0  3  3 14  8  1 11 16 14  3  0  8 16
  0  8  0  0 25 16  3  0  1  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0        0        0
        0        0        0     -170        0        0       27        0] 
sum of rewards: -3000478 

action type: buy - action 11.0
Learning step: -120021.75
desired expected reward: -119955.9375



