 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.59157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -420        0        0       20        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000378 

action type: gain_card_n - action 7
Learning step: -120013.5078125
desired expected reward: -120053.8125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.567695  ]
 [22.249737  ]
 [19.241594  ]
 [ 0.11716866]
 [27.425087  ]
 [20.83819   ]
 [17.830053  ]
 [19.202381  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.66272735595703



buy possibilites: [-1] 
expected returns: [[18.514914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.42508316040039






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.71455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.51491355895996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.461099 ]
 [24.164677 ]
 [21.446398 ]
 [ 3.6945755]
 [21.665865 ]
 [28.915333 ]
 [22.84651  ]
 [29.297638 ]
 [11.554364 ]
 [20.129208 ]
 [20.256802 ]
 [20.86893  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.49164581298828



buy possibilites: [-1] 
expected returns: [[22.4107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.297637939453125






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.650568]
 [24.178978]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.41069984436035



action possibilites: [-1.] 
expected returns: [[21.793781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.635208129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.630034 ]
 [23.68309  ]
 [21.211946 ]
 [ 7.9130325]
 [ 5.46014  ]
 [21.359585 ]
 [28.060429 ]
 [22.460104 ]
 [36.39025  ]
 [28.509659 ]
 [12.254088 ]
 [19.190037 ]
 [19.98896  ]
 [11.165874 ]
 [20.290562 ]
 [21.717783 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.793781280517578



buy possibilites: [-1] 
expected returns: [[32.779205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 36.3902587890625






Player: 1 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[46.69568 ]
 [53.281693]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.779205322265625



action possibilites: [-1] 
expected returns: [[44.532654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.643524169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.348244]
 [42.06168 ]
 [23.873663]
 [43.725582]
 [43.955082]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.53265380859375






Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  0. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  0. 11.  0.  3.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.] 
adversary cards in discard: [ 3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.722034]
 [31.977364]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 43.45391082763672



action possibilites: [-1.] 
expected returns: [[36.132618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.39517593383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.20414 ]
 [39.32387 ]
 [36.85727 ]
 [20.17391 ]
 [43.70376 ]
 [38.10363 ]
 [35.637012]
 [37.470245]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.13261795043945



buy possibilites: [-1] 
expected returns: [[25.53437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.70376205444336






Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[104.093864]
 [110.43479 ]
 [101.14305 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  3. 10.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.53437042236328



action possibilites: [-1] 
expected returns: [[41.383545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3. 10.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.95000457763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.472664]
 [45.51278 ]
 [42.695152]
 [24.86209 ]
 [50.421635]
 [44.19915 ]
 [41.38151 ]
 [42.677303]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  7. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3. 10.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.383544921875



buy possibilites: [-1] 
expected returns: [[59.55119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  0.  3. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  3. 10.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.421634674072266






Player: 1 
cards in hand: [16.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3. 10.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3. 10.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3. 10.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.638084]
 [40.013367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.55118942260742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.035492]
 [45.420494]
 [42.848385]
 [26.349937]
 [49.917793]
 [44.149414]
 [41.577305]
 [43.218964]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.95681381225586



buy possibilites: [-1] 
expected returns: [[40.715675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.91779327392578






Player: 1 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 11. 10.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 11. 10.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [29. 11.  3.  0.  0.  0.  0. 16.  3.  3. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 11. 10.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[34.055473]
 [39.833412]
 [39.833412]
 [30.307087]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 11. 10.] 
cards in discard: [11. 10.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.715675354003906



action possibilites: [-1] 
expected returns: [[37.704117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.610870361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.96446 ]
 [23.125544]
 [37.58443 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11. 10.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.70411682128906






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 25.] 
adversary cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[46.053818]
 [51.700546]
 [52.062984]
 [60.7815  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 25.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 29.  3. 11.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.584434509277344



action possibilites: [-1] 
expected returns: [[14.451386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  0.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 29.  3. 11.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.30790710449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.105721 ]
 [17.466032 ]
 [14.514905 ]
 [-1.4381001]
 [14.790294 ]
 [22.635458 ]
 [16.226269 ]
 [23.159794 ]
 [ 4.489109 ]
 [13.275147 ]
 [13.52378  ]
 [14.981282 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29.  0.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 29.  3. 11.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.451386451721191



buy possibilites: [-1] 
expected returns: [[65.44138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29.  0.  0.] 
cards in discard: [11. 10.  0.  3.  0.  0. 10. 11.  3.  3. 11. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 29.  3. 11.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.159801483154297






Player: 1 
cards in hand: [16.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  3. 11.] 
cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  3. 11.] 
cards in discard: [3. 0. 0. 0. 3. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[46.787228]
 [52.841957]
 [52.15368 ]
 [43.164787]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.4413833618164



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[41.94521]
 [47.34625]
 [38.09536]
 [48.11195]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.57709503173828



action possibilites: [-1. 11. 10.] 
expected returns: [[52.863888]
 [58.308697]
 [48.818653]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.11195373535156



action possibilites: [-1] 
expected returns: [[48.020924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.14812469482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.56603 ]
 [48.99017 ]
 [46.139233]
 [31.060444]
 [54.259033]
 [47.616844]
 [44.930634]
 [48.816345]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.02092361450195



buy possibilites: [-1] 
expected returns: [[20.318148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.259033203125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  0.  6. 16.  0. 29.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[119.439415]
 [123.61168 ]
 [123.61168 ]
 [113.45578 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.318147659301758



action possibilites: [-1] 
expected returns: [[32.675495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.29012298583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.488499]
 [16.801357]
 [32.936295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.67549514770508






Player: 1 
cards in hand: [ 3.  0.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 14.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[103.98978]
 [109.39048]
 [100.05969]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.93629837036133



action possibilites: [-1] 
expected returns: [[70.92542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.25096893310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.111214]
 [72.22209 ]
 [68.41649 ]
 [44.608032]
 [79.2409  ]
 [70.67718 ]
 [66.871574]
 [70.01265 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  4. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.92542266845703



buy possibilites: [-1] 
expected returns: [[43.241848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3.  3. 10.  0. 10. 11. 11.  0. 10.  3. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 79.24089050292969






Player: 1 
cards in hand: [29. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 10. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[47.561897]
 [51.43805 ]
 [61.36936 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.24184799194336



action possibilites: [-1] 
expected returns: [[40.75647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.56739807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.828247]
 [39.864624]
 [36.955624]
 [20.385395]
 [45.25811 ]
 [38.58669 ]
 [35.76884 ]
 [38.400307]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  8.  8.  3. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.7564697265625



buy possibilites: [-1] 
expected returns: [[53.297546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 11. 29.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.25811004638672






Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[69.974846]
 [77.4163  ]
 [66.39263 ]
 [77.4163  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10. 11.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.29754638671875



action possibilites: [-1] 
expected returns: [[41.651775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 80.85789489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.045425]
 [24.13172 ]
 [41.200333]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 16. 29.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.65177536010742






Player: 1 
cards in hand: [ 3. 16. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 29.  0.  0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  2. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 3.  3.  0.  0. 10. 14. 16.  3. 11. 29.  0.  0.  3.  6.  0.  6.  0.  0.
  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 10.  3.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[87.87202]
 [94.89835]
 [94.43459]
 [86.94651]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 10.  3.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.2003288269043



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[115.53442]
 [120.0897 ]
 [111.84045]
 [111.84045]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.89835357666016



action possibilites: [-1] 
expected returns: [[33.205307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.99988555908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.732243]
 [16.414667]
 [33.40396 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.20530700683594






Player: 1 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1.  9.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1.  9.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[29.3861  ]
 [26.143332]
 [33.89462 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1.  9.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.40396499633789



action possibilites: [-1] 
expected returns: [[42.447544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.208099365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[37.969543]
 [45.729324]
 [43.049034]
 [28.860985]
 [50.43476 ]
 [44.463318]
 [43.84661 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  1.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.44754409790039



buy possibilites: [-1] 
expected returns: [[26.93989]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [11. 25. 11.  0.  0.  0. 11. 29. 10. 11.  3.  0. 10. 11. 10. 29. 11.  3.
 10.  3. 10. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 16.  3.  0.  3.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.434776306152344






Player: 1 
cards in hand: [11. 16.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.  0.  3.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  3.  0.  3.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  3.  0.  3.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[21.281183]
 [18.66755 ]
 [18.66755 ]
 [18.66755 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6. 16. 14.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.939889907836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.404059 ]
 [20.52989  ]
 [ 3.2834332]
 [22.026958 ]
 [22.178047 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6. 16. 14.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.281179428100586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  6. 16. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 14.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  0. 25. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[16.5466  ]
 [15.630458]
 [29.920296]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  8.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10. 29.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 503   0] 
sum of rewards: 438 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 73.03553009033203



action possibilites: [-1] 
expected returns: [[15.695567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10. 29.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.920303344726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.80102 ]
 [16.3029  ]
 [ 5.407096]
 [17.266678]
 [15.649928]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  9.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10. 29.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.69556713104248



buy possibilites: [-1] 
expected returns: [[9.176127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10. 29.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 17.266679763793945






Player: 1 
cards in hand: [ 6.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10. 29.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29.  3. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[27.239414]
 [32.81331 ]
 [33.494934]
 [32.81331 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.176127433776855



action possibilites: [-1. 11. 11.] 
expected returns: [[30.346485]
 [33.091454]
 [33.091454]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.87799835205078



action possibilites: [-1] 
expected returns: [[63.26316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 29.772537231445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.48805 ]
 [47.131897]
 [63.436783]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.263160705566406






Player: 1 
cards in hand: [29.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  8.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [ 8. 11.  3.  0.  0.  3.  0. 11. 16.  3.  0.  3.  3. 14.  0.  6. 16.  0.
  6.  3. 10.  6.  0.  0. 29.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[31.86457 ]
 [29.276245]
 [29.276245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 10.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3  8] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.43678283691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.61266 ]
 [18.341764]
 [31.416912]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3. 10.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3  8] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.86457061767578



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3
  6  0 11  8  0  3  6  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 29. 10. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 29. 10. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 29. 10. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 29. 10. 11.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 11. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 10. 11.] 
expected returns: [[11.784329]
 [12.04647 ]
 [17.003765]
 [17.12096 ]
 [12.04647 ]
 [17.003765]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 10. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.416908264160156



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[33.98973 ]
 [33.12313 ]
 [38.020714]
 [38.020714]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.416802406311035



action possibilites: [-1] 
expected returns: [[20.107206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10. 10. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 36.37802505493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.2     ]
 [ 7.532056]
 [20.324253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 11. 11.  8. 25. 10.  0. 11.  0.  0.  0.  1. 29. 11.
  3. 11. 10.  3.  0.  3. 10. 10. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.107206344604492






Player: 1 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[ 6.5026016]
 [ 6.1112328]
 [12.62123  ]
 [ 6.1112328]
 [ 6.1112328]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  1. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.324260711669922



action possibilites: [-1] 
expected returns: [[9.780082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1. 10.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 9.16369342803955





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 5.1148777]
 [ 9.933544 ]
 [-3.8122017]
 [11.049945 ]
 [ 9.69814  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1. 10.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 24. 30.  8.  7.  8.  0.  7.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.780081748962402



buy possibilites: [-1] 
expected returns: [[9.128094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1. 10.] 
cards in discard: [1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.049939155578613






Player: 1 
cards in hand: [14.  6.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  6.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  8.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  6.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  8.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  6.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  1.  3.  0.  8.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[33.900234]
 [31.03859 ]
 [33.582516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  8.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.128093719482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[26.71006 ]
 [34.489285]
 [32.059227]
 [17.269934]
 [33.1848  ]
 [33.755825]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  8.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.900245666503906



buy possibilites: [-1] 
expected returns: [[27.608822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  8.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0 -10   0   0  54   0] 
sum of rewards: -51 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 34.489280700683594






Player: 1 
cards in hand: [11.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  8.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 10. 10.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 10. 10.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 11. 11. 10. 10.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1] -> size -> 36 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10. 10.] 
expected returns: [[11.498418]
 [16.285576]
 [16.285576]
 [16.285576]
 [10.366907]
 [10.366907]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10. 10.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.608821868896484



action possibilites: [-1] 
expected returns: [[37.81251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 13.103341102600098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.62632 ]
 [23.654472]
 [38.05282 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.8125114440918






Player: 1 
cards in hand: [ 0. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10. 29.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10. 29.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  3. 10. 29.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[ 5.4506598]
 [ 5.4484005]
 [12.048983 ]
 [ 5.4484005]
 [12.270671 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10. 29.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 38.05281448364258



action possibilites: [-1. 10. 11.] 
expected returns: [[27.401224]
 [26.160004]
 [31.967697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.571833610534668



action possibilites: [-1] 
expected returns: [[50.559227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -30   0   0  27   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 28.874717712402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.33613 ]
 [37.318687]
 [50.17237 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.559226989746094






Player: 1 
cards in hand: [ 0.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  3.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  3.] 
cards in discard: [ 0.  1. 16.  0.  0.  0.  0.  0.  3. 29.  3.  0.  6.  0. 14.  6.  8.  6.
  0.  1. 11.  3. 11.  8.  0.  8.  0. 29.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[43.349426]
 [48.945095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.17236328125



action possibilites: [-1] 
expected returns: [[24.117165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: -88 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 44.80838394165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[20.024588 ]
 [25.205418 ]
 [23.661898 ]
 [13.5773115]
 [24.329895 ]
 [23.984701 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.117164611816406



buy possibilites: [-1] 
expected returns: [[30.264015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: -71 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 25.205419540405273






Player: 1 
cards in hand: [ 3.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 25.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 20. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 25.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 20. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0. 25.] 
adversary cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[52.714073]
 [50.188263]
 [58.72798 ]
 [69.63816 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0. 25.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 24. 30.  8.  7.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.264015197753906



action possibilites: [-1] 
expected returns: [[58.832115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  0. 29.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 69.63819122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[50.31736 ]
 [61.298584]
 [57.79155 ]
 [37.747517]
 [59.97845 ]
 [58.8321  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.  0. 29.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 20. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.832115173339844



buy possibilites: [-1] 
expected returns: [[61.551018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.  0. 29.] 
cards in discard: [ 1.  8. 11. 10. 10.  1. 10.  1. 10.  1.  3.  0.  8.  1. 11. 11. 11. 10.
 10. 11. 10.  1. 29. 11.  3. 10.  1.  1. 11.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: -81 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 61.29859924316406






Player: 1 
cards in hand: [14.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6
  0 11  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[5.210369 ]
 [2.5676806]
 [2.5676806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 29.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.55101776123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -2.9364731]
 [  2.9021404]
 [-13.461316 ]
 [  4.2963333]
 [  4.357662 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 29.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.210370063781738



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 29.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11. 25. 10.  8.] 
adversary cards in discard: [ 3. 10.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  8. 29.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11. 25. 10.  8.] 
adversary cards in discard: [ 3. 10.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 25. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.  8.] 
expected returns: [[-0.68885994]
 [ 3.9813664 ]
 [ 8.960477  ]
 [-1.3973081 ]
 [ 0.42283368]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 25. 10.  8.] 
cards in discard: [ 3. 10.  3.  1. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  6.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.3576555252075195



action possibilites: [-1] 
expected returns: [[14.798537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  8. 10.  1.] 
cards in discard: [ 3. 10.  3.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 8.960484504699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[10.481684 ]
 [16.963934 ]
 [14.922935 ]
 [ 1.9662368]
 [15.073134 ]
 [15.932036 ]
 [20.531292 ]
 [ 7.416584 ]
 [13.898835 ]
 [13.32492  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  8. 10.  1.] 
cards in discard: [ 3. 10.  3.  1. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.798537254333496



buy possibilites: [-1] 
expected returns: [[44.5974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  8. 10.  1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 16.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0 128   0] 
sum of rewards: 43 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.531293869018555






Player: 1 
cards in hand: [ 1.  0. 29. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 16.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11
  8  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11. 29.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[27.037457]
 [32.35727 ]
 [32.791843]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 29.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.5974006652832



action possibilites: [-1. 11.] 
expected returns: [[65.522865]
 [69.01389 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 19. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.494098663330078



action possibilites: [-1] 
expected returns: [[89.48513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 18. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 64.85344696044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.51677 ]
 [87.27247 ]
 [71.09501 ]
 [88.503815]
 [88.77954 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 18. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.4851303100586






Player: 1 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1. 11. 10.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 18. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10.  1. 11. 10.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1] -> size -> 43 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[10.306865]
 [ 7.786607]
 [12.442683]
 [ 7.786607]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 11. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.77955627441406



action possibilites: [-1] 
expected returns: [[35.304226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 9.931925773620605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[27.788115]
 [31.79546 ]
 [30.694378]
 [23.15427 ]
 [31.045578]
 [32.692898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 17. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.30422592163086






Player: 1 
cards in hand: [0. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11. 11. 10.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 17. 30. 24. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11. 11. 10.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0. 11. 11. 10.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[ 7.5221176]
 [ 7.246546 ]
 [12.19234  ]
 [12.19234  ]
 [ 7.246546 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 11. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.692901611328125



action possibilites: [-1] 
expected returns: [[22.8062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 11. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 9.612446784973145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.22131 ]
 [12.072334]
 [22.806198]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0. 11. 10.  3.] 
adversary cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.80620002746582






Player: 1 
cards in hand: [ 1.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 10.  3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  3.] 
cards in discard: [ 0.  3.  0.  0.  3. 16.  6.  0.  8. 14.  0.  0.  3.  3.  8. 29.  6.  0.
 16.  1. 29.  0.  0.  3.  6.  0.  3.  3.  0.  8.  6.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.0904503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.80620002746582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 2.8057678 ]
 [ 9.934865  ]
 [ 0.60549045]
 [ 7.69703   ]
 [-4.0170875 ]
 [ 2.9314167 ]
 [-5.9638786 ]
 [ 7.8669386 ]
 [ 8.883153  ]
 [21.073425  ]
 [14.069968  ]
 [-0.3313725 ]
 [ 5.7547493 ]
 [-1.3056598 ]
 [ 6.7709618 ]
 [ 7.090459  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 8 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.090450286865234



buy possibilites: [-1] 
expected returns: [[6.3642035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    62.5    0. ] 
sum of rewards: -82.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 21.073415756225586






Player: 1 
cards in hand: [ 3.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.  1.  1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 16. 30. 23. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.  1.  1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 22. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.  1.  1.] 
adversary cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 8.837265 ]
 [15.5911665]
 [ 9.23526  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  1.  1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 16. 30. 22. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 14.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.364203453063965



action possibilites: [-1] 
expected returns: [[43.556732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 22. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 14.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 12.229540824890137





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[35.0515  ]
 [42.740322]
 [40.462894]
 [28.013947]
 [25.736513]
 [40.535767]
 [41.620613]
 [55.300404]
 [47.798584]
 [32.305634]
 [38.909588]
 [31.220776]
 [39.99445 ]
 [43.556732]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 15. 30. 22. 30.  8.  5.  8.  0.  5.  8.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 14.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.556732177734375



buy possibilites: [-1] 
expected returns: [[67.112114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  1.] 
cards in discard: [ 3. 10.  3.  1. 10. 29. 25.  1. 11. 10.  8. 10.  1.  0. 29.  1. 29. 11.
  0.  3.  1. 11.  0. 10.  1. 10.  1. 11. 10.  0. 11. 10. 25.  1.  0.  1.
  0.  1.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 14.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -130    0    0
  250    0] 
sum of rewards: 75 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 55.30040740966797






Player: 1 
cards in hand: [ 0.  6.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 14.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 15. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25] -> size -> 48 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  3. 14.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 15. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25] -> size -> 48 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  3. 14.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 15. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25] -> size -> 48 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[12.061623]
 [14.1198  ]
 [18.69436 ]
 [18.69436 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 15. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.11211395263672



action possibilites: [-1] 
expected returns: [[29.761211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 15.162611961364746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.870356]
 [13.127601]
 [29.69738 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.761211395263672






Player: 1 
cards in hand: [0. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  0. 25.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  0. 25.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  0. 25.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[38.550133]
 [45.68583 ]
 [53.941566]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  0. 25.] 
cards in discard: [ 1. 11.  3.  3.  8. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  5.  8.  0.  5.  7.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14] -> size -> 46 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.6973876953125



action possibilites: [-1] 
expected returns: [[48.789497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  0.  1.  0.] 
cards in discard: [ 1. 11.  3.  3.  8. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  4.  8.  0.  5.  7.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6] -> size -> 47 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.94157409667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[42.257233]
 [51.142094]
 [39.460915]
 [48.345783]
 [33.577602]
 [42.462456]
 [30.781277]
 [48.581112]
 [49.906044]
 [65.11477 ]
 [56.43514 ]
 [38.43009 ]
 [45.990017]
 [37.105156]
 [47.314945]
 [48.218464]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.  0.  1.  0.] 
cards in discard: [ 1. 11.  3.  3.  8. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 8 
card supply: [17. 14. 30. 22. 30.  8.  4.  8.  0.  5.  7.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6] -> size -> 47 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.78949737548828



buy possibilites: [-1] 
expected returns: [[63.78579]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.  0.  1.  0.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25.] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 14. 30. 22. 30.  8.  4.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6] -> size -> 47 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.    20.     0.     0.     0.
    0.  -150.     0.     0.    62.5    0. ] 
sum of rewards: -132.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 65.11480712890625






Player: 1 
cards in hand: [16.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  4.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  0.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25] -> size -> 50 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  3.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  0.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25] -> size -> 50 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 14. 30. 22. 30.  8.  3.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 11.  0.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25] -> size -> 50 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[56.266594]
 [60.07926 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.  1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 14. 30. 22. 30.  8.  3.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.785789489746094



action possibilites: [-1] 
expected returns: [[51.61031]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 55.80854797363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[44.32062 ]
 [51.335   ]
 [42.1806  ]
 [49.194965]
 [37.75996 ]
 [35.62395 ]
 [49.340096]
 [50.4009  ]
 [63.00193 ]
 [55.909866]
 [41.695946]
 [47.649506]
 [40.635143]
 [48.710308]
 [51.42931 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  6.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.61030960083008



buy possibilites: [-1] 
expected returns: [[3.6561716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.    20.     0.     0.     0.
    0.  -170.     0.     0.    62.5    0. ] 
sum of rewards: -92.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.00193786621094






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 11. 29. 11.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25] -> size -> 52 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 11. 29. 11.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25] -> size -> 52 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[38.770973]
 [42.772453]
 [43.394722]
 [42.772453]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 29. 11.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.6561715602874756



action possibilites: [-1. 11. 11.] 
expected returns: [[47.53142]
 [51.12802]
 [51.12802]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 13. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.72565460205078



action possibilites: [-1] 
expected returns: [[51.8537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 12. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 47.56859588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[44.130367]
 [50.067345]
 [48.395416]
 [37.269993]
 [49.087234]
 [51.853683]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 12. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.85369873046875






Player: 1 
cards in hand: [ 0. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  1. 25. 10.  0.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 12. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  1. 25. 10.  0.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[61.2929  ]
 [69.67814 ]
 [58.097263]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25. 10.  0.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  3.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.85369873046875



action possibilites: [-1] 
expected returns: [[20.041101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 10.  0. 10.  3.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 69.67815399169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[14.205764]
 [21.816662]
 [19.169792]
 [ 9.673299]
 [ 8.579455]
 [19.362587]
 [20.604727]
 [35.227493]
 [27.003237]
 [11.997459]
 [17.211187]
 [11.398668]
 [18.272104]
 [20.041088]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 10.  0. 10.  3.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  5.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.041101455688477



buy possibilites: [-1] 
expected returns: [[13.342992]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 10.  0. 10.  3.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6
  6] -> size -> 49 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -190    0    0
  250    0] 
sum of rewards: 75 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 35.22751235961914






Player: 1 
cards in hand: [0. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 11 10  0 16 29  0  0  3  6 29  3 16  3  6  0 11  8
  0  3  6  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10. 25. 10. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10. 25. 10. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10. 25. 10. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10. 25. 10. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 10.] 
expected returns: [[73.925255]
 [72.015076]
 [89.75581 ]
 [72.015076]
 [72.015076]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 25. 10. 10.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 12. 30. 22. 30.  8.  2.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.342991828918457



action possibilites: [-1] 
expected returns: [[14.829572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10. 10. 29.  8.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.7558364868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.0408   ]
 [15.814403 ]
 [ 4.8064823]
 [16.738798 ]
 [14.829579 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10. 10. 29.  8.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  5.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.829571723937988



buy possibilites: [-1] 
expected returns: [[3.4008796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10. 10. 29.  8.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -200    0    0
   16    0] 
sum of rewards: -169 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 16.73879623413086






Player: 1 
cards in hand: [ 0. 29.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29.  1. 10. 11.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29.  1. 10. 11.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6] -> size -> 48 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29.  1. 10. 11.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  0.  0.  6.  3.  3. 14. 14.  0.  0.  0.  8.  1.
  6.  6. 11. 16.  3.  0.  0.  1.  3.  0.  0.  3.  0. 16.  0.  0.  6.  6.
  0.  8.  0.  6.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29.  1. 10. 11.  1.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [29.  1. 10. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[4.4247427]
 [9.209516 ]
 [2.3872564]
 [8.78478  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 10. 11.  1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.4008796215057373



action possibilites: [-1.] 
expected returns: [[10.422204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.335331916809082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 5.386882  ]
 [11.789924  ]
 [ 3.8604157 ]
 [ 9.840979  ]
 [ 0.7943332 ]
 [-0.61129284]
 [ 9.935027  ]
 [10.791612  ]
 [22.53834   ]
 [15.6702795 ]
 [ 3.3319247 ]
 [ 8.276775  ]
 [ 2.749942  ]
 [ 9.133224  ]
 [10.422194  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8] -> size -> 55 
action values: 0 
buys: 1 
player value: 7 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  4.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.42220401763916



buy possibilites: [-1] 
expected returns: [[7.0613165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.    20.     0.     0.     0.
    0.  -210.     0.     0.    62.5    0. ] 
sum of rewards: -102.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 22.538349151611328






Player: 1 
cards in hand: [6. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  1.  0. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25] -> size -> 56 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  1.  0. 10.] 
adversary cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25] -> size -> 56 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 10.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[27.510437]
 [32.603428]
 [26.236595]
 [26.236595]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.  0. 10.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 12. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  6. 29.] 
adversary cards in discard: [6. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.06131649017334



action possibilites: [-1] 
expected returns: [[4.646018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 11. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  6. 29.] 
adversary cards in discard: [6. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: -148 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 28.95629119873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-0.5484569]
 [ 5.6095915]
 [ 3.5274384]
 [-6.787942 ]
 [ 4.446744 ]
 [ 4.6460295]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 11. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  6. 29.] 
adversary cards in discard: [6. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.646018028259277



buy possibilites: [-1] 
expected returns: [[12.7123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 10.] 
cards in discard: [ 1. 11.  3.  3.  8. 11. 25. 25.  1. 11.  1.  0.  1.  0.  1. 25. 11.  0.
  1.  0.  1.  0. 10.  1. 29. 11.  1. 11. 25. 25.  1.  1. 10.  0. 10.  3.
  8. 25.  1. 10. 10. 10. 29.  8. 10. 11. 25. 29.  1.  1.  1.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  6. 29.] 
adversary cards in discard: [6. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -230    0    0
   54    0] 
sum of rewards: -131 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 5.609589576721191






Player: 1 
cards in hand: [ 3.  6. 29.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  6. 29.] 
cards in discard: [6. 0. 6. 6. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 10.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  1.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[7.194706]
 [4.520152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.712300300598145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-0.5416515]
 [ 5.302843 ]
 [-2.2947419]
 [ 3.4625266]
 [-6.035288 ]
 [-7.78578  ]
 [ 3.578862 ]
 [ 4.4119596]
 [14.505309 ]
 [ 8.683082 ]
 [-2.9509938]
 [ 1.9740617]
 [-3.7348163]
 [ 2.7581303]
 [ 4.52849  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1] -> size -> 58 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  3.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.194701194763184



buy possibilites: [-1] 
expected returns: [[20.877346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.  3.] 
cards in discard: [25.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -240.     0.     0.    62.5    0. ] 
sum of rewards: -152.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 14.505305290222168






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  4.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[31.96806 ]
 [29.558002]
 [37.27026 ]
 [29.558002]
 [37.78241 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  1. 29.] 
cards in discard: [25.  1. 10.  1.  1.  3.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.87734603881836



action possibilites: [-1. 10. 11.] 
expected returns: [[10.010018 ]
 [ 7.9323053]
 [16.995651 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25] -> size -> 59 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 10. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.025604248046875



action possibilites: [-1] 
expected returns: [[58.977516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [15.  9. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -250    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 11.619279861450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[53.3276  ]
 [60.59488 ]
 [58.334965]
 [45.06864 ]
 [59.50546 ]
 [58.97752 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [15.  9. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.977516174316406



buy possibilites: [-1] 
expected returns: [[54.562843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -260    0    0
   54    0] 
sum of rewards: -141 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 60.59489440917969






Player: 1 
cards in hand: [10.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  3.  0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 3.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [15.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 3.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [15.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 3.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [14.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  3. 11.  1. 29.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[19.958736]
 [25.084435]
 [25.084435]
 [25.293612]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  1. 29.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.562843322753906



action possibilites: [-1. 11. 11.] 
expected returns: [[60.0554  ]
 [64.392265]
 [64.392265]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [14.  8. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.170867919921875



action possibilites: [-1] 
expected returns: [[99.37292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [14.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -270    0    0
   27    0] 
sum of rewards: -178 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.93152618408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[92.96304 ]
 [99.30747 ]
 [97.26531 ]
 [85.71624 ]
 [98.440796]
 [99.37295 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [14.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.37291717529297






Player: 1 
cards in hand: [0. 8. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 8.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6
  3  8  0  1  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6
  0  8  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  1. 25.  1.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6  3
  0  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6  0  8  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [14.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  1. 25.  1.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6  3
  0  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6  0  8  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [14.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  1. 25.  1.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6  3
  0  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6  0  8  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [13.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 25.  1. 25.  1.] 
adversary cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[18.284744]
 [27.495243]
 [27.495243]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1. 25.  1.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 22. 30.  8.  1.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6  3
  0  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6  0  8  0
  0] -> size -> 49 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.37291717529297



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 5 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 3 
Witch: 8 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  1. 25.  1.  1. 10.] 
cards in discard: [25.  1. 10.  1.  1.  3. 10. 11.  1.  1. 29. 11. 10.  1.  3.  1.  1. 29.
 11. 11.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10 11 10 11 11 10 29 10 11 10 10
 11 11 10 10 10 11  8  1  1  1  8  1  1  1  1  1  1 29  1  1  1 25  1 25
  1 25  1 25  1 25  8 25  1  1 25  1  1  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  7. 30. 22. 30.  8.  0.  8.  0.  3.  2.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 6.  0.  6.  6.  3.  6. 29. 29.  3.  6.  3.  8.  0.  3.  0.  3.  0.  0.
 10.  3.  1.  3.  0.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3 14 11 10  0 16 29  0  0  3 29  3 16  3  6  0 11  0  3  6  3
  0  3  0  1  8  0  6  0  6  0  3  0  0  3  0 14  6  6  6  0  6  0  8  0
  0  6] -> size -> 50 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000045 

action type: take_action - action 25.0
Learning step: 120000.6953125
desired expected reward: 120028.1875



