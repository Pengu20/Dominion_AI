 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.24201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -300        0        0       40        0
        0        0        0     -130        0        0        0        0] 
sum of rewards: -3000395 

action type: gain_card_n - action 0
Learning step: -120015.796875
desired expected reward: -120015.859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.352554]
 [115.7779  ]
 [110.211365]
 [ 92.19507 ]
 [114.51084 ]
 [117.94451 ]
 [114.972664]
 [121.1503  ]
 [100.18685 ]
 [109.433   ]
 [108.30598 ]
 [110.26104 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.37736511230469



buy possibilites: [-1] 
expected returns: [[98.38459]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 121.15026092529297






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.74157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.38459014892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[84.58551 ]
 [92.708244]
 [87.669556]
 [70.988144]
 [94.89812 ]
 [91.8199  ]
 [86.78058 ]
 [89.819084]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.05331420898438



buy possibilites: [-1] 
expected returns: [[107.30474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.8980941772461






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  1.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  1.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.2196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0. 14.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.30474090576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[87.82363 ]
 [96.760925]
 [91.46501 ]
 [72.902245]
 [99.29587 ]
 [95.65447 ]
 [90.35857 ]
 [95.96295 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0. 14.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.31485748291016



buy possibilites: [-1] 
expected returns: [[88.36479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0. 14.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 99.29582977294922






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0. 14.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0. 14.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0. 14.  1.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[109.779335]
 [119.35081 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.36479187011719



action possibilites: [-1.] 
expected returns: [[122.91834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 120.34259033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[117.2244  ]
 [126.32931 ]
 [120.80939 ]
 [107.22273 ]
 [101.70282 ]
 [124.837105]
 [128.85767 ]
 [125.27268 ]
 [142.00458 ]
 [131.98865 ]
 [109.75112 ]
 [118.42044 ]
 [119.752785]
 [109.31553 ]
 [118.85603 ]
 [124.28771 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 122.91834259033203



buy possibilites: [-1] 
expected returns: [[121.34176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 142.00457763671875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [16.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[149.0638 ]
 [156.55385]
 [153.58194]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.34175872802734



action possibilites: [-1. 11.] 
expected returns: [[124.62357]
 [128.819  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 157.72824096679688



action possibilites: [-1] 
expected returns: [[116.7386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.54112243652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.76005 ]
 [117.26622 ]
 [112.11174 ]
 [ 93.320816]
 [119.63376 ]
 [116.28206 ]
 [111.12757 ]
 [115.35893 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  7. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.73860168457031



buy possibilites: [-1] 
expected returns: [[108.96694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 119.63375091552734






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [11.  0. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [11.  0. 16.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [11.  0. 16.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 94.64327 ]
 [110.110954]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.9669418334961



action possibilites: [-1] 
expected returns: [[112.776405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.87117767333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.87015 ]
 [118.20924 ]
 [113.099365]
 [ 96.423325]
 [116.74277 ]
 [120.67577 ]
 [117.14893 ]
 [123.606316]
 [103.43222 ]
 [112.12936 ]
 [111.41111 ]
 [117.21204 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.77640533447266



buy possibilites: [-1] 
expected returns: [[117.36192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.6063003540039






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 6. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[129.041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.36192321777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[123.155464]
 [132.2613  ]
 [126.77935 ]
 [109.35463 ]
 [134.81058 ]
 [131.18668 ]
 [125.70472 ]
 [130.57202 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  6. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 129.556884765625



buy possibilites: [-1] 
expected returns: [[113.00649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 134.81056213378906






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[161.39351]
 [166.26051]
 [166.26051]
 [169.26343]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 29.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 16.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.0064926147461



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[141.41658]
 [144.81346]
 [144.81346]
 [157.1224 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 25.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  5. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 16.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.0443115234375



action possibilites: [-1] 
expected returns: [[167.94783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0. 29.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  8.  9.  5. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 16.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.1223907470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[158.74448]
 [169.12625]
 [163.05391]
 [141.02914]
 [167.34042]
 [172.0879 ]
 [167.81958]
 [175.48631]
 [150.27303]
 [161.74721]
 [160.87852]
 [168.82825]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.  0. 29.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  8.  9.  5. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 16.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.9478302001953



buy possibilites: [-1] 
expected returns: [[144.31079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.  0. 29.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 16.] 
adversary cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 175.486328125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  1. 16.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16 11  0  1  6 10 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 6. 10.  0. 11.  0.  3.  0. 29.  0.  0.  0.  0.  1.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[143.06076]
 [146.83177]
 [146.83177]
 [139.35083]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.310791015625



action possibilites: [-1] 
expected returns: [[145.51355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 148.6868438720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[138.59528]
 [125.13471]
 [145.80856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.5135498046875






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1  6 10 29  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5. 10.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5.  9.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5.  9.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29.  0.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[118.43702]
 [126.05778]
 [136.5331 ]
 [126.05778]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 29.  0.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  8.  9.  5.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0. 10.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.80856323242188



action possibilites: [-1] 
expected returns: [[103.3698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  0. 11.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  5.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0. 10.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.5528564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.940094]
 [107.95666 ]
 [102.50846 ]
 [ 84.779335]
 [110.46534 ]
 [106.89698 ]
 [101.44875 ]
 [106.20789 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0.  0. 11.] 
cards in discard: [10. 11. 11. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  5.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0. 10.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.36979675292969



buy possibilites: [-1] 
expected returns: [[132.6846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0.  0. 11.] 
cards in discard: [10. 11. 11. 10.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0. 10.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.4653091430664






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 10.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[138.16095]
 [145.13968]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.68460083007812



action possibilites: [-1.] 
expected returns: [[115.98568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 145.58175659179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.2131  ]
 [116.27934 ]
 [112.148735]
 [ 98.04258 ]
 [115.05745 ]
 [118.46573 ]
 [115.37389 ]
 [121.14197 ]
 [103.88332 ]
 [111.243286]
 [110.673325]
 [116.50833 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.98567962646484



buy possibilites: [-1] 
expected returns: [[148.14558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11. 10.  3.  0. 11. 25. 29.  0. 29.  0.  0. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 121.14196014404297






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  8. 16.  0.  3.  0.  6. 14. 10. 11.  0.  3.  0.  6. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[129.66948]
 [135.26297]
 [135.26297]
 [133.02705]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.1455841064453



action possibilites: [-1. 29. 11.] 
expected returns: [[123.33492]
 [128.42722]
 [126.37148]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 133.71168518066406



action possibilites: [-1. 11. 11.] 
expected returns: [[124.208824]
 [127.88981 ]
 [127.88981 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.42723083496094



action possibilites: [-1] 
expected returns: [[149.43533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.1502685546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[146.32397]
 [153.56856]
 [148.9789 ]
 [135.19832]
 [152.27327]
 [155.7283 ]
 [152.6668 ]
 [158.31677]
 [140.97714]
 [148.16385]
 [147.52255]
 [152.22702]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  5.  8. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.43533325195312



buy possibilites: [-1] 
expected returns: [[134.12216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 158.3167724609375






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [15.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  8.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 29.  0.  3.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[137.67465]
 [141.32982]
 [133.13757]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.12216186523438



action possibilites: [-1. 10.] 
expected returns: [[126.225136]
 [120.56144 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.41104125976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.540306]
 [130.38971 ]
 [124.94128 ]
 [107.35921 ]
 [128.83015 ]
 [132.94121 ]
 [129.26662 ]
 [135.98474 ]
 [114.71286 ]
 [123.86242 ]
 [123.074974]
 [129.45999 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  4.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.22513580322266



buy possibilites: [-1] 
expected returns: [[122.24212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 135.98475646972656






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 30. 30.  8.  7.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8.  7.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11. 11. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[169.97113]
 [170.53223]
 [170.53223]
 [178.06442]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 25.  3.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  7.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  1.  0.  3. 16.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.24211883544922



action possibilites: [-1] 
expected returns: [[143.0028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  1.  0.  3. 16.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 178.06442260742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[139.04749]
 [140.81628]
 [133.33913]
 [142.68811]
 [143.49948]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0. 11. 29. 29.  0.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  1.  0.  3. 16.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.0028076171875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [14.  1.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  3. 16.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3. 16.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  3. 16.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 10.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[132.84491]
 [136.6814 ]
 [129.66124]
 [139.11606]
 [136.6814 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  8.  8.  6.  0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.49949645996094



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[126.35796]
 [128.54599]
 [122.54062]
 [128.54599]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  8.  8.  6.  0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.80780029296875



action possibilites: [-1] 
expected returns: [[126.37975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8.  8.  6.  0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.14279174804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[120.28872 ]
 [122.341194]
 [111.616974]
 [125.06971 ]
 [126.2602  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8.  8.  6.  0.] 
adversary cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.37975311279297






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11.  8.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  6.  0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  6  1  8  8  6 14 15  8
  1  6 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.] 
cards in discard: [ 8. 15.  0. 29.  0.  3.  1.  1.  0.  0.  6.  0.  6. 10. 14.  1.  0.  3.
 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[130.99889]
 [135.55682]
 [125.54551]
 [132.96158]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 11.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.26020050048828



action possibilites: [-1. 10. 11.] 
expected returns: [[110.64955]
 [105.43276]
 [114.11548]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  0.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.55682373046875



action possibilites: [-1] 
expected returns: [[145.21472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 118.1036148071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[140.00742]
 [146.86671]
 [142.72627]
 [128.57158]
 [145.66026]
 [148.89761]
 [145.9967 ]
 [151.29666]
 [134.51755]
 [141.91   ]
 [141.28381]
 [146.13107]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  3.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.2147216796875



buy possibilites: [-1] 
expected returns: [[181.05856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 151.29666137695312






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[207.733  ]
 [210.31401]
 [210.31401]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 29.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.05856323242188



action possibilites: [-1. 29. 29.] 
expected returns: [[213.125  ]
 [215.10648]
 [215.10648]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 210.31402587890625



action possibilites: [-1. 29. 29.] 
expected returns: [[212.61412]
 [216.36266]
 [216.36266]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 215.10647583007812



action possibilites: [-1. 29. 11.] 
expected returns: [[228.04126]
 [230.79485]
 [229.00313]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 11.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 216.36264038085938



action possibilites: [-1. 11.] 
expected returns: [[217.79025]
 [219.12704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 230.79483032226562



action possibilites: [-1] 
expected returns: [[206.1817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 223.14730834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[202.71785]
 [209.82445]
 [198.63763]
 [205.56122]
 [195.21713]
 [191.91655]
 [208.58382]
 [212.05345]
 [208.90945]
 [222.86449]
 [214.6751 ]
 [197.19176]
 [203.81236]
 [204.69244]
 [196.8888 ]
 [204.11533]
 [209.4829 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  9.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 206.18170166015625



buy possibilites: [-1] 
expected returns: [[241.53603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [10. 29. 11. 10.  0. 11.  3. 10. 29. 29. 11.  0.  0. 10.  0. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 11.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   60.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 217.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 222.864501953125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 11.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  8. 11.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 30. 30.  8.  6.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  8. 11.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 30. 30.  8.  6.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 25. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 11.] 
expected returns: [[139.15489]
 [138.93097]
 [150.74869]
 [131.7384 ]
 [138.93097]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  6.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  1.  8.  1. 16.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 241.53602600097656



action possibilites: [-1] 
expected returns: [[154.90805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  5.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  1.  8.  1. 16.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.7698974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[148.60434]
 [136.4344 ]
 [155.26747]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 30. 30.  8.  5.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  1.  8.  1. 16.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.90805053710938






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 6.  1.  8.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  8.  1. 16.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  8  6 14 15  8  1
  6 10 10  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  5.  9.  4.  7.  8.  2.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 1.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  5.  9.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 30. 30.  8.  5.  9.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  5.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[188.06818]
 [191.75702]
 [198.23851]
 [184.04492]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  5.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 15.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.26748657226562



action possibilites: [-1] 
expected returns: [[173.44171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 10. 11.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 15.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 198.23849487304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[167.79898]
 [170.8171 ]
 [156.5564 ]
 [174.00967]
 [175.44598]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 10. 11.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 15.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 173.44171142578125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 15.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 29. 10.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 15.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 29. 10.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 15.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 29. 10.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[191.58412]
 [194.52652]
 [194.52652]
 [186.29309]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29. 10.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.44598388671875



action possibilites: [-1. 29. 11.] 
expected returns: [[231.69228]
 [232.80457]
 [231.12762]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 190.677001953125



action possibilites: [-1. 11.] 
expected returns: [[169.77129]
 [172.30014]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 229.41680908203125



action possibilites: [-1] 
expected returns: [[147.40536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 176.12425231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[140.27028]
 [147.35765]
 [143.33969]
 [129.65192]
 [146.04868]
 [149.53453]
 [146.37833]
 [151.76292]
 [135.15137]
 [141.89488]
 [148.91093]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.40536499023438



buy possibilites: [-1] 
expected returns: [[157.91418]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 29. 14.  3. 10.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 151.7628936767578






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 6. 29. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 14.  3. 10.] 
cards in discard: [10. 10.  0.  0.  0.  3.  0.  0.  0.  0.  8.  8. 11.  6. 29. 16. 16.  6.
  1.  1.  6. 10.  1.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0. 10.  3.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 29. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 14.  3.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0. 10.  3.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 14.  3.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10] -> size -> 32 
action values: 2 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0. 10.  3.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 14.  3.  8.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0. 10.  3.] 
adversary cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[166.76901]
 [160.59378]
 [166.33481]
 [160.59378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  3.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 157.9141845703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.13306]
 [152.0205 ]
 [169.09584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  3.] 
cards in discard: [25. 11. 10. 11.  0. 29. 29. 25.  0. 29. 10.  0. 10. 11. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 166.76901245117188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 30. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[179.3649 ]
 [183.63647]
 [183.63647]
 [183.63647]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 169.0958251953125



action possibilites: [-1. 11.] 
expected returns: [[157.59485]
 [160.23343]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 179.99746704101562



action possibilites: [-1] 
expected returns: [[131.1059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 157.8649139404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.41334]
 [127.89254]
 [115.43222]
 [130.65202]
 [131.30193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.10589599609375






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  0.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  0. 29. 11. 25.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  0.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  0. 29. 11. 25.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 25.] 
expected returns: [[154.0141 ]
 [158.14526]
 [158.14526]
 [155.50064]
 [167.0827 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 11. 25.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  4.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.3019256591797



action possibilites: [-1] 
expected returns: [[212.9843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 11. 10. 29.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 167.0826873779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[207.03992]
 [197.05392]
 [213.65985]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 11. 10. 29.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3  6] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 212.9842987060547






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 15.  0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  1 10 29  1  8  6 14 15  8  1  6
 10 10  0  6 29 16  6 10  0  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  0. 10.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  0. 10.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  0. 10.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  0. 10.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[202.15369]
 [198.64864]
 [206.44934]
 [198.64864]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  0. 10.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  6.  1.  0. 10.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 213.65985107421875



action possibilites: [-1. 10. 11.] 
expected returns: [[176.2157 ]
 [170.85081]
 [177.13943]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  6.  1.  0. 10.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 202.66781616210938



action possibilites: [-1] 
expected returns: [[161.29889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  6.  1.  0. 10.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 175.26361083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.87094]
 [144.60208]
 [161.41986]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29.  6.  1.  0. 10.] 
adversary cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.29888916015625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [29.  6.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  1.  0. 10.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 24. 30. 29. 30.  8.  3.  8.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0. 10.  6. 29. 14.  3.  8.  3.  0.  0. 11.  6.  0.  6.  0. 16.  0.  0.
  6.  0.  8.  0.  6. 10. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11.  3. 11.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[235.30573]
 [230.98901]
 [237.63144]
 [237.63144]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3. 11.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.4198455810547



action possibilites: [-1] 
expected returns: [[198.04578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 235.72181701660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[192.0163 ]
 [183.17603]
 [197.86725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 11.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 23. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 16.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 198.0457763671875






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 25. 15.  0.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 25. 15.  0.] 
adversary cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 25. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 15.] 
expected returns: [[157.3947 ]
 [154.33676]
 [169.29648]
 [153.84808]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25. 15.  0.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  3.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 197.86724853515625



action possibilites: [-1] 
expected returns: [[146.05783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  0.  0. 29.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 169.29647827148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[143.87285]
 [147.37877]
 [145.30743]
 [139.47765]
 [148.61942]
 [146.79985]
 [148.13329]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.  0. 29.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  4.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.05783081054688



buy possibilites: [-1] 
expected returns: [[186.77017]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  0.  0. 29.] 
cards in discard: [29. 29.  1. 29. 11.  3.  0. 25. 29.  0. 29. 11. 10. 29.  0. 10.  1. 29.
 11.  3. 10.  1. 11. 10.  0.  3. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  6.  3. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 148.61941528320312






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  7.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 10.  0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [11.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[117.391  ]
 [120.01409]
 [122.32472]
 [112.99856]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.77017211914062



action possibilites: [-1. 29.] 
expected returns: [[125.681114]
 [126.94352 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [11. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 117.99544525146484



action possibilites: [-1.] 
expected returns: [[123.12504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 10.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 117.14295196533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[116.33123]
 [122.98444]
 [119.09535]
 [105.20496]
 [124.92481]
 [122.16074]
 [122.96674]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 10.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  3.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.12503814697266



buy possibilites: [-1] 
expected returns: [[104.81035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 10.  0.  0. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 124.9248275756836






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 10.  0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 29. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  6.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 29. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 29. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 29. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 29. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 29. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 1. 29.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[175.3804 ]
 [179.82092]
 [179.82092]
 [177.42722]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 29. 11.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.  0.  1.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.81034851074219



action possibilites: [-1. 29. 29.] 
expected returns: [[143.21716]
 [145.37155]
 [145.37155]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.  0.  1.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 175.3114013671875



action possibilites: [-1.] 
expected returns: [[135.23323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.  0.  1.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 142.04714965820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.99583]
 [131.08554]
 [117.00833]
 [134.54231]
 [135.32777]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 1 
buys: 1 
player value: 2 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 11. 16.  0.  1.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 135.2332305908203






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 16.  0.  1.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  2.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  1.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  1.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  1.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  1.  6.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  1.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 11.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[190.39278]
 [185.93033]
 [185.2829 ]
 [192.92088]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 15. 11.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  2.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 16.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11  8] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 135.32777404785156



action possibilites: [-1] 
expected returns: [[203.69322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 15.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  2.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 16.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11  8] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 190.9397430419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[197.78027]
 [200.34273]
 [187.5451 ]
 [203.17451]
 [203.92029]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 15.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 22. 30. 28. 30.  8.  2.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 16.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11  8] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 203.69322204589844






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  0. 16.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0
  6 29 16  6 10  0  3  6  0 16  6  8  3 11  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  2.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  1. 25.  3.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1. 11.  0.
  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0  6
 29 16  6 10  0  3  6  0 16  6  8  3 11  8  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  1.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  1. 25.  3.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1. 11.  0.
  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0  6
 29 16  6 10  0  3  6  0 16  6  8  3 11  8  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 22. 30. 28. 30.  8.  1.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 29.  1. 25.  3.] 
adversary cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1. 11.  0.
  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 29.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[254.03247]
 [257.13995]
 [263.48132]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1. 25.  3.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1. 11.  0.
  0. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  1.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [14. 29.  0.  1. 29.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.  6. 16.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0  6
 29 16  6 10  0  3  6  0 16  6  8  3 11  8  6] -> size -> 39 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 203.9202880859375



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 2 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 29.  1.  3. 10.  0.] 
cards in discard: [11. 10.  0.  0. 11. 29. 29.  0.  1. 11. 29.  1. 29. 29.  3.  1. 11.  0.
  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 29 11 29 10 11 29 10 29
 29 10 10 29 10 25 15 29  1  1  1 11 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 30.  8.  0.  7.  1.  5.  8.  0.  8. 10.  0. 10.  8.] 
adversary cards in hand: [14. 29.  0.  1. 29.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.  6.  8.  0.  6.  3. 10.  0.  3. 10. 10.  6.  0.  0.
  6.  0. 11.  8. 11.  3. 16.  0.  1.  6. 16.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16 11  0 10 29  1  8  6 14  8  1  6 10 10  0  6
 29 16  6 10  0  3  6  0 16  6  8  3 11  8  6  6] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000165 

action type: take_action - action 25.0
Learning step: 119996.0546875
desired expected reward: 120259.5390625



