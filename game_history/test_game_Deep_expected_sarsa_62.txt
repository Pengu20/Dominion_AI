 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.49183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1
Learning step: -119994.0703125
desired expected reward: -120177.40625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[51.25383 ]
 [67.11856 ]
 [64.99279 ]
 [35.822613]
 [85.77734 ]
 [71.55601 ]
 [69.429184]
 [68.05686 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.5749740600586



buy possibilites: [-1] 
expected returns: [[74.27391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.77733612060547






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.903015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.27391052246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 65.96809 ]
 [ 81.69121 ]
 [ 79.60125 ]
 [ 49.629395]
 [ 80.172455]
 [100.07108 ]
 [ 86.04975 ]
 [102.208435]
 [ 69.70424 ]
 [ 83.9598  ]
 [ 85.42735 ]
 [ 82.62334 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.11553192138672



buy possibilites: [-1] 
expected returns: [[96.776764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.20841979980469






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 90.47277]
 [111.01732]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.77676391601562



action possibilites: [-1.] 
expected returns: [[86.41077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.1197738647461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 75.75126 ]
 [ 89.579636]
 [ 87.72828 ]
 [ 61.953888]
 [ 88.23957 ]
 [105.63654 ]
 [ 93.43843 ]
 [107.52066 ]
 [ 78.98034 ]
 [ 91.5871  ]
 [ 92.891174]
 [ 90.41709 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.4107666015625



buy possibilites: [-1] 
expected returns: [[96.74249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.52066802978516






Player: 1 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.00664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.74249267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 79.69462 ]
 [ 95.4775  ]
 [ 93.371284]
 [ 63.53302 ]
 [ 93.95711 ]
 [114.14732 ]
 [ 99.86172 ]
 [116.387825]
 [ 83.47745 ]
 [ 97.7555  ]
 [ 99.26032 ]
 [ 96.50308 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.37467956542969



buy possibilites: [-1] 
expected returns: [[96.31287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 116.38783264160156






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 89.41691]
 [105.72308]
 [103.91904]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.3128662109375



action possibilites: [-1. 11.] 
expected returns: [[108.2151 ]
 [123.95889]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.71438598632812



action possibilites: [-1] 
expected returns: [[131.33691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.07197570800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.40687]
 [134.8064 ]
 [133.1544 ]
 [109.54758]
 [149.08392]
 [138.25587]
 [136.60387]
 [135.65274]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.3369140625



buy possibilites: [-1] 
expected returns: [[122.72081]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 149.0839385986328






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[140.3432 ]
 [159.47116]
 [159.47116]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.72080993652344



action possibilites: [-1. 29.] 
expected returns: [[173.3748]
 [193.3353]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 155.78549194335938



action possibilites: [-1.] 
expected returns: [[209.91795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 193.33531188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[199.19954]
 [214.89609]
 [197.14407]
 [212.78253]
 [185.31836]
 [183.28714]
 [213.37375]
 [232.99194]
 [219.29317]
 [249.63855]
 [235.10435]
 [202.90411]
 [212.78171]
 [217.17957]
 [197.14912]
 [218.70111]
 [215.96344]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 209.91795349121094



buy possibilites: [-1] 
expected returns: [[194.02426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 249.6385498046875






Player: 1 
cards in hand: [ 0. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[125.65924]
 [141.25574]
 [141.25574]
 [126.66943]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 194.02426147460938



action possibilites: [-1. 29. 10.] 
expected returns: [[134.4484 ]
 [149.87341]
 [135.44415]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 137.4320831298828



action possibilites: [-1. 10.] 
expected returns: [[167.72473]
 [168.80267]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 149.8734130859375



action possibilites: [-1.] 
expected returns: [[163.12929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 2 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 168.80267333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.85458]
 [166.43227]
 [164.62277]
 [140.67128]
 [138.90681]
 [165.11896]
 [182.56067]
 [170.20695]
 [197.46556]
 [184.45143]
 [156.11261]
 [164.6033 ]
 [168.39641]
 [151.0256 ]
 [169.69032]
 [167.33972]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 163.12928771972656



buy possibilites: [-1] 
expected returns: [[148.02979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 197.46554565429688






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[166.5734 ]
 [196.12357]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.02978515625



action possibilites: [-1] 
expected returns: [[170.61722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.  0.] 
cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 191.70635986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[157.07408]
 [170.59425]
 [168.7869 ]
 [143.04303]
 [169.30174]
 [186.06354]
 [174.35074]
 [187.87749]
 [160.3197 ]
 [172.54337]
 [173.8399 ]
 [171.47708]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.  0.] 
cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6. 10.  8.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 170.61721801757812



buy possibilites: [-1] 
expected returns: [[210.57703]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.  0.] 
cards in discard: [25. 29. 29. 10.  0.  3.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 187.87750244140625






Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  5. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[126.01462]
 [126.95381]
 [141.15222]
 [139.42607]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  5. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 210.5770263671875



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[126.09729 ]
 [127.074936]
 [140.11302 ]
 [153.62234 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  5. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 137.33218383789062



action possibilites: [-1] 
expected returns: [[132.41187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.62234497070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[118.4762 ]
 [129.9589 ]
 [128.33337]
 [106.68914]
 [128.78384]
 [144.69199]
 [133.5082 ]
 [146.41438]
 [121.24202]
 [131.78406]
 [133.03038]
 [130.85066]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.411865234375



buy possibilites: [-1] 
expected returns: [[160.36128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.  0. 29.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 146.41436767578125






Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[145.29868]
 [162.30081]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 160.3612823486328



action possibilites: [-1.] 
expected returns: [[181.77063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 156.18368530273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[170.8583 ]
 [185.34882]
 [183.40508]
 [155.84024]
 [183.9585 ]
 [201.97638]
 [189.38802]
 [203.92686]
 [174.3351 ]
 [187.44421]
 [188.84181]
 [186.30412]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 181.7706298828125



buy possibilites: [-1] 
expected returns: [[179.61227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 203.92684936523438






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  8. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3. 29.] 
adversary cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[61.331512]
 [86.341446]
 [73.64448 ]
 [75.245544]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3. 29.] 
cards in discard: [29. 29. 25.  0. 10.  0. 11.  0. 29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 179.61227416992188



action possibilites: [-1] 
expected returns: [[132.1514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.03030395507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.55445]
 [133.43915]
 [109.61487]
 [138.62547]
 [136.04343]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5. 10.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.15139770507812



buy possibilites: [-1] 
expected returns: [[150.48361]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 29.  0. 29.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 138.62548828125






Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  0.  3. 11.  0.  0.  3.  1. 11.  0.  0.  0.  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[156.11383]
 [172.51498]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.48361206054688



action possibilites: [-1. 10.] 
expected returns: [[160.78592]
 [161.7702 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 167.91017150878906



action possibilites: [-1. 29.] 
expected returns: [[137.96207]
 [153.42073]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 161.77020263671875



action possibilites: [-1. 11.] 
expected returns: [[175.37485]
 [190.444  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 153.42074584960938



action possibilites: [-1.] 
expected returns: [[139.13287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 192.35165405273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[123.62756]
 [136.95566]
 [135.16483]
 [109.78321]
 [135.6907 ]
 [152.20074]
 [140.66351]
 [154.03178]
 [126.8497 ]
 [138.87265]
 [140.1778 ]
 [137.86761]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 139.13287353515625



buy possibilites: [-1] 
expected returns: [[117.854004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 154.0317840576172






Player: 1 
cards in hand: [ 6.  0. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 11. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 25.] 
adversary cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10. 29. 29. 10. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 11. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 25.] 
adversary cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10. 29. 29. 10. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[26.360687]
 [37.215942]
 [45.392212]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 25.] 
cards in discard: [ 8. 25.  0. 11.  3. 29.  0. 29. 10. 29. 29. 10. 29. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.85400390625



action possibilites: [-1] 
expected returns: [[126.936066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 45.392215728759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[115.79985 ]
 [128.81558 ]
 [127.06857 ]
 [102.280045]
 [144.0467  ]
 [132.44438 ]
 [130.69427 ]
 [129.75914 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  5.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.93606567382812



buy possibilites: [-1] 
expected returns: [[167.00044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29. 29.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 144.0467071533203






Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 29. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[153.57416]
 [167.78401]
 [169.64847]
 [169.64847]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 29.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.0004425048828



action possibilites: [-1. 11. 29. 25.] 
expected returns: [[143.89128]
 [158.48933]
 [160.34497]
 [172.59488]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 25.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  6. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1] -> size -> 24 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.1335906982422



action possibilites: [-1] 
expected returns: [[106.74573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 11.  3.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 172.5948944091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.26378 ]
 [102.80415 ]
 [100.978676]
 [ 75.31826 ]
 [118.35354 ]
 [106.58652 ]
 [104.761055]
 [103.74082 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29. 11.  3.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  4.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.7457275390625



buy possibilites: [-1] 
expected returns: [[64.98555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29. 11.  3.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6] -> size -> 25 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.35353088378906






Player: 1 
cards in hand: [ 3.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  9.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0. 29.] 
adversary cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  3.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[23.556053]
 [24.030807]
 [24.945969]
 [31.901451]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0. 29.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.98554992675781



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[19.119183]
 [19.563759]
 [20.44801 ]
 [27.038689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0. 29.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.901447296142578



action possibilites: [-1. 10.  8.] 
expected returns: [[ 9.807376]
 [10.251199]
 [11.132007]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 10 11 25 25 29 29 29  8 10 29
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.038692474365234



action possibilites: [-1] 
expected returns: [[128.32582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 18.001163482666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[112.29316 ]
 [124.621124]
 [122.95027 ]
 [100.20293 ]
 [138.8689  ]
 [128.08488 ]
 [126.41405 ]
 [125.45862 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  2.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.32582092285156



buy possibilites: [-1] 
expected returns: [[89.75078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 25.  0.  0.  0. 29. 29. 29. 11. 29. 25. 11.  0.  0. 29. 11.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.868896484375






Player: 1 
cards in hand: [0. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [ 6.  0. 10. 11. 29.  6.  1.  0.  0.  0.  1.  0.  6. 11.  8. 11.  3.  0.
  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[119.26824]
 [134.14604]
 [134.14604]
 [120.1058 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.75077819824219



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[103.44028]
 [116.85356]
 [104.22177]
 [115.34558]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.62319946289062



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[116.71805]
 [117.61978]
 [130.08109]
 [130.08109]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.85355377197266



action possibilites: [-1] 
expected returns: [[97.67681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.680419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.35028 ]
 [ 97.293434]
 [ 95.94314 ]
 [ 77.10022 ]
 [108.92117 ]
 [100.09555 ]
 [ 98.74523 ]
 [ 98.02435 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  1.  8.  8.  2. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.67681121826172



buy possibilites: [-1] 
expected returns: [[107.10925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  0.  8.  8.  2. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.92118835449219






Player: 1 
cards in hand: [11. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  0.  8.  8.  2. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  0.  8.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  0.  8.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[139.36853]
 [154.56097]
 [165.86276]
 [165.86276]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25.  3.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10.  0.  8.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.1092529296875



action possibilites: [-1] 
expected returns: [[66.76315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  4. 10.  0.  8.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.8627471923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.551285]
 [62.026093]
 [41.209747]
 [66.7674  ]
 [64.316124]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  3. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  4. 10.  0.  8.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.76315307617188



buy possibilites: [-1] 
expected returns: [[61.641846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  3. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 66.76741027832031






Player: 1 
cards in hand: [ 1.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5.  9. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29.] 
expected returns: [[34.939648]
 [46.19318 ]
 [46.19318 ]
 [46.19318 ]
 [47.618713]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  6. 11.  3. 29.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.641845703125



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[27.059181]
 [36.70278 ]
 [36.70278 ]
 [36.70278 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  6. 11.  3. 29.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.253761291503906



action possibilites: [-1] 
expected returns: [[33.446426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0. 29.
 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 1.  6. 11.  3. 29.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.99296188354492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.492413]
 [31.170109]
 [14.541989]
 [35.08462 ]
 [33.04641 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0. 29.
 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  7.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 1.  6. 11.  3. 29.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.44642639160156



buy possibilites: [-1] 
expected returns: [[12.325753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11.  0. 10.  3. 11.  8. 25. 29.  0. 25.  3. 29.  0. 29.
 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  6.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 1.  6. 11.  3. 29.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 35.084632873535156






Player: 1 
cards in hand: [ 1.  6. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 11.  3. 29.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  6.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 11.  3. 29.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  6.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 11.  3. 29.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  5.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[39.158546]
 [41.084343]
 [50.65957 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  5.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.325753211975098



action possibilites: [-1.  8.] 
expected returns: [[74.867584]
 [77.05939 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11
 10 11  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  5.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.42238998413086



action possibilites: [-1] 
expected returns: [[35.626602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  5.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 74.55386352539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.734661]
 [33.215584]
 [17.295715]
 [36.87819 ]
 [35.106606]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  5.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.62660217285156



buy possibilites: [-1] 
expected returns: [[38.66974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.87818145751953






Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11. 11. 29. 11. 29.] 
adversary cards in discard: [ 8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11. 11. 29. 11. 29.] 
adversary cards in discard: [ 8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  4.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11. 11. 29. 11. 29.] 
adversary cards in discard: [ 8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [11. 11. 29. 11. 29.] 
adversary cards in discard: [ 8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 11. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 11. 29.] 
expected returns: [[87.3872 ]
 [98.33182]
 [98.33182]
 [99.83982]
 [98.33182]
 [99.83982]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 11. 29.] 
cards in discard: [ 8.  8. 29.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.66973876953125



action possibilites: [-1. 11. 11. 11. 25.] 
expected returns: [[72.66887]
 [84.13643]
 [84.13643]
 [84.13643]
 [95.26787]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 25.] 
cards in discard: [ 8.  8. 29.  8.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  4.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.63676452636719



action possibilites: [-1] 
expected returns: [[86.63875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29. 29.] 
cards in discard: [ 8.  8. 29.  8.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.26788330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.438644]
 [60.13282 ]
 [85.26221 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11. 29. 29.] 
cards in discard: [ 8.  8. 29.  8.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.63874816894531






Player: 1 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10. 29. 15. 25.  0.] 
adversary cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [10. 11. 10.  3.  0.  3.  6.  3. 22. 11.  1.  0.  0.  0.  8.  1.  6. 11.
  3. 29. 16.  3. 11.  8.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [10. 29. 15. 25.  0.] 
adversary cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 29. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15. 25.] 
expected returns: [[60.74868 ]
 [61.612396]
 [74.8328  ]
 [62.756477]
 [85.636055]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 15. 25.  0.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6] -> size -> 36 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.26222229003906



action possibilites: [-1] 
expected returns: [[44.310524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 15.  0.  0.  8.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.63606262207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.778866]
 [39.752544]
 [22.2332  ]
 [43.563213]
 [41.67361 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 15.  0.  0.  8.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  4.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.310523986816406



buy possibilites: [-1] 
expected returns: [[22.711994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 15.  0.  0.  8.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.56321716308594






Player: 1 
cards in hand: [0. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 10.] 
adversary cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 10.] 
adversary cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 11. 10.] 
adversary cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8] -> size -> 29 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[36.9109  ]
 [47.14251 ]
 [47.14251 ]
 [37.565613]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11. 10.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  9.] 
adversary cards in hand: [22. 16.  3. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.711994171142578



action possibilites: [-1] 
expected returns: [[36.15719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [22. 16.  3. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.43242645263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.483944]
 [21.1151  ]
 [36.126823]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10.] 
cards in discard: [ 8.  8. 29.  8.  0. 29. 29. 25. 11. 11. 11. 29. 29.  8. 25. 10. 29. 15.
  0.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [22. 16.  3. 11.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.157188415527344






Player: 1 
cards in hand: [22. 16.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 16.  3. 11.  0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [11. 29. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 16.  3. 11.  0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [11. 29. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 16.  3. 11.  0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [11. 29. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 29. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 29.] 
expected returns: [[34.93489 ]
 [44.46877 ]
 [45.707005]
 [44.46877 ]
 [45.707005]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.1268310546875



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[66.92212]
 [76.75415]
 [76.75415]
 [76.75415]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 11.] 
cards in discard: [29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  8.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.31129455566406



action possibilites: [-1] 
expected returns: [[65.646614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.98127746582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.10138 ]
 [46.859814]
 [65.99478 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.64661407470703






Player: 1 
cards in hand: [3. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 11 11  6 11  6  0  1  6 10  6  1
  6 11  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0.  8. 15. 15.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0.  8. 15. 15.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0.  8. 15. 15.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  8. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 15.] 
expected returns: [[54.58081 ]
 [65.53265 ]
 [56.576332]
 [56.234753]
 [56.234753]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 15. 15.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.99478149414062



action possibilites: [-1] 
expected returns: [[38.337944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 15.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.97743225097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.596077]
 [21.808178]
 [37.798626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15. 15.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  8.  0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.33794403076172






Player: 1 
cards in hand: [ 3.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  2. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 29. 25. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 29. 25. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 29. 25. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8. 29. 25. 10. 25.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 25. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25. 10. 25.] 
expected returns: [[23.799728]
 [25.44828 ]
 [33.62381 ]
 [41.12535 ]
 [24.362019]
 [41.12535 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 25. 10. 25.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  2.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6.  6. 11. 29.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0] -> size -> 39 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.79862976074219



action possibilites: [-1] 
expected returns: [[8.117032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 25.  0. 11.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6.  6. 11. 29.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.1253662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.2368104]
 [-12.060219 ]
 [  8.17581  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 10. 25.  0. 11.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6.  6. 11. 29.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6] -> size -> 40 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.117032051086426






Player: 1 
cards in hand: [10.  6.  6. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6. 11. 29.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [29.  8.  3.  0. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6. 11. 29.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [29.  8.  3.  0. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6. 11. 29.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [29.  8.  3.  0. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  8.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-7.122015 ]
 [ 2.5547552]
 [-5.4649463]
 [ 2.5547552]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  0. 29.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.175808906555176



action possibilites: [-1.  8. 29.] 
expected returns: [[-1.687357  ]
 [-0.41342163]
 [ 6.111373  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.6913838386535645



action possibilites: [-1.  8.] 
expected returns: [[30.63092 ]
 [31.296272]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11
  8 15  8  8  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.1837944984436035



action possibilites: [-1] 
expected returns: [[-16.29774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 30.59109878540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-26.5336  ]
 [-18.199991]
 [-19.391148]
 [-33.346466]
 [-15.721186]
 [-16.925068]
 [-17.586735]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  3.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.297740936279297



buy possibilites: [-1] 
expected returns: [[-20.79496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [3. 6. 6. 1. 0.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
   4.   0.] 
sum of rewards: 179.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -15.721182823181152






Player: 1 
cards in hand: [3. 6. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8.  0. 29. 11. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.  8. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8.  0. 29. 11. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.  8. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 1. 0.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [ 8.  0. 29. 11. 29.] 
adversary cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.  8. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11. 29.] 
expected returns: [[-12.103701 ]
 [-11.070228 ]
 [ -5.3970623]
 [ -6.211613 ]
 [ -5.3970623]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 11. 29.] 
cards in discard: [29. 15. 29. 11. 11.  3. 11. 15. 11.  0.  8. 15. 15. 25.  8. 29. 10. 25.
  0. 11. 10.  8.  8. 29. 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [10.  1.  0.  0. 11.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.794960021972656



action possibilites: [-1.  8. 11.  8.] 
expected returns: [[32.8851  ]
 [34.050392]
 [39.460644]
 [34.050392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  8.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  6.] 
adversary cards in hand: [10.  1.  0.  0. 11.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.63946533203125



action possibilites: [-1] 
expected returns: [[35.91094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [10.  1.  0.  0. 11.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.323028564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.384167]
 [34.037785]
 [21.671051]
 [36.74454 ]
 [35.46119 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  2.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [10.  1.  0.  0. 11.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.91093826293945



buy possibilites: [-1] 
expected returns: [[30.818714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [29. 15.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [10.  1.  0.  0. 11.] 
adversary cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.74454879760742






Player: 1 
cards in hand: [10.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0. 11.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0. 29. 15.  8.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0. 11.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0. 29. 15.  8.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0. 11.] 
cards in discard: [ 6. 10.  0.  6.  6.  0.  0.  0. 22. 16.  3. 11.  0.  8.  3.  0. 29.  0.
 11.  3.  0.  8.  0.  6.  0. 10.  6.  6. 11. 29.  0.  3.  6.  6.  1.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0. 29. 15.  8.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
expected returns: [[25.636837]
 [37.072487]
 [27.178146]
 [27.49794 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  8.  0.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.818714141845703



action possibilites: [-1. 15.  8.] 
expected returns: [[35.989304]
 [37.440727]
 [37.736485]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
 15  8  8  8 15 15 15  8 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.96941375732422



action possibilites: [-1] 
expected returns: [[26.399319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 36.13862991333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[18.933521]
 [25.686657]
 [24.753883]
 [12.39437 ]
 [27.612282]
 [26.680946]
 [26.28431 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  1.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.39931869506836



buy possibilites: [-1] 
expected returns: [[24.776207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   4.   0.] 
sum of rewards: 159.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 27.612300872802734






Player: 1 
cards in hand: [ 0.  0.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 8. 29. 15. 15. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 8. 29. 15. 15. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15. 15. 10.] 
expected returns: [[28.105   ]
 [30.335056]
 [41.03864 ]
 [29.947418]
 [29.947418]
 [28.901459]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 15. 15. 10.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.776206970214844



action possibilites: [-1. 15. 15. 10.] 
expected returns: [[-0.07629824]
 [ 1.404233  ]
 [ 1.404233  ]
 [ 0.54647064]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.37725830078125



action possibilites: [-1] 
expected returns: [[-3.559389]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 1.4042391777038574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.693702 ]
 [-20.977667 ]
 [ -4.0244355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.559389114379883






Player: 1 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [ 0.  0.  6. 11.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  4.  9.  5.] 
adversary cards in hand: [ 8.  8. 25. 10. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  6. 11.  3. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  3.  9.  5.] 
adversary cards in hand: [ 8.  8. 25. 10. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  6. 11.  3. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 28. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  3.  9.  5.] 
adversary cards in hand: [ 8.  8. 25. 10. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  6. 11.  3. 10.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0 10  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  3.  9.  5.] 
adversary cards in hand: [ 8.  8. 25. 10. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25. 10. 11.] 
expected returns: [[-18.755287 ]
 [-17.142302 ]
 [-17.142302 ]
 [ -1.4905801]
 [-18.216751 ]
 [-10.176922 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25. 10. 11.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  1.  9.  0.  0.  8.  1. 10. 10.  3.  9.  5.] 
adversary cards in hand: [ 0. 29.  6. 11. 29.] 
adversary cards in discard: [ 0.  0.  6. 11.  3. 10.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0 10  3] -> size -> 45 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.024435997009277



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 8 
Witch: 2 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  8. 10. 11. 11. 25.] 
cards in discard: [29. 15.  8. 29. 11.  8.  0.  8. 29.  8. 29.  8.  0.  0.  8. 29. 29. 15.
 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 25 29 29 29  8 10 29 11 11 11 10 11  8
  8  8  8 15 15 15  8 15  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  0.  9.  0.  0.  8.  1. 10. 10.  3.  9.  5.] 
adversary cards in hand: [ 0. 29.  6. 11. 29.] 
adversary cards in discard: [ 0.  0.  6. 11.  3. 10.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  0  0 11 11 11  6  0  1  6 10  6  1  6 11
  8  0 10  6  3 22  8 16  3  6  6 10  0 29  0  6  0  0  0 10  3  6] -> size -> 46 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000105 

action type: take_action - action 25.0
Learning step: 120004.2578125
desired expected reward: 120002.765625



