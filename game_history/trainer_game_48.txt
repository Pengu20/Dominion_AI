 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.1941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    6  -10    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -485 

action type: buy - action 8.0
Learning step: -23.874235153198242
desired expected reward: -31.389514923095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[288.72092]
 [298.60312]
 [296.3209 ]
 [272.37827]
 [307.8446 ]
 [298.47104]
 [296.4136 ]
 [316.14938]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.168575286865234
desired expected reward: 309.4653015136719



buy possibilites: [-1] 
expected returns: [[298.9614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.542280197143555
desired expected reward: 249.83595275878906






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.24554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.878190040588379
desired expected reward: 290.08319091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[302.55197]
 [311.28842]
 [308.71802]
 [288.0043 ]
 [306.06952]
 [318.74713]
 [311.3397 ]
 [314.74677]
 [297.84738]
 [308.9267 ]
 [307.66782]
 [325.7554 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.088932037353516
desired expected reward: 310.79461669921875



buy possibilites: [-1] 
expected returns: [[314.96323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -9.402749061584473
desired expected reward: 301.88568115234375






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.93823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.325669288635254
desired expected reward: 304.6375427246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[264.56165]
 [269.63715]
 [252.19693]
 [272.07126]
 [286.70752]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.533920288085938
desired expected reward: 282.57684326171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [3. 0. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.23663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [3. 0. 6. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -8.721863746643066
desired expected reward: 277.9856262207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[271.29074]
 [281.31036]
 [267.69424]
 [279.24332]
 [260.12048]
 [255.7796 ]
 [275.42194]
 [291.96173]
 [280.99655]
 [300.40674]
 [286.43182]
 [266.6494 ]
 [272.48172]
 [279.19266]
 [261.05524]
 [278.09564]
 [302.1279 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [3. 0. 6. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.707219123840332
desired expected reward: 290.8932800292969



buy possibilites: [-1] 
expected returns: [[292.43503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [3. 0. 6. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -22.90919303894043
desired expected reward: 232.8704376220703






Player: 1 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [8. 0. 3. 3. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[301.85358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -9.966986656188965
desired expected reward: 282.4680480957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[268.47375]
 [279.0504 ]
 [277.026  ]
 [256.21368]
 [251.29198]
 [272.93115]
 [289.48267]
 [278.75348]
 [297.70847]
 [284.11948]
 [263.49017]
 [269.84143]
 [276.99207]
 [257.49786]
 [275.92   ]
 [298.89435]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -11.019591331481934
desired expected reward: 293.63665771484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [0. 1. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.42673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [0. 1. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -10.391502380371094
desired expected reward: 288.5028381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.71332]
 [283.77692]
 [281.1476 ]
 [257.5972 ]
 [293.50937]
 [283.63538]
 [281.2343 ]
 [302.13516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [0. 1. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -10.669142723083496
desired expected reward: 289.4737854003906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [1. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.75375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -11.220564842224121
desired expected reward: 290.9145812988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[260.94324]
 [269.9121 ]
 [268.2109 ]
 [245.81326]
 [264.7438 ]
 [278.69592]
 [269.6918 ]
 [274.27292]
 [256.55707]
 [268.21768]
 [267.39584]
 [287.08127]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -11.129058837890625
desired expected reward: 281.590576171875



buy possibilites: [-1] 
expected returns: [[249.82043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -22 

action type: buy - action 14.0
Learning step: -7.346279144287109
desired expected reward: 229.9984893798828






Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  8  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [14.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [14.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [14.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [14.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.11087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [14.  1.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.883755683898926
desired expected reward: 241.93667602539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[258.29907]
 [268.38553]
 [266.23932]
 [241.75159]
 [277.88745]
 [268.13382]
 [266.2181 ]
 [286.65558]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [14.  1.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.525365829467773
desired expected reward: 270.79754638671875



buy possibilites: [-1] 
expected returns: [[266.88718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [14.  1.  0.  6.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 11.0
Learning step: -8.689411163330078
desired expected reward: 269.1980285644531






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[261.7123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [0. 8. 0. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.116167068481445
desired expected reward: 257.77099609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[236.08603]
 [244.07465]
 [242.2239 ]
 [224.67805]
 [252.07396]
 [243.88019]
 [242.2202 ]
 [259.50372]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [0. 8. 0. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.2478609085083
desired expected reward: 254.22735595703125



buy possibilites: [-1] 
expected returns: [[269.31165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 26. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [0. 8. 0. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 3.0
Learning step: -7.101683139801025
desired expected reward: 235.12222290039062






Player: 1 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [0. 8. 0. 1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  3.  0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[326.89758]
 [320.03564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  3.  0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.841556072235107
desired expected reward: 261.4700927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[299.22275]
 [309.097  ]
 [306.44315]
 [282.96045]
 [317.72607]
 [309.0185 ]
 [306.55365]
 [324.98584]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  3.  0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -10.831908226013184
desired expected reward: 314.3828125



buy possibilites: [-1] 
expected returns: [[267.57086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  3.  0.] 
cards in discard: [3. 3. 0. 3. 0. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 8.0
Learning step: -10.980578422546387
desired expected reward: 298.0378723144531






Player: 1 
cards in hand: [0. 3. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  0.  8.  6. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  0.  8.  6. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 1.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 3.  3.  0.  3.  0.  0.  8.  6. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[236.10211]
 [215.2763 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 3.  3.  0.  3.  0.  0.  8.  6. 11.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -9.759111404418945
desired expected reward: 257.8117370605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[224.12878]
 [229.0189 ]
 [227.80263]
 [215.19026]
 [234.70639]
 [229.15833]
 [228.08282]
 [240.47073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 3.  3.  0.  3.  0.  0.  8.  6. 11.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.374857902526855
desired expected reward: 231.24586486816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [8. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[236.9728 ]
 [220.77313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 8.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -8.43664836883545
desired expected reward: 232.03408813476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[214.36176]
 [202.00117]
 [238.56607]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 8.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.416163444519043
desired expected reward: 229.0053253173828



buy possibilites: [-1] 
expected returns: [[222.64879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 8.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8 10] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -22.290462493896484
desired expected reward: 179.71072387695312






Player: 1 
cards in hand: [0. 1. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 8.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  3  3  0  1  3  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  9.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[251.07315]
 [243.34073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [6. 8. 3. 6. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.2534990310668945
desired expected reward: 215.39529418945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[211.30086]
 [219.94673]
 [218.03102]
 [196.78333]
 [214.98103]
 [228.04012]
 [219.78633]
 [223.7571 ]
 [206.94589]
 [218.06454]
 [217.04964]
 [234.59735]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [6. 8. 3. 6. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.285819053649902
desired expected reward: 224.54714965820312



buy possibilites: [-1] 
expected returns: [[216.47658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [6. 8. 3. 6. 0. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -32.0 

action type: buy - action 8.0
Learning step: -7.718594551086426
desired expected reward: 212.06776428222656






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  8.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  8.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 10.  0.  3.  0.  0.  3. 11.  8.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  8.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [14.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[172.7653 ]
 [145.85115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  8.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.857771873474121
desired expected reward: 207.61880493164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.95259]
 [157.44571]
 [137.79492]
 [159.19586]
 [174.70671]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  8.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.537919044494629
desired expected reward: 163.98907470703125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[227.3973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -5.79213809967041
desired expected reward: 168.91458129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[210.13934]
 [218.54044]
 [216.7961 ]
 [196.80101]
 [213.64825]
 [226.69711]
 [218.3691 ]
 [222.56767]
 [206.13237]
 [216.8375 ]
 [215.99199]
 [234.40405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.588706016540527
desired expected reward: 219.99789428710938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.  3.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  8. 14.] 
adversary cards in discard: [0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  8.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  8. 14.] 
adversary cards in discard: [0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  8.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  8. 14.] 
adversary cards in discard: [0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  8.] 
cards in discard: [ 3. 10.  8.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  8. 14.] 
adversary cards in discard: [0. 0. 6. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[218.1715 ]
 [204.34557]
 [193.32173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  8. 14.] 
cards in discard: [0. 0. 6. 3. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -9.21142864227295
desired expected reward: 225.19264221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[200.25142]
 [187.78185]
 [221.46498]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  8. 14.] 
cards in discard: [0. 0. 6. 3. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.290122985839844
desired expected reward: 208.42303466796875



buy possibilites: [-1] 
expected returns: [[239.75357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  8. 14.] 
cards in discard: [0. 0. 6. 3. 1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -8.318117141723633
desired expected reward: 191.93333435058594






Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[213.13094]
 [205.80446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -9.530107498168945
desired expected reward: 230.2234649658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[186.99417]
 [194.05429]
 [171.26923]
 [196.30455]
 [212.17052]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  7. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.141600608825684
desired expected reward: 200.97406005859375



buy possibilites: [-1] 
expected returns: [[182.06322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [ 0.  0.  6.  3.  1.  0.  0.  3.  6.  8. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [1. 0. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -22.217039108276367
desired expected reward: 149.05218505859375






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [1. 0. 0. 3. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [1. 0. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [1. 0. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [1. 0. 0. 3. 1. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[183.97096]
 [172.75517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 10.  3.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  0.  0. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -7.7746782302856445
desired expected reward: 174.28854370117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[166.50276]
 [172.2147 ]
 [154.37985]
 [173.78639]
 [187.11108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  8. 10.  3.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  0.  0. 10.  0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.988210201263428
desired expected reward: 176.74301147460938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 10.  3.] 
cards in discard: [ 1.  0.  0.  3.  1.  0.  0. 10.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 10.  3.] 
cards in discard: [ 1.  0.  0.  3.  1.  0.  0. 10.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 10.  3.] 
cards in discard: [ 1.  0.  0.  3.  1.  0.  0. 10.  0.  3.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[214.91435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6. 0. 8. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -7.328301906585693
desired expected reward: 179.7827606201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[190.03954]
 [197.94638]
 [196.3194 ]
 [178.46722]
 [206.29411]
 [197.70786]
 [196.28766]
 [214.47394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6. 0. 8. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -8.764681816101074
desired expected reward: 203.55760192871094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  8  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[202.02818]
 [173.91676]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.  6.  0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -8.549514770507812
desired expected reward: 192.46932983398438



action possibilites: [-1] 
expected returns: [[212.57979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 14.0
Learning step: -5.434191703796387
desired expected reward: 163.91055297851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.50896]
 [202.37086]
 [200.35088]
 [181.4681 ]
 [197.79764]
 [209.2321 ]
 [202.22197]
 [205.43655]
 [190.3247 ]
 [200.35083]
 [199.20598]
 [215.14821]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -7.736413478851318
desired expected reward: 204.84336853027344






Player: 1 
cards in hand: [10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [0. 8. 0. 3. 3. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 11.  6.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [0. 8. 0. 3. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 11.  6.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0. 8. 0. 3. 3. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 11.  6.  0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[207.26106]
 [205.80441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  6.  0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -8.8955078125
desired expected reward: 206.25267028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[195.3502 ]
 [200.09714]
 [198.03046]
 [187.00375]
 [203.7542 ]
 [200.38159]
 [198.38551]
 [205.75664]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  6.  0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 24. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -8.483067512512207
desired expected reward: 196.9103240966797



buy possibilites: [-1] 
expected returns: [[222.36888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  6.  0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  3.  3.  0.  0. 14.  0.  6.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -42.0 

action type: buy - action 3.0
Learning step: -6.998220920562744
desired expected reward: 191.03221130371094






Player: 1 
cards in hand: [ 0. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 11.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  3. 10.  3.  0.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[150.5717 ]
 [144.9698 ]
 [138.61232]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6 14 11  3  8  6  8  0  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -10.073943138122559
desired expected reward: 212.29493713378906



action possibilites: [-1] 
expected returns: [[160.85225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.6438395977020264
desired expected reward: 128.616455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.7182 ]
 [148.86485]
 [132.20898]
 [150.51285]
 [162.65623]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -5.228302001953125
desired expected reward: 155.6239471435547






Player: 1 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[203.88167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  3.] 
adversary cards in discard: [1. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -5.306362628936768
desired expected reward: 157.34988403320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[184.04271]
 [190.73807]
 [188.42639]
 [171.88203]
 [196.03873]
 [190.84146]
 [188.63344]
 [199.87695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 10.  3.] 
adversary cards in discard: [1. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.244029521942139
desired expected reward: 191.7093048095703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10.  3.] 
cards in discard: [1. 0. 0. 0. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 10  3  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [1. 0. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [1. 0. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[188.70634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -6.4854736328125
desired expected reward: 193.39149475097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[169.01428]
 [176.27124]
 [174.7856 ]
 [157.10822]
 [183.30109]
 [176.13614]
 [174.80046]
 [190.04836]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -5.807618618011475
desired expected reward: 179.00901794433594



buy possibilites: [-1] 
expected returns: [[147.87633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -5.162805557250977
desired expected reward: 169.6376495361328






Player: 1 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14.  6.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14.  6.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 23. 30.  8.  6. 10.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14.  6.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  6. 14.  6.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[132.15001 ]
 [121.935425]
 [113.78627 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6. 14.  6.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -5.21845006942749
desired expected reward: 142.6578826904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.83202]
 [102.10714]
 [125.73168]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6. 14.  6.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.  0.  1.  3. 10.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.180569648742676
desired expected reward: 119.67774200439453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  1. 10.  8.  3. 16. 10.  0.  3.  0.  0.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[202.09016]
 [185.69633]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -2.6178033351898193
desired expected reward: 123.11386108398438



action possibilites: [-1. 14.] 
expected returns: [[169.43956]
 [151.08768]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 10.0
Learning step: -4.974074363708496
desired expected reward: 175.3740692138672



action possibilites: [-1.] 
expected returns: [[202.7809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action 14.0
Learning step: -1.6418125629425049
desired expected reward: 149.4458465576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[184.46811]
 [191.47993]
 [181.84946]
 [189.79665]
 [176.5301 ]
 [173.08601]
 [187.35677]
 [199.11905]
 [191.28616]
 [205.42496]
 [195.05156]
 [181.00018]
 [184.98573]
 [189.80394]
 [177.17764]
 [188.92958]
 [206.20552]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -4.379873752593994
desired expected reward: 198.40103149414062



buy possibilites: [-1] 
expected returns: [[156.65834]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 39.5 

action type: buy - action 22.0
Learning step: -3.3590691089630127
desired expected reward: 173.81857299804688






Player: 1 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [3. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [3. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[137.88927]
 [124.7584 ]
 [131.74077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  3.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -5.545111179351807
desired expected reward: 151.1132354736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.41938]
 [122.90246]
 [105.62651]
 [124.40089]
 [137.4712 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  3.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.475118160247803
desired expected reward: 129.76141357421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [ 3.  0. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 1. 6. 6.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  1.] 
cards in discard: [ 3.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  6. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 1. 6. 6.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 1. 6. 6.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  5. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 1. 6. 6.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 1. 6. 6.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.89512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 6. 6.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  1. 14. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -4.8259196281433105
desired expected reward: 132.64527893066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.739815]
 [108.55985 ]
 [107.11375 ]
 [ 93.21803 ]
 [113.7048  ]
 [108.41475 ]
 [107.083595]
 [118.27083 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 6. 6.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  1. 14. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.124864101409912
desired expected reward: 115.77025604248047



buy possibilites: [-1] 
expected returns: [[113.84192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 6. 6.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1. 14. 10.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -2.542736768722534
desired expected reward: 104.54085540771484






Player: 1 
cards in hand: [ 0.  1. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14. 10.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14. 10.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14. 10.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[64.35747]
 [52.64863]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -4.9700140953063965
desired expected reward: 108.87190246582031



action possibilites: [-1] 
expected returns: [[91.75737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.6696096658706665
desired expected reward: 50.01340103149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.87287]
 [70.35783]
 [91.71815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [22. 10. 14.  0.  0.  0.  0.  0.  0.  8. 11.  3. 10.  0.  3.  1.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.880798816680908
desired expected reward: 88.87657165527344






Player: 1 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.  8. 10. 11.  0.  3.  0.  1. 10.  0.  1. 14. 10.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[123.81425]
 [108.82549]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.2551026344299316
desired expected reward: 88.46304321289062



action possibilites: [-1] 
expected returns: [[132.59514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.5452866554260254
desired expected reward: 101.02825164794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.54131]
 [111.69203]
 [128.51569]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -5.154055118560791
desired expected reward: 127.44108581542969



buy possibilites: [-1] 
expected returns: [[100.672165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action 0.0
Learning step: -6.461942195892334
desired expected reward: 112.0793685913086






Player: 1 
cards in hand: [ 0.  8. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0.  8.  0.  3.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0] -> size -> 21 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [11.  0.  8.  0.  3.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0] -> size -> 21 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[125.063  ]
 [120.95156]
 [116.61067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  3.] 
cards in discard: [0. 8. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -4.639339447021484
desired expected reward: 96.03282165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.93061]
 [113.34106]
 [101.87422]
 [114.75111]
 [123.66235]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  3.] 
cards in discard: [0. 8. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 23. 30.  8.  6.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -5.7570648193359375
desired expected reward: 116.1906509399414



buy possibilites: [-1] 
expected returns: [[104.35071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  3.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -357.0 

action type: buy - action 6.0
Learning step: -20.595821380615234
desired expected reward: 81.27841186523438






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 22. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[66.10368 ]
 [48.990334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  6.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [11. 10.  8.  0.  1.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -7.220265865325928
desired expected reward: 97.13043975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.360435]
 [55.96185 ]
 [44.170536]
 [57.215588]
 [66.09053 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  6.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 22. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [11. 10.  8.  0.  1.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3] -> size -> 27 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.245163917541504
desired expected reward: 59.56233215332031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 10.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  0.  1.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 11.  8. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  1. 10.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  9.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 10.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10. 10.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 22.  1. 10.  6.] 
adversary cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  1. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[48.184628]
 [25.09594 ]
 [36.202927]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  1. 10.  6.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -5.72205114364624
desired expected reward: 60.36848068237305



action possibilites: [-1. 22.] 
expected returns: [[72.82908]
 [59.57752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  1.  6.  0.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -46 

action type: take_action - action 10.0
Learning step: -2.557460308074951
desired expected reward: 33.64544677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[71.72175 ]
 [75.00327 ]
 [74.03169 ]
 [66.223274]
 [72.967964]
 [79.018105]
 [74.97748 ]
 [77.04159 ]
 [69.92386 ]
 [74.10983 ]
 [73.687965]
 [82.8127  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.  6.  0.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -4.238706111907959
desired expected reward: 68.59034729003906



buy possibilites: [-1] 
expected returns: [[67.878174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.  6.  0.] 
cards in discard: [ 0.  8.  6.  6. 11.  0.  8.  0.  3.  0.  3.  0. 14.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -77.0 

action type: buy - action 0.0
Learning step: -5.908828258514404
desired expected reward: 65.81291198730469






Player: 1 
cards in hand: [10.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [ 0.  8. 14.  8.  3.  3.  3.  0.  0.  0.  0. 16. 29. 10. 11. 10.  8.  0.
  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 22.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 22.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[88.983986]
 [71.546036]
 [78.578705]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [14. 16.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -4.952393531799316
desired expected reward: 62.92578125



action possibilites: [-1. 22.] 
expected returns: [[93.64234]
 [73.64592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [14. 16.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -46 

action type: take_action - action 10.0
Learning step: -4.087817668914795
desired expected reward: 71.21306610107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[82.371216]
 [87.60752 ]
 [86.40195 ]
 [76.300125]
 [73.75618 ]
 [84.593155]
 [92.39249 ]
 [87.43689 ]
 [96.329254]
 [89.75945 ]
 [79.66074 ]
 [82.72856 ]
 [86.34266 ]
 [76.75935 ]
 [85.62996 ]
 [96.39873 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9. 10.] 
adversary cards in hand: [14. 16.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.007420063018799
desired expected reward: 88.63491821289062



buy possibilites: [-1] 
expected returns: [[153.22556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22.  0.  0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [14. 16.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -39.0 

action type: buy - action 15.0
Learning step: -2.3410422801971436
desired expected reward: 74.43130493164062






Player: 1 
cards in hand: [14. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 10.  8.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 6. 10.  8.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 27. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 6. 10.  8.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  1.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 6. 10.  8.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[17.298595 ]
 [10.5299015]
 [10.813749 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29  1] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: discard_down_to_3_cards - action 4
Learning step: -4.595561981201172
desired expected reward: 26.95362091064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.6295395]
 [ 4.5179157]
 [17.89906  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 16.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29  1] -> size -> 30 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.9101645946502686
desired expected reward: 13.388426780700684



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 16.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8
 10  0  3 16 29  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  5.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [14.  8.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[52.105637]
 [42.678448]
 [47.707043]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  6.  6.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  6 14 11  3  8  6  8  0  6  3 10 22 10  0  6  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -2.1323723793029785
desired expected reward: 15.766687393188477



action possibilites: [-1] 
expected returns: [[41.875786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.8569172620773315
desired expected reward: 49.12553024291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.826443]
 [34.164852]
 [43.182507]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -1.4343489408493042
desired expected reward: 40.441436767578125






Player: 1 
cards in hand: [11. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  3.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3. 10.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  8.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.79254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [29.  1.  0.  8.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1] -> size -> 33 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -1.4337936639785767
desired expected reward: 41.748722076416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[72.134514]
 [77.03191 ]
 [75.89556 ]
 [64.651436]
 [81.4926  ]
 [76.89895 ]
 [75.86865 ]
 [85.52973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15. 10.  0.  1. 22.  0.  0.  6.  0.  6. 10.  8.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [29.  1.  0.  8.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1] -> size -> 33 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.8364174365997314
desired expected reward: 83.95612335205078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  1.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  8.  0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  8.  0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 22. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  8.  0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [15. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 10. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11.] 
expected returns: [[106.60342]
 [100.55563]
 [100.92888]
 [100.92888]
 [104.22031]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -3.721724033355713
desired expected reward: 81.8080062866211



action possibilites: [-1. 15. 10. 11.] 
expected returns: [[46.502186]
 [36.024517]
 [36.660015]
 [42.42432 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -4.691473484039307
desired expected reward: 94.48118591308594



action possibilites: [-1. 15. 11.  8.] 
expected returns: [[8.735159 ]
 [3.1794786]
 [6.325459 ]
 [3.904951 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -1.427964448928833
desired expected reward: 35.23203659057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.01408339]
 [ 1.5468206 ]
 [-2.5382075 ]
 [ 1.9869695 ]
 [ 6.3844504 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -0.10683160275220871
desired expected reward: 8.628336906433105



buy possibilites: [-1] 
expected returns: [[25.572887]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.  0.  8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -0.6739062666893005
desired expected reward: -0.6879820227622986






Player: 1 
cards in hand: [ 8.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.  0.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  8.  1.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  8.  1.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 1. 14. 16.  0.  0.  1.  6.  0. 16.  0.  0. 10. 11.  1. 10. 10. 11.  0.
  0.  3.  0.  3. 29.  1.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [22.  8.  1.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [22.  8.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
expected returns: [[47.069424]
 [36.17232 ]
 [41.4462  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  1.  0.  6.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 14 11  3  8  8  0  6  3 10 22 10  0  6  0 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -2.041032552719116
desired expected reward: 23.5318546295166



action possibilites: [-1] 
expected returns: [[38.06669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.3214788436889648
desired expected reward: 38.23810577392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.97654 ]
 [21.966755]
 [37.398132]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -1.378015160560608
desired expected reward: 36.68867492675781






Player: 1 
cards in hand: [3. 3. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  4. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 8.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[29.833862]
 [19.810997]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  6.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 16.  0. 14.  6.] 
adversary cards in discard: [8. 3. 3. 1. 0. 8.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.4636685848236084
desired expected reward: 34.93447494506836



action possibilites: [-1] 
expected returns: [[-0.27585745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 14.0
Learning step: -1.196757197380066
desired expected reward: 18.6142520904541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-2.2354503 ]
 [-2.6709857 ]
 [-2.3703358 ]
 [-0.8717371 ]
 [-2.5722115 ]
 [-1.9733291 ]
 [-2.6840546 ]
 [-2.2408857 ]
 [-1.5322189 ]
 [-2.3504    ]
 [-2.1961956 ]
 [-0.65809655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6.] 
cards in discard: [ 0. 10. 10. 15.  0. 11.  0.  8.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.21881024539470673
desired expected reward: -0.4946677088737488






Player: 1 
cards in hand: [ 0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.45589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 1. 11. 10. 16. 10.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -0.8055145144462585
desired expected reward: -1.4636108875274658





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.7178545]
 [11.988469 ]
 [11.276455 ]
 [ 3.5682645]
 [10.098445 ]
 [15.066224 ]
 [11.882947 ]
 [13.36798  ]
 [ 7.056821 ]
 [11.246152 ]
 [10.807254 ]
 [18.578556 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [ 1. 11. 10. 16. 10.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.6820366382598877
desired expected reward: 14.388215065002441



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 11. 10. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 16. 10.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  1  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10
  0  3 16 29  1  6  0 11  1  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.17625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -0.032462503761053085
desired expected reward: 18.546100616455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[73.43128 ]
 [77.56284 ]
 [76.76372 ]
 [66.52445 ]
 [75.174736]
 [81.591095]
 [77.4219  ]
 [79.45172 ]
 [71.3127  ]
 [76.72954 ]
 [76.25505 ]
 [85.42668 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -4.052918434143066
desired expected reward: 89.12332916259766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  0.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [10.  8. 11.  3. 14.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [10.  8. 11.  3. 14.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 25. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [10.  8. 11.  3. 14.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [10.  8. 11.  3. 14.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  8. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 14.] 
expected returns: [[91.90074 ]
 [83.44465 ]
 [84.47537 ]
 [88.39912 ]
 [78.743416]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  3. 14.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.488008975982666
desired expected reward: 81.93866729736328



action possibilites: [-1] 
expected returns: [[78.21601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 14.0
Learning step: -2.3773112297058105
desired expected reward: 76.36611938476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[67.413536]
 [70.82142 ]
 [59.980137]
 [72.160286]
 [80.15592 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 21. 30.  8.  4.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.437685966491699
desired expected reward: 75.77832794189453



buy possibilites: [-1] 
expected returns: [[111.32411]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0. 0. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 21. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -16.24421501159668
desired expected reward: 43.735939025878906






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 21. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 15. 22.  8. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 21. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 15. 22.  8. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 15. 22.  8. 10.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 22.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22.  8. 10.] 
expected returns: [[103.95147 ]
 [ 96.168144]
 [ 90.28968 ]
 [ 97.949   ]
 [ 96.77459 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 22.  8. 10.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 22 10  0  6  0 15  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.567147731781006
desired expected reward: 105.75696563720703



action possibilites: [-1] 
expected returns: [[96.18374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.4324963092803955
desired expected reward: 83.50011444091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.68106]
 [78.16809]
 [95.63108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [ 0.  0.  0.  0.  3.  0.  0.  0.  6.  0.  6. 14. 10.  8. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [8. 0. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -4.034698009490967
desired expected reward: 92.14904022216797






Player: 1 
cards in hand: [8. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 1.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 1.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 1.] 
cards in discard: [ 8.  3.  3.  1.  0.  8. 16.  6.  0.  0.  0. 14. 22. 16. 11. 10. 10.  1.
 29.  1.  0.  0.  0.  3.  0.  8.  3.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[12.623673 ]
 [ 3.402671 ]
 [-1.0093815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 16. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3  1] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -6.8463640213012695
desired expected reward: 88.78469848632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.10665965]
 [ 2.7543194 ]
 [-4.458537  ]
 [ 2.8512423 ]
 [11.821679  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 16. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3  1] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.7352044582366943
desired expected reward: 9.888463020324707



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10 11  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0
  3 16 29  1  6  0 11  1  3  8  0 22  1  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[22.473236]
 [18.490818]
 [18.50824 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 0. 8. 1.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.3698084354400635
desired expected reward: 9.451865196228027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.451036]
 [19.759459]
 [19.719416]
 [16.303753]
 [21.448456]
 [19.730377]
 [19.747803]
 [23.76789 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  3. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 0. 8. 1.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.8895103931427
desired expected reward: 19.583717346191406



buy possibilites: [-1] 
expected returns: [[19.602802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 0. 8. 1.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -43.0 

action type: buy - action 8.0
Learning step: -2.69545578956604
desired expected reward: 17.0349178314209






Player: 1 
cards in hand: [3. 8. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 1.] 
cards in discard: [ 1. 16.  0. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3  8 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3
 16 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  6.  6. 11.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 16.  0. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  6.  6. 11.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 16.  0. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  6.  6. 11.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6  8] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[6.9476166]
 [5.9780016]
 [6.571147 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6.  6. 11.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14 11  3  8  8  0  3 10 10  0  6  0 15  0  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 14.  3. 10.  3.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -3.0796406269073486
desired expected reward: 16.523160934448242



action possibilites: [-1] 
expected returns: [[73.73971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 14.  3. 10.  3.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.7083765864372253
desired expected reward: 5.723713397979736





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.00472 ]
 [54.562897]
 [73.25576 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 14.  3. 10.  3.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -2.876887559890747
desired expected reward: 70.86282348632812



buy possibilites: [-1] 
expected returns: [[97.52744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 14.  3. 10.  3.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -3.0058681964874268
desired expected reward: 56.99884796142578






Player: 1 
cards in hand: [ 0. 14.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 10.  3.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[17.476461]
 [17.437029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [22.  0.  3.  1.  0.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: discard_down_to_3_cards - action 1
Learning step: -2.413012981414795
desired expected reward: 19.70653533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.89155 ]
 [16.85014 ]
 [16.562086]
 [17.077583]
 [16.998   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  2. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [22.  0.  3.  1.  0.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.1921942234039307
desired expected reward: 15.284257888793945



buy possibilites: [-1] 
expected returns: [[50.84297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0. 10.  0.  3. 14.  8.  0.  0.  8. 10.  0.  0.  8.  0.  6.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [22.  0.  3.  1.  0.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 8.0
Learning step: -0.9263997077941895
desired expected reward: 16.151180267333984






Player: 1 
cards in hand: [22.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 8. 14. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  3.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  4.  8.  9.] 
adversary cards in hand: [ 8. 14. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  3.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 8. 14. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8. 14. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.] 
expected returns: [[31.712986]
 [26.653198]
 [21.036306]
 [24.909405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [11.  0.  0. 10.  1.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.6017205715179443
desired expected reward: 47.24125289916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.70843 ]
 [27.192741]
 [18.543211]
 [28.31578 ]
 [33.411236]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [11.  0.  0. 10.  1.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.624422550201416
desired expected reward: 29.088571548461914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  1.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.  1.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.  1.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.654534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8. 14. 15.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [29. 16.  0.  1.  0.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0] -> size -> 41 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -3.175835132598877
desired expected reward: 30.235408782958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 5.408844 ]
 [ 6.619317 ]
 [ 6.575881 ]
 [ 4.4109726]
 [ 5.8797007]
 [ 8.32855  ]
 [ 6.577567 ]
 [ 7.5401106]
 [ 5.2901382]
 [ 6.60009  ]
 [ 6.5285616]
 [10.005081 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8. 14. 15.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [29. 16.  0.  1.  0.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0] -> size -> 41 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -1.9511823654174805
desired expected reward: 6.703351974487305



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29. 16.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  0.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  0.  1.  0.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[43.828445]
 [41.60005 ]
 [40.48696 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -1.238203763961792
desired expected reward: 8.766879081726074



action possibilites: [-1] 
expected returns: [[96.23059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.4569225311279297
desired expected reward: 37.98529052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 94.579704]
 [ 97.37095 ]
 [ 87.50996 ]
 [ 98.48205 ]
 [103.702675]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 20. 30.  8.  3.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.2738914489746094
desired expected reward: 92.95669555664062



buy possibilites: [-1] 
expected returns: [[84.735344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -18.718952178955078
desired expected reward: 68.79100036621094






Player: 1 
cards in hand: [0. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [10.  3.  6.  8.  8.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  3.  8.  9.] 
adversary cards in hand: [10.  3.  6.  8.  8.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 1. 16.  0. 10. 10.  8.  3.  0.  1.  1. 14.  0.  3. 10.  3. 10. 22.  0.
  3.  1.  0.  0. 11.  0.  0. 10.  1. 29. 29. 16.  0.  1.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [10.  3.  6.  8.  8.] 
adversary cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10.  3.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[53.96862 ]
 [43.44938 ]
 [44.255325]
 [44.255325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  8.  8.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.369609355926514
desired expected reward: 79.36573791503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.586983]
 [35.74649 ]
 [53.49814 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  8.  8.] 
cards in discard: [ 8. 14. 15.  0.  0.  0.  0.  0.  3.  0.  6.  8. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.8773396015167236
desired expected reward: 50.0912971496582



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16
 29  1  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[55.01716 ]
 [50.543446]
 [46.140404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  8.] 
adversary cards in discard: [0. 8. 3. 8.] 
adversary owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.7447617053985596
desired expected reward: 49.75338363647461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.15113 ]
 [48.389336]
 [42.025524]
 [49.083923]
 [53.627365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  8.] 
adversary cards in discard: [0. 8. 3. 8.] 
adversary owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.8691322803497314
desired expected reward: 51.14802169799805



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  8.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  8. 14.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  0  3 10  3  0  1  0  0  0 10  0 16 14  0  8  8 10  0  3 16 29  1
  6  0 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 8. 3. 8. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.511185]
 [17.966713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 8.  0.  6. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 1. 29.  0. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -4.438336372375488
desired expected reward: 49.189029693603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.539158]
 [17.746979]
 [10.793966]
 [18.34047 ]
 [23.863474]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 8.  0.  6. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 1. 29.  0. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.9743523597717285
desired expected reward: 20.536832809448242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 29.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 10.  1.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  1.  3.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  3. 10.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  3. 10.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  2.  8.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  3. 10.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[ 0.6762812]
 [-3.6232905]
 [-3.4247832]
 [-3.6232905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  8.] 
cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [29.  1.  0.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.469153642654419
desired expected reward: 20.394319534301758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.185072  ]
 [-4.978937  ]
 [-0.03201604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  8.] 
cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [29.  1.  0.  6. 10.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.297834873199463
desired expected reward: -2.229189157485962



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  1.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  6. 10.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  6.  0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  0. 22.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 22.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  7.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 22.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[14.286736]
 [12.347982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  0.] 
cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.9395250082015991
desired expected reward: -1.971544861793518





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.233248 ]
 [12.90732  ]
 [11.754639 ]
 [10.930112 ]
 [12.235725 ]
 [13.633373 ]
 [13.2130575]
 [12.785986 ]
 [11.321413 ]
 [12.01926  ]
 [11.52622  ]
 [14.501795 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  0.] 
cards in discard: [ 8.  0.  6. 14.  0.  0.  3.  6.  0.  8.  8.  0.  3. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.6650338172912598
desired expected reward: 11.6217041015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 6.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 7 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  1.  8.  9.] 
adversary cards in hand: [ 6.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [ 6.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[3.1517289]
 [2.0271122]
 [2.0271122]
 [2.2486145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [ 0. 11.  0. 16. 16.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10] -> size -> 44 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.914400815963745
desired expected reward: 11.587389945983887





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.8143437]
 [1.9000905]
 [2.6563847]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [ 0. 11.  0. 16. 16.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10] -> size -> 44 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.3547308444976807
desired expected reward: 0.7970008850097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16. 16.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 16. 16.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  1. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 16. 16.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.4061887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6.  8.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [ 1.  0.  3. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.4369587898254395
desired expected reward: 0.21942925453186035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
expected returns: [[-3.202954 ]
 [-3.56914  ]
 [-3.1496062]
 [-2.6080394]
 [-3.3482392]
 [-3.1499066]
 [-3.2360091]
 [-2.6359477]
 [-2.8911502]
 [-2.0229235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6.  8.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [ 1.  0.  3. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.1876425743103027
desired expected reward: -4.5938310623168945



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.  1.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [14.  0.  3. 15.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [14.  0.  3. 15.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8. 10.  0.  8.  9.] 
adversary cards in hand: [14.  0.  3. 15.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [ 0.  8.  3.  8.  0. 10.  8.  3.  3. 10. 10. 29.  1.  0.  1.  3. 10. 11.
 10. 29.  1.  0.  6.  0. 22. 10.  1.  1.  0.  0.  0.  8.  0. 11.  0. 16.
 16. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [14.  0.  3. 15.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [14.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[13.888111 ]
 [ 0.29195  ]
 [ 3.6388419]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 15.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 1.  1.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.9395023584365845
desired expected reward: -3.96242618560791



action possibilites: [-1] 
expected returns: [[26.648798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [1. 1. 3.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 14.0
Learning step: -0.6649991273880005
desired expected reward: -0.3730570077896118





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
expected returns: [[22.837738]
 [24.732939]
 [24.183504]
 [20.98088 ]
 [23.621231]
 [26.285975]
 [25.330992]
 [21.854933]
 [23.814533]
 [27.601183]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [1. 1. 3.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -2.0065245628356934
desired expected reward: 24.64227294921875






Player: 1 
cards in hand: [1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [10.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [10.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  6.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [10.  0. 11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[17.889044]
 [14.1045  ]
 [13.428706]
 [14.1045  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  8.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [10.  0.  0.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.266576051712036
desired expected reward: 24.33460807800293



action possibilites: [-1] 
expected returns: [[3.2929027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [10.  0.  0.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 7
Learning step: -1.715906023979187
desired expected reward: 9.084017753601074





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.17882037]
 [-1.3193376 ]
 [ 3.4991724 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  2.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [10.  0.  0.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.3711141347885132
desired expected reward: 1.9217885732650757



buy possibilites: [-1] 
expected returns: [[46.103107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 6.  8.  0.  8. 10.  6.  0.  0.  0.  0. 14.  0.  3. 15.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [10.  0.  0.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -336.0 

action type: buy - action 6.0
Learning step: -15.6967134475708
desired expected reward: -17.01604652404785






Player: 1 
cards in hand: [10.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 16.] 
cards in discard: [10.  0. 11.  1.  1.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 16.] 
cards in discard: [10.  0. 11.  1.  1.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 16.] 
cards in discard: [10.  0. 11.  1.  1.  3.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[2.3607776 ]
 [0.81434345]
 [1.1505082 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0.  8.  1. 10.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.  0. 10.  0.  0.  3. 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11  0] -> size -> 48 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.063960552215576
desired expected reward: 41.039146423339844



action possibilites: [-1] 
expected returns: [[-7.6348467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0.  8.  1. 10.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.  0. 10.  0.  0.  3. 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11  0] -> size -> 48 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 15.0
Learning step: -1.9149340391159058
desired expected reward: -3.051936626434326





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
expected returns: [[-7.398078 ]
 [-8.245432 ]
 [-7.457099 ]
 [-5.143958 ]
 [-7.7020535]
 [-8.09836  ]
 [-7.947135 ]
 [-6.3900313]
 [-7.073131 ]
 [-7.4170237]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30. 20. 30.  8.  1.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0.  8.  1. 10.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.  0. 10.  0.  0.  3. 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11  0] -> size -> 48 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.5618056058883667
desired expected reward: -9.19665241241455



Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 0. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 14  3  8  0  3 10 10  0  0 15  0  6  8  0  8  6  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 21. 30. 20. 30.  8.  0.  8.  5.  0. 10.  8.  8.  9.  0.  8.  9.] 
adversary cards in hand: [ 8.  0.  8.  1. 10.] 
adversary cards in discard: [10.  0. 11.  1.  1.  3.  0. 10.  0.  0.  3. 16.] 
adversary owned cards: [10  0  3 10  3  0  1  0  0  0 10  0 16  0  8  8 10  0  3 16 29  1  6  0
 11  1  3  8  0 22  1  3  1  1  1 10  0 29 10  0  0 10 11 10  8 23 11  0] -> size -> 48 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -847 

action type: buy - action 6.0
Learning step: -42.09280014038086
desired expected reward: -47.236759185791016



