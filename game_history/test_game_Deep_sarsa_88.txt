 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action -1
Learning step: -300034.84375
desired expected reward: -300051.4375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [16. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [16. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [16. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [16. 11.  0.  3. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [16. 11.  0.  3. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 29. 30.  8. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [16. 11.  0.  3. 16.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [10.  1.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16  1 11 16 16 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 16. 11.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 16. 11.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0. 16. 11.] 
adversary cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0. 16. 11.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0. 16.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0. 16.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0. 16.] 
cards in discard: [10.  1.  3.  0.  0.  0.  3. 10. 16.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  1 11 16 16 10  3 10  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 27. 30.  8. 10.  7.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  1.  3. 10.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  1.  3. 10.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16. 10.  1.  3. 10.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [16. 10.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  1.  3. 10.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3. 10.  0.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  0.  3.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  0.  3.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 27. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  0.  3.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 28. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 16.] 
adversary cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 16.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 11 16 16 10  3 10  3  0  1 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 26. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 11. 16.  0.  0.  0.  3. 10. 10. 16.  1.  3.  0.  3.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [14.  1.  3.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [14.  1.  3.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [15. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 25. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 24. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16. 16. 11. 16.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 24. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16. 16. 11. 16.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16. 16. 11. 16.] 
adversary cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 16. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16. 11. 16.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 16.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 16.] 
cards in discard: [14.  1.  3.  3.  0.  0.  1.  1.  0.  3.  3.  3.  3.  0.  3. 10.  0.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 16.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [11. 16.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1 11  3  1  3 14  1
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 16.  3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 16.  3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 16.  3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 16.  3.] 
cards in discard: [ 8. 16.  1.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 9. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 24. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 8. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  1.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 8. 26. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 3.] 
adversary cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 3.] 
cards in discard: [ 8. 16.  1.  0. 10.  0.  0. 16.  0. 16.  3.  3.  0.  3.  3.  1.  3.  1.
 14.  0.  0.  3.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.
 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 6. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  1.  0.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  1.  0.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  1.  0.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [29. 10.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  1.  0.  3.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  3.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 3. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 16.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  8.  0.  8.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  1 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8
  8  0  0  3  1 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 14. 16.  1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 16.  1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8. 10.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 1.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [ 0.  0.  3.  3.  0. 10. 29. 10.  1.  0.  3.  0.  0. 23.  0. 16.  8.  0.
  8. 25. 14.  3.  0. 16.  1. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -10.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8
  0  0  3  1 29  0 23  0 25 23] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 23. 30.  8. 10.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.  -20.
   0.    0.   13.5   0. ] 
sum of rewards: -71.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6 10] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6 10] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6 10] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 8.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16 16 16 10  3 10  3  0  1  3  1  3 14  1  3  8  8  0
  0  3  1 29  0 23  0 25 23  6 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [23. 23. 16.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 22. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [23. 23. 16.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 21. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [23. 23. 16.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: -91.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [23. 23. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 23. 16.  0.  3.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 23. 16.  0.  3.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  0.  3.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.  -50.
   0.    0.   13.5   0. ] 
sum of rewards: -101.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  0.  3.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 16 16 10  3 10  3  0  3  1  3 14  1  3  8  0  0  3  1
 29  0 23  0 25 23  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  8.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  1.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 20. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  1.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  3.  1.] 
adversary cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -60.
   0.    0.   13.5   0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3.  1.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  7.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [ 6. 10. 16.  0.  0.  3. 10.  0. 14.  1.  3.  0.  8.  0. 23. 23. 16.  0.
  3. 15.  8. 16.  0. 10.  0.  1. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 19. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: -91.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29
  0 23  0 25 23  6 10 15  8 16] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 18. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -80.
   0.    0.   13.5   0. ] 
sum of rewards: -101.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [25.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 10.  0.] 
cards in discard: [ 3. 10. 29.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0. 10.  0.] 
cards in discard: [ 3. 10. 29.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  7.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0. 10.  0.] 
cards in discard: [ 3. 10. 29.  8.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 3. 23. 16.  1. 10.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 17. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 3. 23. 16.  1. 10.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 3. 23. 16.  1. 10.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 23. 16.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 16.  1. 10.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 1. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 16.  1.  1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 1. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 16.  1.  1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  8.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 1. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 16.  1.  1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 1. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  1.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8 11] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0. 16. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  1.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8 11] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 0.] 
cards in discard: [1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 0. 15. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  3.  1.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
adversary owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8 11] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  6.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  3.  1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0
 25 23  6 10 15  8 16  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 15. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 15. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 14. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [14.  8. 23. 16.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 14. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [14.  8. 23. 16.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 13. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [14.  8. 23. 16.  0.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    13.5    0. ] 
sum of rewards: -131.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [14.  8. 23. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 23. 16.  0.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 23. 16.  0.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 13. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 16.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 13. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 16.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 12. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 16.] 
adversary cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.] 
adversary owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -120.     0.     0.    13.5    0. ] 
sum of rewards: -141.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0. 16.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25
 23  6 10 15  8 16  8 11  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 23. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.] 
cards in discard: [ 3. 10. 29.  8.  8. 25.  3.  0. 10.  0. 11. 10.  3. 23. 16.  1.  1.  1.
 15.  6.  3.  1. 14.  8. 23. 16.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 12. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 12. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -130.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  0.  0.] 
cards in discard: [10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 16. 10.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1] -> size -> 48 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 11. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 16. 10.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 10. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 16. 10.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.] 
adversary owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -140.     0.     0.    13.5    0. ] 
sum of rewards: -191.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 16. 10.] 
cards in discard: [10.  6. 11.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 16.  0.] 
cards in discard: [10.  6. 11.  1.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 16 10 10  3  0  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23
  6 10 15  8 16  8 11  1  3 10] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  9.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 10. 29.  3.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 10. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 10. 29.  3.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  9. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 10. 29.  3.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -150.     0.     0.    13.5    0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [16. 10. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 29.  3.  8.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10. 29.  3.  8.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 23. 25. 14. 23.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  9. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 23. 25. 14. 23.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 23. 25. 14. 23.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -160.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 1. 23. 25. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 25. 14. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23. 25. 14. 23.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 25. 14. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 14. 23. 16.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 14. 23. 16.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  8. 10.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  8. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  8. 10.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  8. 10.  8.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -170.     0.     0.    13.5    0. ] 
sum of rewards: -191.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 10.  8.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 10.  8.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  6.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 10.  8.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 15.  3.  0.  1.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.  3.  1.  8. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 52 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  7. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 15.  3.  0.  1.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.  3.  1.  8. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  6. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16. 15.  3.  0.  1.] 
adversary cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.  3.  1.  8. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    13.5    0. ] 
sum of rewards: -201.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [16. 15.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  3.  0.  1.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.  3.  1.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  3.  0.  1.] 
cards in discard: [10.  6. 11.  1.  0.  0.  6. 10. 16.  3.  3.  3. 16. 10. 29.  3.  8. 23.
  1. 25. 14. 23. 16.  8.  3.  1.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  6. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  6. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  5. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -190.     0.     0.    13.5    0. ] 
sum of rewards: -211.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 1. 10. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 22. 30.  8.  8.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 22. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  5. 30. 22. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  6. 15.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  5. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  8. 10.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0 -200    0 -300
    0    0] 
sum of rewards: -595 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6] -> size -> 55 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  5. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  8. 10.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  8. 10.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
adversary owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -90.     0.     0.     0.     0.     0.     0.
    0.  -210.     0.     0.    13.5    0. ] 
sum of rewards: -291.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  8. 10.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 8. 0.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 16 10 10  3  3  1  3 14  1  3  8  0  0  3  1 29  0 23  0 25 23  6
 10 15  8 16  8 11  1  3 10  6  8  3] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3.  1.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  4. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3.  1.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3.  1.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -220.     0.     0.    13.5    0. ] 
sum of rewards: -271.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 1. 10. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  3.  1.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.  1.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  7.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.  1.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [23.  3. 16. 23. 14.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  3. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [23.  3. 16. 23. 14.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  2. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [23.  3. 16. 23. 14.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -230.     0.     0.    13.5    0. ] 
sum of rewards: -281.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [23.  3. 16. 23. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16. 23. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 16. 23. 14.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3. 16. 23. 14.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [29. 16.  3. 16.  6.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  2. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [29. 16.  3. 16.  6.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  1. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [29. 16.  3. 16.  6.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -240.     0.     0.    13.5    0. ] 
sum of rewards: -291.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [29. 16.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  3. 16.  6.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  3. 16.  6.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16.  0.  1.  8. 11.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  1. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16.  0.  1.  8. 11.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [16.  0.  1.  8. 11.] 
adversary cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
adversary owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -250.     0.     0.    13.5    0. ] 
sum of rewards: -301.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [16.  0.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  8. 11.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 16 10 10  3  1  3 14  1  3  0  3  1 29  0 23  0 25 23  6 10 15 16
  8 11  1  3 10  6  8  3 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3. 25.  1. 10.  3.  0.  6. 15. 10.  8. 11.  1. 10. 10.  3.  1. 23.  3.
 16. 23. 14. 29. 16.  3. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [25. 11. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 30. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [25. 11. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [25. 11. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0 1500    0 -260    0    0
  432    0] 
sum of rewards: 1607 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [25. 11. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29  0 23  0 25 23  6 10 15 16  8 11  1
  3 10  6  8  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  5.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  3.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  3.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  6. 23.  3.  0.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2] -> size -> 61 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 29. 21. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  6. 23.  3.  0.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3] -> size -> 62 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 20. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 3.  6. 23.  3.  0.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0. -270.
    0.    0.    4.    0.] 
sum of rewards: -301.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 23.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 23.  3.  0.] 
cards in discard: [ 8. 16. 25. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 20. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3] -> size -> 62 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 23.  3.  0.] 
cards in discard: [ 8. 16. 25. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 29. 20. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3] -> size -> 62 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 20. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [10.  3. 10. 16.  1.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3] -> size -> 62 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 29. 20. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [10.  3. 10. 16.  1.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 1. 0. 0. 3. 1. 0. 0. 1. 1. 1. 6. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 3. 1. 0. 2. 0. 0. 0. 0.
 1. 3. 0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [10.  3. 10. 16.  1.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.] 
adversary owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. -280.
    0.    0.    4.    0.] 
sum of rewards: -281.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [10.  3. 10. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 16.  1.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16.  1.  1.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 10 10  3  3 14  1  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3
 10  6  8  3 11  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  4.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 16. 10.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16. 10. 29.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16. 10. 29.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 11. 16. 14.  8.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3] -> size -> 63 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 29. 19. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 11. 16. 14.  8.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [3.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [ 1. 11. 16. 14.  8.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0. -290.
    0.    0.    4.    0.] 
sum of rewards: -261.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 1. 11. 16. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 16. 14.  8.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16  8 11  1  3 10
  6  8  3 11  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 14.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 14.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  3.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 14.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [15.  6.  8. 10. 10.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3] -> size -> 64 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 29. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [15.  6.  8. 10. 10.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [15.  6.  8. 10. 10.] 
adversary cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0 1500    0 -300    0    0
  432    0] 
sum of rewards: 1657 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [15.  6.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  8. 10. 10.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10. 10.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10. 10.] 
cards in discard: [ 8. 16. 25. 11.  3.  3.  6. 23.  3.  0.  8.  3.  1. 10. 16. 10. 29.  3.
 10.  8. 16.  1. 11. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 6. 16. 14.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2] -> size -> 65 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 28. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 6. 16. 14.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 27. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 6. 16. 14.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0. 1500.    0. -310.
    0.    0.  108.    0.] 
sum of rewards: 1323.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 6. 16. 14.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 23.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 14.  3. 23.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23  6 10 15 16 11  1  3 10  6
  8  3 11  8  8 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 18. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 23.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 23.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 27. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [25.  3. 10. 29. 15.] 
adversary cards in discard: [ 3. 16. 14.  3. 23.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2] -> size -> 66 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 27. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [25.  3. 10. 29. 15.] 
adversary cards in discard: [ 3. 16. 14.  3. 23.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2] -> size -> 67 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 26. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [25.  3. 10. 29. 15.] 
adversary cards in discard: [ 3. 16. 14.  3. 23.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0. 1500.    0. -320.
    0.    0.  108.    0.] 
sum of rewards: 1253.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [25.  3. 10. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 29. 15.] 
cards in discard: [ 3. 16. 14.  3. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [6. 0. 1. 1. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 10. 29. 15.] 
cards in discard: [ 3. 16. 14.  3. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 26. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [6. 0. 1. 1. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2] -> size -> 67 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 1. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [11.  6. 10. 10. 16.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 1. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2] -> size -> 67 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 26. 17. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [11.  6. 10. 10. 16.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 1. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [11.  6. 10. 10. 16.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. -330.
    0.    0.    4.    0.] 
sum of rewards: -331.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [11.  6. 10. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10. 10. 16.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
adversary victory points: 6
player victory points: 6 


action possibilites: [-1. 11. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10. 16.  3.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
adversary victory points: 6
player victory points: 6 


action possibilites: [-1. 11. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 16.  3.  8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 16.  3.  8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 3 
buys: 1 
player value: 0 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3] -> size -> 68 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 26. 16. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
adversary owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0. -340.
    0.    0.    4.    0.] 
sum of rewards: -311.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10  3  3 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  8
  3 11  8  8 10  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 1. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [10.  1. 23.  3.  1.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3] -> size -> 69 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 26. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [10.  1. 23.  3.  1.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [10.  1. 23.  3.  1.] 
adversary cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -350.
    0.    0.  108.    0.] 
sum of rewards: 1343.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [10.  1. 23.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 23.  3.  1.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  1.  8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  1.  8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3] -> size -> 28 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  9.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
adversary victory points: 7
player victory points: 4 


buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  1.  8.] 
cards in discard: [ 3. 16. 14.  3. 23. 25.  3. 10. 29. 15. 10. 10. 11.  6. 16.  3.  8.  8.
  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 1. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 15. 10. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3 25] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2] -> size -> 70 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 25. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 15. 10. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3 25] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 15. 10. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3 25] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -360.
    0.    0.  108.    0.] 
sum of rewards: 1333.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [23. 15. 10. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15. 10. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 15. 10. 11. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 15 16 11  1  3 10  6  3 11  8
  8 10  8  3 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  8.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10. 11.] 
cards in discard: [23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 10. 11.] 
cards in discard: [23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [10. 14.  3.  3. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2] -> size -> 71 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 24. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [10. 14.  3.  3. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2] -> size -> 72 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 23. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [10. 14.  3.  3. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -370.
    0.    0.  108.    0.] 
sum of rewards: 1323.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [10. 14.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  3.  3. 25.] 
cards in discard: [23. 16. 23. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 2.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2] -> size -> 72 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  3. 25.] 
cards in discard: [23. 16. 23. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 23. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 1. 2.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2] -> size -> 72 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 1. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 2.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [23.  8.  3. 29.  0.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 2.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2] -> size -> 72 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 23. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [23.  8.  3. 29.  0.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 2.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [23.  8.  3. 29.  0.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -380.
    0.    0.  108.    0.] 
sum of rewards: 1313.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [23.  8.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 29.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  3. 29.  0.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  0.  1.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [16 16 10 10 14  3  3  1 29 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8
 10  8  3 25 23] -> size -> 29 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 0 
buys: 2 
player value: 2 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 1. 1.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 16. 10. 10. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2] -> size -> 73 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 22. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 16. 10. 10. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 1.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2] -> size -> 74 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 21. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 16. 10. 10. 25.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -390.
    0.    0.  108.    0.] 
sum of rewards: 1303.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8. 16. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10. 10. 25.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2. 0. 0. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2] -> size -> 74 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 10. 10. 25.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2. 0. 0. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2] -> size -> 74 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2. 0. 0. 1. 1. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2] -> size -> 74 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  3.  1.  6.  3.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2. 0. 0. 1. 1. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2] -> size -> 74 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 21. 15. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  3.  1.  6.  3.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 1. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0.
 3. 6. 0. 1. 1. 3. 3. 1. 0. 0. 0. 3. 2. 0. 1. 0. 1. 1. 2. 0. 1. 0. 1. 1.
 2. 1. 0. 1. 1. 0. 2. 1. 0. 1. 1. 2. 2. 0. 0. 1. 1. 1. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  3.  1.  6.  3.] 
adversary cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -400.
    0.    0.    4.    0.] 
sum of rewards: -281.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [16.  3.  1.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.  6.  3.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  1.  6.  3.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  2.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  1.  6.  3.] 
cards in discard: [23. 16. 23. 10. 11. 10. 14.  3.  3. 25. 23.  8.  3.  0.  8. 16. 10. 10.
 25.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  1.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  1.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  8.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3] -> size -> 75 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 21. 14. 30.  8.  7.  6.  6.  1.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  8.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [16.  8.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23  8] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0.    0.    0. -410.
    0.    0.    4.    0.] 
sum of rewards: -261.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [16.  8.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8. 10. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8  8 10  8
  3 25 23  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  9.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.] 
cards in discard: [14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.] 
cards in discard: [14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [10. 10. 25. 11.  3.] 
adversary cards in discard: [14. 16.  8. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3] -> size -> 76 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 21. 13. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [10. 10. 25. 11.  3.] 
adversary cards in discard: [14. 16.  8. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3] -> size -> 77 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 21. 12. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [10. 10. 25. 11.  3.] 
adversary cards in discard: [14. 16.  8. 10. 11.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0. -420.
    0.    0.    4.    0.] 
sum of rewards: -241.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [10. 10. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25. 11.  3.] 
cards in discard: [14. 16.  8. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 12. 30.  8.  7.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 2. 0. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3] -> size -> 77 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  3.  3.  6.] 
cards in discard: [14. 16.  8. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 2. 0. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6] -> size -> 78 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.  3.  3.  6.] 
cards in discard: [14. 16.  8. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 2. 0. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6] -> size -> 78 
adversary victory points: 10
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 2. 0. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 2. 0. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6] -> size -> 78 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 23.  3. 10. 10.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  150    0    0    0    0    0    0    0 -430    0 -300
    0    0] 
sum of rewards: -585 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 2. 0. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6] -> size -> 78 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 21. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 23.  3. 10. 10.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 2. 0. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 8. 23.  3. 10. 10.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -440.
    0.    0.  108.    0.] 
sum of rewards: 1313.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 8. 23.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  3. 10. 10.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1.  8. 23. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  3. 10. 16.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  3. 10. 16.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [2. 0. 0. 1. 0.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [2. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 23. 25.  8.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2] -> size -> 79 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 20. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 23. 25.  8.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 0.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 23. 25.  8.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
adversary owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -450.
    0.    0.  108.    0.] 
sum of rewards: 1303.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 23. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23. 25.  8.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3 23  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3
 25 23  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 2. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 2. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 2. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 1. 2. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 2. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16.  1.  3. 14. 23.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.
  8.  0.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 2. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2] -> size -> 80 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 19. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16.  1.  3. 14. 23.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.
  8.  0.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 2. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2] -> size -> 81 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 18. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16.  1.  3. 14. 23.] 
adversary cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.
  8.  0.  3. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -460.
    0.    0.  108.    0.] 
sum of rewards: 1293.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [16.  1.  3. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3. 14. 23.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.
  8.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 2. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2] -> size -> 81 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3. 14. 23.] 
cards in discard: [14. 16.  8. 10. 11. 25. 10. 10. 11.  3.  3.  6. 10.  8. 23.  3. 10. 16.
  8.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 18. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 2. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2] -> size -> 81 
adversary victory points: 9
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 2. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 2. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2] -> size -> 81 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [23.  6.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 2. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2] -> size -> 81 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 18. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [23.  6.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 2. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2] -> size -> 82 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 17. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [23.  6.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -470.
    0.    0.  108.    0.] 
sum of rewards: 1283.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [23.  6.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2] -> size -> 82 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 17. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2] -> size -> 82 
adversary victory points: 9
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2] -> size -> 82 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14. 11. 16. 10. 25.] 
adversary cards in discard: [23.  6.  8. 10. 10.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2] -> size -> 82 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 17. 12. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14. 11. 16. 10. 25.] 
adversary cards in discard: [23.  6.  8. 10. 10.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3] -> size -> 83 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 17. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14. 11. 16. 10. 25.] 
adversary cards in discard: [23.  6.  8. 10. 10.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0. -480.
    0.    0.    4.    0.] 
sum of rewards: -301.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [14. 11. 16. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 16. 10. 25.] 
cards in discard: [23.  6.  8. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 1. 2. 3. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3] -> size -> 83 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 16. 10. 25.] 
cards in discard: [23.  6.  8. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 17. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 1. 2. 3. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3] -> size -> 83 
adversary victory points: 10
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 2. 3. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 2. 3. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3] -> size -> 83 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14.  3. 10.  3.  3.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 3. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3] -> size -> 83 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 17. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14.  3. 10.  3.  3.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 3. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [14.  3. 10.  3.  3.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0. 1500.    0. -490.
    0.    0.  108.    0.] 
sum of rewards: 1293.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [14.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10.  3.  3.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  3.  1.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  9.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
adversary victory points: 10
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-14.545166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16. 23.  3.  8.  0.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29. 10. 14.  3.  3.  3.  1.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14 29] -> size -> 28 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[   -5     0     0   180     0     0     0     0     0 21000     0  -490
     0  -300  3701     0] 
sum of rewards: 24086 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -14.545166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]
 [-14.545164]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2] -> size -> 84 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 16. 11. 30.  8.  6.  6.  6.  1.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16. 23.  3.  8.  0.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29. 10. 14.  3.  3.  3.  1.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14 29] -> size -> 28 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.545166015625



buy possibilites: [-1] 
expected returns: [[-14.545166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2 3] -> size -> 85 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 16. 10. 30.  8.  6.  6.  6.  1.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [16. 23.  3.  8.  0.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29. 10. 14.  3.  3.  3.  1.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14 29] -> size -> 28 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0.    0.    0. -500.
    0.    0.    4.    0.] 
sum of rewards: -291.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.545166015625






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [16. 23.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 23.  3.  8.  0.] 
cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29. 10. 14.  3.  3.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11  8 10  8  3 25
 23  8 14 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 10. 30.  8.  6.  6.  6.  1.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [1. 0. 1. 0. 2.] 
adversary cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2 3] -> size -> 85 
adversary victory points: 11
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 25 
Silver: 24 
Gold: 14 
Estate: 10 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 0. 1. 0. 2.] 
cards in discard: [3. 1. 0. 3. 0. 0. 3. 0. 3. 1. 0. 0. 6. 2. 0. 0. 2. 0. 2. 2. 2. 0. 0. 1.
 0. 2. 0. 3. 1. 2. 1. 2. 1. 0. 2. 0. 1. 3. 3. 3. 1. 0. 1. 2. 0. 1. 2. 3.
 2. 0. 1. 3. 0. 0. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 6 1 1 1 1 1 2 3 3 3 2 2 2 3 3 2 2 2 2 2
 3 3 3 6 2 2 2 2 3 2 3] -> size -> 85 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 10. 30.  8.  6.  6.  6.  0.  8.  8.  8.  7.  5. 10.  9.] 
adversary cards in hand: [23.  3.  0.] 
adversary cards in discard: [23.  6.  8. 10. 10. 14. 11. 16. 10. 25. 29. 10. 14.  3.  3.  3.  1.  8.] 
adversary owned cards: [16 16 10 10 14  3  3  0 25 23 10 16 11  1  3 10  6  3 11 10  8  3 25 23
  8 14 29  8] -> size -> 28 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[     -5 3000000       0     210       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000205 

action type: buy - action -1
Learning step: 300021.96875
desired expected reward: 300007.4375



