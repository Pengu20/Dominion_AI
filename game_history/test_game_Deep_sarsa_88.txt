 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.98544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000078 

action type: buy - action 11.0
Learning step: -300010.09375
desired expected reward: -299987.0





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.104702]
 [69.9089  ]
 [56.957104]
 [23.718283]
 [77.81934 ]
 [56.64342 ]
 [46.02275 ]
 [42.344254]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.98844528198242



buy possibilites: [-1] 
expected returns: [[32.448666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 77.8193588256836






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[46.128162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.448665618896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 42.884792]
 [ 76.5005  ]
 [ 62.77167 ]
 [ 25.164778]
 [ 64.87189 ]
 [ 84.55423 ]
 [ 62.60626 ]
 [109.36622 ]
 [ 38.710823]
 [ 49.868004]
 [ 69.919044]
 [ 45.34839 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.58208465576172



buy possibilites: [-1] 
expected returns: [[14.498998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.36622619628906






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.49594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.498997688293457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.494144]
 [48.770767]
 [39.79466 ]
 [ 9.915268]
 [41.050724]
 [55.494606]
 [39.648052]
 [76.62925 ]
 [21.480381]
 [30.820335]
 [44.438984]
 [26.70345 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.527629852294922



buy possibilites: [-1] 
expected returns: [[12.30548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.62925720214844






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 7.211877]
 [36.409607]
 [26.98029 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.305480003356934



action possibilites: [-1. 11.] 
expected returns: [[24.132923]
 [53.358448]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.48695373535156



action possibilites: [-1] 
expected returns: [[34.074352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.96038818359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.992313]
 [59.57655 ]
 [50.98244 ]
 [25.272635]
 [51.82989 ]
 [65.21009 ]
 [50.761044]
 [81.99933 ]
 [35.499302]
 [42.764843]
 [55.385162]
 [38.2489  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.0743522644043



buy possibilites: [-1] 
expected returns: [[17.105759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.99931335449219






Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 4.691477]
 [18.59825 ]
 [18.59825 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.105758666992188



action possibilites: [-1. 29.] 
expected returns: [[21.142418]
 [58.3644  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.16393280029297



action possibilites: [-1.] 
expected returns: [[47.10249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.3643913269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 55.842064]
 [ 81.44167 ]
 [ 71.03361 ]
 [ 48.066196]
 [ 38.97256 ]
 [ 72.40578 ]
 [ 87.82987 ]
 [ 70.84107 ]
 [117.2414  ]
 [105.41968 ]
 [ 51.52816 ]
 [ 78.07454 ]
 [ 60.924114]
 [ 53.347794]
 [ 76.49248 ]
 [ 54.72857 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.10248947143555



buy possibilites: [-1] 
expected returns: [[39.377827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 117.24140930175781






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[ 6.860463]
 [31.123466]
 [ 8.661247]
 [22.054703]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  3.  0.] 
cards in discard: [25. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.37782669067383



action possibilites: [-1. 10. 11.] 
expected returns: [[19.456558]
 [23.418247]
 [45.207607]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [25. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.578083038330078



action possibilites: [-1] 
expected returns: [[31.693672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [25. 29. 29.  0.  3.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.83866882324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.05839 ]
 [59.236504]
 [51.40128 ]
 [28.866535]
 [62.203854]
 [51.910538]
 [44.43294 ]
 [38.027946]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [25. 29. 29.  0.  3.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.69367218017578



buy possibilites: [-1] 
expected returns: [[64.72208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [25. 29. 29.  0.  3.  3.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 62.20383834838867






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[20.48647 ]
 [41.497955]
 [25.108244]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.72207641601562



action possibilites: [-1] 
expected returns: [[14.756013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.46797561645508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.822313 ]
 [32.858593 ]
 [ 2.8236792]
 [32.865482 ]
 [19.45468  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.756012916564941



buy possibilites: [-1] 
expected returns: [[23.411467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.86548614501953






Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0. 11.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[11.071913]
 [16.568184]
 [49.130474]
 [37.4039  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.411466598510742



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[26.675829]
 [30.253887]
 [50.73244 ]
 [65.05976 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 29.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.771785736083984



action possibilites: [-1. 10. 11.] 
expected returns: [[ 77.24875 ]
 [ 81.03659 ]
 [103.022064]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 65.05978393554688



action possibilites: [-1] 
expected returns: [[80.13345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.76350402832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 86.06551 ]
 [107.072945]
 [ 98.07389 ]
 [ 78.149826]
 [ 68.62084 ]
 [ 99.8232  ]
 [112.61697 ]
 [ 98.0919  ]
 [140.29062 ]
 [129.33131 ]
 [ 82.32385 ]
 [104.35791 ]
 [ 90.3768  ]
 [ 83.70865 ]
 [102.535965]
 [ 86.4131  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.13345336914062



buy possibilites: [-1] 
expected returns: [[62.851254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 140.2906494140625






Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3.  3.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3.  3.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[44.08714]
 [72.14769]
 [65.6422 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  3.  3.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 10. 25. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.851253509521484



action possibilites: [-1] 
expected returns: [[12.0272875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.39417266845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.3255024]
 [19.242685 ]
 [-7.46949  ]
 [18.17971  ]
 [14.478602 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.027287483215332



buy possibilites: [-1] 
expected returns: [[36.84369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3. 10.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.242694854736328






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[46.14085]
 [67.09897]
 [49.49436]
 [56.26589]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  8.  0.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.84368896484375



action possibilites: [-1] 
expected returns: [[11.784852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.89883422851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.5602045]
 [26.585587 ]
 [ 1.9077837]
 [26.400429 ]
 [15.939494 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 26. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.784852027893066



buy possibilites: [-1] 
expected returns: [[25.11224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 26.585590362548828






Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6. 3. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6. 3. 0. 3. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29. 25.  3. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 25.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 11.] 
expected returns: [[ 83.28097]
 [107.92686]
 [115.48293]
 [107.92686]
 [ 97.92997]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 29. 11.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3 0] -> size -> 15 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.112239837646484



action possibilites: [-1] 
expected returns: [[12.974164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 11.  0. 10.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3 0 6] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.22492980957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.4995823]
 [-3.0003293]
 [11.553754 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 11.  0. 10.] 
cards in discard: [ 3. 25.  0. 29.  3.  3. 10.  0. 10.  3. 11.  0. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3 0 6] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.974164009094238






Player: 1 
cards in hand: [8. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 3 1 3 6 3 0 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[22.721128]
 [66.40995 ]
 [26.430805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [6. 0. 8. 1.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.553749084472656



action possibilites: [-1. 10.] 
expected returns: [[74.58205]
 [82.01851]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [6. 0. 8. 1.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 55.13277816772461



action possibilites: [-1.] 
expected returns: [[89.56094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [6. 0. 8. 1.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 82.01850128173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[112.64954 ]
 [139.85258 ]
 [101.62833 ]
 [127.99255 ]
 [103.6253  ]
 [ 91.95039 ]
 [131.5907  ]
 [144.7765  ]
 [128.44023 ]
 [177.67567 ]
 [165.12517 ]
 [106.60152 ]
 [136.75984 ]
 [116.422485]
 [110.024086]
 [133.64629 ]
 [106.56533 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  8.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [6. 0. 8. 1.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.56094360351562



buy possibilites: [-1] 
expected returns: [[96.57061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [6. 0. 8. 1.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 177.67567443847656






Player: 1 
cards in hand: [0. 3. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [6. 0. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10.  3. 29.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25] -> size -> 26 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [6. 0. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10.  3. 29.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25] -> size -> 26 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[32.703903]
 [34.675396]
 [46.72881 ]
 [34.675396]
 [56.166836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3. 29.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.57061004638672



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[28.60537 ]
 [27.801746]
 [42.61579 ]
 [27.801746]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  3.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.23295974731445



action possibilites: [-1] 
expected returns: [[79.02379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.69017028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.11446 ]
 [46.528625]
 [81.3033  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.02378845214844






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  8.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6. 0. 8. 1. 0. 3. 6. 3. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[69.144226]
 [72.84909 ]
 [84.71833 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 11.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.30329895019531



action possibilites: [-1] 
expected returns: [[89.7746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.84405517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.164764]
 [59.73405 ]
 [91.82962 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.77459716796875






Player: 1 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 10.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 10.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 10.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[16.560177]
 [49.984035]
 [64.956375]
 [15.532458]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 10.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.82960510253906



action possibilites: [-1] 
expected returns: [[54.516644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10. 25. 10.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6] -> size -> 13 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.95632934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.576664]
 [30.728756]
 [54.04581 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10. 25. 10.] 
cards in discard: [25. 29. 10.  0.  0.  0.  0.  0. 10. 29. 11. 10. 10.  3.  3. 10. 11.  8.
  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6] -> size -> 13 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.51664352416992






Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [8. 3. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[65.94664]
 [71.91143]
 [71.91143]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.04581069946289



action possibilites: [-1. 10. 25.] 
expected returns: [[ 92.889694]
 [ 99.188034]
 [152.16676 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 63.34208297729492



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[63.08534]
 [66.409  ]
 [90.70804]
 [90.70804]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0. 6.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.166748046875



action possibilites: [-1] 
expected returns: [[83.389244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0. 6.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.49728393554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.70925 ]
 [61.987408]
 [83.65018 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [1. 6. 6. 0. 3.] 
adversary cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0. 6.] 
adversary owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.38924407958984






Player: 1 
cards in hand: [1. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  8.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [8. 3. 6. 0. 8. 3. 3. 3. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 3 1 3 6 3 0 6 0 8 6 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  8.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  8.  3.  3.  3.  0.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  8.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[18.057884]
 [25.307964]
 [25.307964]
 [15.532067]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  8.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.6501693725586



action possibilites: [-1. 29.  8.] 
expected returns: [[36.613117]
 [60.198036]
 [40.593548]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8.  0.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.67270851135254



action possibilites: [-1.  8. 10.] 
expected returns: [[71.43138]
 [75.24213]
 [69.33652]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 25 10 11 10  8 10 25  3 10
  3 25 10 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.198055267333984



action possibilites: [-1] 
expected returns: [[83.18149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 83.77519226074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 58.95629 ]
 [ 91.55947 ]
 [ 86.74523 ]
 [ 46.885513]
 [ 38.687885]
 [ 75.7755  ]
 [107.308975]
 [ 82.93172 ]
 [127.40439 ]
 [111.80491 ]
 [ 59.565193]
 [ 85.84    ]
 [ 76.75791 ]
 [ 53.491436]
 [ 93.06413 ]
 [ 86.785034]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  7.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.18148803710938



buy possibilites: [-1] 
expected returns: [[66.58506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 425 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 127.40435791015625






Player: 1 
cards in hand: [6. 3. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 1.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[42.09448 ]
 [60.810795]
 [38.278263]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 10.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.5850601196289



action possibilites: [-1. 10.] 
expected returns: [[61.917988]
 [65.42825 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.8108024597168



action possibilites: [-1. 25.] 
expected returns: [[ 90.06951]
 [131.38448]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 65.42826843261719



action possibilites: [-1. 25. 10.] 
expected returns: [[ 67.46263 ]
 [119.5771  ]
 [ 72.537796]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25. 10.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  5. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 131.38446044921875



action possibilites: [-1] 
expected returns: [[198.01556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.  3.  3.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.5771255493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.51752]
 [223.7457 ]
 [213.71785]
 [172.18542]
 [213.13101]
 [231.94318]
 [212.91809]
 [247.53093]
 [190.39772]
 [202.89026]
 [219.6259 ]
 [199.29883]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.  3.  3.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 198.01556396484375



buy possibilites: [-1] 
expected returns: [[94.18349]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.  3.  3.] 
cards in discard: [10. 10. 25. 11.  3.  3. 10.  0. 11. 25. 29. 29.  8.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 3.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
adversary owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 247.53091430664062






Player: 1 
cards in hand: [8. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 3.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3  1  3  6  3  0  6  0  8  6  0  6 10  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 10.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[ 96.68401 ]
 [127.820435]
 [ 97.76295 ]
 [ 97.76295 ]
 [ 97.76295 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.18348693847656



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[135.82312]
 [140.60675]
 [140.60675]
 [140.60675]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.34138488769531



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[141.0282 ]
 [142.66737]
 [142.66737]
 [165.35596]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 140.6067657470703



action possibilites: [-1. 10. 10.] 
expected returns: [[136.29108]
 [141.87993]
 [141.87993]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 262 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 174.40512084960938



action possibilites: [-1. 10. 25.] 
expected returns: [[134.16916]
 [135.17029]
 [168.00897]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 25.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0] -> size -> 18 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 141.87991333007812



action possibilites: [-1. 10. 10.] 
expected returns: [[105.4686 ]
 [111.24412]
 [111.24412]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 168.00897216796875



action possibilites: [-1. 10. 10.] 
expected returns: [[ 97.27223]
 [100.45979]
 [100.45979]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 111.2441177368164



action possibilites: [-1. 10.] 
expected returns: [[95.74508]
 [97.15404]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 3 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 100.45980834960938



action possibilites: [-1.] 
expected returns: [[103.31195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 4 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 97.15406036376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 98.88621 ]
 [117.31987 ]
 [111.558334]
 [ 85.41847 ]
 [110.62387 ]
 [122.89668 ]
 [110.90282 ]
 [132.23586 ]
 [ 96.7991  ]
 [115.26653 ]
 [103.77258 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.31195068359375



buy possibilites: [-1] 
expected returns: [[71.52956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 11. 10. 25. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0 160   0   0   0   0   0   0   0 128   0] 
sum of rewards: 463 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 132.23585510253906






Player: 1 
cards in hand: [ 3. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  7.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [0. 6. 3. 6. 3. 1. 6. 6. 0. 8. 3. 3. 6. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 25. 25.  3. 29.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 25. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[10.398336]
 [41.306038]
 [48.38838 ]
 [48.38838 ]
 [41.306038]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  3. 29.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8] -> size -> 20 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.52955627441406



action possibilites: [-1] 
expected returns: [[82.6747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 29.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.38840866088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.94684]
 [81.5335 ]
 [71.7685 ]
 [81.28518]
 [79.63987]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 29.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.67469787597656



buy possibilites: [-1] 
expected returns: [[80.02971]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 29.  0.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  3.  3.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 81.53350067138672






Player: 1 
cards in hand: [10.  3.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  3.  6.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6] -> size -> 21 
action values: 2 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 3.] 
cards in discard: [6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[78.37186 ]
 [93.41371 ]
 [71.540085]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.02970886230469



action possibilites: [-1] 
expected returns: [[83.64034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 98.72648620605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.94105 ]
 [79.039444]
 [43.26151 ]
 [75.07755 ]
 [82.46574 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.64034271240234






Player: 1 
cards in hand: [6. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3. 29. 25. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3. 29. 25. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  3. 29. 25. 10.] 
adversary cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25. 10.] 
expected returns: [[111.34915 ]
 [106.803505]
 [130.67609 ]
 [142.76102 ]
 [102.66349 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29. 25. 10.] 
cards in discard: [10. 29. 29. 10. 11. 10. 25. 10. 10. 10.  3.  0.  3.  0.  0.  3. 25. 29.
 25.  3. 29.  0.  0. 15. 11. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  2. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.46577453613281



action possibilites: [-1] 
expected returns: [[43.71607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.76100158691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.778358]
 [16.339224]
 [35.36745 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.716068267822266






Player: 1 
cards in hand: [1. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6. 3. 0.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  3  6  3  6  0  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  0. 10.  3.  3.  3.  6.  3.  0.  6.  0.  6.  6.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[48.743423]
 [68.964005]
 [77.855446]
 [68.964005]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0. 29.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  1. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.3674430847168



action possibilites: [-1] 
expected returns: [[52.135582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  3. 25.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.85546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.459469]
 [52.329697]
 [48.317623]
 [56.65633 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 29.  3. 25.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.135581970214844






Player: 1 
cards in hand: [6. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[47.597042]
 [87.87161 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  0. 10.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.65629959106445



action possibilites: [-1.] 
expected returns: [[76.87578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  0. 10.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.0155029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[71.66194 ]
 [87.09528 ]
 [82.342766]
 [93.42155 ]
 [81.60692 ]
 [76.44846 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  8.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  0. 10.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.87577819824219



buy possibilites: [-1] 
expected returns: [[82.98165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8.  0. 10.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
adversary owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 93.42155456542969






Player: 1 
cards in hand: [ 6.  6.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8.  0. 10.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  3  6  8  6  0  6 10  0  6  6  0  6  8  6  0  0  6  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 15. 10. 11. 10.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 15. 10. 11. 10.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 15. 10. 11. 10.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 15. 10. 11. 10.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 15. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 11. 10.] 
expected returns: [[87.61058 ]
 [94.53505 ]
 [81.56381 ]
 [72.504486]
 [94.53505 ]
 [72.504486]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 11. 10.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.98165130615234



action possibilites: [-1] 
expected returns: [[15.707156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 10.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 302 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 78.69932556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 4.1498938]
 [15.544812 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11. 10.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.70715618133545






Player: 1 
cards in hand: [3. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  3. 25.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  3. 25.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10. 10.  3. 25.] 
adversary cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 25.] 
expected returns: [[104.92623]
 [ 94.89562]
 [ 94.89562]
 [ 94.89562]
 [129.93242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3. 25.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.544806480407715



action possibilites: [-1] 
expected returns: [[33.690464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.  0. 10.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.9324188232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.008769]
 [30.751865]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.  0. 10.] 
cards in discard: [25.  8.  3. 29. 10.  0. 10. 25.  0. 29.  0. 29.  3. 25.  0.  3. 11. 29.
  3.  0.  0.  1. 11. 15. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.69046401977539






Player: 1 
cards in hand: [6. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 24. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [6. 0. 6. 0. 6. 6. 8. 0. 8. 6. 0. 0. 3. 6. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.] 
expected returns: [[122.40994]
 [146.01193]
 [130.29886]
 [146.01193]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  3. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.751876831054688



action possibilites: [-1. 29. 10.] 
expected returns: [[ 94.74271 ]
 [118.613335]
 [ 93.40069 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.] 
cards in discard: [15.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 143.5325164794922



action possibilites: [-1. 10.] 
expected returns: [[78.644424]
 [78.476944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.49484252929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[71.72194]
 [85.39545]
 [84.53908]
 [78.58741]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1] -> size -> 36 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 23. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.64442443847656



buy possibilites: [-1] 
expected returns: [[112.89157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 85.39543151855469






Player: 1 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  6.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[113.0403  ]
 [104.691635]
 [130.84003 ]
 [104.691635]
 [150.85663 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 25.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.89157104492188



action possibilites: [-1] 
expected returns: [[103.1396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 10. 25.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.85671997070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 83.848236]
 [102.213455]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10. 10. 25.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.13960266113281






Player: 1 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [8. 3. 0. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 29.  3.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [8. 3. 0. 6. 0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 29.  3.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
adversary victory points: 7
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[74.186066]
 [68.3042  ]
 [96.22507 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  3.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 102.21345520019531



action possibilites: [-1. 10. 29.] 
expected returns: [[38.52376 ]
 [24.783257]
 [60.508495]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.78675079345703



action possibilites: [-1. 10.] 
expected returns: [[41.51281 ]
 [37.723736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.6165885925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.24192 ]
 [42.770016]
 [41.498653]
 [40.962444]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3] -> size -> 37 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 22. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.51280975341797



buy possibilites: [-1] 
expected returns: [[62.710827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 42.770015716552734






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[164.71904]
 [147.35756]
 [167.18181]
 [172.43518]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25.  3.  0.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.7108268737793



action possibilites: [-1] 
expected returns: [[175.64441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0. 10.  3.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 172.43516540527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[145.93884]
 [169.89357]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  0. 10.  3.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 175.6444091796875






Player: 1 
cards in hand: [3. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  1. 25.  0. 29.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  1. 25.  0. 29.] 
adversary cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
adversary victory points: 8
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[10.614449]
 [29.037949]
 [21.634647]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  0. 29.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 169.8935546875



action possibilites: [-1] 
expected returns: [[-0.08581305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29.  0.  0.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.037960052490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-14.463917  ]
 [ -6.2792196 ]
 [ -6.9364667 ]
 [-15.5475645 ]
 [-13.11352   ]
 [  2.8179138 ]
 [ -9.127607  ]
 [  9.522733  ]
 [  1.680805  ]
 [-12.608266  ]
 [ -8.977347  ]
 [-15.258628  ]
 [ -4.2437406 ]
 [ -0.08583117]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29.  0.  0.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  6.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.08581304550170898



buy possibilites: [-1] 
expected returns: [[-18.157473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29.  0.  0.] 
cards in discard: [15.  3.  0. 10.  3. 29. 29. 10. 25.  3. 10. 11. 10. 10. 25.  0.  0.  3.
 10.  3. 29. 29. 10. 25.  8. 11.  3.  0. 10.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -40   0   0 250   0] 
sum of rewards: 525 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 9.522744178771973






Player: 1 
cards in hand: [3. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25] -> size -> 39 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [8. 3. 0. 6. 0. 6. 0. 8. 6. 0. 3. 0. 8. 3. 0. 0. 0. 3. 6. 3. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10. 10. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25] -> size -> 39 
adversary victory points: 8
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[106.21394]
 [104.10281]
 [104.10281]
 [104.10281]
 [124.92268]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -18.157472610473633



action possibilites: [-1] 
expected returns: [[82.64698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 292 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 116.2655258178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[77.74779]
 [82.72664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.64698028564453






Player: 1 
cards in hand: [3. 6. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 25.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 25.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 25.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25.] 
expected returns: [[137.09106 ]
 [127.2289  ]
 [121.107376]
 [177.54474 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 25.  3.] 
cards in discard: [ 1. 11.  0. 10. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.72663116455078



action possibilites: [-1] 
expected returns: [[120.260864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.  1.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.5447235107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 94.119934]
 [111.96203 ]
 [109.871666]
 [123.0697  ]
 [107.1446  ]
 [116.142105]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  3.  1.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  7.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.2608642578125



buy possibilites: [-1] 
expected returns: [[128.45312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  3.  1.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 123.06969451904297






Player: 1 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [0. 3. 6. 3. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 25.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 6. 3. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 25.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 6. 3. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  5.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 25.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 25.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25. 10. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 10. 25.] 
expected returns: [[ 81.77048 ]
 [107.48082 ]
 [ 68.888695]
 [ 89.911865]
 [ 68.888695]
 [107.48082 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 10. 25.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.453125



action possibilites: [-1] 
expected returns: [[61.64166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 25. 11. 10.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.48081970214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.61646]
 [61.68588]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 25. 11. 10.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.641658782958984






Player: 1 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[77.28528 ]
 [91.526306]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.68587875366211



action possibilites: [-1.] 
expected returns: [[85.33505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.38482666015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[70.19058 ]
 [89.840935]
 [84.837135]
 [97.84709 ]
 [83.34245 ]
 [81.16904 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  6.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.33505249023438



buy possibilites: [-1] 
expected returns: [[21.546307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.84707641601562






Player: 1 
cards in hand: [0. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 15. 25.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  4.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 15. 25.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3. 15. 25.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  3. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 25.] 
expected returns: [[ 80.77284 ]
 [ 67.77474 ]
 [ 80.532486]
 [112.252785]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15. 25.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.546306610107422



action possibilites: [-1] 
expected returns: [[35.863632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.  0. 29.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.25279235839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.6521  ]
 [36.571335]
 [35.022835]
 [35.863644]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.  0. 29.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.86363220214844



buy possibilites: [-1] 
expected returns: [[54.11662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.  0. 29.  0.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 251 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.57133102416992






Player: 1 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  3.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [0. 3. 6. 3. 6. 3. 8. 8. 0. 0. 3. 0. 8. 0. 6. 6. 0. 8. 0. 3. 0. 6. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  3.  3.  3.] 
adversary cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 29.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[102.60565]
 [135.64772]
 [119.10056]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  3.  3.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 31 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.11661911010742



action possibilites: [-1] 
expected returns: [[86.273506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  3. 29. 29.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 31 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.64772033691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.172295]
 [86.273506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  3. 29. 29.] 
cards in discard: [ 1. 11.  0. 10. 10. 10. 11. 25.  3.  8. 10.  3.  1.  0. 25. 10. 11. 10.
 25. 11. 10.  0.  3. 11. 29.  0.  3.  0.  3. 25. 10.  3. 15.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 31 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.27350616455078






Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 0 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 25. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 25. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 20. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 25. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 25. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 25. 25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25. 29. 10.] 
expected returns: [[ 97.37409]
 [ 94.57885]
 [133.5008 ]
 [133.5008 ]
 [123.11506]
 [ 94.57885]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 25. 29. 10.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 31 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.27350616455078



action possibilites: [-1] 
expected returns: [[126.27931]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 29. 10. 29. 25.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 31 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.50079345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 83.31404 ]
 [126.400024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25. 29. 10. 29. 25.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 3. 0. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 31 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.27931213378906






Player: 1 
cards in hand: [6. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 8.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 3 8 6 0 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 8. 0. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[ 88.67337 ]
 [ 78.77843 ]
 [ 78.77843 ]
 [114.959076]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  3. 11.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
adversary owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.40005493164062



action possibilites: [-1] 
expected returns: [[86.04007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
adversary owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 97.68827819824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[57.215717]
 [91.34992 ]
 [87.990746]
 [87.814125]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 19. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
adversary owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.04006958007812



buy possibilites: [-1] 
expected returns: [[90.31231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
adversary owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 91.34992980957031






Player: 1 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 6 6 0 6 8 6 0 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 11. 29. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 11.] 
expected returns: [[118.18142]
 [111.94335]
 [133.0561 ]
 [134.30756]
 [133.0561 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 29. 11.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
adversary owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.31230926513672



action possibilites: [-1.  8. 11.] 
expected returns: [[104.13728]
 [ 91.68265]
 [119.89558]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
adversary owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 119.67529296875



action possibilites: [-1] 
expected returns: [[86.8131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
adversary owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 100.3254623413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[56.6005 ]
 [78.98332]
 [74.91894]
 [86.32205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
adversary owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.81310272216797






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 3 3 8 6 6 8 6 0 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 25.  3. 10.  3.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 25.  3. 10.  3.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 25.  3. 10.  3.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 98.102905]
 [127.04379 ]
 [ 86.75477 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3. 10.  3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.32205963134766



action possibilites: [-1] 
expected returns: [[101.7928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  3.  3. 25.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.04379272460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 65.95633 ]
 [ 90.667946]
 [ 85.96741 ]
 [101.7928  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  3.  3. 25.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.79280090332031






Player: 1 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 10. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 10. 11.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[47.133755]
 [38.68553 ]
 [38.68553 ]
 [64.06607 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 11.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.79280090332031



action possibilites: [-1] 
expected returns: [[59.054405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 252 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 50.500919342041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.997967]
 [59.054432]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 6. 8.] 
adversary cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.054405212402344






Player: 1 
cards in hand: [6. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 8.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 8.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 8.] 
cards in discard: [3. 8. 0. 0. 3. 0. 8. 6. 0. 8. 0. 8. 0. 0. 6. 6. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-13.674598]
 [ -1.283649]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 29.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.054405212402344



action possibilites: [-1.] 
expected returns: [[-8.339119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.047677040100098





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.518559]
 [ -8.339127]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.339118957519531






Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 15.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 18. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 15.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29. 15.] 
adversary cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[66.41529]
 [76.78062]
 [77.36253]
 [65.56368]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29. 15.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.339118957519531



action possibilites: [-1. 11. 15.] 
expected returns: [[154.40205]
 [166.9928 ]
 [154.1041 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.53847122192383



action possibilites: [-1] 
expected returns: [[120.60593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 232 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 151.964599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 85.801865]
 [113.23652 ]
 [108.63411 ]
 [120.60594 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [25. 10. 25. 29. 10. 29. 25.  1.  3. 11.  1. 10. 10.  3. 11. 10.  1. 29.
 11.  8.  0. 25.  1.  3. 10.  3.  3. 25.  1. 11.  3.  0. 10. 10.  3.  0.
 29.  3.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3.] 
adversary owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.60592651367188






Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [3. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 8 6 6 0 6 0 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[116.259056]
 [124.50061 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.60592651367188



action possibilites: [-1.] 
expected returns: [[123.85312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 112.7000732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[100.89508 ]
 [120.976135]
 [119.84322 ]
 [ 91.48302 ]
 [110.01734 ]
 [133.6206  ]
 [116.585205]
 [141.64389 ]
 [131.80583 ]
 [102.91953 ]
 [116.99575 ]
 [ 96.44351 ]
 [123.74835 ]
 [127.06824 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  5.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.85311889648438



buy possibilites: [-1] 
expected returns: [[90.841484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 25. 25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 3. 8. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -140    0    0
  250    0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.64389038085938






Player: 1 
cards in hand: [8. 3. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[116.74066]
 [105.70669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.84148406982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 94.46609]
 [135.64114]
 [126.10782]
 [152.78064]
 [121.81142]
 [122.36289]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  5.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.74065399169922



buy possibilites: [-1] 
expected returns: [[108.66322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 152.7806396484375






Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  1. 11.  8.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11] -> size -> 50 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 17. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  1. 11.  8.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11] -> size -> 50 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 16. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  1. 11.  8.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11] -> size -> 50 
adversary victory points: 10
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[134.58478]
 [165.89236]
 [142.17603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1. 11.  8.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 16. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.66322326660156



action possibilites: [-1] 
expected returns: [[75.948555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 153.61383056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 58.761177]
 [ 86.564995]
 [ 78.28531 ]
 [ 74.92371 ]
 [ 97.08094 ]
 [ 76.642654]
 [109.45255 ]
 [ 56.313454]
 [ 84.158035]
 [ 73.93779 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 16. 30.  8.  0. 10.  4.  2.  4.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.94855499267578



buy possibilites: [-1] 
expected returns: [[147.28574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -170    0    0
  128    0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.45256042480469






Player: 1 
cards in hand: [0. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 16. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 16. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [3. 0. 6. 0. 6. 3. 8. 0. 0. 8. 3. 3. 8. 6. 3. 8. 8. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 11.] 
expected returns: [[117.657326]
 [100.05242 ]
 [133.5949  ]
 [100.05242 ]
 [130.32086 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  3. 11.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 26 
adversary victory points: 3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.28573608398438



action possibilites: [-1. 10. 10.] 
expected returns: [[156.19806]
 [134.55646]
 [134.55646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 26 
adversary victory points: 3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 111.11593627929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[113.324844]
 [156.19806 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 6. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 26 
adversary victory points: 3
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 156.1980438232422






Player: 1 
cards in hand: [8. 6. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 8 6 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
adversary victory points: 10
player victory points: 5 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 97.644615]
 [127.39389 ]
 [ 84.53091 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 24 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.1980438232422



action possibilites: [-1] 
expected returns: [[66.298615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 24 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 105.59217834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.403156]
 [66.2986  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 24 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.29861450195312






Player: 1 
cards in hand: [6. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [0. 8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 6 6 0 0 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [0. 8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3. 11.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 11.] 
expected returns: [[10.349399]
 [30.375362]
 [17.975922]
 [14.093427]
 [17.975922]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  3. 11.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.29861450195312



action possibilites: [-1] 
expected returns: [[-18.051813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 11. 10. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.375377655029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.301716]
 [-18.051819]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3. 11. 10. 10.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.05181312561035






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[ 90.158646]
 [112.95153 ]
 [112.95153 ]
 [100.7341  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  0. 29.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -18.05181312561035



action possibilites: [-1] 
expected returns: [[93.845024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29. 15.  3.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.95150756835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.964756]
 [87.15695 ]
 [82.67145 ]
 [93.84506 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 29. 15.  3.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.84502410888672






Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 3 8 0 0 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10.  3. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10.  3. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10.  3. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3. 10.  3. 29.] 
adversary cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[58.503372]
 [50.818142]
 [74.85138 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  3. 29.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.84502410888672



action possibilites: [-1. 25.] 
expected returns: [[35.5505  ]
 [62.716778]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.] 
cards in discard: [ 0. 25. 25. 29.  1.  0.  0. 11. 10.  1.  3.  0.  3.  1. 29. 11.  1.  3.
  1.  8. 11. 10. 29. 10.  3. 10.  1. 11.  3.  3.  0. 10. 25. 11. 29.  3.
 11. 10. 10. 25.  0. 25.  0. 29. 15.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 59.85896682739258



action possibilites: [-1] 
expected returns: [[105.5356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  1.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.71682357788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 92.12863 ]
 [116.94944 ]
 [109.585236]
 [ 83.10177 ]
 [106.8556  ]
 [126.49199 ]
 [108.26556 ]
 [152.32878 ]
 [139.40724 ]
 [ 90.257645]
 [113.36944 ]
 [ 88.49324 ]
 [114.70135 ]
 [103.85236 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  1.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  4.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.53559875488281



buy possibilites: [-1] 
expected returns: [[186.1867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  1.] 
cards in discard: [25.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -190    0    0
  250    0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 152.32879638671875






Player: 1 
cards in hand: [3. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 29.  1. 29.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 29.  1. 29.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [0. 8. 8. 0. 8. 6. 1. 0. 0. 0. 3. 3. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 29.  1. 29.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[113.81296]
 [138.62155]
 [ 93.95896]
 [140.48238]
 [140.48238]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  1. 29.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.18670654296875



action possibilites: [-1. 10. 29.] 
expected returns: [[103.778336]
 [ 76.19878 ]
 [111.37053 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 29.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 144.07290649414062



action possibilites: [-1.] 
expected returns: [[93.13225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.47779846191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 55.60343 ]
 [ 96.85169 ]
 [ 89.69719 ]
 [ 76.19711 ]
 [117.86232 ]
 [ 85.02675 ]
 [123.98909 ]
 [ 58.136093]
 [ 98.06362 ]
 [ 92.99812 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.13224792480469



buy possibilites: [-1] 
expected returns: [[-1.6036611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -200    0    0
  128    0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.98912048339844






Player: 1 
cards in hand: [8. 8. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 0 8 8 3 0 0 0 3 0 3 3 0 0 1 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[67.13043 ]
 [61.421597]
 [78.85496 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 20. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.603661060333252



action possibilites: [-1] 
expected returns: [[73.268326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 70.14877319335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[51.978867]
 [65.81857 ]
 [63.353718]
 [73.268295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.26832580566406






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  1.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  2.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  1.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  1.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[132.52576]
 [165.18095]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  1.  3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.26832580566406



action possibilites: [-1] 
expected returns: [[115.41279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 3. 3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.18093872070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 93.393005]
 [113.11804 ]
 [110.82514 ]
 [127.05229 ]
 [107.84819 ]
 [115.41279 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 3. 3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  4.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.41278839111328



buy possibilites: [-1] 
expected returns: [[89.35026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 3. 3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -220    0    0
   54    0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 127.05227661132812






Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  3.  0.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 19. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  3.  0.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 25.  3.  0.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-20.095839]
 [-32.025936]
 [ -5.573611]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  3.  0.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 6.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.35025787353516



action possibilites: [-1] 
expected returns: [[16.434078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 11. 29.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 6.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.573598861694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.030116]
 [16.434101]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0. 11. 29.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 6.] 
adversary cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
adversary owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.434078216552734






Player: 1 
cards in hand: [0. 0. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 6.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 0 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 25. 25.  1.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 25. 25.  1.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [0. 8. 0. 6. 8. 0. 3. 3. 0. 3. 1. 0. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 10. 25. 25.  1.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [11. 10. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 25.] 
expected returns: [[31.541409]
 [41.533974]
 [13.248176]
 [53.823387]
 [53.823387]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25. 25.  1.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.434078216552734



action possibilites: [-1] 
expected returns: [[39.92833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.  1.  3.  0.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.82339859008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[14.4311495]
 [47.165775 ]
 [40.60156  ]
 [64.01623  ]
 [37.163998 ]
 [39.928314 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  1.  3.  0.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  3.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.92832946777344



buy possibilites: [-1] 
expected returns: [[-6.9996605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  1.  3.  0.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -230    0    0
   54    0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.01625061035156






Player: 1 
cards in hand: [3. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  1. 11. 15.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11] -> size -> 58 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 18. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  1. 11. 15.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11] -> size -> 58 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 3.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 18. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  1. 11. 15.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11] -> size -> 58 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
expected returns: [[58.386776]
 [44.226555]
 [73.91505 ]
 [57.287327]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11. 15.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 18. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 3.] 
adversary cards in discard: [0. 3. 8. 6. 0. 3.] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.999660491943359



action possibilites: [-1] 
expected returns: [[31.954998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 15.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 3.] 
adversary cards in discard: [0. 3. 8. 6. 0. 3.] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 54.08808517456055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[-8.2483  ]
 [22.34997 ]
 [20.218197]
 [43.04974 ]
 [14.813088]
 [31.955051]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 15.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  2.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 3.] 
adversary cards in discard: [0. 3. 8. 6. 0. 3.] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.954998016357422



buy possibilites: [-1] 
expected returns: [[17.203379]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 15.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  1.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 3.] 
adversary cards in discard: [0. 3. 8. 6. 0. 3.] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -250    0    0
   54    0] 
sum of rewards: -1 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.04972457885742






Player: 1 
cards in hand: [1. 8. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8. 3. 3.] 
cards in discard: [0. 3. 8. 6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  1.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  1. 29.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1. 11. 11.  8.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1 11] -> size -> 60 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 8. 3. 3.] 
cards in discard: [0. 3. 8. 6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  1.  1.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  1. 29.  3.] 
adversary cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1. 11. 11.  8.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1 11] -> size -> 60 
adversary victory points: 10
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 1 
Witch: 7 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 29.  1. 29.  3.] 
cards in discard: [25. 29. 25.  1.  3. 10.  1. 11. 11. 10.  1. 29. 29. 29.  1.  1. 11.  0.
  0. 10.  3. 11. 25.  3.  0.  1.  3.  3.  3. 25.  3. 10.  3.  0. 11. 29.
 11. 25. 11. 10. 25.  1.  3.  0.  1. 11. 11.  8.  0.  1. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 29 25 10 11 10  8 10 25  3 10  3
 25 10 10 10 25 29 10 29  3 15 11  1  3  3 25  1 11 11  3  1  3  1  1  1
 25 11  1 29  1 25 29  1 11 11  1 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 17. 30. 15. 30.  8.  0. 10.  1.  0.  3.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 3.] 
adversary cards in discard: [0. 3. 8. 6. 0. 3. 8.] 
adversary owned cards: [3 6 6 3 8 8 8 3 0 0 0 3 0 3 3 0 0 0 0 0 8 1 0 8] -> size -> 24 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000175 

action type: buy - action -1
Learning step: 300015.78125
desired expected reward: 300033.0



