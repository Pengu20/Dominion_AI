 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[279.3949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   4  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 549 

action type: buy - action -1.0
Learning step: 28.190887451171875
desired expected reward: 13.373153686523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.0279 ]
 [270.76816]
 [263.83395]
 [215.18564]
 [283.04382]
 [265.62775]
 [262.06747]
 [286.41306]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.98300313949585
desired expected reward: 273.1255187988281



buy possibilites: [-1] 
expected returns: [[259.8316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.435177803039551
desired expected reward: 258.1925964355469






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[272.53583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.966744899749756
desired expected reward: 252.86485290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[255.21562]
 [271.61224]
 [263.22647]
 [224.65752]
 [262.0681 ]
 [279.70294]
 [268.11642]
 [267.58093]
 [238.09042]
 [261.6588 ]
 [253.81685]
 [279.2725 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.635502815246582
desired expected reward: 264.57940673828125



buy possibilites: [-1] 
expected returns: [[267.02045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -7.852189064025879
desired expected reward: 271.85076904296875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.85678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.232369899749756
desired expected reward: 259.7880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.02966]
 [269.22717]
 [260.28842]
 [216.82059]
 [277.94986]
 [265.78232]
 [259.43933]
 [277.1547 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.870184421539307
desired expected reward: 268.5143737792969



buy possibilites: [-1] 
expected returns: [[279.77103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.90663480758667
desired expected reward: 244.12303161621094






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [8. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8.  3.  0.  0.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[276.297 ]
 [274.0634]
 [263.2367]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.919217109680176
desired expected reward: 271.851806640625



action possibilites: [-1] 
expected returns: [[310.9062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 4
Learning step: -5.468902587890625
desired expected reward: 250.81692504882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[275.07336]
 [287.86935]
 [237.07887]
 [288.45627]
 [309.947  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.563709259033203
desired expected reward: 302.34246826171875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[289.18317]
 [271.36798]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.675840377807617
desired expected reward: 300.2711181640625



action possibilites: [-1] 
expected returns: [[298.8745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.918878078460693
desired expected reward: 272.95220947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[263.9264 ]
 [271.81744]
 [233.10426]
 [274.87833]
 [286.57858]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.37772274017334
desired expected reward: 290.4967956542969



buy possibilites: [-1] 
expected returns: [[296.8933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  8. 25.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -19.650135040283203
desired expected reward: 202.9545440673828






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 25.  0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25.  0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25.  0.] 
cards in discard: [11.  0.  0.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[265.42764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -10.082717895507812
desired expected reward: 286.81060791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[238.66588]
 [257.55484]
 [249.35564]
 [197.77664]
 [266.80328]
 [252.24783]
 [246.38092]
 [268.14536]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.653302192687988
desired expected reward: 256.3221740722656



buy possibilites: [-1] 
expected returns: [[245.5978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 11.0
Learning step: -8.114214897155762
desired expected reward: 258.6890869140625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  7.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  6.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[221.13148]
 [219.86565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.504664421081543
desired expected reward: 237.09312438964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[202.21219]
 [210.4389 ]
 [168.5665 ]
 [214.1179 ]
 [226.66472]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  6 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.425262451171875
desired expected reward: 214.04367065429688



buy possibilites: [-1] 
expected returns: [[273.93405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -6.647091865539551
desired expected reward: 195.5650634765625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [11. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 8.] 
cards in discard: [11. 11.  0.  0.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[212.75371]
 [198.13539]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  6 11  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: -25.751636505126953
desired expected reward: 248.1824188232422



action possibilites: [-1] 
expected returns: [[272.64905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.99353551864624
desired expected reward: 191.56924438476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.37358]
 [263.44928]
 [258.1021 ]
 [226.18768]
 [270.2172 ]
 [261.10907]
 [257.86816]
 [271.81927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -8.976851463317871
desired expected reward: 263.6722106933594






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[217.75009]
 [205.26686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -11.078120231628418
desired expected reward: 260.74114990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[190.02151]
 [205.55728]
 [198.37085]
 [157.74794]
 [213.08119]
 [201.37648]
 [195.8957 ]
 [214.0684 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  8. 10.  6.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -8.52219295501709
desired expected reward: 208.39559936523438



buy possibilites: [-1] 
expected returns: [[250.77057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  7. 10.  6.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10] -> size -> 19 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -357.0 

action type: buy - action 6.0
Learning step: -20.095056533813477
desired expected reward: 137.65283203125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [10.  0.  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7. 10.  6.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [6. 8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[195.72208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6. 8. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -10.920244216918945
desired expected reward: 239.85032653808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.66801]
 [188.4225 ]
 [183.65889]
 [148.3712 ]
 [197.91159]
 [185.1164 ]
 [182.79727]
 [200.89873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [6. 8. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -8.463335037231445
desired expected reward: 190.12709045410156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 25. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3.  3.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  3.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  3.] 
cards in discard: [10.  0.  0.  1.  0.  3. 29.  1. 11.  0.  8.  0.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  6.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[172.62505]
 [164.82503]
 [172.8581 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -8.286819458007812
desired expected reward: 176.2924346923828



action possibilites: [-1] 
expected returns: [[148.17902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: -6.772578716278076
desired expected reward: 167.3595428466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[130.7482  ]
 [100.625145]
 [149.19205 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -6.15471887588501
desired expected reward: 142.0242919921875






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[219.9382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10. 11.  3.  6.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  1. 10.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -5.381558895111084
desired expected reward: 143.8104705810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[192.96951]
 [207.36128]
 [202.29044]
 [164.01299]
 [198.91283]
 [216.79105]
 [202.96371]
 [202.92456]
 [179.47467]
 [200.32983]
 [193.73859]
 [219.73596]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10. 11.  3.  6.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  1. 10.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -9.097753524780273
desired expected reward: 209.9263916015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 10.] 
cards in discard: [14.  0.  0.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 10.] 
cards in discard: [14.  0.  0.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[187.72691]
 [174.39297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -9.725428581237793
desired expected reward: 210.01051330566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.69843]
 [172.16026]
 [128.92847]
 [175.76006]
 [189.00989]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -8.162642478942871
desired expected reward: 177.92063903808594



buy possibilites: [-1] 
expected returns: [[163.04527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -38 

action type: buy - action 3.0
Learning step: -6.839494228363037
desired expected reward: 165.32077026367188






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29. 11.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  8.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[113.61576]
 [111.11724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [3. 6. 8. 6. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0.  0.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -7.977133274078369
desired expected reward: 155.06814575195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.038704]
 [ 98.78498 ]
 [ 94.072296]
 [ 65.14117 ]
 [106.702736]
 [ 94.605545]
 [ 92.21841 ]
 [109.09599 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [3. 6. 8. 6. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0.  0.] 
adversary cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -5.55527925491333
desired expected reward: 105.07837677001953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  0.  0.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  6.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [14.  0.  0.  0. 14.  0.  3.  3.  0.  1. 10.  8. 10. 29. 11.  0.  0. 11.
  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[127.73601]
 [111.30761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.893579006195068
desired expected reward: 104.2024154663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[112.335464]
 [118.70082 ]
 [ 88.63534 ]
 [123.841354]
 [134.59015 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -6.052780628204346
desired expected reward: 125.2781982421875



buy possibilites: [-1] 
expected returns: [[137.26384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -357.0 

action type: buy - action 6.0
Learning step: -19.193330764770508
desired expected reward: 69.44200897216797






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11. 11.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11.  6.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  7.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[139.90974]
 [139.25404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: discard_down_to_3_cards - action 0
Learning step: -4.513370513916016
desired expected reward: 90.74737548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.015205]
 [ 79.99042 ]
 [130.52226 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -6.517414093017578
desired expected reward: 120.05964660644531



buy possibilites: [-1] 
expected returns: [[158.69302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -368 

action type: buy - action 6.0
Learning step: -18.828927993774414
desired expected reward: 61.1614990234375






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [29.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3. 10.] 
cards in discard: [ 8. 14. 11. 11.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6] -> size -> 17 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3. 10.] 
cards in discard: [ 8. 14. 11. 11.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.  6. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6] -> size -> 17 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[128.94379]
 [120.29405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.  6. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -8.52258014678955
desired expected reward: 150.17044067382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[111.62739 ]
 [123.13631 ]
 [119.044586]
 [ 92.7221  ]
 [128.36272 ]
 [119.01166 ]
 [115.9529  ]
 [127.61088 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.  6. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  5.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -6.998205661773682
desired expected reward: 120.20082092285156



buy possibilites: [-1] 
expected returns: [[138.01945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  3. 10.  6.  0.  0.  0.  0.  6.  6. 11.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3. 10.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -50 

action type: buy - action 11.0
Learning step: -5.8126959800720215
desired expected reward: 122.54998779296875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3. 10.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3.  0.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  3.  0.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  3.  0.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [10.  8.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[108.05743]
 [ 92.66596]
 [ 98.01255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  6.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -8.527195930480957
desired expected reward: 129.4922637939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 87.56167 ]
 [ 60.37215 ]
 [107.632744]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  6.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.97774076461792
desired expected reward: 97.93582916259766



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [25.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14.  0.  0.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 14.  0.  0.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[133.97949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  8.  6.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  1.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -6.335947513580322
desired expected reward: 101.29682922363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[115.258064]
 [123.533195]
 [120.08568 ]
 [ 89.52949 ]
 [128.37848 ]
 [120.464066]
 [118.06574 ]
 [129.01682 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  8.  6.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  1.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -7.667213439941406
desired expected reward: 123.25240325927734



buy possibilites: [-1] 
expected returns: [[84.18574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10.  8.  6.  6.  6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  1.] 
adversary cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -60 

action type: buy - action 10.0
Learning step: -7.009108066558838
desired expected reward: 111.05662536621094






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  1.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11. 11.] 
adversary cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11. 11.] 
adversary cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11. 11.] 
adversary cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 8. 14. 11. 11.  0.  8. 29.  3.  0.  3. 10.  3. 10.  0. 29.  8.  3.  0.
 25.  0. 14.  0.  0. 29. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 11. 11.] 
adversary cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[117.68041]
 [117.67813]
 [117.67813]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11. 11.] 
cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  1. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -5.461494445800781
desired expected reward: 78.7242431640625



action possibilites: [-1] 
expected returns: [[36.01153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  1. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -49 

action type: gain_card_n - action 9
Learning step: -7.5670342445373535
desired expected reward: 110.97883605957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.918266]
 [29.001133]
 [12.399548]
 [27.650982]
 [36.245613]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [10.  8.  6.  6.  6. 10.  6.  3.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  1. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -4.002683162689209
desired expected reward: 32.00885009765625






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [11.  0.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1. 14.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[87.410904]
 [77.18506 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: discard_down_to_3_cards - action 4
Learning step: -4.380927562713623
desired expected reward: 41.959877014160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[64.287636]
 [70.56517 ]
 [48.50884 ]
 [70.20522 ]
 [80.12414 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  6.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.093011379241943
desired expected reward: 70.7956771850586



buy possibilites: [-1] 
expected returns: [[57.576042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 3. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -70 

action type: buy - action 8.0
Learning step: -5.7148003578186035
desired expected reward: 64.49042510986328






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [29. 29.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  3. 29.] 
cards in discard: [14. 14. 11.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6. 10.] 
adversary cards in discard: [3. 3. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  1.  3. 29.] 
cards in discard: [14. 14. 11.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6. 10.] 
adversary cards in discard: [3. 3. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[37.034077]
 [28.969677]
 [28.969677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6. 10.] 
cards in discard: [3. 3. 8. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.006330966949463
desired expected reward: 51.56970977783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.891068]
 [19.014952]
 [37.817482]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  6. 10.] 
cards in discard: [3. 3. 8. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -5.012870788574219
desired expected reward: 32.021217346191406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  5.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.879265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  3. 14.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: discard_down_to_3_cards - action 0
Learning step: -4.734921455383301
desired expected reward: 43.85917663574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.74721 ]
 [61.542435]
 [31.981377]
 [60.559082]
 [70.20463 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  3. 14.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.031693935394287
desired expected reward: 64.84757232666016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 25.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  3. 14.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [10.  6.  6. 11. 11.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  3.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 25.  3.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  4.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 25.  3.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.870674]
 [17.222775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.] 
cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0. 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 8. 0. 8.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: discard_down_to_3_cards - action 4
Learning step: -2.851337194442749
desired expected reward: -11.139199256896973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.875804 ]
 [-7.2826815]
 [33.230732 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [ 3.  3.  8.  8.  0.  0.  0. 10.  6.  6. 10.  0.  0.  6.  0.  0. 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 8. 0. 8.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11] -> size -> 34 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.971508979797363
desired expected reward: 26.899169921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 0. 8.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0. 8.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0. 8.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.87185 ]
 [25.146389]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 10.  3. 11.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.  8.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0] -> size -> 35 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.942488193511963
desired expected reward: 28.288236618041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.840618]
 [25.420418]
 [23.947245]
 [13.399901]
 [28.263836]
 [23.759565]
 [22.997908]
 [28.761189]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 10.  3. 11.] 
adversary cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.  8.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0] -> size -> 35 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.75601053237915
desired expected reward: 24.099618911743164



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11.  0. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3. 11.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.  8.  3.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5. 10.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.  8.  3.  8.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [14. 14. 11.  0.  1.  0. 29. 29.  1.  3. 29.  8. 14.  0.  0.  0.  0. 11.
 14.  0. 10. 25.  3.  0.  8.  3.  8.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[11.031467]
 [11.874955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 0.  0. 10.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  3.  4.  9.  7.  6. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -5.0756425857543945
desired expected reward: 23.685550689697266



action possibilites: [-1] 
expected returns: [[30.0988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  3.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -49 

action type: gain_card_n - action 9
Learning step: -2.4288010597229004
desired expected reward: 10.69167709350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.995966]
 [29.100624]
 [27.74025 ]
 [ 9.220619]
 [32.33786 ]
 [26.130472]
 [25.506315]
 [33.07964 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  3.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -3.7433745861053467
desired expected reward: 26.355426788330078



buy possibilites: [-1] 
expected returns: [[54.394848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [25.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -40 

action type: buy - action 11.0
Learning step: -2.0760066509246826
desired expected reward: 23.921810150146484






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [25.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  5.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  6.  8.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11] -> size -> 23 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  6.  8.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  6.  8.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0. 14.  0.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  6.  8.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[13.387951 ]
 [ 7.61506  ]
 [ 7.61506  ]
 [ 8.9952965]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  6.  8.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  1.  8. 29.  0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -80    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -389 

action type: buy - action -1
Learning step: -21.913572311401367
desired expected reward: 32.48127746582031



action possibilites: [-1. 10.  8.  8.] 
expected returns: [[61.262543]
 [56.111828]
 [56.267006]
 [56.267006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  8.  8.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  1.  8. 29.  0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 10.0
Learning step: -2.4951517581939697
desired expected reward: 5.119902610778809





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.843956]
 [46.43516 ]
 [62.66504 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  8.  8.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  4.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  1.  8. 29.  0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -5.190052032470703
desired expected reward: 56.0724983215332



buy possibilites: [-1] 
expected returns: [[33.7488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  8.  8.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  1.  8. 29.  0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -380.0 

action type: buy - action 6.0
Learning step: -20.562410354614258
desired expected reward: 25.872751235961914






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [29.  1.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8. 29.  0.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  3.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 4 


action possibilites: [-1.  8. 29. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 29.  0. 14.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  8 25 11  0 11 14 10 29  1 29  0 14
  8 10 11  8  3 29 14 14  8 11  0 16  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  3.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  3.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  3.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  3.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 4 





Player: 0 
cards in hand: [ 6. 11.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.489838]
 [21.721888]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  3.  6.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -6.200009346008301
desired expected reward: 27.548789978027344



action possibilites: [-1] 
expected returns: [[13.880283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -71 

action type: gain_card_n - action 1
Learning step: -4.217117786407471
desired expected reward: 15.371362686157227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 3.762729 ]
 [-2.8963623]
 [13.535694 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action -1
Learning step: -4.4882378578186035
desired expected reward: 9.392045974731445



buy possibilites: [-1] 
expected returns: [[-6.843948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6.] 
cards in discard: [ 0.  0. 10.  0.  6. 10. 11. 11.  0.  0.  0.  3.  6.  6. 10.  0. 10.  6.
  8.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -110 

action type: buy - action 0.0
Learning step: -5.842124938964844
desired expected reward: -2.079402208328247






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [16.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11. 11.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11. 11.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11. 11.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-8.154401 ]
 [-7.4011993]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0  6 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6
  6  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.328588008880615
desired expected reward: -12.17253589630127



action possibilites: [-1] 
expected returns: [[33.969044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.7750189304351807
desired expected reward: -10.988570213317871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.459185]
 [30.937973]
 [21.059208]
 [30.735332]
 [36.787716]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  3.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -4.906578063964844
desired expected reward: 29.06246566772461



buy possibilites: [-1] 
expected returns: [[0.31670785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -390.0 

action type: buy - action 6.0
Learning step: -20.545835494995117
desired expected reward: 0.5133781433105469






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 11.  6. 11. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  7.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 11.  6. 11. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 11.  6. 11. 10.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 1. 11.  6. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[12.697599]
 [12.345943]
 [12.345943]
 [ 8.107874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6. 11. 10.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 14.  8.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.245103359222412
desired expected reward: -4.9283952713012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 4.9020514]
 [ 8.119282 ]
 [-4.5017233]
 [ 8.05238  ]
 [10.734533 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6. 11. 10.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 14.  8.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.846603870391846
desired expected reward: 4.723405361175537



buy possibilites: [-1] 
expected returns: [[21.65036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6. 11. 10.] 
cards in discard: [6. 8. 3. 0. 0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 14.  8.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -91 

action type: buy - action 3.0
Learning step: -4.468831539154053
desired expected reward: 3.6504578590393066






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 14.  8.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3] -> size -> 28 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 14.  8.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3] -> size -> 28 
adversary victory points: -4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-5.8280096]
 [-7.02829  ]
 [-5.5417023]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  2.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.  3.  0. 10. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -6.163888931274414
desired expected reward: 15.486471176147461



action possibilites: [-1] 
expected returns: [[-13.138407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.  3.  0. 10. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -390 

action type: gain_card_n - action 3
Learning step: -19.466310501098633
desired expected reward: -26.052410125732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-14.736755]
 [-13.593407]
 [-15.647629]
 [-14.510336]
 [-12.88352 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.  3.  0. 10. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.14868688583374
desired expected reward: -17.287094116210938






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 29.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.  3.  0. 10. 14.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3. 29.] 
cards in discard: [ 0. 25.  0. 14.  0.  0. 14.  0.  0. 29.  8. 29. 14.  3. 16.  0.  0. 11.
 11. 29.  3.  0.  8.  1.  0.  3.  0. 10. 14.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 6.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 6. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-8.257427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 6.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8. 11.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -5.041615962982178
desired expected reward: -17.925134658813477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-16.339573]
 [-16.914497]
 [ -8.458939]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 6.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [10.  8. 11.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.339032173156738
desired expected reward: -13.59645938873291



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [10.  8. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  8. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  8. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.  0.
  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  8. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  8. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.  0.
  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  8. 11.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  8. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.  0.
  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[26.791105]
 [19.422276]
 [20.877123]
 [19.422276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  8. 10.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.  0.
  6.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -4.532635688781738
desired expected reward: -12.991585731506348





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.164139 ]
 [ 2.7027626]
 [22.587963 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  8. 10.] 
cards in discard: [ 6.  8.  3.  0.  0.  3.  1. 11.  6. 11. 10.  6. 11.  3. 10.  0.  0.  0.
  6.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -6.438033580780029
desired expected reward: 20.35306739807129



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  0.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 14.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14. 14.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 27. 30. 26. 30.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
adversary victory points: -5
player victory points: 8 





Player: 0 
cards in hand: [ 6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[10.934479 ]
 [ 6.8290324]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  1.] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: discard_down_to_3_cards - action 0
Learning step: -8.48437786102295
desired expected reward: 25.659446716308594



action possibilites: [-1.] 
expected returns: [[27.73884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -119 

action type: take_action - action 10.0
Learning step: -5.667327404022217
desired expected reward: 1.1617012023925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.557655]
 [24.60598 ]
 [22.719622]
 [ 8.50234 ]
 [27.243519]
 [22.163233]
 [20.754465]
 [26.966269]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  2.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1.0
Learning step: -6.839599609375
desired expected reward: 20.899240493774414



buy possibilites: [-1] 
expected returns: [[28.894432]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [ 0.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -102 

action type: buy - action 11.0
Learning step: -5.812051296234131
desired expected reward: 21.43146324157715






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [29.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0.  0.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
adversary victory points: -5
player victory points: 8 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10
 11  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
adversary victory points: -5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
adversary victory points: -5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  4.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
adversary victory points: -5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
adversary victory points: -5
player victory points: 8 





Player: 0 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-17.777985]
 [-19.22769 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: buy - action -1
Learning step: -8.852923393249512
desired expected reward: 20.041507720947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-23.566702]
 [-17.451532]
 [-17.309267]
 [-40.411064]
 [-16.968561]
 [-19.108963]
 [-18.934217]
 [-17.251394]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 29.  8.  1.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 40 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: take_action - action -1.0
Learning step: -6.581169128417969
desired expected reward: -23.590269088745117



buy possibilites: [-1] 
expected returns: [[-11.379404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 40 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -140.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -451.0 

action type: buy - action 6.0
Learning step: -20.78548240661621
desired expected reward: -61.19654846191406






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11
  8  3 29 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  6. 10. 11.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6] -> size -> 31 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  6. 10. 11.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6] -> size -> 31 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  6. 10. 11.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6] -> size -> 31 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [11. 10.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 11.] 
expected returns: [[-0.9142363]
 [ 0.5454979]
 [-1.1981761]
 [-1.1981761]
 [ 0.5454979]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6. 10. 11.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -6.979944705963135
desired expected reward: -18.35934829711914



action possibilites: [-1] 
expected returns: [[1.4822459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10. 11.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -122 

action type: gain_card_n - action 8
Learning step: -6.061442852020264
desired expected reward: -6.1655731201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.5283117]
 [ 1.466908 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10. 11.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1
Learning step: -6.619349956512451
desired expected reward: -5.137104034423828






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  3.  3.  8. 10.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  3.  3.  8. 10.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
adversary victory points: -6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  3.  3.  8. 10.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [ 6.  3.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-2.7484488]
 [-6.585732 ]
 [-6.6061463]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  8. 10.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [11. 14.  3. 25. 16.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1.0
Learning step: -7.714191436767578
desired expected reward: -6.247270584106445



action possibilites: [-1.  8.] 
expected returns: [[-10.696205]
 [-11.293623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 8. 6.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [11. 14.  3. 25. 16.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action 10.0
Learning step: -6.4637346267700195
desired expected reward: -13.069886207580566





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.957178]
 [-10.696205]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 8. 6.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10] -> size -> 32 
action values: 2 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [11. 14.  3. 25. 16.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1.0
Learning step: -6.243404865264893
desired expected reward: -16.939611434936523



buy possibilites: [-1] 
expected returns: [[12.781328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 8. 6.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [11. 14.  3. 25. 16.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -161 

action type: buy - action 0.0
Learning step: -7.264560699462891
desired expected reward: -17.221736907958984






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [11. 14.  3. 25. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 25. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3. 25. 16.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 25. 16.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 25. 16.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
adversary victory points: -6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 25. 16.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [11.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-9.566652]
 [-9.69943 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [14. 10.  0. 11. 29.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -8.40506649017334
desired expected reward: 4.3762617111206055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-10.443815]
 [-10.599686]
 [-11.511824]
 [-10.843718]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [14. 10.  0. 11. 29.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: take_action - action -1.0
Learning step: -7.311243534088135
desired expected reward: -16.877891540527344



buy possibilites: [-1] 
expected returns: [[-13.894051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [ 0.  0. 11. 10.  6.  1.  0.  6.  0.  6.  8.  0.  0. 10. 11. 10.  6. 10.
 11.  0. 10.  6.  3.  3.  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [14. 10.  0. 11. 29.] 
adversary cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -181.0 

action type: buy - action 0.0
Learning step: -8.840425491333008
desired expected reward: -19.284238815307617






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [14. 10.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0. 11. 29.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0. 11. 29.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
adversary victory points: -6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0. 11. 29.] 
cards in discard: [ 0. 10.  8. 11.  8. 11.  4. 29. 29. 14.  0.  3.  0. 14.  8. 29.  8.  0.
  0.  3.  8.  0.  1.  0.  3.  0.  3.  1. 10.  0. 11. 14.  3. 25. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [0. 8. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-29.44604 ]
 [-30.415398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -7.523313999176025
desired expected reward: -21.4173641204834





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-29.554325]
 [-29.760458]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: take_action - action -1.0
Learning step: -6.74383544921875
desired expected reward: -36.18987274169922



buy possibilites: [-1] 
expected returns: [[-6.919957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 16.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -181.0 

action type: buy - action 0.0
Learning step: -7.6796746253967285
desired expected reward: -37.2339973449707






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [10. 16.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 10.  8. 11. 11.] 
adversary cards in discard: [0. 0. 8. 6. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0] -> size -> 35 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 10.  8. 11. 11.] 
adversary cards in discard: [0. 0. 8. 6. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0] -> size -> 35 
adversary victory points: -6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  3. 11.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 10.  8. 11. 11.] 
adversary cards in discard: [0. 0. 8. 6. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0] -> size -> 35 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [ 6. 10.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 11.] 
expected returns: [[-4.97235  ]
 [-5.4358397]
 [-5.3359346]
 [-3.84822  ]
 [-3.84822  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8. 11. 11.] 
cards in discard: [0. 0. 8. 6. 6. 6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 29.  8.  0.  9.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -7.300084590911865
desired expected reward: -14.220041275024414



action possibilites: [-1] 
expected returns: [[-17.984282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8. 11.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0   -1    0    0
   16    0] 
sum of rewards: -116 

action type: gain_card_n - action 3
Learning step: -5.981229305267334
desired expected reward: -10.449569702148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-16.727806]
 [-17.82409 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8. 11.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1
Learning step: -6.033360481262207
desired expected reward: -24.017642974853516



buy possibilites: [-1] 
expected returns: [[19.134565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  8. 11.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  1.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20  -30    0    0    0   -2    0    0
    0    0] 
sum of rewards: -163 

action type: buy - action 0.0
Learning step: -6.883081912994385
desired expected reward: -23.610889434814453






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  1.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 26. 30. 26. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 10.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
adversary victory points: -6
player victory points: 9 





Player: 0 
cards in hand: [10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-17.06777 ]
 [-14.371731]
 [-15.593327]
 [-14.371731]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -161 

action type: discard_down_to_3_cards - action 3
Learning step: -8.087530136108398
desired expected reward: -14.025716781616211



action possibilites: [-1. 11. 10.] 
expected returns: [[-18.19537 ]
 [-18.491858]
 [-17.815485]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -141 

action type: take_action - action 10.0
Learning step: -6.736243724822998
desired expected reward: -21.107975006103516



action possibilites: [-1. 11.] 
expected returns: [[14.008471]
 [13.692791]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0] -> size -> 37 
action values: 3 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  6.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: take_action - action 10.0
Learning step: -4.845820426940918
desired expected reward: -22.661300659179688



action possibilites: [-1.] 
expected returns: [[10.314241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0   60    0    0    0    0   -3    0    0
   16    0] 
sum of rewards: -88 

action type: gain_card_n - action 6
Learning step: -4.170012950897217
desired expected reward: -4.128345966339111





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.114159]
 [10.400467]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29] -> size -> 38 
action values: 2 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.350282192230225
desired expected reward: 4.963959217071533



buy possibilites: [-1] 
expected returns: [[0.06438088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
adversary victory points: 9
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -150    0    0   60  -30    0    0    0   -4    0    0
    0    0] 
sum of rewards: -135 

action type: buy - action 0.0
Learning step: -7.104259490966797
desired expected reward: 0.009899616241455078






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29
 14 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0] -> size -> 39 
adversary victory points: -6
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0] -> size -> 39 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0] -> size -> 39 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [10.  0.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-7.6211815]
 [-6.522717 ]
 [-5.9995365]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -7.696292877197266
desired expected reward: -7.6319122314453125



action possibilites: [-1] 
expected returns: [[2.2150893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20  -30    0    0    0   -5    0    0
    0    0] 
sum of rewards: -166 

action type: gain_card_n - action 0
Learning step: -7.902736186981201
desired expected reward: -14.515822410583496





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.2302716]
 [-0.419899 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -131 

action type: take_action - action -1
Learning step: -6.68043851852417
desired expected reward: -4.465349197387695



buy possibilites: [-1] 
expected returns: [[-4.248931]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  6.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29.  0.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -140.    0.    0.   20.  -30.    0.    0.    0.   -6.
    0.    0.    0.    0.] 
sum of rewards: -167.0 

action type: buy - action 0.0
Learning step: -8.334087371826172
desired expected reward: -10.56435489654541






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [25. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 29.  0.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
adversary victory points: -6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  8. 14.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
adversary victory points: -6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  0.  8. 14.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
adversary victory points: -6
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-4.2014475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: buy - action -1
Learning step: -7.43208646774292
desired expected reward: -11.68101692199707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-11.890057 ]
 [ -3.2861028]
 [ -2.9491837]
 [ -8.328231 ]
 [ -3.1773818]
 [ -7.7397804]
 [ -8.201897 ]
 [-19.700056 ]
 [ -7.7587056]
 [-11.414194 ]
 [ -4.201453 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 25. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -151 

action type: take_action - action -1.0
Learning step: -7.464065074920654
desired expected reward: -11.665512084960938



buy possibilites: [-1] 
expected returns: [[-5.0069876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -130.    0.    0.    0.    0.    0.    0.    0.   -7.
    0.    0.    2.    0.] 
sum of rewards: -145.0 

action type: buy - action 3.0
Learning step: -7.215198040008545
desired expected reward: -10.16438102722168






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  3.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
adversary victory points: -5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  2.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
adversary victory points: -5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  2.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
adversary victory points: -5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
adversary victory points: -5
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-4.53619 ]
 [-6.807082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  8. 14. 29. 11.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8] -> size -> 44 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: buy - action -1
Learning step: -6.8645548820495605
desired expected reward: -11.871541976928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.7093167]
 [-5.488432 ]
 [-7.4257784]
 [-4.53619  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 24. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  8. 14. 29. 11.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8] -> size -> 44 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: take_action - action -1.0
Learning step: -6.89508581161499
desired expected reward: -11.431283950805664



buy possibilites: [-1] 
expected returns: [[-12.224098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 0.  0.  8.  6.  6.  6. 16.  0. 11.  6. 10.  8. 11.  0.  0. 29.  0. 10.
 10. 11.  6.  6.  0.  0. 11. 10.  0.  3.  6.  3.  0.  0.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 4.  8. 14. 29. 11.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8] -> size -> 44 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0   -8    0    0
    8    0] 
sum of rewards: -129 

action type: buy - action 3.0
Learning step: -6.450620174407959
desired expected reward: -11.939056396484375






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 4.  8. 14. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8. 14. 29. 11.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8. 14. 29.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 14. 29.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8. 14. 29.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
adversary victory points: -4
player victory points: 8 





Player: 0 
cards in hand: [ 6. 10.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-14.5895195]
 [-15.995522 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 14.  8.  8.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 46 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: buy - action -1
Learning step: -6.175008773803711
desired expected reward: -18.399106979370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-16.97899 ]
 [-16.210918]
 [-16.367529]
 [-15.618443]
 [-16.81172 ]
 [-16.828093]
 [-15.89798 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  1.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 14.  8.  8.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 46 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action -1.0
Learning step: -6.080637454986572
desired expected reward: -20.670156478881836



buy possibilites: [-1] 
expected returns: [[-2.487568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  1.] 
cards in discard: [11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  0.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 14.  8.  8.  3.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
adversary owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 46 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0   -9    0    0
   18    0] 
sum of rewards: -120 

action type: buy - action 11.0
Learning step: -5.27504825592041
desired expected reward: -20.893497467041016






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  8.  8.  3.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  8 25 11  0 11 14 10 29  1 29  0 14  8 10 11  8  3 29 14
 14  8 11  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  0.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  6. 29.] 
adversary cards in discard: [11.  6. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3 11] -> size -> 44 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25 11  0 11 10 29  1 29  0 14  8 10 11  8  3 29 14 14  8 11
  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  0.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  6. 29.] 
adversary cards in discard: [11.  6. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3 11] -> size -> 44 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25 11  0 11 10 29  1 29  0 14  8 10 11  8  3 29 14 14  8 11
  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  0.  1.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  6. 29.] 
adversary cards in discard: [11.  6. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3 11] -> size -> 44 
adversary victory points: -4
player victory points: 7 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 0 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 6 
Chapel: 2 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0.  6.  6. 29.] 
cards in discard: [11.  6. 10.  0.  3.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  0 11  0  6  6 10  3  6  6 11 10 10  8 10 11  6  6
  1  0  6  3  6 11  6 10  0  0  0 16  0 29  0  0  0  3  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 23. 29.  8.  0.  8.  0.  0.  9.  5.  6. 10.  1. 10. 10.] 
adversary cards in hand: [1.] 
adversary cards in discard: [ 0. 10. 16.  3.  3. 11.  0.  1.  3. 29. 29. 14.  0.  0.  8.  0.  0.  0.
 25. 10.  0. 29.  0.  8. 14.  8.  8. 11.  0.  0.  0.  3. 10.  0. 11.  4.
  8. 14. 29.  8.] 
adversary owned cards: [ 0  0  3  0 25 11  0 11 10 29  1 29  0 14  8 10 11  8  3 29 14 14  8 11
  0 16  0  0  3 29  0  4  8  1 10  0  0  0  3  8  8 10  0  8] -> size -> 44 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -619 

action type: buy - action -1
Learning step: -30.82562255859375
desired expected reward: -33.31319046020508



