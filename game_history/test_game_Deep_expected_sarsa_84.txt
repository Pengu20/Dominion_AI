 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.676674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -119997.5859375
desired expected reward: -120152.796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 55.982643]
 [ 86.85805 ]
 [ 68.22732 ]
 [ 12.489048]
 [ 79.125626]
 [ 89.49459 ]
 [ 77.130905]
 [103.09599 ]
 [ 30.597553]
 [ 58.503372]
 [ 60.6398  ]
 [ 71.93587 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.21160125732422



buy possibilites: [-1] 
expected returns: [[74.88676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.09598541259766






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[84.8412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.88675689697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 71.23347 ]
 [ 99.44714 ]
 [ 82.368706]
 [ 28.802006]
 [101.82121 ]
 [ 90.49016 ]
 [ 73.52155 ]
 [ 85.70859 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.02562713623047



buy possibilites: [-1] 
expected returns: [[70.70516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.82121276855469






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.72703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.70516204833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.480045]
 [79.14293 ]
 [61.72242 ]
 [ 8.465267]
 [81.53183 ]
 [69.90752 ]
 [52.785477]
 [65.07123 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.45399475097656



buy possibilites: [-1] 
expected returns: [[64.30249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.53182983398438






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[64.31839 ]
 [95.595894]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.302490234375



action possibilites: [-1.] 
expected returns: [[82.83553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 95.92395782470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 69.04776 ]
 [ 97.1249  ]
 [ 80.171104]
 [ 43.002094]
 [ 26.816612]
 [ 90.09771 ]
 [ 99.39945 ]
 [ 88.27609 ]
 [138.38211 ]
 [111.25462 ]
 [ 45.17403 ]
 [ 75.071365]
 [ 71.3223  ]
 [ 46.994217]
 [ 73.249756]
 [ 83.42895 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.83553314208984



buy possibilites: [-1] 
expected returns: [[91.518425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 138.38214111328125






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0. 0. 3. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[58.177505]
 [75.0303  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.51842498779297



action possibilites: [-1] 
expected returns: [[39.684196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.7730941772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 25.290928 ]
 [ 53.715324 ]
 [ 36.40514  ]
 [-14.0168915]
 [ 56.135742 ]
 [ 44.67905  ]
 [ 27.548172 ]
 [ 39.947273 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.68419647216797



buy possibilites: [-1] 
expected returns: [[49.049812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.13574981689453






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 71.13201]
 [125.25848]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.04981231689453



action possibilites: [-1] 
expected returns: [[76.97699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.7445297241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.849556]
 [90.28783 ]
 [74.04028 ]
 [25.513168]
 [92.48667 ]
 [81.71467 ]
 [65.94664 ]
 [77.116905]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.97698974609375



buy possibilites: [-1] 
expected returns: [[73.943825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 92.48666381835938






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[32.07128]
 [58.54545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.9438247680664



action possibilites: [-1.] 
expected returns: [[28.350624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.67469787597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 17.996132 ]
 [ 44.17292  ]
 [ 28.386665 ]
 [ -6.3591638]
 [-20.849169 ]
 [ 37.614384 ]
 [ 46.323345 ]
 [ 35.932804 ]
 [ 78.292404 ]
 [ 57.77404  ]
 [ -4.208735 ]
 [ 23.649626 ]
 [ 20.146559 ]
 [ -2.527175 ]
 [ 21.968052 ]
 [ 31.618729 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.350624084472656



buy possibilites: [-1] 
expected returns: [[71.86582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 78.29239654541016






Player: 1 
cards in hand: [0. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11. 11.  0.] 
adversary cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11. 11.  0.] 
adversary cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 11. 11.  0.] 
adversary cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[ 62.83145]
 [109.72525]
 [ 74.71064]
 [ 74.71064]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11. 11.  0.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 0. 3. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.8658218383789



action possibilites: [-1] 
expected returns: [[57.791718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 10.  3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 0. 3. 1. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.39555358886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.006493]
 [63.404762]
 [27.576794]
 [68.75063 ]
 [65.914345]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 10.  3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5. 10.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 0. 3. 1. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.791717529296875



buy possibilites: [-1] 
expected returns: [[89.565834]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 10.  3.] 
cards in discard: [25. 29.  0.  3.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [3. 0. 3. 1. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.75065612792969






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [3. 0. 3. 1. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [3. 0. 3. 1. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[11.8578415]
 [33.299637 ]
 [24.048983 ]
 [24.048983 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.56583404541016



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[24.607786]
 [35.164165]
 [35.164165]
 [15.92057 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.77992630004883



action possibilites: [-1] 
expected returns: [[38.518585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.18574905395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.29406 ]
 [39.18523 ]
 [ 1.122344]
 [44.8759  ]
 [41.93534 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.518585205078125



buy possibilites: [-1] 
expected returns: [[62.337914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  8.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 44.875885009765625






Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  8.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 11. 25.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 11. 25.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  5.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 11. 25.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  1.  3.  3.  6. 29.  0.  0.  0.  0.  6. 29. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  4.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 11. 25.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 25.] 
expected returns: [[27.261368]
 [29.767887]
 [65.35658 ]
 [36.654533]
 [65.35658 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0. 11. 25.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8. 10.  4.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.337913513183594



action possibilites: [-1] 
expected returns: [[5.9226456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 25.  0.  3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.61884307861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -4.87137  ]
 [  2.6998024]
 [-32.353382 ]
 [  7.8467636]
 [  5.1870317]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 25.  0.  3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.922645568847656



buy possibilites: [-1] 
expected returns: [[44.970016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 25.  0.  3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 7.846752166748047






Player: 1 
cards in hand: [29.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [ 6. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.9105868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [6. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.97001647949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-14.730807  ]
 [ 12.692516  ]
 [ -3.7309709 ]
 [-54.222168  ]
 [  5.825844  ]
 [ 15.0852165 ]
 [  4.1221247 ]
 [ 26.714348  ]
 [-37.784348  ]
 [-12.331524  ]
 [-10.30679   ]
 [  0.49642563]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [6. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.9105868339538574



buy possibilites: [-1] 
expected returns: [[18.886192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  8. 29. 11. 11.  3.  0. 10.  8. 25.  8.  0. 11. 25.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [6. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.714332580566406






Player: 1 
cards in hand: [6. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 3.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 3.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[37.36283 ]
 [76.45846 ]
 [48.682697]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.886192321777344



action possibilites: [-1] 
expected returns: [[60.562386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 72.54377746582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.73962 ]
 [62.535896]
 [20.464169]
 [68.904915]
 [65.53098 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  7.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.56238555908203



buy possibilites: [-1] 
expected returns: [[63.9514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  8.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.90491485595703






Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [10.  8. 25. 29.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [10.  8. 25. 29.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [10.  8. 25. 29.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [10.  8. 25. 29.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  8. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25. 29.] 
expected returns: [[-29.061806]
 [-36.535183]
 [-25.852657]
 [ 10.172482]
 [ -8.958254]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 25. 29.  0.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.95140075683594



action possibilites: [-1] 
expected returns: [[-43.047188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  0.  8. 10.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.838314056396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-49.725456]
 [-74.95546 ]
 [-40.61256 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 29.  0.  8. 10.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -43.04718780517578






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [ 6. 22. 29.  1.  0. 11.  0.  6.  6.  3.  3.  3.  3.  6. 14.  1. 11.  0.
  0.  0.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-27.848078]
 [-23.554617]
 [-23.554617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -40.612579345703125



action possibilites: [-1] 
expected returns: [[-13.840082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -17.882991790771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-22.489056 ]
 [ -4.638968 ]
 [-15.374123 ]
 [-49.959717 ]
 [ -3.1132064]
 [-10.241407 ]
 [-20.965858 ]
 [-12.841984 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.840082168579102



buy possibilites: [-1] 
expected returns: [[21.000877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 8. 25.  0.  0.  3. 11.  3.  8. 25. 10.  8. 29.  0.  8. 10. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  3.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -3.11322021484375






Player: 1 
cards in hand: [ 1.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  3.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  6.  8.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[-47.94628 ]
 [-23.901764]
 [-39.30658 ]
 [-32.597275]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.000877380371094



action possibilites: [-1] 
expected returns: [[-3.4177642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -25.155141830444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-18.70858 ]
 [-51.809723]
 [ -7.918714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.417764186859131






Player: 1 
cards in hand: [14. 29.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  3. 29.  6.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  3. 29.  6.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-52.24421]
 [-44.18273]
 [-44.18273]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.918704986572266



action possibilites: [-1] 
expected returns: [[-35.80363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -34.300758361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-42.523266]
 [-24.764881]
 [-35.86628 ]
 [-65.98513 ]
 [-23.048918]
 [-30.959036]
 [-41.20103 ]
 [-33.43015 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -35.80363082885742



buy possibilites: [-1] 
expected returns: [[-33.476524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -23.048900604248047






Player: 1 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  0. 10.  3.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[ -7.2275667]
 [-14.791136 ]
 [ -4.74436  ]
 [-14.791136 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.  3.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 25 10 11 11 25  8 10  8  8 29  8
 10 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -33.476524353027344



action possibilites: [-1] 
expected returns: [[-61.876526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 12.832786560058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-63.206985]
 [-82.47712 ]
 [-60.88059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -61.87652587890625






Player: 1 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8.  0. 25.  3. 10.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8.  0. 25.  3. 10.] 
adversary cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[-35.512215]
 [-33.313915]
 [ -7.156066]
 [-42.314857]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  3. 10.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  3. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -60.880584716796875



action possibilites: [-1] 
expected returns: [[4.9833527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  0. 29.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.156073093414307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -5.337923 ]
 [  1.8777924]
 [-40.990227 ]
 [  7.074381 ]
 [  4.443775 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0. 29.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  6.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.9833526611328125



buy possibilites: [-1] 
expected returns: [[-42.3843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  0. 29.] 
cards in discard: [25. 11. 29.  3.  0.  8. 11. 10. 11. 11. 11.  0.  0.  0.  8. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 1. 22.  0.  3.  0.] 
adversary cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 7.074380874633789






Player: 1 
cards in hand: [ 1. 22.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  0.  3.  0.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 11.  6.  0.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 11.  6.  0.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 11.  6.  0.] 
cards in discard: [ 6. 15. 11.  1.  0.  3.  0.  6. 14. 29.  3. 29.  6.  3.  3.  0.  6.  0.
  6.  6.  3.  0.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8. 11.] 
expected returns: [[-83.635765]
 [-84.15808 ]
 [-85.69561 ]
 [-84.15808 ]
 [-84.15808 ]
 [-82.85073 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 3. 15. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -42.384300231933594



action possibilites: [-1] 
expected returns: [[-65.60863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 15. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -80.5550308227539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-68.02359 ]
 [-87.975426]
 [-65.316826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  8.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 15. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6  0] -> size -> 34 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -65.60862731933594






Player: 1 
cards in hand: [ 3. 15. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6
 14  1  6  3  6 15  6  3  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  5.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0. 25.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  5.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0. 25.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  6.  9. 10.  5.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0. 25.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [25. 29. 11.  0. 25.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25. 29. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 25.] 
expected returns: [[-48.746193]
 [-35.62726 ]
 [-40.58229 ]
 [-43.337532]
 [-35.62726 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11.  0. 25.] 
cards in discard: [10. 11.  8. 10.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  2. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29] -> size -> 34 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -65.31682586669922



action possibilites: [-1] 
expected returns: [[-41.68782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 25.  8. 11.] 
cards in discard: [10. 11.  8. 10.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -35.62725067138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-48.601784]
 [-69.99992 ]
 [-40.998062]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 25.  8. 11.] 
cards in discard: [10. 11.  8. 10.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.68782043457031






Player: 1 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [29. 15.  3. 14.  1.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [29. 15.  3. 14.  1.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-57.39319]
 [-56.38078]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  6.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -40.99807357788086



action possibilites: [-1] 
expected returns: [[-23.297092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  6.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -55.54736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-32.27084 ]
 [-17.023994]
 [-26.177528]
 [-55.62689 ]
 [-15.705855]
 [-21.799156]
 [-30.952698]
 [-23.935085]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  2.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  6.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -23.29709243774414



buy possibilites: [-1] 
expected returns: [[-19.795557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  6.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -15.705863952636719






Player: 1 
cards in hand: [ 6.  0.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.  6.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11. 11.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.  6.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11. 11.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11] -> size -> 29 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-28.791185]
 [-36.45094 ]
 [-18.56607 ]
 [-36.45094 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 10.  0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11. 11.  0.  3.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 3.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.795557022094727



action possibilites: [-1] 
expected returns: [[-14.855987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11. 11.  0.  3.
  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 3.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -9.060522079467773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.404541]
 [-43.594803]
 [-14.488596]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10. 11.  8. 10.  8.  8. 25. 29. 11.  0. 25.  8. 11. 10. 11. 11.  0.  3.
  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [6. 0. 3. 3. 3.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.855986595153809






Player: 1 
cards in hand: [6. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[-82.11013]
 [-77.35184]
 [-80.93949]
 [-73.56015]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [29.  6.  6. 22.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.48861312866211



action possibilites: [-1. 11.  8. 29.] 
expected returns: [[-69.04042 ]
 [-69.414925]
 [-69.99081 ]
 [-68.60454 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [29.  6.  6. 22.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -73.5601577758789



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[-53.82357 ]
 [-54.31274 ]
 [-54.591206]
 [-54.591206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [29.  6.  6. 22.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -68.6045913696289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-59.19905 ]
 [-52.393982]
 [-53.963593]
 [-81.2069  ]
 [-52.710617]
 [-52.185867]
 [-52.90735 ]
 [-51.773697]
 [-71.34026 ]
 [-57.984314]
 [-56.95758 ]
 [-52.614426]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  5.  9. 10.  3.  9.  9.] 
adversary cards in hand: [29.  6.  6. 22.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -53.82357406616211



buy possibilites: [-1] 
expected returns: [[-25.072363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  8.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [29.  6.  6. 22.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -51.77373504638672






Player: 1 
cards in hand: [29.  6.  6. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  6. 22.  0.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 22.  0.  3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22.  0.  3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 22.  0.  3.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 25. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 11. 11.] 
expected returns: [[-40.90365 ]
 [-46.858692]
 [-15.507145]
 [-46.858692]
 [-33.837215]
 [-33.837215]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 11. 11.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  1. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0] -> size -> 38 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.072362899780273



action possibilites: [-1] 
expected returns: [[-31.227255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11. 10.  8.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6] -> size -> 39 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -15.50715160369873





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-40.391956]
 [-31.13779 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11. 10.  8.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6] -> size -> 39 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.22725486755371






Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [29. 15.  3. 14.  1.  6.  3.  0.  6.  6.  3.  0.  6.  0.  0. 29.  6.  0.
  6.  0.  3.  3.  3.  0. 29.  6.  6. 22.  0.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11.  0.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-21.902252]
 [-28.185396]
 [-28.185396]
 [-14.085758]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11.  0.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  1.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -31.13779640197754



action possibilites: [-1] 
expected returns: [[-7.559329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  1.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -5.56445837020874





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-16.408577]
 [ -7.064487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  1.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.559329032897949






Player: 1 
cards in hand: [ 0.  1.  6.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  1. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  0. 11. 10.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15] -> size -> 32 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6.  1. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  0. 11. 10.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15] -> size -> 32 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[-50.102432]
 [-47.22294 ]
 [-39.596966]
 [-57.62188 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11. 10.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.064497947692871



action possibilites: [-1] 
expected returns: [[-38.970234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -23.86358642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-45.049202]
 [-38.688904]
 [-33.96062 ]
 [-36.502937]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  5.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -38.97023391723633



buy possibilites: [-1] 
expected returns: [[-20.836468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -33.960601806640625






Player: 1 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0.  1.  6.  1. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.  8. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0.  1.  6.  1. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.  8. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 11.  3. 25.  8.] 
adversary cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.  8. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[-36.033943]
 [-30.25668 ]
 [-14.5961  ]
 [-34.575653]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25.  8.] 
cards in discard: [29. 29. 29.  0. 11.  8.  0.  8. 25. 10. 10. 11. 11. 10.  8. 15. 11. 10.
 10.  3.  0. 15.  8. 11.  0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  6. 15.  3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.836467742919922



action possibilites: [-1] 
expected returns: [[-28.783352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  6. 15.  3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -14.596090316772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-33.051105]
 [-27.975956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  6. 15.  3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -28.78335189819336






Player: 1 
cards in hand: [ 0.  0.  6. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15.  3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14
  1  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [29. 10. 11.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [29. 10. 11.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [29. 10. 11.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [29. 10. 11.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.  8. 29.] 
expected returns: [[ -7.940527 ]
 [  4.591507 ]
 [-13.868742 ]
 [ -0.8909292]
 [ -6.072527 ]
 [  4.591507 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  8. 29.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 3. 29.  0. 22.  0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.9759578704834



action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[-17.98389 ]
 [-23.776209]
 [-13.608651]
 [-16.121302]
 [-23.776209]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 3. 29.  0. 22.  0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.0073089599609375



action possibilites: [-1] 
expected returns: [[21.574501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0. 22.  0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -12.54517936706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.8848  ]
 [22.320808]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0. 22.  0.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.574501037597656






Player: 1 
cards in hand: [ 3. 29.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 22.  0.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  0. 10. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  0. 10. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  0. 10. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  0. 10. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 11.] 
expected returns: [[-26.222675]
 [-23.153461]
 [-33.696625]
 [-35.098614]
 [-15.064785]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 10. 11.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  6.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.32082748413086



action possibilites: [-1] 
expected returns: [[15.515392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.8418455123901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.648892]
 [16.055435]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [14. 29.  3. 29.  6.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.515392303466797






Player: 1 
cards in hand: [14. 29.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  3. 29.  6.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [ 3.  0. 10.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  3. 29.  6.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [ 3.  0. 10.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  3. 29.  6.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [ 3.  0. 10.  8. 29.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[-0.7881508]
 [-7.982645 ]
 [ 1.5095558]
 [14.707371 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8. 29.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [6. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.05542755126953



action possibilites: [-1. 10. 11.] 
expected returns: [[ 4.8682327]
 [-1.5621891]
 [12.027086 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  5.] 
adversary cards in hand: [6. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.46368408203125



action possibilites: [-1] 
expected returns: [[26.521446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.88589859008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.880928]
 [24.5587  ]
 [28.408371]
 [26.383545]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  4.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.521446228027344



buy possibilites: [-1] 
expected returns: [[-1.3747969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 6. 0. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.408367156982422






Player: 1 
cards in hand: [6. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [10. 15.  0.  0.  8.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [10. 15.  0.  0.  8.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[-26.186296]
 [-31.42942 ]
 [-30.598639]
 [-24.518349]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  0.  8.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11 11 25 11 11 25  8 10  8  8 29  8 10 11 10
 11  8 10 10 11 10 29 15 15  8 15 15 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.  6.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.3747968673706055



action possibilites: [-1] 
expected returns: [[6.8758984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.  6.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: -13.015138626098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.5060816]
 [ 6.076376 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.  6.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.875898361206055






Player: 1 
cards in hand: [3. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.  6.  6.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 8. 25.  0. 11. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [ 0.  1.  6.  1. 11.  0.  6.  3.  0.  3.  0.  0. 15.  0.  6.  3.  3. 14.
 29.  0. 22.  0.  0.  0. 14. 29.  3. 29.  6.  6.  6.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 8. 25.  0. 11. 11.] 
adversary cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 11.] 
expected returns: [[-12.654886]
 [-10.853564]
 [ 10.255199]
 [ -6.125983]
 [ -6.125983]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0. 11. 11.] 
cards in discard: [25.  0. 11.  3.  8. 10. 11. 29. 15. 29. 11. 10.  8. 10. 15. 11.  8. 15.
  0. 10.  8. 15.  8. 29. 11.  3.  0. 10.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.076396942138672



action possibilites: [-1] 
expected returns: [[1.1581259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11.  8. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.25522232055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.629984 ]
 [ 1.6637745]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 11.  8. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.158125877380371






Player: 1 
cards in hand: [ 3.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  8. 10.  3.  9.  4.] 
adversary cards in hand: [ 3. 15.  0. 11. 29.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  4.] 
adversary cards in hand: [ 3. 15.  0. 11. 29.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  4.] 
adversary cards in hand: [ 3. 15.  0. 11. 29.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[12.326286]
 [ 6.834957]
 [20.17808 ]
 [26.465485]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 11. 29.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.6637639999389648



action possibilites: [-1. 15. 29.] 
expected returns: [[17.760048]
 [10.611937]
 [31.606205]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 29.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.949785232543945



action possibilites: [-1. 15. 11.] 
expected returns: [[53.97664 ]
 [47.65485 ]
 [62.998695]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  4.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.399612426757812



action possibilites: [-1] 
expected returns: [[63.21747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  3.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.93655395507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[56.507652]
 [69.738365]
 [61.783493]
 [70.882835]
 [65.58149 ]
 [57.642204]
 [63.67772 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  1.  3.  8.  4.  7. 10.  3.  9.  3.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.21746826171875



buy possibilites: [-1] 
expected returns: [[41.755478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  3.  9.  3.] 
adversary cards in hand: [6. 6. 0. 0. 1.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.88282775878906






Player: 1 
cards in hand: [6. 6. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 1.] 
cards in discard: [14. 11.  3.  0.  3.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  3.  9.  3.] 
adversary cards in hand: [15.  8. 10. 15. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11] -> size -> 37 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 1.] 
cards in discard: [14. 11.  3.  0.  3.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  3.  9.  3.] 
adversary cards in hand: [15.  8. 10. 15. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11] -> size -> 37 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 1.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8. 10. 15. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11] -> size -> 37 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15.  8. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 15. 11.] 
expected returns: [[-50.370182]
 [-56.65436 ]
 [-48.5399  ]
 [-57.415432]
 [-56.65436 ]
 [-42.253654]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 15. 11.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  6.  3.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.75547790527344



action possibilites: [-1] 
expected returns: [[-62.630276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 15.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  6.  3.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -43.66896057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-72.89299 ]
 [-63.688988]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 10. 15.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  6.  3.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -62.63027572631836






Player: 1 
cards in hand: [ 3.  6.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3.  0. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0. 25.  0.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  0. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0. 25.  0.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3.  0. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8.  0. 25.  0.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  8.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 25.] 
expected returns: [[-23.66904 ]
 [-31.046177]
 [-20.637577]
 [ 13.58136 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 25.  0.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -63.68898010253906



action possibilites: [-1] 
expected returns: [[10.068314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0. 10.  8.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.581361770629883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 3.2411652]
 [ 9.020642 ]
 [13.196585 ]
 [10.967583 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0. 10.  8.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  3.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.068313598632812



buy possibilites: [-1] 
expected returns: [[0.809165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0. 10.  8.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3.  0.  0.  3. 22.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 81 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.196592330932617






Player: 1 
cards in hand: [ 3.  0.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 22.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3. 10. 10. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3.  0. 11.  0.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3. 10. 10. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 11.  0.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3. 10. 10. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3.  0. 11.  0.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 3. 10. 10. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[-22.904484]
 [-28.181402]
 [-28.181402]
 [-17.689592]
 [-17.689592]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11. 11.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.8091650009155273



action possibilites: [-1] 
expected returns: [[-47.966515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -18.499494552612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-52.93804]
 [-47.96653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 11.] 
cards in discard: [25.  8.  0. 11. 11.  8. 10. 11.  3. 15. 11. 29. 29. 11. 15.  0.  1. 11.
 15.  8. 10. 15.  8. 25. 15.  8.  0.  0. 10.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -47.966514587402344






Player: 1 
cards in hand: [6. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8. 15.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  8. 15.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [15.  8. 15.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15.  8. 29.] 
expected returns: [[-56.888058]
 [-65.93728 ]
 [-53.606506]
 [-65.93728 ]
 [-53.606506]
 [-34.425323]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15.  8. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -47.966514587402344



action possibilites: [-1. 15.  8.] 
expected returns: [[-24.15834 ]
 [-29.7881  ]
 [-21.737053]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  1.] 
cards in discard: [15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15 15  8 15 15 15  8 15 11  1  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -46.281982421875



action possibilites: [-1] 
expected returns: [[-38.342773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -16.094871520996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-44.229477]
 [-29.780426]
 [-38.038994]
 [-34.090904]
 [-42.718765]
 [-36.04989 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -38.3427734375



buy possibilites: [-1] 
expected returns: [[-22.981218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15.  8.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -29.78043556213379






Player: 1 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 8. 11. 10. 11.  8.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  0.  2.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 8. 11. 10. 11.  8.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 8. 11. 10. 11.  8.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 11.  8.] 
expected returns: [[16.948263]
 [19.4748  ]
 [26.718838]
 [ 8.584091]
 [26.718838]
 [19.4748  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 11.  8.] 
cards in discard: [15.  8.  1. 29.  8.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  6. 14.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.981218338012695



action possibilites: [-1] 
expected returns: [[-93.05123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  8.] 
cards in discard: [15.  8.  1. 29.  8.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  6. 14.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 25.15669059753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-102.11028]
 [ -91.59208]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  8.] 
cards in discard: [15.  8.  1. 29.  8.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15.  6. 14.  0. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -93.05123138427734






Player: 1 
cards in hand: [15.  6. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 14.  0. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1
  6  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15. 15.  3.  8. 25.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.  1. 11.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1  6
  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15. 15.  3.  8. 25.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.  1. 11.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 29.] 
cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1  6
  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  1.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [15. 15.  3.  8. 25.] 
adversary cards in discard: [15.  8.  1. 29.  8.  1.  1. 11.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 8 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 15.  3.  8. 25.] 
cards in discard: [15.  8.  1. 29.  8.  1.  1. 11.  8. 10. 11.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11 11 25 11 11 25  8  8  8 29  8 10 11 10 11  8 10
 10 11 10 29 15  8 15 15 15  8 15 11  1  8  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  0. 10.  0.  0.  8.  4.  7. 10.  2.  9.  3.] 
adversary cards in hand: [ 6. 14. 29.] 
adversary cards in discard: [14. 11.  3.  0.  3.  6. 10.  6.  6.  0.  0.  1.  0.  3.  6.  3.  0. 29.
  1. 22.  3.  0.  0.  3.  0. 11.  0.  6.  0.  3.  6.  3.  8.  0.  0.  0.
  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  3  1 11  6  0  3  6 29 29 11  6 22  6 14  1  6
  3  6 15  6  3  6  0 29  6  3  0  0  6  3  0  0 14  0 14 10  0  1  8  8] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      90       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000085 

action type: buy - action -1.0
Learning step: 120007.0546875
desired expected reward: 119915.4609375



