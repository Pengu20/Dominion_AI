 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.66965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1.0
Learning step: 13.889982223510742
desired expected reward: 45.89057159423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.184673]
 [20.985682]
 [20.578758]
 [19.140032]
 [20.563164]
 [22.130953]
 [21.73687 ]
 [22.264076]
 [20.677656]
 [21.329945]
 [21.47866 ]
 [21.95205 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.587232768535614
desired expected reward: 21.449539184570312



buy possibilites: [-1] 
expected returns: [[21.9259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.39586204290390015
desired expected reward: 21.87452507019043






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.771923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5558764934539795
desired expected reward: 21.370023727416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.581848]
 [23.382854]
 [22.975931]
 [21.537205]
 [24.528126]
 [24.134043]
 [23.72712 ]
 [24.349222]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6216294169425964
desired expected reward: 23.368894577026367



buy possibilites: [-1] 
expected returns: [[25.487148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.07822871953248978
desired expected reward: 24.44989776611328






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[21.975285]
 [21.5019  ]
 [22.15419 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.681522786617279
desired expected reward: 24.805625915527344



action possibilites: [-1] 
expected returns: [[23.719856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.934173583984375
desired expected reward: 12.173568725585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.982882]
 [22.783888]
 [22.376965]
 [20.93824 ]
 [23.92916 ]
 [23.535076]
 [23.128153]
 [23.750256]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.01979862153530121
desired expected reward: 23.700057983398438



buy possibilites: [-1] 
expected returns: [[22.968075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 6. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.5373201966285706
desired expected reward: 23.66547393798828






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 10. 11. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 10. 11. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 10. 11. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.994167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5961140990257263
desired expected reward: 22.37196159362793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.75128 ]
 [22.552286]
 [22.145365]
 [20.706638]
 [23.697557]
 [23.303473]
 [22.89655 ]
 [23.518652]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6047151684761047
desired expected reward: 22.531299591064453



buy possibilites: [-1] 
expected returns: [[24.380224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 15.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5465459823608398
desired expected reward: 21.204730987548828






Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.962748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6169602274894714
desired expected reward: 23.763263702392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.451656]
 [24.252668]
 [23.845743]
 [22.407022]
 [23.830149]
 [25.39794 ]
 [25.003855]
 [25.531063]
 [23.944641]
 [24.596931]
 [24.74565 ]
 [25.219038]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6473875641822815
desired expected reward: 24.537986755371094



buy possibilites: [-1] 
expected returns: [[23.941896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.3262017071247101
desired expected reward: 25.071853637695312






Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [10. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10. 15.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[26.762964]
 [26.156061]
 [26.301714]
 [26.947992]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6.  0. 11.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5873430371284485
desired expected reward: 23.35455322265625



action possibilites: [-1] 
expected returns: [[27.145763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.057931479066610336
desired expected reward: 26.374135971069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.421022]
 [26.212957]
 [25.809359]
 [24.38776 ]
 [27.345871]
 [26.957535]
 [26.55394 ]
 [27.160843]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08660487830638885
desired expected reward: 27.059158325195312



buy possibilites: [-1] 
expected returns: [[22.518042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.] 
cards in discard: [15.  0.  0.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.429821252822876
desired expected reward: 26.9837589263916






Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 4. 29.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [ 4. 29.  0.  3.  0.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.421793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5362905263900757
desired expected reward: 21.98175048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.943756]
 [26.735685]
 [26.33209 ]
 [24.920187]
 [27.8686  ]
 [27.480267]
 [27.07667 ]
 [27.68357 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6931636333465576
desired expected reward: 26.854522705078125



buy possibilites: [-1] 
expected returns: [[24.929922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  0.  3. 10. 15. 10.  6. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.15030641853809357
desired expected reward: 26.585378646850586






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[24.892473]
 [24.431223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6369832754135132
desired expected reward: 24.292938232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.845207]
 [24.637136]
 [24.233541]
 [22.81194 ]
 [24.218534]
 [25.770052]
 [25.381718]
 [25.900694]
 [24.331844]
 [24.97812 ]
 [25.123772]
 [25.585024]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6388410329818726
desired expected reward: 24.3946533203125



buy possibilites: [-1] 
expected returns: [[29.880419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.34672340750694275
desired expected reward: 26.247421264648438






Player: 1 
cards in hand: [ 3.  0. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11. 15.  1.  6.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29] -> size -> 18 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11. 15.  1.  6.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29] -> size -> 18 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  1.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 11. 15.  1.  6.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29] -> size -> 18 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 15.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[34.13214]
 [34.31717]
 [33.67089]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  1.  6.] 
cards in discard: [29.  0.  0.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  9. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6872901320457458
desired expected reward: 29.19312858581543



action possibilites: [-1] 
expected returns: [[27.435034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.028699835762381554
desired expected reward: 32.67429733276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.952995]
 [26.341331]
 [24.91973 ]
 [27.489506]
 [27.692814]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0924702063202858
desired expected reward: 27.34256362915039



buy possibilites: [-1] 
expected returns: [[27.620481]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.038574885576963425
desired expected reward: 25.9144229888916






Player: 1 
cards in hand: [3. 0. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 14.  3.  0. 29.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[33.24626]
 [32.63936]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [4. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6313720345497131
desired expected reward: 26.98910903930664



action possibilites: [-1.] 
expected returns: [[35.15703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [4. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.1568419635295868
desired expected reward: 32.376182556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.492016]
 [34.28243 ]
 [33.87788 ]
 [32.459286]
 [35.414127]
 [35.028263]
 [34.623714]
 [35.216312]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [4. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.2422274798154831
desired expected reward: 34.91480255126953



buy possibilites: [-1] 
expected returns: [[34.043648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0. 15. 11.  0. 11.  3. 15.  1.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [4. 3. 1. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.3189854025840759
desired expected reward: 34.60141372680664






Player: 1 
cards in hand: [4. 3. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 1. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  8. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 1. 0. 1.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[23.165817]
 [23.492678]
 [23.363636]
 [22.573221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [11.  4.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9267125725746155
desired expected reward: 33.11693572998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.921236]
 [22.71165 ]
 [22.3071  ]
 [20.888504]
 [23.843351]
 [23.457485]
 [23.052935]
 [23.645533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [11.  4.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6063042879104614
desired expected reward: 22.63684844970703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [11.  4.  3.  1.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  4.  3.  1.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  4.  3.  1.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  4.  3.  1.  0.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.173506]
 [21.371323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6349673867225647
desired expected reward: 23.01056480407715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.840868]
 [20.63128 ]
 [20.226732]
 [18.808136]
 [21.762981]
 [21.37712 ]
 [20.972569]
 [21.565165]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 29. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.568431556224823
desired expected reward: 20.684165954589844



buy possibilites: [-1] 
expected returns: [[28.273249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.399932861328125
desired expected reward: 19.826799392700195






Player: 1 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 28. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [11.  4.  3.  1.  0.  1. 10. 29.  0.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  6.  0.  3.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.114191]
 [19.541185]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  3.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.78896164894104
desired expected reward: 27.48428726196289



action possibilites: [-1.] 
expected returns: [[23.645395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.11077411472797394
desired expected reward: 19.69419288635254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.023018]
 [22.813433]
 [22.408882]
 [21.002966]
 [23.945137]
 [23.55927 ]
 [23.15472 ]
 [23.747316]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  7. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.017289619892835617
desired expected reward: 23.62810516357422



buy possibilites: [-1] 
expected returns: [[22.016562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5028197765350342
desired expected reward: 24.447954177856445






Player: 1 
cards in hand: [ 3.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  3. 15.  1.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.] 
adversary cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[28.18709]
 [27.7532 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.
 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  4.  3.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
   59    0] 
sum of rewards: -246 

action type: discard_down_to_3_cards - action 4
Learning step: -7.868991374969482
desired expected reward: 18.235448837280273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.723253]
 [27.487574]
 [27.096384]
 [25.724615]
 [28.581915]
 [28.208788]
 [27.817595]
 [28.390602]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.
 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  4.  3.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7045584321022034
desired expected reward: 27.48253059387207



buy possibilites: [-1] 
expected returns: [[25.62499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.] 
cards in discard: [ 0. 29.  1. 11. 10.  3.  0.  0. 11.  3.  0. 11. 10.  6.  0.  3.  0.  0.
 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 10.  4.  3.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.6274519562721252
desired expected reward: 26.468931198120117






Player: 1 
cards in hand: [ 0. 11. 10.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  4.  3.] 
cards in discard: [14.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15. 11.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  4.  3.] 
cards in discard: [14.  3.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15. 11.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  4.  3.] 
cards in discard: [14.  3.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15. 11.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [15. 11.  3.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[27.311468]
 [26.88468 ]
 [27.527245]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6312771439552307
desired expected reward: 24.99371337890625



action possibilites: [-1] 
expected returns: [[26.951277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.07595162838697433
desired expected reward: 26.888715744018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.280636]
 [25.659204]
 [24.25914 ]
 [26.800833]
 [26.96362 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08525613695383072
desired expected reward: 26.86602020263672






Player: 1 
cards in hand: [3. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15. 11.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 26. 29.  8.  9. 10.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15. 11.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15. 11.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.416468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [15. 11.  3.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16] -> size -> 24 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7229787707328796
desired expected reward: 26.240638732910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.551064]
 [22.331919]
 [21.929632]
 [20.908497]
 [20.529568]
 [21.91507 ]
 [23.449825]
 [23.07126 ]
 [24.216116]
 [23.573551]
 [22.026407]
 [21.65107 ]
 [22.668972]
 [20.870216]
 [22.807259]
 [23.234049]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [15. 11.  3.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16] -> size -> 24 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5859454274177551
desired expected reward: 21.8835506439209



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.  3.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.  3.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  9. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [14.  3.  0.  3.  0.  0. 11.  0. 10.  4.  3. 16.  3.  3.  0.  1.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.151873]
 [29.367647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5395674109458923
desired expected reward: 22.694480895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.57866 ]
 [27.957224]
 [26.557169]
 [29.098856]
 [29.261646]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7271447777748108
desired expected reward: 28.424728393554688



buy possibilites: [-1] 
expected returns: [[27.410833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4609030485153198
desired expected reward: 27.49632453918457






Player: 1 
cards in hand: [10.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 2 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10. 10.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 11.  0. 15.  3.] 
adversary cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
adversary victory points: 5
player victory points: 8 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[26.089746]
 [26.418026]
 [26.298405]
 [25.677109]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 15.  3.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6974322199821472
desired expected reward: 26.713401794433594



action possibilites: [-1. 11. 15.] 
expected returns: [[28.090172]
 [28.305946]
 [27.663383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.  3.  0.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.04773176088929176
desired expected reward: 26.370296478271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.636421]
 [27.417276]
 [27.014986]
 [25.614927]
 [28.535183]
 [28.156618]
 [27.754332]
 [28.319407]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  3.  0.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10235973447561264
desired expected reward: 27.98781394958496



buy possibilites: [-1] 
expected returns: [[24.830465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  3.  0.] 
cards in discard: [15. 11.  3.  1.  6.  0.  1.  0.  3.  0.  3. 11.  0.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0.  3.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.41808992624282837
desired expected reward: 28.172422409057617






Player: 1 
cards in hand: [14.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6. 10.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
adversary victory points: 5
player victory points: 8 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[27.616295]
 [27.05122 ]
 [27.05122 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6075504422187805
desired expected reward: 24.222915649414062



action possibilites: [-1. 10.] 
expected returns: [[29.937922]
 [29.372847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.05115262791514397
desired expected reward: 27.053096771240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.373209]
 [29.154058]
 [28.751776]
 [27.35171 ]
 [30.27197 ]
 [29.893404]
 [29.49112 ]
 [30.056194]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1395559459924698
desired expected reward: 29.798364639282227



buy possibilites: [-1] 
expected returns: [[32.081142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [4. 0. 0. 3. 0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.4557065963745117
desired expected reward: 29.60976791381836






Player: 1 
cards in hand: [4. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 11.  1.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1] -> size -> 27 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  6.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 11.  1.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1] -> size -> 27 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3. 0.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  5.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 11.  1.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1] -> size -> 27 
adversary victory points: 5
player victory points: 8 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[31.280924]
 [30.87593 ]
 [31.520111]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 11.  1.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  5.  9.  9.  7.  8. 10.  6. 10.  8.] 
adversary cards in hand: [16. 11.  3. 14.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8 11] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7839464545249939
desired expected reward: 31.297195434570312



action possibilites: [-1] 
expected returns: [[26.988064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  1.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [16. 11.  3. 14.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8 11] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.04569431021809578
desired expected reward: 31.968374252319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.616673]
 [26.392994]
 [25.990425]
 [24.599571]
 [27.504238]
 [27.13049 ]
 [26.727915]
 [27.265047]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  1.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [16. 11.  3. 14.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8 11] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08009427785873413
desired expected reward: 26.907970428466797






Player: 1 
cards in hand: [16. 11.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3. 14.  0.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16
 14 25  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  9.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.] 
cards in discard: [25. 29. 29. 10.  3.  0.  3.  0.  0.  8. 14.  0.  0.  0.  3. 11.  4.  0.
  0.  3.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[27.173824]
 [27.405117]
 [26.654512]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3. 10.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.682947039604187
desired expected reward: 26.582101821899414



action possibilites: [-1. 11. 15.] 
expected returns: [[29.052086]
 [29.283379]
 [28.660526]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3. 15.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3
  3 10  1 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.04455144703388214
desired expected reward: 26.60995864868164



action possibilites: [-1. 11.] 
expected returns: [[26.064257]
 [26.303442]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.4653657376766205
desired expected reward: 29.125892639160156



action possibilites: [-1] 
expected returns: [[30.414925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 1.4346843957901
desired expected reward: 28.257095336914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.843016]
 [29.619339]
 [29.216764]
 [27.825912]
 [30.730581]
 [30.356833]
 [29.954258]
 [30.491394]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.0509763956069946
desired expected reward: 31.465900421142578



buy possibilites: [-1] 
expected returns: [[25.068068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 18  0] 
sum of rewards: 73 

action type: buy - action 1.0
Learning step: 1.5646345615386963
desired expected reward: 31.18397331237793






Player: 1 
cards in hand: [0. 0. 3. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.937714]
 [25.293903]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6379520297050476
desired expected reward: 24.43011474609375



action possibilites: [-1.] 
expected returns: [[24.152805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.05521265044808388
desired expected reward: 25.238691329956055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.660597]
 [23.436916]
 [23.034346]
 [21.643494]
 [24.548162]
 [24.17441 ]
 [23.771841]
 [24.308973]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  5.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.026075363159179688
desired expected reward: 24.12672996520996



buy possibilites: [-1] 
expected returns: [[25.538933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 1. 10.  0.  0.  0. 10.  3. 10. 11.  0.  3. 15.  1. 10.  1. 10. 15. 11.
  6.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  4.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.52171391248703
desired expected reward: 25.069873809814453






Player: 1 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [29.  0.  0.  3.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  4.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11] -> size -> 30 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [29.  0.  0.  3.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  4.  9.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11] -> size -> 30 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11. 10. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11] -> size -> 30 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[21.212534]
 [21.443825]
 [20.693222]
 [21.443825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  8.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10. 14.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6930698156356812
desired expected reward: 24.845863342285156



action possibilites: [-1] 
expected returns: [[26.064121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1.  0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10. 14.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.867361068725586
desired expected reward: 10.833780288696289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.71639 ]
 [25.490469]
 [25.085398]
 [23.700863]
 [26.595987]
 [26.226976]
 [25.821905]
 [26.328363]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1.  0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10. 14.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06190738454461098
desired expected reward: 26.002214431762695






Player: 1 
cards in hand: [ 0. 29.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10. 14.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 29.  0.  3. 10.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.210701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25.  0. 16.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.607024610042572
desired expected reward: 20.6508731842041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.747943]
 [14.797977]
 [17.270718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 25.  0. 16.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4961659014225006
desired expected reward: 16.714534759521484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11. 25.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0. 16.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  7.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10.  1. 10.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6] -> size -> 31 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 16.  8. 11.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10.  1. 10.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6] -> size -> 32 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 16.  8. 11.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10.  1. 10.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6] -> size -> 32 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  1. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[21.174934]
 [20.69237 ]
 [20.69237 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10.  6.  0.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 4.  6. 14.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.448487281799316
desired expected reward: 7.822232246398926



action possibilites: [-1. 10.] 
expected returns: [[22.954454]
 [22.47189 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  6.  0.  0.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 4.  6. 14.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.06822383403778076
desired expected reward: 20.760595321655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.590363]
 [22.32799 ]
 [21.942007]
 [20.622633]
 [21.926882]
 [23.381466]
 [23.029823]
 [23.486246]
 [22.026115]
 [22.643839]
 [22.76374 ]
 [23.1264  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  6.  0.  0.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  4.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 4.  6. 14.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.0011053276248276234
desired expected reward: 22.953350067138672



buy possibilites: [-1] 
expected returns: [[22.130295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  6.  0.  0.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 4.  6. 14.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.11592412739992142
desired expected reward: 23.497390747070312






Player: 1 
cards in hand: [ 4.  6. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6. 14.  3.  3.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  3.  0.  1.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11] -> size -> 33 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  6. 14.  3.  3.] 
cards in discard: [29.  0.  0.  3.  1.  1.  8.  0. 29.  0.  3.  0.  0. 14.  0. 29.  3. 10.
 25.  0. 11.  0. 16.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  3.  0.  1.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11] -> size -> 33 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[21.08359 ]
 [20.601025]
 [21.338654]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  1.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.592632532119751
desired expected reward: 21.537662506103516



action possibilites: [-1. 11. 15.] 
expected returns: [[21.627209]
 [21.882273]
 [21.26455 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1. 15.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.059289321303367615
desired expected reward: 20.660314559936523



action possibilites: [-1. 15.] 
expected returns: [[25.310574]
 [24.929977]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 15.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3
 10  1 10 10  1 11  6  6 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: gain_card_n - action 0
Learning step: 0.7114275693893433
desired expected reward: 20.802595138549805



action possibilites: [-1] 
expected returns: [[21.395638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 15.0
Learning step: 1.1267547607421875
desired expected reward: 26.056732177734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.011646]
 [20.758995]
 [20.363289]
 [19.393923]
 [19.043919]
 [20.348166]
 [21.849047]
 [21.485197]
 [22.596638]
 [21.95748 ]
 [20.4474  ]
 [20.082085]
 [21.085806]
 [19.344458]
 [21.209887]
 [21.585154]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.229654312133789
desired expected reward: 22.62529182434082



buy possibilites: [-1] 
expected returns: [[20.31695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 59.5 

action type: buy - action 10.0
Learning step: 1.3611174821853638
desired expected reward: 22.601469039916992






Player: 1 
cards in hand: [ 1. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  8.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.980757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  8.] 
adversary cards in hand: [29.  6. 11. 10. 16.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5182105302810669
desired expected reward: 19.798738479614258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.839945]
 [22.58553 ]
 [22.191395]
 [20.859854]
 [22.176052]
 [23.648752]
 [23.297304]
 [23.749197]
 [22.27337 ]
 [22.903166]
 [23.018955]
 [23.364017]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  8.] 
adversary cards in hand: [29.  6. 11. 10. 16.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5992140769958496
desired expected reward: 22.381542205810547



buy possibilites: [-1] 
expected returns: [[20.546999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 6. 11. 10. 11.  1.  0. 29. 10.  3.  0.  3.  6. 11. 10.  1. 10.  6.  0.
  0.  0. 10. 10. 11. 15.  3.  1. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  7.] 
adversary cards in hand: [29.  6. 11. 10. 16.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.3351747691631317
desired expected reward: 23.354129791259766






Player: 1 
cards in hand: [29.  6. 11. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 11. 10. 16.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  7.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10. 16.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10. 16.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[23.1845  ]
 [22.723646]
 [22.839434]
 [23.46923 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 11.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5234692692756653
desired expected reward: 20.023529052734375



action possibilites: [-1. 15. 11.] 
expected returns: [[22.955925]
 [22.61086 ]
 [23.240656]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  3.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.00975683145225048
desired expected reward: 22.733402252197266



action possibilites: [-1. 15.] 
expected returns: [[24.429724]
 [24.072834]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  6.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 50 

action type: gain_card_n - action 7
Learning step: 1.120408058166504
desired expected reward: 22.273910522460938



action possibilites: [-1] 
expected returns: [[24.095192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 15.0
Learning step: 1.1808146238327026
desired expected reward: 25.253646850585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.577784]
 [21.564157]
 [24.15404 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  6.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.1690964698791504
desired expected reward: 25.2642879486084



buy possibilites: [-1] 
expected returns: [[25.957775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [29.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  5.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 25.  1.  4.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   60    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -247 

action type: buy - action 6.0
Learning step: -7.78436803817749
desired expected reward: 13.779788970947266






Player: 1 
cards in hand: [ 0.  3. 25.  1.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  4.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  5.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  1. 15.  0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6] -> size -> 37 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  4.  0. 29.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  1. 15.  0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 38 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  4.  0. 29.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  1. 15.  0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 38 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  4.  0. 29.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [10.  3.  1. 15.  0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 38 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  3.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[18.946661]
 [18.50535 ]
 [18.616209]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 15.  0.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10
  1 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -3    0 -300
    0    0] 
sum of rewards: -308 

action type: buy - action -1
Learning step: -9.821953773498535
desired expected reward: 16.135822296142578



action possibilites: [-1] 
expected returns: [[23.31495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.13632069528102875
desired expected reward: 18.75252914428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.832737]
 [22.603834]
 [22.196209]
 [21.1814  ]
 [20.819109]
 [22.180338]
 [23.703438]
 [23.339966]
 [24.45867 ]
 [23.807333]
 [22.281   ]
 [21.892477]
 [22.93234 ]
 [21.121376]
 [23.052103]
 [23.40899 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  9.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.008659343235194683
desired expected reward: 23.306291580200195



buy possibilites: [-1] 
expected returns: [[20.214367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 50  0] 
sum of rewards: 62 

action type: buy - action 25.0
Learning step: 1.338490605354309
desired expected reward: 25.797163009643555






Player: 1 
cards in hand: [ 8.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 10. 11.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 10. 11.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 10. 11.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 10. 11.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[22.201574]
 [21.861475]
 [21.74737 ]
 [22.482225]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1. 10. 11.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  8.  3.  3.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5238037109375
desired expected reward: 19.690563201904297



action possibilites: [-1. 15. 11. 10.] 
expected returns: [[21.192478]
 [20.873934]
 [21.50309 ]
 [20.763218]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1. 11. 10.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  8.  3.  3.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.005380268208682537
desired expected reward: 22.23454475402832



action possibilites: [-1. 11. 10.] 
expected returns: [[17.79467 ]
 [18.09726 ]
 [17.377575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  8.  3.  3.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.6109408140182495
desired expected reward: 21.484874725341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.535892]
 [16.87223 ]
 [15.588776]
 [17.943064]
 [17.978004]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 24. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  8.  3.  3.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6965758800506592
desired expected reward: 18.49124526977539



buy possibilites: [-1] 
expected returns: [[21.820976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  8.  3.  3.] 
adversary cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 39 

action type: buy - action 3.0
Learning step: 0.8929533362388611
desired expected reward: 17.765182495117188






Player: 1 
cards in hand: [ 0. 14.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  3.  3.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  8.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [22. 29.  1.  0.  0.  0.  0. 15. 11. 29.  6. 10. 16.  1. 25.  0.  3.  1.
  4.  0. 29.  3.  0. 11.  8.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  7.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.766087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  7.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -4
     0 -1200   117     0] 
sum of rewards: -1092 

action type: discard_down_to_3_cards - action 5
Learning step: -33.05331039428711
desired expected reward: -15.308027267456055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.489548]
 [21.840763]
 [20.50058 ]
 [22.958931]
 [22.995043]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  7.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6002544164657593
desired expected reward: 22.16583251953125



buy possibilites: [-1] 
expected returns: [[20.356934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0  8  0] 
sum of rewards: -2 

action type: buy - action 8.0
Learning step: -0.535020112991333
desired expected reward: 22.42391014099121






Player: 1 
cards in hand: [ 8.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[20.212524]
 [19.783264]
 [20.616938]
 [19.783264]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  6. 10.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 4. 10.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5485808253288269
desired expected reward: 19.808353424072266



action possibilites: [-1. 29. 10.] 
expected returns: [[18.994225]
 [19.39864 ]
 [18.564964]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6. 10.  1.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 4. 10.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.05672115087509155
desired expected reward: 19.839984893798828



action possibilites: [-1. 10. 11.] 
expected returns: [[20.104872]
 [19.675613]
 [20.415485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  1. 11.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 4. 10.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.6794620156288147
desired expected reward: 20.078102111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.620924]
 [19.360798]
 [18.96712 ]
 [17.647943]
 [18.950207]
 [20.415483]
 [20.06929 ]
 [20.509289]
 [19.046453]
 [19.675613]
 [19.786327]
 [20.104874]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  1. 11.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 23. 29.  8.  4.  9.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 4. 10.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6531312465667725
desired expected reward: 20.758005142211914



buy possibilites: [-1] 
expected returns: [[20.782951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  1. 11.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 4. 10.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -6  0  0 32  0] 
sum of rewards: 61 

action type: buy - action 16.0
Learning step: 1.4797147512435913
desired expected reward: 20.429922103881836






Player: 1 
cards in hand: [ 4. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  8. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.446163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5693038702011108
desired expected reward: 20.213647842407227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.962215]
 [18.702087]
 [18.30841 ]
 [16.991474]
 [18.291494]
 [19.756773]
 [19.410582]
 [19.850578]
 [18.387745]
 [19.016901]
 [19.127619]
 [19.446163]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  6.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5340222120285034
desired expected reward: 18.912141799926758



buy possibilites: [-1] 
expected returns: [[21.148407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [29.  6. 10. 11. 15.  3.  3.  6.  6. 25. 15. 10.  3.  1.  3. 10. 15.  3.
  1. 11. 10.  0. 11.  8.  0.  3.  0. 16. 10. 29.  0.  6. 10.  1. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  5.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -7.  0.  0.  2.  0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -0.6612703800201416
desired expected reward: 18.749309539794922






Player: 1 
cards in hand: [ 3. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  8.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  5.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6.  6.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 6.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14
 25  8 11  6  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  5.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6.  6.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  5.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6.  6.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  5.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6.  6.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6.  6.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.432758]
 [22.770115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  6. 11.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 29.  0. 16.  3.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.546782910823822
desired expected reward: 20.60162353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.133047]
 [20.157604]
 [22.587158]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  6. 11.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0. 29.  0. 16.  3.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5966917872428894
desired expected reward: 21.8360652923584



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 16.  3.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 23. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 6.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.172062]
 [23.165104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 6.] 
cards in discard: [ 0.  6.  6.  6. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 25.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5843372941017151
desired expected reward: 22.00282096862793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.665813]
 [20.642338]
 [23.191597]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 6.] 
cards in discard: [ 0.  6.  6.  6. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 25.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6130601763725281
desired expected reward: 22.55900001525879



buy possibilites: [-1] 
expected returns: [[24.710049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 6.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 25.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -8.  0.  0.  0.  0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -0.7805189490318298
desired expected reward: 20.885295867919922






Player: 1 
cards in hand: [11. 25.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  1. 14.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [16.  1. 10. 10. 29.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  1.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 10. 10.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0.  1.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 23. 30. 22. 29.  8.  4.  8.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 10. 10.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0.  1.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 22. 29.  8.  4.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1. 10. 10.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[28.06856 ]
 [27.647177]
 [27.647177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 22. 29.  8.  4.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -8
     0 -1500   113     0] 
sum of rewards: -1400 

action type: discard_down_to_3_cards - action 1
Learning step: -42.357200622558594
desired expected reward: -20.705097198486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.568928]
 [26.929811]
 [25.552822]
 [28.087755]
 [28.094711]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 22. 29.  8.  4.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.705864667892456
desired expected reward: 27.362693786621094



buy possibilites: [-1] 
expected returns: [[25.858261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -9.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -9.91507339477539
desired expected reward: 15.637748718261719






Player: 1 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[20.446026]
 [20.024643]
 [20.024643]
 [20.024643]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  0.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 22. 15. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7137192487716675
desired expected reward: 25.144542694091797



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[21.573465]
 [21.152084]
 [21.152084]
 [21.927391]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 22. 15. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.0754987895488739
desired expected reward: 20.100141525268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.876226]
 [20.237108]
 [18.852747]
 [21.39505 ]
 [21.402006]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 22. 29.  8.  3.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 22. 15. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.018702277913689613
desired expected reward: 21.5921688079834



buy possibilites: [-1] 
expected returns: [[22.215805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 22. 15. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -10.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -9.182315826416016
desired expected reward: 9.670433044433594






Player: 1 
cards in hand: [ 8. 22. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 15. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22. 15. 11.  0.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  3. 11.  3. 15.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11.  0. 29.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  3. 11.  3. 15.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.  0. 29.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  3. 11.  3. 15.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.  0. 29.] 
cards in discard: [ 0.  8.  0.  3. 14.  3. 14.  4. 10.  0.  1.  0.  8. 29.  8.  3.  0.  3.
 29.  0.  0. 16.  3.  0. 16. 14. 11. 25.  0.  1.  0.  0.  1.  3.  0.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  3. 11.  3. 15.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[22.772049]
 [23.11425 ]
 [22.472815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 43 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5765287280082703
desired expected reward: 21.6392765045166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.296959]
 [21.645859]
 [20.307463]
 [22.765348]
 [22.772049]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 22. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 43 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6025768518447876
desired expected reward: 22.169471740722656



buy possibilites: [-1] 
expected returns: [[22.2289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 43 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -11   0   0   8   0] 
sum of rewards: -8 

action type: buy - action 3.0
Learning step: -0.6431483030319214
desired expected reward: 21.002714157104492






Player: 1 
cards in hand: [29.  0. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  8.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  1 29  4  3 29 14  0 11 10  3  0 16 14 25
  8 11  0 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 25.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 25.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 25.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[16.552141]
 [16.186163]
 [17.576794]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10. 25.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  2.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0] -> size -> 40 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6390734910964966
desired expected reward: 21.589826583862305



action possibilites: [-1] 
expected returns: [[21.16682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 21. 29.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6] -> size -> 41 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.14494776725769043
desired expected reward: 17.72174072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.700613]
 [20.453949]
 [20.050797]
 [18.704401]
 [21.52851 ]
 [21.178331]
 [20.775175]
 [21.16682 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 10.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 21. 29.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6] -> size -> 41 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03194177523255348
desired expected reward: 21.198762893676758



buy possibilites: [-1] 
expected returns: [[25.373812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 10.  3. 15.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 20. 29.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6] -> size -> 41 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   2.   0.] 
sum of rewards: 5.0 

action type: buy - action 3.0
Learning step: -0.18509888648986816
desired expected reward: 19.865697860717773






Player: 1 
cards in hand: [0. 4. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 8. 25.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 20. 29.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 11.  8. 29.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 8. 25.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 23. 30. 20. 29.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 11.  8. 29.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 8. 25.  6.  4.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 20. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  1. 11.  8. 29.] 
adversary cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
adversary victory points: 2
player victory points: 12 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[18.670685]
 [19.032375]
 [18.682194]
 [19.118877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  8. 29.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 20. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7125059962272644
desired expected reward: 24.661306381225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.208134]
 [17.957813]
 [17.555237]
 [16.220661]
 [19.032375]
 [18.682194]
 [18.27904 ]
 [18.670685]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  8. 29.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 20. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5193660855293274
desired expected reward: 18.151317596435547



buy possibilites: [-1] 
expected returns: [[19.324709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  8. 29.] 
cards in discard: [ 0.  6.  6.  6. 11.  0.  3.  0.  8.  3.  6. 16. 29.  6.  1. 10. 10.  6.
 10.  0. 10. 10.  0. 11.  3.  1.  3. 11.  3. 15.  3. 25.  3.  0.  1. 10.
  3. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -13.   0.   0.
   2.   0.] 
sum of rewards: -16.0 

action type: buy - action 3.0
Learning step: -0.8037475943565369
desired expected reward: 16.751489639282227






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  4.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 3.  3.  6. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[19.242794]
 [18.960934]
 [19.599537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 15. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 16.  8.  1. 10.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8] -> size -> 43 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5267331004142761
desired expected reward: 18.797975540161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.7597  ]
 [16.777155]
 [19.205761]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 15. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 16.  8.  1. 10.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8] -> size -> 43 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5364723801612854
desired expected reward: 18.706321716308594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 16.  8.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  8.  1. 10.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.  1. 10.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.  1. 10.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[17.41675]
 [17.76144]
 [17.76144]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [ 3.  3.  6. 15. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  3.  9.  6.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5406428575515747
desired expected reward: 18.665117263793945



action possibilites: [-1] 
expected returns: [[20.423607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -14   0   0   9   0] 
sum of rewards: 10 

action type: gain_card_n - action 9
Learning step: -0.029919547960162163
desired expected reward: 18.11566162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.866673]
 [19.620005]
 [19.216852]
 [17.870459]
 [20.694565]
 [20.344385]
 [19.941233]
 [20.332874]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  3.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04548179358243942
desired expected reward: 20.46908950805664



buy possibilites: [-1] 
expected returns: [[23.571953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0  18   0] 
sum of rewards: 18 

action type: buy - action 11.0
Learning step: 0.16666854918003082
desired expected reward: 20.86123275756836






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  6. 25.  6.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  6. 25.  6.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
adversary victory points: 3
player victory points: 12 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 25.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[15.547143]
 [16.554653]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  6.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  1.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0] -> size -> 44 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6875662803649902
desired expected reward: 22.88438606262207



action possibilites: [-1] 
expected returns: [[15.725242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  1. 29.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.12289437651634216
desired expected reward: 16.67754554748535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.670857 ]
 [15.358989 ]
 [14.991274 ]
 [14.0786705]
 [14.973097 ]
 [16.343523 ]
 [16.022322 ]
 [17.026003 ]
 [16.422396 ]
 [15.062419 ]
 [14.701324 ]
 [15.654606 ]
 [14.013191 ]
 [15.750549 ]
 [16.005636 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  1. 29.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  5.  7. 10.  2.  9.  6.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.14339929819107056
desired expected reward: 15.868640899658203



buy possibilites: [-1] 
expected returns: [[20.758833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  1. 29.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   8.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: -0.06470409035682678
desired expected reward: 16.357690811157227






Player: 1 
cards in hand: [14.  3.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0. 29.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  3. 15. 10.  3.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11 29] -> size -> 51 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  0. 29.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  3. 15. 10.  3.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11 29] -> size -> 51 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  0. 29.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  3. 15. 10.  3.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11 29] -> size -> 51 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 15. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[16.099659]
 [16.116365]
 [15.845298]
 [15.750273]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15. 10.  3.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1
 10 10  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3
 10 11 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29. 16. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0] -> size -> 46 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6049162745475769
desired expected reward: 20.15391731262207



action possibilites: [-1] 
expected returns: [[21.62924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29. 16. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0] -> size -> 46 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.2609029710292816
desired expected reward: 14.134371757507324





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.255388]
 [21.629242]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29. 16. 11.  0.  3.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0] -> size -> 46 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.022459659725427628
desired expected reward: 21.65169906616211






Player: 1 
cards in hand: [29. 16. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16. 11.  0.  3.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 6. 10.  3.  3. 10.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
adversary victory points: 2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  3.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 10.  3.  3. 10.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  0.  3.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 10.  3.  3. 10.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  0.  3.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 10.  3.  3. 10.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[19.480673]
 [19.119398]
 [19.119398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  3. 10.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 48 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.59635329246521
desired expected reward: 21.032886505126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.106817]
 [19.480673]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  3. 10.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 48 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5356431603431702
desired expected reward: 18.945026397705078



buy possibilites: [-1] 
expected returns: [[18.4882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  3. 10.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [14.  0. 15.  3.  8.] 
adversary cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 48 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -15   0   0   0   0] 
sum of rewards: -20 

action type: buy - action 0.0
Learning step: -0.949078381061554
desired expected reward: 17.157737731933594






Player: 1 
cards in hand: [14.  0. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15.  3.  8.] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  0  1  4  3 29 14  0 11 10  3  0 16 14 25  8 11  0
 29  8  0 22 15  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
adversary victory points: 2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 25.  6.  4.  0.  4.  0.  0.  1.  8.  0.  0.  1.  0.  0.  0. 11. 16.
  8.  1. 10.  3.  3.  0.  3.  0.  6.  0. 14.  3.  8.  0. 29. 15.  0. 11.
 29. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[16.099371]
 [16.439932]
 [15.744781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 15.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.53492671251297
desired expected reward: 17.953271865844727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.751004]
 [15.074694]
 [16.116243]
 [16.099371]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 15.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4688502848148346
desired expected reward: 15.630522727966309



buy possibilites: [-1] 
expected returns: [[15.536165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 15.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -0.9094004034996033
desired expected reward: 13.841604232788086






Player: 1 
cards in hand: [ 0. 15.  3. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3. 14. 22.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  6. 11.  3.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0] -> size -> 51 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3. 14.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  6. 11.  3.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0] -> size -> 51 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3. 14.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  6. 11.  3.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0] -> size -> 51 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[17.848164]
 [17.496126]
 [18.191454]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  3.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 19. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3. 25.  0.  1.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.42798280715942383
desired expected reward: 15.108182907104492



action possibilites: [-1] 
expected returns: [[15.3654175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 18. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3. 25.  0.  1.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -17   0   0   4   0] 
sum of rewards: 2 

action type: gain_card_n - action 2
Learning step: -0.26296132802963257
desired expected reward: 15.8803129196167





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.055484]
 [14.369566]
 [15.381941]
 [15.365417]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 18. 28.  8.  0.  7.  2.  3.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3. 25.  0.  1.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1456015706062317
desired expected reward: 15.511018753051758



buy possibilites: [-1] 
expected returns: [[14.896391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  3. 25.  0.  1.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -18   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -0.1435440182685852
desired expected reward: 14.85499382019043






Player: 1 
cards in hand: [11.  3. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.  0.  1.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 29.  3. 15. 16.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 25.  0.  1.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 29.  3. 15. 16.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 25.  0.  1.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 6. 29.  3. 15. 16.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  3. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 16.] 
expected returns: [[15.91729 ]
 [16.343145]
 [15.661716]
 [14.869736]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3. 15. 16.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4307081401348114
desired expected reward: 14.465682983398438



action possibilites: [-1. 15.] 
expected returns: [[16.656527]
 [16.400953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.19817087054252625
desired expected reward: 14.38647747039795





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.301174]
 [15.627785]
 [16.677057]
 [16.656527]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  2.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.12027734518051147
desired expected reward: 16.776803970336914



buy possibilites: [-1] 
expected returns: [[14.635132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.  0.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -19   0   0   8   0] 
sum of rewards: 4 

action type: buy - action 8.0
Learning step: -0.22664281725883484
desired expected reward: 16.450414657592773






Player: 1 
cards in hand: [29.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  8.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3.  8.  6. 10.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3.  8.  6. 10.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3.  8.  6. 10.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3.  8.  6. 10.  1.] 
adversary cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[20.086983]
 [20.107794]
 [19.728796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6. 10.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  1.  4.  0.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3790415823459625
desired expected reward: 14.25609016418457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.723898]
 [19.047602]
 [20.107794]
 [20.086983]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6. 10.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 18. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  1.  4.  0.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5466539859771729
desired expected reward: 19.54033088684082



buy possibilites: [-1] 
expected returns: [[18.678988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6. 10.  1.] 
cards in discard: [ 3.  3.  6. 15. 11. 10. 11. 11. 11.  0.  0.  0. 29. 25.  0.  6.  6.  1.
 29.  1.  8. 10.  3.  0.  6. 10.  3.  3. 10.  0. 11.  3.  0. 10.  0.  3.
  8. 11. 10.  6.  3.  1. 16.  8. 29.  6.  3. 15.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  1.  4.  0.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -20   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: -0.8852986693382263
desired expected reward: 18.162303924560547






Player: 1 
cards in hand: [10.  1.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  4.  0.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  3.  1. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  4.  0.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  5.] 
adversary cards in hand: [10.  3.  1. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  4.  0.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [10.  3.  1. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
adversary victory points: 4
player victory points: 10 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [10.  3.  1. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[21.904812]
 [21.551712]
 [21.551712]
 [22.330667]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 10. 29.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [14.  0. 16.  8.  3.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4800634980201721
desired expected reward: 18.198923110961914



action possibilites: [-1. 10. 29.] 
expected returns: [[20.81639 ]
 [20.450808]
 [21.25724 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [14.  0. 16.  8.  3.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.023157348856329918
desired expected reward: 21.574867248535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[19.371279]
 [19.7094  ]
 [20.795668]
 [20.774439]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  1.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [14.  0. 16.  8.  3.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.038545873016119
desired expected reward: 20.854934692382812



buy possibilites: [-1] 
expected returns: [[15.190958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10. 29.  3.] 
cards in discard: [8.] 
cards in deck: 49 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [14.  0. 16.  8.  3.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -21   0   0   8   0] 
sum of rewards: 2 

action type: buy - action 8.0
Learning step: -0.4043649435043335
desired expected reward: 20.39130210876465






Player: 1 
cards in hand: [14.  0. 16.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  8.  3.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1  4  3 29  0 11 10  3  0 16 14 25  8 11  0 29  8  0
 22  1  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[17.941874]
 [17.576296]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [29.  4.  6.  3.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.41887447237968445
desired expected reward: 14.772083282470703



action possibilites: [-1.] 
expected returns: [[17.813618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [29.  4.  6.  3.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.10975410044193268
desired expected reward: 17.686050415039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[16.57904 ]
 [17.29741 ]
 [16.914103]
 [18.32559 ]
 [17.607224]
 [17.969494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [29.  4.  6.  3.  0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.10064517706632614
desired expected reward: 17.914262771606445






Player: 1 
cards in hand: [29.  4.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4.  6.  3.  0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6.  8. 10. 16.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6.  8. 10. 16.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 17. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6.  8. 10. 16.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 6.  8. 10. 16.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
adversary victory points: 4
player victory points: 10 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 10. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
expected returns: [[17.293451]
 [17.315573]
 [16.953905]
 [16.279974]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10. 16.  3.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5018867254257202
desired expected reward: 17.188764572143555



action possibilites: [-1.  8. 16.] 
expected returns: [[18.855825]
 [18.878159]
 [17.842127]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 16.  3.  0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10
  1 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11
 29  0  0  3  8  8  3  8] -> size -> 56 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  4.  7. 10.  2.  9.  4.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.13664010167121887
desired expected reward: 17.090545654296875



action possibilites: [-1.  8.] 
expected returns: [[16.00732 ]
 [16.029016]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1
 11  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29
  0  0  3  8  8  3  8 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -21   0   0  16   0] 
sum of rewards: 30 

action type: gain_card_n - action 5
Learning step: 0.6886885166168213
desired expected reward: 13.339524269104004



action possibilites: [-1] 
expected returns: [[16.587942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.3625197410583496
desired expected reward: 16.750974655151367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.298152]
 [16.587942]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [0. 0. 1. 8. 0.] 
adversary cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
adversary owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.3211181163787842
desired expected reward: 17.909059524536133






Player: 1 
cards in hand: [0. 0. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1
  3  0  8  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [25.  0. 15.  8.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [25.  0. 15.  8.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [25.  0. 15.  8.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [22.  8.  0. 15.  3. 14.  0.  6.  8.  0. 11.  3. 25.  0.  1.  0.  1. 29.
  0. 11.  8.  0. 15. 10.  1.  4.  0.  0.  8. 14.  0.  4.  3.  3. 29.  6.
  0. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [25.  0. 15.  8.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [25.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.  8.] 
expected returns: [[18.489027]
 [19.489048]
 [18.243547]
 [18.511147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15.  8.  0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [22.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4497724175453186
desired expected reward: 16.13817024230957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[17.17704 ]
 [17.49379 ]
 [18.489027]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  8.  0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [22.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5169962644577026
desired expected reward: 17.972030639648438



buy possibilites: [-1] 
expected returns: [[14.926177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15.  8.  0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [22.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -21.   0.   0.
   0.   0.] 
sum of rewards: -26.0 

action type: buy - action 0.0
Learning step: -1.1385862827301025
desired expected reward: 16.038454055786133






Player: 1 
cards in hand: [22.  6.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 3. 10. 11.  1. 29.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 3. 10. 11.  1. 29.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 3. 10. 11.  1. 29.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  3. 10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 3. 10. 11.  1. 29.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[15.142168]
 [14.802429]
 [15.483961]
 [15.560987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  1. 29.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 8.  0.  4. 11.  6.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4370291829109192
desired expected reward: 14.489148139953613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.8294735]
 [14.146388 ]
 [15.142168 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  1. 29.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [ 8.  0.  4. 11.  6.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0] -> size -> 45 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4517359733581543
desired expected reward: 14.690431594848633



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  4. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  4. 11.  6.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  2.  9.  4.] 
adversary cards in hand: [11.  3. 29.  0.  1.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 4. 6.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  3. 29.  0.  1.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 4. 6.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  3. 29.  0.  1.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [11.  3. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[21.092882]
 [21.443518]
 [21.522013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0.  1.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [ 0. 14.  4.  8.  0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3797052204608917
desired expected reward: 14.76246166229248





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[19.735287]
 [20.437284]
 [20.063044]
 [21.443516]
 [20.74152 ]
 [21.092878]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  0.  1.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [ 0. 14.  4.  8.  0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5648360848426819
desired expected reward: 20.528043746948242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  4.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  4.  8.  0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  4.  8.  0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [ 8.  0. 10.  6.  6.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.] 
adversary owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
adversary victory points: 3
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[19.674543]
 [19.697214]
 [19.326437]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  6.  6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  6 10  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11
  6  6 11  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0
  0  3  8  8  3  8 29  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5770673155784607
desired expected reward: 20.51581382751465



action possibilites: [-1] 
expected returns: [[15.26161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.008263320662081242
desired expected reward: 20.074382781982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.980684]
 [15.261609]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
adversary owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.147018700838089
desired expected reward: 15.408628463745117






Player: 1 
cards in hand: [0. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8
  0 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  0. 15. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  0. 15. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 22. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  0. 15. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [11.  0. 15. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
adversary victory points: 4
player victory points: 10 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [11.  0. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[23.462624]
 [23.832706]
 [23.208351]
 [23.832706]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 11.  3.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  4.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3596931993961334
desired expected reward: 14.90191650390625



action possibilites: [-1] 
expected returns: [[20.722187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -19   0   0  16   0] 
sum of rewards: 12 

action type: gain_card_n - action 8
Learning step: -0.1272869110107422
desired expected reward: 23.368375778198242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.3984  ]
 [20.722187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.  3.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.040357474237680435
desired expected reward: 20.762544631958008






Player: 1 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3.  3.  3. 11. 10.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 8. 21. 30. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3.  3.  3. 11. 10.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3.  3.  3. 11. 10.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
adversary victory points: 4
player victory points: 10 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[18.427303]
 [18.797384]
 [18.074461]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11. 10.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  2.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [11.  3. 29.  8.  3.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5773534774780273
desired expected reward: 20.144832611083984



action possibilites: [-1] 
expected returns: [[14.982368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [11.  3. 29.  8.  3.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -20   0   0   9   0] 
sum of rewards: 4 

action type: gain_card_n - action 4
Learning step: -0.21508297324180603
desired expected reward: 16.198179244995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.695908]
 [14.982369]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [11.  3. 29.  8.  3.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15244068205356598
desired expected reward: 15.134809494018555






Player: 1 
cards in hand: [11.  3. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  8.  3.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
adversary victory points: 4
player victory points: 10 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.863028]
 [22.23311 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  1.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 8.  0. 25.  3. 15.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.  8.  3. 29. 15. 11.
  3.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3675777018070221
desired expected reward: 14.614790916442871



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 4 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 3 

Remodel: 1 
Workshop: 5 
Chapel: 5 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 3 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 8. 10.  3.  1. 10. 29.  3. 10.  6.  0.  3.  6.  1. 29. 10. 16.  8.  6.
  0. 25.  0. 15.  8.  0.  3. 10. 11.  1. 29. 11.  3. 29.  0.  1.  8.  6.
 15. 11.  0. 15. 11.  3. 11. 11.  3.  3.  3. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 15 10  1 29 11  0  1  3 11  3  3 10  1 10 10  1 11  6  6 11
  0 10 15 29  6  6 25  3  8 16  8  0  6  6  3  3  3 10 11 29  0  0  3  8
  8  3  8 29  0 15 11 11] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 29. 16. 28.  8.  0.  7.  0.  0.  8.  3.  7. 10.  1.  9.  3.] 
adversary cards in hand: [ 8.  0. 25.  3. 15.] 
adversary cards in discard: [ 0. 22.  6.  0.  3.  3. 10.  0.  0. 10. 11.  8.  0.  4.  6.  0. 14.  4.
  8.  0.  1.  8.  0.  0.  0.  2.  0.  1.  1.  0.  0.  8.  3. 29. 15. 11.
  3.] 
adversary owned cards: [ 3  0  4  3 29  0 11 10  3  0 14 25  8 11  0 29  8  0 22  1  3  0  8  0
 14  8  3 16  0  0  6  4  8  0  6  0 15  0  0  1 15  3  0  0 10  1  2] -> size -> 47 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0  -21    0    0
    9    0] 
sum of rewards: -497 

action type: gain_card_n - action 4
Learning step: -15.50546932220459
desired expected reward: 4.343518257141113



