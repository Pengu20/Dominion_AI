 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.18445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 528 

action type: buy - action -1.0
Learning step: 8.990259170532227
desired expected reward: 357.1850891113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.54398]
 [322.6353 ]
 [322.98444]
 [320.2302 ]
 [323.3982 ]
 [326.68945]
 [323.97595]
 [329.07733]
 [323.93484]
 [324.32513]
 [326.2992 ]
 [337.5323 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.714679718017578
desired expected reward: 330.4462585449219



buy possibilites: [-1] 
expected returns: [[329.6473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -8.589701652526855
desired expected reward: 314.0456237792969






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[355.7948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.551857948303223
desired expected reward: 321.095458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[339.39185]
 [342.09985]
 [342.5557 ]
 [338.9865 ]
 [347.18896]
 [343.81833]
 [344.2623 ]
 [359.90048]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.093180656433105
desired expected reward: 346.81829833984375



buy possibilites: [-1] 
expected returns: [[327.08618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -9.053674697875977
desired expected reward: 335.2085876464844






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[322.79343]
 [307.33453]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.245612144470215
desired expected reward: 317.840576171875



action possibilites: [-1.] 
expected returns: [[332.20978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -7.143473148345947
desired expected reward: 303.22039794921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[302.8076 ]
 [305.30603]
 [305.7291 ]
 [302.43436]
 [306.22046]
 [310.1557 ]
 [306.90582]
 [313.00546]
 [306.86053]
 [307.32886]
 [309.68732]
 [323.12534]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -8.680720329284668
desired expected reward: 323.529052734375



buy possibilites: [-1] 
expected returns: [[308.99866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 22.5 

action type: buy - action 10.0
Learning step: -7.288976192474365
desired expected reward: 300.0399475097656






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.52222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.120726585388184
desired expected reward: 300.8779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.0292 ]
 [312.4895 ]
 [312.89783]
 [309.65994]
 [317.24103]
 [314.0539 ]
 [314.4622 ]
 [329.96463]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.426292419433594
desired expected reward: 320.76068115234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[316.2187 ]
 [299.70688]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.544886589050293
desired expected reward: 320.4197082519531



action possibilites: [-1.] 
expected returns: [[344.24496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: -6.450624942779541
desired expected reward: 296.47210693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.8228 ]
 [323.05908]
 [323.42722]
 [320.48584]
 [323.86673]
 [327.37283]
 [324.47977]
 [329.9205 ]
 [324.4311 ]
 [324.84793]
 [326.95605]
 [338.92593]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -8.900710105895996
desired expected reward: 335.3442687988281



buy possibilites: [-1] 
expected returns: [[319.7905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 31.0 

action type: buy - action 3.0
Learning step: -7.4260735511779785
desired expected reward: 316.0010986328125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.63507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.872306823730469
desired expected reward: 311.9181823730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[321.05698]
 [323.6946 ]
 [324.12363]
 [320.64117]
 [324.6297 ]
 [328.67993]
 [325.34134]
 [331.60764]
 [325.28256]
 [325.77042]
 [328.19205]
 [341.7976 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -9.103245735168457
desired expected reward: 330.8834228515625



buy possibilites: [-1] 
expected returns: [[325.72522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3. 10.  3.  0.  3.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 8.0
Learning step: -8.388251304626465
desired expected reward: 316.953125






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[291.78363]
 [280.45947]
 [280.45947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.85486125946045
desired expected reward: 315.870361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[277.99432]
 [279.64847]
 [279.91684]
 [277.74008]
 [283.01138]
 [280.69495]
 [280.9633 ]
 [292.57944]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.323792457580566
desired expected reward: 285.24029541015625



buy possibilites: [-1] 
expected returns: [[269.57968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 11.0
Learning step: -7.235026836395264
desired expected reward: 275.7763671875






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [ 3.  0.  0.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 15.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.08398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.300713539123535
desired expected reward: 263.2789611816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[305.99722]
 [308.4086 ]
 [305.68167]
 [309.38113]
 [323.48938]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.043550491333008
desired expected reward: 312.21295166015625



buy possibilites: [-1] 
expected returns: [[331.68918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11. 10.  0.  0. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -9.386856079101562
desired expected reward: 296.61041259765625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[257.64597]
 [236.801  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 1.] 
cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  8. 10.  7.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -312 

action type: buy - action -1
Learning step: -26.59480094909668
desired expected reward: 305.0943908691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[232.25801]
 [235.37378]
 [235.915  ]
 [231.78773]
 [236.5342 ]
 [241.47595]
 [237.40051]
 [245.03499]
 [237.3473 ]
 [237.94171]
 [240.88158]
 [258.01297]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 1.] 
cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  8. 10.  7.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.898311138153076
desired expected reward: 248.05801391601562



buy possibilites: [-1] 
expected returns: [[291.50803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 1.] 
cards in discard: [11. 10.  0.  0. 10.  0.  0.  3.  3.  3.  0.  0.  6. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  7. 10.  7.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 10.0
Learning step: -5.713156223297119
desired expected reward: 232.22857666015625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.  0.] 
cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [15. 25.  3.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [15. 25.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[288.62326]
 [274.18134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.812918663024902
desired expected reward: 282.6950988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[272.63174]
 [272.29214]
 [290.73145]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.655299186706543
desired expected reward: 279.3280944824219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [0. 3. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [0. 3. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [0. 3. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [0. 3. 6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[291.3533 ]
 [278.64285]
 [278.64285]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [0. 3. 6. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15.  0.] 
adversary cards in discard: [ 0. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.730818748474121
desired expected reward: 282.00067138671875



action possibilites: [-1. 10.] 
expected returns: [[315.7899 ]
 [300.71805]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [0. 3. 6. 8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15.  0.] 
adversary cards in discard: [ 0. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -6.522557258605957
desired expected reward: 271.5889892578125



action possibilites: [-1.] 
expected returns: [[306.42062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 6. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15.  0.] 
adversary cards in discard: [ 0. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -6.278789520263672
desired expected reward: 294.4393005371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[281.04236]
 [283.94757]
 [284.4295 ]
 [280.58072]
 [285.00967]
 [289.5981 ]
 [285.8231 ]
 [292.8993 ]
 [285.73303]
 [286.30508]
 [289.0261 ]
 [304.6635 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 6. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15.  0.] 
adversary cards in discard: [ 0. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.345813751220703
desired expected reward: 299.0747985839844



buy possibilites: [-1] 
expected returns: [[295.11868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 6. 8. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0. 15.  0.] 
adversary cards in discard: [ 0. 15.  3.  3. 25.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 32.5 

action type: buy - action 1.0
Learning step: -5.932206630706787
desired expected reward: 278.01531982421875






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15.  0.] 
cards in discard: [ 0. 15.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 15.  0.] 
cards in discard: [ 0. 15.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 15.  0.] 
cards in discard: [ 0. 15.  3.  3. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 10.  3.] 
adversary cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[237.42336]
 [217.71165]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  3.] 
cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.269148826599121
desired expected reward: 284.84954833984375



action possibilites: [-1.] 
expected returns: [[240.6864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 9 

action type: take_action - action 10.0
Learning step: -4.808244705200195
desired expected reward: 208.66552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[225.38385]
 [227.5085 ]
 [227.85727]
 [225.15805]
 [225.04657]
 [228.27884]
 [231.62923]
 [228.87585]
 [234.45534]
 [234.03746]
 [228.80673]
 [230.61429]
 [229.22462]
 [228.20973]
 [231.21132]
 [242.61316]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -6.381247520446777
desired expected reward: 234.30516052246094



buy possibilites: [-1] 
expected returns: [[212.78084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 0.  3.  6.  8.  3.  1. 10. 10.  0.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 10.0 

action type: buy - action 8.0
Learning step: -6.156224727630615
desired expected reward: 222.7196502685547






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[276.70715]
 [264.886  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.138896942138672
desired expected reward: 207.64193725585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[253.48708]
 [255.96614]
 [256.37976]
 [253.09384]
 [260.79422]
 [257.56912]
 [257.9828 ]
 [273.6605 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.461015701293945
desired expected reward: 267.0254821777344



buy possibilites: [-1] 
expected returns: [[231.4672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 15.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 1.0
Learning step: -7.290295600891113
desired expected reward: 248.67584228515625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 15.] 
cards in discard: [ 0.  3.  0.  0. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 15.] 
cards in discard: [ 0.  3.  0.  0. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 15.] 
cards in discard: [ 0.  3.  0.  0. 15.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [1. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[243.05327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 25.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.  0.  0. 10.  0.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.7277092933654785
desired expected reward: 224.73948669433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[226.03761]
 [228.80359]
 [226.13274]
 [229.26926]
 [225.74574]
 [225.60068]
 [229.81644]
 [234.1917 ]
 [230.58952]
 [237.77724]
 [237.27562]
 [230.50758]
 [232.87096]
 [231.0552 ]
 [229.73448]
 [233.64407]
 [247.35461]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 25.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.  0.  0. 10.  0.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.392305850982666
desired expected reward: 234.63661193847656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 25.  0.] 
cards in discard: [ 0.  3.  0.  0. 15.  3.  0.  0. 10.  0.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[184.57933]
 [168.44688]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -323 

action type: buy - action -1.0
Learning step: -24.541446685791016
desired expected reward: 222.8131866455078



action possibilites: [-1. 10.] 
expected returns: [[220.08052]
 [203.09778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  3. 10.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -3.6563022136688232
desired expected reward: 162.7509307861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[196.74962]
 [196.3264 ]
 [218.60759]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  3. 10.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.474040508270264
desired expected reward: 213.60647583007812






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  8.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6. 10.  6.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  8.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6. 10.  6.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  8.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6. 10.  6.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 8. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[204.60016]
 [186.8225 ]
 [187.23988]
 [186.8225 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  8.  0.] 
cards in discard: [ 1.  0.  0.  0.  3. 11.  1.  0.  3.  1.  0.  6. 10.  6.  0.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -8.191485404968262
desired expected reward: 210.4161376953125



action possibilites: [-1.  8.  8.] 
expected returns: [[239.3279 ]
 [224.40529]
 [224.40529]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 10  3  8 11  0  6 10  1  8  1  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: -4.582168102264404
desired expected reward: 182.65771484375



action possibilites: [-1.] 
expected returns: [[200.43881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 8
Learning step: -7.169459819793701
desired expected reward: 233.4171905517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[191.2176 ]
 [191.06053]
 [200.46288]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -5.262364387512207
desired expected reward: 195.17645263671875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15. 15.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 25.  3.  0. 15.  0.  0.  0.  3.  3.  0.  3.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[253.83177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -5.995166301727295
desired expected reward: 194.46771240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[232.65547]
 [235.03705]
 [235.43152]
 [232.27464]
 [235.91566]
 [239.89095]
 [236.59727]
 [242.82236]
 [236.50766]
 [236.99174]
 [239.36583]
 [253.3115 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.815528869628906
desired expected reward: 243.53903198242188



buy possibilites: [-1] 
expected returns: [[259.7689]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [10.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -22.968931198120117
desired expected reward: 209.30567932128906






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[206.83922]
 [192.53662]
 [195.10747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [15.  3.  3.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -10.728678703308105
desired expected reward: 249.0402069091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[189.84369]
 [189.52824]
 [207.74   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [15.  3.  3.  3.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.9407877922058105
desired expected reward: 196.4528350830078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  3.  0.] 
cards in discard: [ 1. 10.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  1.  0.  1. 10.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  3.  0.] 
cards in discard: [ 1. 10.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  1.  0.  1. 10.] 
adversary cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.  3.  0. 10.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  1.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[307.22455]
 [290.38934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.  3.  0. 10.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -5.840939521789551
desired expected reward: 201.89906311035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[291.84393]
 [294.514  ]
 [291.92917]
 [294.9693 ]
 [291.55313]
 [291.42056]
 [295.5174 ]
 [299.78348]
 [296.28802]
 [303.37164]
 [302.8255 ]
 [296.19717]
 [298.4667 ]
 [296.74332]
 [295.42654]
 [299.23737]
 [313.74933]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.  3.  0. 10.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -10.704306602478027
desired expected reward: 295.2269287109375



buy possibilites: [-1] 
expected returns: [[213.54169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  1. 10.] 
cards in discard: [10.  8.  6.  0.  0.  3.  1.  3.  3.  0. 10.  6. 11.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3. 10.] 
adversary cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 4.0
Learning step: -9.697967529296875
desired expected reward: 281.8551330566406






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3. 10.] 
cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4] -> size -> 21 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3. 10.] 
cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4] -> size -> 21 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3. 10.] 
cards in discard: [ 1. 10.  0.  0.  0.  3.  0. 15.  3.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11. 10.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4] -> size -> 21 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [11. 10.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[229.49083]
 [220.16237]
 [218.11671]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -6.209140300750732
desired expected reward: 207.33255004882812



action possibilites: [-1] 
expected returns: [[236.7494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 18 

action type: gain_card_n - action 9
Learning step: -4.6882500648498535
desired expected reward: 213.61398315429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[228.29878]
 [228.0883 ]
 [238.66772]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -6.130726337432861
desired expected reward: 230.61868286132812



buy possibilites: [-1] 
expected returns: [[230.349]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  3.] 
cards in discard: [10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -7.101255893707275
desired expected reward: 221.19749450683594






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 15. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [1. 4. 0. 0. 0.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0] -> size -> 23 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 15. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [1. 4. 0. 0. 0.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0] -> size -> 23 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 4. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[195.42496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1. 10.] 
adversary cards in discard: [ 3. 15.  0. 15. 25.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.730958461761475
desired expected reward: 222.6180419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[186.84236]
 [188.48691]
 [188.75816]
 [186.65799]
 [186.57777]
 [189.08623]
 [191.69507]
 [189.55943]
 [193.88936]
 [193.54797]
 [189.49113]
 [190.88232]
 [189.83066]
 [189.01791]
 [191.35553]
 [200.50198]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10. 10. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1. 10.] 
adversary cards in discard: [ 3. 15.  0. 15. 25.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.839457035064697
desired expected reward: 186.8935089111328



buy possibilites: [-1] 
expected returns: [[175.1126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1. 10.] 
adversary cards in discard: [ 3. 15.  0. 15. 25.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -3.0 

action type: buy - action 14.0
Learning step: -5.68452262878418
desired expected reward: 183.8065948486328






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1. 10.] 
cards in discard: [ 3. 15.  0. 15. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  3.] 
cards in discard: [ 3. 15.  0. 15. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3. 15.  0. 15. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3. 15.  0. 15. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[188.16788]
 [178.03577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 6.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -5.163300037384033
desired expected reward: 169.9492950439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[175.01932]
 [174.7781 ]
 [188.11258]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8. 6.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  7. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.852904319763184
desired expected reward: 181.99765014648438



buy possibilites: [-1] 
expected returns: [[167.33951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8. 6.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -322 

action type: buy - action 6.0
Learning step: -21.073766708374023
desired expected reward: 153.70436096191406






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  0.] 
cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  6. 10.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  6. 10.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  9.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  6. 10.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3. 15.  0. 15. 25. 10. 10.  0.  0.  1.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0.  1.  6. 10.] 
adversary cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[156.73038]
 [144.0567 ]
 [144.0567 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  6. 10.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -6.077609539031982
desired expected reward: 161.26190185546875



action possibilites: [-1. 10.] 
expected returns: [[234.34567]
 [219.10522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 10.  1.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 0 

action type: take_action - action 10.0
Learning step: -2.0536770820617676
desired expected reward: 142.0030059814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[210.79933]
 [213.18471]
 [213.5943 ]
 [210.53442]
 [210.41841]
 [214.08064]
 [217.90053]
 [214.77481]
 [221.103  ]
 [220.60837]
 [214.68976]
 [216.7117 ]
 [215.18443]
 [213.9956 ]
 [217.4059 ]
 [230.36702]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.  1.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 27. 29.  8.  6. 10.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.867750644683838
desired expected reward: 227.47787475585938



buy possibilites: [-1] 
expected returns: [[255.77728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.  1.] 
cards in discard: [10.  0. 11. 10.  0.  6.  3. 14.  1.  4.  0.  0.  0.  6.  3.  3.  3.  8.
  6. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 6.0 

action type: buy - action 16.0
Learning step: -4.649044036865234
desired expected reward: 209.43161010742188






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6 16] -> size -> 26 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6 16] -> size -> 26 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6 16] -> size -> 26 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[214.73772]
 [203.97995]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 10  3 11  0  6 10  1  8  1  6  6  4 10  0 14
  6 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  0. 15. 10.  1.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.243853569030762
desired expected reward: 246.53343200683594



action possibilites: [-1] 
expected returns: [[179.97578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  0. 15. 10.  1.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.955719470977783
desired expected reward: 195.14776611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[164.05046]
 [163.74368]
 [179.80089]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  0. 15. 10.  1.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: -4.125270843505859
desired expected reward: 175.8505096435547






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [15.  0. 15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 10.  1.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10. 16.  3.  0.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15. 10.  1.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10. 16.  3.  0.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15. 10.  1.] 
cards in discard: [1. 0. 0. 3. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10. 16.  3.  0.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [10. 16.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[216.57507]
 [203.46469]
 [202.50854]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  0.  6.] 
cards in discard: [8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  6  4 10  0 14  6 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 25.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -4.328538417816162
desired expected reward: 175.4723358154297



action possibilites: [-1] 
expected returns: [[252.08052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 25.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 1 

action type: gain_card_n - action 0
Learning step: -6.020009517669678
desired expected reward: 228.81642150878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[233.97386]
 [233.5736 ]
 [254.46814]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 25.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1
Learning step: -5.552305698394775
desired expected reward: 246.52821350097656



buy possibilites: [-1] 
expected returns: [[262.57523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 25.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 1.0 

action type: buy - action 0.0
Learning step: -5.740749835968018
desired expected reward: 228.23309326171875






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 10.] 
cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 29.  8.  6.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3. 15.] 
cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 27. 29.  8.  5.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3. 15.] 
cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 27. 29.  8.  5.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3. 15.] 
cards in discard: [ 1.  0.  0.  3.  0.  0.  0. 15.  0. 15. 10.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 29.  8.  5.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[175.21315]
 [164.35793]
 [162.25429]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 29.  8.  5.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[  -5    0    5  -10    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -310 

action type: buy - action -1
Learning step: -24.85994529724121
desired expected reward: 237.7152862548828



action possibilites: [-1] 
expected returns: [[165.47707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5    0    4  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -301 

action type: gain_card_n - action 3
Learning step: -20.006399154663086
desired expected reward: 153.5862579345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.01292]
 [148.6882 ]
 [165.53528]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -4.779757022857666
desired expected reward: 160.6973114013672






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [15.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [14.  6.  0. 10. 10.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [14.  6.  0. 10. 10.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [14.  6.  0. 10. 10.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [14.  6.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
expected returns: [[142.49196]
 [138.22495]
 [138.36198]
 [138.36198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0. 10. 10.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 15.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.171502113342285
desired expected reward: 159.36380004882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.37074]
 [137.2577 ]
 [142.6871 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0. 10. 10.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 26. 29.  8.  4.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 15.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -5.022246360778809
desired expected reward: 137.46971130371094



buy possibilites: [-1] 
expected returns: [[74.837006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0. 10. 10.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 26. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 15.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -332.0 

action type: buy - action 6.0
Learning step: -21.779054641723633
desired expected reward: 115.47866821289062






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0. 15.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15  0 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 26. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 1. 4. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 25. 30. 26. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 1. 4. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 26. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 1. 4. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 1. 4. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [1. 1. 4. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[162.6481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 4. 0. 1.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -2.1822681427001953
desired expected reward: 72.65473937988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[143.2006 ]
 [145.3566 ]
 [143.27013]
 [145.75826]
 [142.96298]
 [142.8637 ]
 [146.22957]
 [149.99977]
 [146.92099]
 [153.14824]
 [152.65314]
 [146.82756]
 [148.81325]
 [147.32263]
 [146.1361 ]
 [149.50468]
 [162.59676]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 4. 0. 1.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 7 
card supply: [16. 25. 30. 25. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -6.8130998611450195
desired expected reward: 155.8350067138672



buy possibilites: [-1] 
expected returns: [[168.13004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 4. 0. 1.] 
cards in discard: [ 8.  0.  0.  0. 16. 10.  3.  0.  6.  6. 11.  3.  0. 10.  3.  6. 14.  6.
  0. 10. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -34.0 

action type: buy - action 15.0
Learning step: -5.392308712005615
desired expected reward: 144.1123809814453






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  0.  3.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  3.  9.  8.  8.  9. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  1.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  9. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  1.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  9. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  1.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[133.09007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25. 25. 10.  0.  0.  3.  1.
  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -353 

action type: buy - action -1
Learning step: -23.0856990814209
desired expected reward: 145.04434204101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[118.899155]
 [121.03547 ]
 [121.40405 ]
 [118.557755]
 [121.826614]
 [125.251396]
 [122.45214 ]
 [127.664856]
 [122.36885 ]
 [122.82075 ]
 [124.79951 ]
 [135.91884 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  1.  3.  3.  0.] 
adversary cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25. 25. 10.  0.  0.  3.  1.
  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -6.3937273025512695
desired expected reward: 125.64196014404297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  3.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25. 25. 10.  0.  0.  3.  1.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 4. 15. 10.  1. 16.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  3.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25. 25. 10.  0.  0.  3.  1.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  8.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 4. 15. 10.  1. 16.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  3.  0.] 
cards in discard: [ 0. 11. 15.  3.  0.  3.  3. 15.  3.  0. 15. 25. 25. 10.  0.  0.  3.  1.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 4. 15. 10.  1. 16.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 4. 15. 10.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 16.] 
expected returns: [[162.66856]
 [151.35945]
 [149.50143]
 [148.60999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 15. 10.  1. 16.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -5.365038871765137
desired expected reward: 119.01090240478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.70744]
 [147.93115]
 [145.4349 ]
 [148.92691]
 [162.44629]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15. 10.  1. 16.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -7.328848361968994
desired expected reward: 155.33970642089844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [11.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 14. 11.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 25. 29.  8.  2.  9.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 14. 11.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  6. 14. 11.  8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 3.  6. 14. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
expected returns: [[140.79303]
 [127.81556]
 [130.53638]
 [127.90957]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14. 11.  8.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 10  3 11  0 10  1  8  1  4 10  0 14  6 16  0  0
  6  6  6 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [15.  8. 10.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -7.750951290130615
desired expected reward: 154.69532775878906



action possibilites: [-1] 
expected returns: [[126.67332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [15.  8. 10.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: trash_cards_n_from_hand - action 11
Learning step: -5.162203311920166
desired expected reward: 122.08484649658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.18175]
 [112.94059]
 [126.72878]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  2.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [15.  8. 10.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -5.28008508682251
desired expected reward: 121.39323425292969



buy possibilites: [-1] 
expected returns: [[136.11667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [15.  8. 10.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -344 

action type: buy - action 6.0
Learning step: -19.784406661987305
desired expected reward: 93.15618896484375






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [15.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10.  0.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  0  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0
  3 25  8 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[213.59525]
 [201.14685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  3.  3. 15.  0.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -5.3009138107299805
desired expected reward: 130.8157501220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.08524]
 [194.37843]
 [191.77298]
 [195.36655]
 [208.1547 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  7.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  3.  3. 15.  0.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -9.3877592086792
desired expected reward: 204.20748901367188



buy possibilites: [-1] 
expected returns: [[153.12076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10.  3.  3. 15.  0.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -56 

action type: buy - action 8.0
Learning step: -9.1231107711792
desired expected reward: 186.2434539794922






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [10.  3.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 15.  0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  1. 10.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.  8.  0.  6. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 15.  0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  1. 10.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.  8.  0.  6. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  1. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[166.46002]
 [156.82516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10.  1.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.  8.  0.  6. 10.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 1. 15.  3. 25.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -7.188838958740234
desired expected reward: 145.93191528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[153.65073]
 [155.16919]
 [155.42285]
 [153.47403]
 [153.40714]
 [155.73633]
 [158.16983]
 [156.1877 ]
 [160.21185]
 [159.88336]
 [156.11281]
 [157.38998]
 [156.44131]
 [155.66147]
 [157.84134]
 [166.07619]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10.  1.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  3.  4. 15. 10.  1. 16.  6.  8. 14.  8.  0.  6. 10.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 1. 15.  3. 25.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -7.9347076416015625
desired expected reward: 158.5253143310547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 1. 15.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3. 25.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10. 10.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3. 25.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [10. 10.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[124.22218]
 [115.38668]
 [115.38668]
 [115.38668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -8.83728313446045
desired expected reward: 157.2388916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.78959]
 [111.56624]
 [123.18624]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3.] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -6.7172770500183105
desired expected reward: 116.57278442382812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  1.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [10. 10.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8] -> size -> 28 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6] -> size -> 29 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 30. 25. 29.  8.  0.  8.  8.  6.  8. 10.  9. 10.  4. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6] -> size -> 29 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [16. 11.  1.  3.  0.  0. 15.  8. 10.  3. 10.  3.  3. 15.  0.  1. 15.  3.
 25.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  0.  8.  8.  6.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [6. 0. 0. 1. 3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6] -> size -> 29 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[125.03445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [10. 10.  6. 10.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  8.  8.  6.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16 10] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -375 

action type: buy - action -1.0
Learning step: -22.096036911010742
desired expected reward: 101.0901870727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.25117 ]
 [108.66799 ]
 [108.90587 ]
 [109.198814]
 [111.47865 ]
 [109.62397 ]
 [113.09078 ]
 [109.55496 ]
 [109.86201 ]
 [111.17102 ]
 [118.81918 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [10. 10.  6. 10.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 25. 29.  8.  0.  8.  8.  6.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16 10] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -7.460116863250732
desired expected reward: 117.57433319091797



buy possibilites: [-1] 
expected returns: [[78.555824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 3.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  7.  8.  6.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [16. 10.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16 10] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -43 

action type: buy - action 16.0
Learning step: -5.255107402801514
desired expected reward: 92.1971664428711






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [16. 10.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3
 25  8 16 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  7.  8.  6.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 6.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 6.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 6.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 6.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [1. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.209946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0. 6.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -5.058067321777344
desired expected reward: 73.49775695800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[84.77831 ]
 [86.376976]
 [86.64136 ]
 [86.98218 ]
 [89.55873 ]
 [87.469345]
 [91.36936 ]
 [87.37854 ]
 [87.733734]
 [89.20353 ]
 [98.200134]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 6.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 25. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -5.905123233795166
desired expected reward: 88.30482482910156



buy possibilites: [-1] 
expected returns: [[107.17902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 6.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -60.5 

action type: buy - action 1.0
Learning step: -4.932321071624756
desired expected reward: 81.44466400146484






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 8.  0. 16. 10.  0. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 8. 14.  4.  6.  3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 8.  0. 16. 10.  0. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 8. 14.  4.  6.  3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 8. 14.  4.  6.  3.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 8. 14.  4.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[106.642525]
 [ 95.74779 ]
 [ 95.650314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  4.  6.  3.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -6.327849864959717
desired expected reward: 100.8511734008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 93.478134]
 [107.14092 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  4.  6.  3.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -6.282277584075928
desired expected reward: 100.36022186279297



buy possibilites: [-1] 
expected returns: [[121.58983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  4.  6.  3.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action 0.0
Learning step: -6.688134670257568
desired expected reward: 86.78997802734375






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [10.  0. 16.  1. 15.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.  8. 14.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  2. 10.  6.] 
adversary cards in hand: [10.  0. 16.  1. 15.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.  8. 14.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10.  0. 16.  1. 15.] 
adversary cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.  8. 14.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [10.  0. 16.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 15.] 
expected returns: [[51.382835]
 [45.88144 ]
 [45.476437]
 [46.67541 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  1. 15.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.  8. 14.  4.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  8.  0. 15.  3.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10 10] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -8.238736152648926
desired expected reward: 113.35108947753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[42.831642]
 [43.694332]
 [43.83257 ]
 [45.407284]
 [44.285683]
 [44.42392 ]
 [49.911877]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.  1. 15.] 
cards in discard: [10. 10.  6. 10.  3.  6. 16.  6.  0.  0.  1.  3.  1.  1.  6.  0.  0.  6.
  0.  8. 14.  4.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  8.  0. 15.  3.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10 10] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.777228832244873
desired expected reward: 46.60560989379883



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 15.  3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 25 15 10  0  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25
  8 16 10  8  0 10 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [15. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[117.61396 ]
 [107.484856]
 [105.90457 ]
 [105.615845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 15. 10. 11.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -2.7365102767944336
desired expected reward: 47.17537307739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 99.911026]
 [101.95697 ]
 [102.85615 ]
 [115.300705]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  5.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 15. 10. 11.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -6.20343542098999
desired expected reward: 111.4104995727539



buy possibilites: [-1] 
expected returns: [[78.13443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  8.  0.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 15. 10. 11.] 
adversary cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -47 

action type: buy - action 8.0
Learning step: -5.734782695770264
desired expected reward: 97.1213607788086






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [15.  3. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 10. 11.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 15. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 11. 10.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 11.  0.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16
 10  8  0 10 10] -> size -> 29 
action values: 3 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 15.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 3 
card supply: [14. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 15. 11.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [13. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 15. 11.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 8.  0. 16. 10.  0. 25. 10.  0.  0.  0.  3.  1. 10.  1.  3.  0.  0.  3.
  8. 15.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10. 15. 11.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.22026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  1.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.031765937805176
desired expected reward: 73.1026611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[67.75878 ]
 [68.265564]
 [68.34981 ]
 [68.46562 ]
 [69.37331 ]
 [68.63435 ]
 [70.03624 ]
 [68.60403 ]
 [68.727196]
 [69.24769 ]
 [72.45208 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  1.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.785494327545166
desired expected reward: 67.43476867675781



buy possibilites: [-1] 
expected returns: [[113.8745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  1.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -5.075762748718262
desired expected reward: 62.68301010131836






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 6.  1.  1. 10.  6.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 6.  1.  1. 10.  6.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 25.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  1.  1. 10.  6.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6.  1.  1. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[108.55746]
 [100.98636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  1. 10.  6.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.062593936920166
desired expected reward: 107.81190490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[86.4738  ]
 [87.59498 ]
 [87.78262 ]
 [88.0163  ]
 [89.83036 ]
 [88.36372 ]
 [91.24414 ]
 [88.29607 ]
 [89.57507 ]
 [96.609436]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1. 10.  6.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.923445701599121
desired expected reward: 98.67365264892578



buy possibilites: [-1] 
expected returns: [[89.14568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1. 10.  6.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -23 

action type: buy - action 29.0
Learning step: -3.706428289413452
desired expected reward: 87.53768920898438






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  8.  3.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 11.] 
cards in discard: [10.  3.  1.  0.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  8.  3.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 11.] 
cards in discard: [10.  3.  1.  0.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  8.  3.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 11.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  8.  3.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[63.484146]
 [61.539658]
 [61.513725]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  8.  3.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 16.  3. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.800061225891113
desired expected reward: 83.34561920166016



action possibilites: [-1.  8.] 
expected returns: [[58.578316]
 [55.145073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 16.  3. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -3.5368194580078125
desired expected reward: 58.00284957885742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[56.44023 ]
 [60.914307]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0. 16.  3. 10.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.344635009765625
desired expected reward: 55.23368835449219






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  3. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  6.  4.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  6.  4.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  3. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 10.  0.  6.  4.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6. 10.  0.  6.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[56.20423]
 [49.77978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.  4.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 10. 25.  8.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -4.583231449127197
desired expected reward: 56.331085205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.36762 ]
 [55.436073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.  4.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3. 10. 25.  8.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.378345489501953
desired expected reward: 51.82587814331055



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 25.  8.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  1. 16. 16.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  8.  3.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  1. 16. 16.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.  8. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 15. 15.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  1. 16. 16.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 15. 15.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  1. 16. 16.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 15. 15.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  1. 16. 16.] 
adversary cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0. 14.  1. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 16.] 
expected returns: [[79.21292]
 [64.50045]
 [63.93911]
 [63.93911]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 16. 16.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 10.  1.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.9230728149414062
desired expected reward: 51.51300048828125



action possibilites: [-1] 
expected returns: [[24.170832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16. 16.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 14.0
Learning step: -4.431179046630859
desired expected reward: 60.069271087646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[18.171434]
 [19.141891]
 [19.293447]
 [18.052881]
 [19.494331]
 [21.01233 ]
 [19.790556]
 [22.208563]
 [22.008427]
 [19.723795]
 [20.529287]
 [19.42758 ]
 [20.812197]
 [26.172855]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16. 16.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 22. 30. 25. 29.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -2.4630260467529297
desired expected reward: 21.707805633544922



buy possibilites: [-1] 
expected returns: [[23.096807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16. 16.] 
cards in discard: [ 8. 15. 10.  0.  8.  0.  0.  3.  0.  6.  1.  0. 29.  6.  1.  1. 10.  6.
 10.  6.  0.  8.  3.  3.  6. 10.  0.  6.  4.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.] 
adversary cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0  -1   0   0  50   0] 
sum of rewards: 47 

action type: buy - action 4.0
Learning step: 1.9670342206954956
desired expected reward: 20.01991081237793






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [10.  3.  1.  0.  0. 25.  1. 10.  1.  3.  0.  0. 11.  0.  8.  0. 16.  3.
 10.  0. 10. 25.  0.  3.  8.  3. 15. 15.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[56.559418]
 [53.025955]
 [51.085335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -1.030962347984314
desired expected reward: 22.065845489501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[49.20224 ]
 [50.157604]
 [50.591927]
 [56.19728 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -2.7391297817230225
desired expected reward: 53.820281982421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [15. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10. 14.  6.  3.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 25 15 10  0  0  0  3 10  1  0 11  1  0  3  0  3 25  8 16 10
  8  0 10 10  0  1 10  1  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10. 14.  6.  3.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10. 14.  6.  3.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10. 14.  6.  3.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10. 14.  6.  3.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 10. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[63.21345 ]
 [59.193428]
 [59.048904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  6.  3.] 
cards in discard: [ 0. 29. 10.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 10.  3. 16. 25.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -2.5318198204040527
desired expected reward: 53.66545867919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[54.347473]
 [59.783813]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14.  6.  3.] 
cards in discard: [ 0. 29. 10.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 10.  3. 16. 25.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -2.9596307277679443
desired expected reward: 60.253780364990234



buy possibilites: [-1] 
expected returns: [[29.35919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14.  6.  3.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1. 10.  3. 16. 25.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0 -30   0   0   0  -2   0   0   0   0] 
sum of rewards: -54 

action type: buy - action 0.0
Learning step: -4.705277442932129
desired expected reward: 49.642173767089844






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  3. 16. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 25.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3. 16. 25.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 16. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 16. 25.  3.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16. 25.  3.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 22. 30. 25. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 16. 25.  3.] 
cards in discard: [ 0. 10.  8.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 24. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 1.  0.  8. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
expected returns: [[35.86014 ]
 [32.082314]
 [31.903238]
 [32.18041 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 16. 10.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 24. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -2.3073995113372803
desired expected reward: 27.051790237426758



action possibilites: [-1.  8. 16.] 
expected returns: [[116.11215]
 [109.4489 ]
 [109.13182]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 16.  6.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6  6
 15  6  6  8  6 16  1  0  8  0 29  4  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 24. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: 0.3297243118286133
desired expected reward: 32.510135650634766



action possibilites: [-1.  8.] 
expected returns: [[41.927746]
 [35.207314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  40   0   0   0   0  -2   0   0   4   0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0.44576796889305115
desired expected reward: 41.30765914916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[33.393578]
 [34.204597]
 [34.3392  ]
 [35.924168]
 [34.768925]
 [41.217457]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: 0.24054507911205292
desired expected reward: 42.16830062866211



buy possibilites: [-1] 
expected returns: [[97.52484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -10.   0.   0.  40. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: 0.37462902069091797
desired expected reward: 33.768226623535156






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [10. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  1.  0.  4.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  1.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  1.  0.  4.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  1.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  1.  0.  4.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  1.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 16.  1.  0.  4.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 0. 16.  1.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.89924]
 [26.25615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  0.  4.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  0. 25. 15.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -4.761837005615234
desired expected reward: 92.76300048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[26.777512]
 [26.997786]
 [27.03217 ]
 [27.082369]
 [27.440922]
 [27.1548  ]
 [27.693726]
 [27.140043]
 [27.391785]
 [28.59948 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  4.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  4.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  0. 25. 15.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -1.272051215171814
desired expected reward: 26.627197265625



buy possibilites: [-1] 
expected returns: [[15.62236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  4.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  0. 25. 15.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -10.   0.   0.   0.   0.   0.   0.   0.  -4.   0.   0.
   2.   0.] 
sum of rewards: -12.0 

action type: buy - action 8.0
Learning step: -1.6062370538711548
desired expected reward: 25.548564910888672






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 15.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 6. 1. 1. 8.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.  3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 6. 1. 1. 8.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.  3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 22. 30. 23. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 6. 1. 1. 8.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.  3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 6. 1. 1. 8.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [4. 6. 1. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.17168 ]
 [19.298483]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 1. 1. 8.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15
  6  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  8. 10. 15.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0  3] -> size -> 35 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -1.3199493885040283
desired expected reward: 14.302411079406738



action possibilites: [-1] 
expected returns: [[34.829517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 1.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  8. 10. 15.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0  3] -> size -> 35 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.5609418749809265
desired expected reward: 26.331178665161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.623049]
 [26.632383]
 [27.089502]
 [32.984787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 1.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  8. 10. 15.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0  3] -> size -> 35 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -1.0788475275039673
desired expected reward: 33.75067138671875






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 15.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3 25 15 10  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10
 10  0  1 10  1  0  0  0  3  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  8.  0.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  8.  0.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  8.  0.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10.  1.  3. 16. 25.  3.  0. 10. 10.  0.  0.  0.  1.
  3. 25.  3.  0.  0. 15.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  8.  0.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[51.79646 ]
 [46.661793]
 [46.53951 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  8.  0.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6  6 15  6
  6  8  6 16  1  0  8  0 29  4  0  3  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -1.040012001991272
desired expected reward: 31.944766998291016



action possibilites: [-1] 
expected returns: [[46.18061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: trash_cards_n_from_hand - action 11
Learning step: -0.10868530720472336
desired expected reward: 43.84629440307617





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.274715]
 [43.817177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1
Learning step: -0.3343234956264496
desired expected reward: 45.84628677368164






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 15.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  8.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 15.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 10. 11.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  6. 15.] 
adversary cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[25.70821]
 [21.22663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 15.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  0. 16.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0 11] -> size -> 35 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: buy - action -1.0
Learning step: -1.5987757444381714
desired expected reward: 42.21840286254883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.397549]
 [18.562506]
 [18.773487]
 [22.419947]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 15.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 22. 30. 22. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  0. 16.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0 11] -> size -> 35 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: take_action - action -1.0
Learning step: -0.777708113193512
desired expected reward: 24.930492401123047



buy possibilites: [-1] 
expected returns: [[52.90647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 15.] 
cards in discard: [ 0. 29. 10.  6.  0.  0.  3. 10. 14.  6.  3.  3.  0. 10. 16.  1.  0.  8.
  8.  0. 16.  1.  0.  4.  8.  4.  6.  1.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 15.  0. 16.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.] 
adversary owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0 11] -> size -> 35 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  7 10  0  0  0  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 19 

action type: buy - action 3.0
Learning step: 1.2122703790664673
desired expected reward: 19.7747745513916






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0. 16.] 
cards in discard: [11.  3.  0.  1. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 25 15  0  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0
  1 10  1  0  0  0  3  0  3  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [11.  3.  0.  1. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 22. 30. 21. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [11.  3.  0.  1. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 22. 30. 21. 28.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 9 





Player: 0 
cards in hand: [10.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[53.470352]
 [49.950672]
 [49.950672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.] 
adversary owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11  4] -> size -> 35 
adversary victory points: 9
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: buy - action -1
Learning step: -2.3803067207336426
desired expected reward: 50.52616500854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[48.277695]
 [48.81101 ]
 [48.892838]
 [49.85263 ]
 [49.166367]
 [52.585495]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.] 
adversary owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11  4] -> size -> 35 
adversary victory points: 9
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1.0
Learning step: -2.438814640045166
desired expected reward: 51.03153610229492



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1
 10  1  0  0  0  3  0  3  0 11  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 1. 8. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 1. 8. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [4. 1. 8. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
adversary victory points: 7
player victory points: 8 





Player: 0 
cards in hand: [4. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[99.9179  ]
 [91.279396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1. 8. 0. 0.] 
cards in discard: [10.  3. 10.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 10. 10. 15.  0.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1.0
Learning step: -0.8511924743652344
desired expected reward: 51.734310150146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 95.76999 ]
 [ 97.09475 ]
 [ 97.31404 ]
 [ 97.59903 ]
 [ 99.74998 ]
 [ 98.01794 ]
 [101.245384]
 [ 97.933975]
 [ 99.44671 ]
 [106.69573 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 8. 0. 0.] 
cards in discard: [10.  3. 10.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  3.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 10. 10. 15.  0.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action -1.0
Learning step: -3.118680000305176
desired expected reward: 96.79923248291016



buy possibilites: [-1] 
expected returns: [[80.149376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 8. 0. 0.] 
cards in discard: [10.  3. 10.  1.  0.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 10. 10. 15.  0.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7. -10.   0.   0.   0.   0.   0.   0.   0.  -2.   0.   0.
   2.   0.] 
sum of rewards: -8.0 

action type: buy - action 8.0
Learning step: -3.4975364208221436
desired expected reward: 94.5204086303711






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 15.  0.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1.  8. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15.  0.  1.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15.  0.  1.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15.  0.  1.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 





Player: 0 
cards in hand: [6. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[123.00811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10.  0.  1. 25.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0] -> size -> 35 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1
Learning step: -1.6397863626480103
desired expected reward: 78.50959014892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[113.30947]
 [114.66573]
 [115.32128]
 [124.3157 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10.  0.  1. 25.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0] -> size -> 35 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action -1.0
Learning step: -3.8735554218292236
desired expected reward: 119.13455200195312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  1. 25.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  1. 25.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  2.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  1. 25.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 10.  0.  6.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 





Player: 0 
cards in hand: [ 3. 10.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[223.93953]
 [214.01634]
 [213.76309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6.  8.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.  3. 10.  0.  1. 25.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8] -> size -> 36 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1.0
Learning step: -1.6858352422714233
desired expected reward: 122.6298599243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[211.83145]
 [224.23717]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  6.  8.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.  3. 10.  0.  1. 25.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8] -> size -> 36 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action -1.0
Learning step: -6.652268886566162
desired expected reward: 217.28729248046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.  3. 10.  0.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [16. 29.  0. 14.  0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.  3. 10.  0.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [16. 29.  0. 14.  0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [11.  3.  0.  1. 10. 11.  4. 15.  0.  0. 16.  8.  0.  0.  0.  0. 10.  8.
 10. 15.  0.  1.  8.  3. 10.  0.  1. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [16. 29.  0. 14.  0.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 





Player: 0 
cards in hand: [16. 29.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 14.] 
expected returns: [[108.196594]
 [101.64794 ]
 [104.087105]
 [101.82872 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0. 14.  0.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15.  8.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1.0
Learning step: -9.24648666381836
desired expected reward: 214.9906768798828



action possibilites: [-1] 
expected returns: [[188.87059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.  0.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15.  0.  3.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action 14.0
Learning step: -0.2551765441894531
desired expected reward: 101.57353210449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[178.0579 ]
 [178.7654 ]
 [178.86949]
 [179.01619]
 [180.14348]
 [179.23857]
 [180.93178]
 [179.18346]
 [179.98427]
 [183.57759]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  0.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15.  0.  3.] 
adversary cards in discard: [ 8. 25.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action -1
Learning step: -4.774692535400391
desired expected reward: 184.0959014892578






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  4.  0. 15.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  4.  0. 15.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 25.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  4.  0. 15.  8.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
adversary victory points: 7
player victory points: 8 





Player: 0 
cards in hand: [ 0.  4.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[191.08748]
 [180.66144]
 [178.62527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0. 15.  8.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  0.  1. 10. 10.] 
adversary cards in discard: [ 8. 25.  0. 15.  0.  3.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1.0
Learning step: -5.403181076049805
desired expected reward: 178.17440795898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[175.56606]
 [177.74347]
 [178.72809]
 [191.26778]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 15.  8.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  0.  1. 10. 10.] 
adversary cards in discard: [ 8. 25.  0. 15.  0.  3.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action -1.0
Learning step: -5.820235729217529
desired expected reward: 185.2672119140625



buy possibilites: [-1] 
expected returns: [[129.36696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 15.  8.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  0.  1. 10. 10.] 
adversary cards in discard: [ 8. 25.  0. 15.  0.  3.] 
adversary owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7. -10.   0.   0.   0. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -7.917543888092041
desired expected reward: 167.64846801757812






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [25.  0.  1. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1. 10. 10.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 25. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1. 10.  3.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  3. 10.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 10. 15. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10. 15. 11.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10. 25.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 15. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15. 11. 10.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 10. 25. 10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15. 11.  1.] 
cards in discard: [ 8. 25.  0. 15.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0] -> size -> 38 
action values: 4 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15.  1.] 
cards in discard: [ 8. 25.  0. 15.  0.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 11.] 
owned cards: [15 25 15  0  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10
  1  0  0  0  3  0  3  0 11  4  0  8  0  0 15] -> size -> 39 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [ 8. 25.  0. 15.  0.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 11. 15.] 
owned cards: [15 25 15  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10  1
  0  0  0  3  0  3  0 11  4  0  8  0  0 15] -> size -> 38 
action values: 2 
buys: 0 
player value: 3 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 8. 25.  0. 15.  0.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 10. 25. 10. 10. 11. 15.] 
owned cards: [15 25 15  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10  1
  0  0  0  3  0  3  0 11  4  0  8  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  1.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 1.  8. 16.  3.  6.] 
adversary cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
adversary victory points: 7
player victory points: 8 


Player 1 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 4 
Gold: 0 
Estate: 2 
Duchy: 2 
Province: 0 
Curse: 4 

Remodel: 2 
Workshop: 1 
Chapel: 6 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  8. 16.  3.  6.] 
cards in discard: [10.  3. 10.  1.  0.  8.  4.  1.  8.  0.  0.  6.  6.  3.  0.  0.  3. 10.
  0.  6.  8. 14. 16. 29.  0.  0.  0.  0.  4.  0. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  3  0 10  1  8  1  4 10  0 14 16  0  0  6 15  6  6  8  6
 16  1  0  8  0 29  4  0  3  0  8  3  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 27.  8.  0.  7.  7.  0.  8.  9.  9. 10.  0. 10.  5.] 
adversary cards in hand: [1. 3. 1.] 
adversary cards in discard: [ 8. 25.  0. 15.  0.  3. 15.  8.] 
adversary owned cards: [15 25 15  3 10  0 11  1  0  3  0  3 25  8 16 10  8  0 10 10  0  1 10  1
  0  0  0  3  0  3  0 11  4  0  8  0  0 15  8] -> size -> 39 
adversary victory points: 8
player victory points: 7 

Reward from previous game state: 
[  -5 -500    7  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -508 

action type: buy - action -1
Learning step: -31.86834716796875
desired expected reward: 97.49861145019531



