 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.2963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     420       0       0      20       0       0
       0       0    -320       0       0       0       0] 
sum of rewards: 3000115 

action type: buy - action 0.0
Learning step: 300000.8125
desired expected reward: 300107.71875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[73.676605]
 [87.08731 ]
 [82.67493 ]
 [68.218216]
 [89.12415 ]
 [80.07792 ]
 [75.6829  ]
 [67.97515 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.05883026123047



buy possibilites: [-1] 
expected returns: [[62.303658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.12413787841797






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.35295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.30365753173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 83.52716 ]
 [ 97.67362 ]
 [ 92.97649 ]
 [ 77.500984]
 [ 84.965225]
 [ 99.89433 ]
 [ 90.227394]
 [104.8171  ]
 [ 84.164856]
 [ 85.61315 ]
 [ 98.3565  ]
 [ 77.2257  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.62207794189453



buy possibilites: [-1] 
expected returns: [[34.043915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 104.81709289550781






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[27.44074 ]
 [41.712708]
 [39.467175]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.043914794921875



action possibilites: [-1. 11.] 
expected returns: [[24.361351]
 [39.14251 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.4588623046875



action possibilites: [-1] 
expected returns: [[35.550236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.366268157958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.15246 ]
 [51.069626]
 [47.822445]
 [36.866344]
 [42.154705]
 [52.558773]
 [45.88878 ]
 [55.769245]
 [41.60266 ]
 [42.641613]
 [51.519825]
 [36.67098 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.550235748291016



buy possibilites: [-1] 
expected returns: [[18.4242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.76923370361328






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[65.45439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.4242000579834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[68.61107 ]
 [81.38566 ]
 [77.12033 ]
 [63.11637 ]
 [69.96568 ]
 [83.3428  ]
 [74.694244]
 [87.76286 ]
 [69.19956 ]
 [70.50148 ]
 [81.99738 ]
 [62.864464]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.53596496582031



buy possibilites: [-1] 
expected returns: [[26.140936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.76286315917969






Player: 1 
cards in hand: [3. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[32.10495]
 [49.69358]
 [49.69358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.14093589782715



action possibilites: [-1. 29.] 
expected returns: [[26.66203]
 [47.10537]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.449825286865234



action possibilites: [-1.] 
expected returns: [[37.00047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.10536193847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.80633 ]
 [55.094925]
 [51.396057]
 [42.62596 ]
 [38.920036]
 [44.952736]
 [56.788673]
 [49.198944]
 [61.756805]
 [60.54606 ]
 [44.31972 ]
 [51.36209 ]
 [45.50009 ]
 [41.42856 ]
 [55.608315]
 [38.69684 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.00046920776367



buy possibilites: [-1] 
expected returns: [[16.605999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 61.756813049316406






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 11.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[23.532482]
 [28.245203]
 [40.902473]
 [37.704872]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 11.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 16.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.605998992919922



action possibilites: [-1. 10. 11.] 
expected returns: [[32.945965]
 [39.209614]
 [49.98937 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  8. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 16.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.84910583496094



action possibilites: [-1] 
expected returns: [[1.3034377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 16.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.670867919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 7.594835 ]
 [14.061157 ]
 [11.922907 ]
 [ 4.9816604]
 [15.0998955]
 [10.543425 ]
 [ 8.530659 ]
 [ 4.8647227]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  8. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 16.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.3034377098083496



buy possibilites: [-1] 
expected returns: [[-7.126115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1.  1. 16.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 15.09990119934082






Player: 1 
cards in hand: [ 3.  1.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 16.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 16.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 16.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[35.990585]
 [52.830563]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.126114845275879



action possibilites: [-1] 
expected returns: [[40.671387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.29948425292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.342125]
 [57.37822 ]
 [54.108017]
 [43.006954]
 [48.322933]
 [58.89319 ]
 [52.127304]
 [62.079216]
 [47.792126]
 [48.857105]
 [57.828217]
 [42.810036]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.67138671875



buy possibilites: [-1] 
expected returns: [[6.598747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.07921600341797






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[34.75305 ]
 [45.928368]
 [45.928368]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.5987467765808105



action possibilites: [-1. 29.] 
expected returns: [[41.699245]
 [57.49506 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.50982666015625



action possibilites: [-1. 10.] 
expected returns: [[48.082584]
 [55.20341 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.49505615234375



action possibilites: [-1. 25.] 
expected returns: [[23.249191]
 [40.813847]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 25.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 2 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 55.20338439941406



action possibilites: [-1. 10. 11.] 
expected returns: [[21.376886]
 [25.726088]
 [33.778275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 10. 11.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  7. 10.  9.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.81382369995117



action possibilites: [-1] 
expected returns: [[14.201521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  7. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.54186248779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.669048]
 [20.367426]
 [18.606758]
 [11.381039]
 [21.254314]
 [17.384802]
 [15.62414 ]
 [11.229242]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  7. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.201520919799805



buy possibilites: [-1] 
expected returns: [[0.13030481]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 11.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  54   0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.254314422607422






Player: 1 
cards in hand: [ 3. 16. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 11.  1.  0.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 16 11  3 15  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  9.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[21.26643 ]
 [40.415283]
 [40.415283]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.13030481338500977



action possibilites: [-1. 29.] 
expected returns: [[ 6.175011]
 [18.319384]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.25709915161133



action possibilites: [-1.] 
expected returns: [[13.449806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.31938362121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.945086]
 [32.12977 ]
 [21.481195]
 [29.457819]
 [23.037819]
 [20.573921]
 [24.523626]
 [33.471443]
 [27.672508]
 [37.258163]
 [36.20215 ]
 [24.265047]
 [29.13383 ]
 [25.172321]
 [22.190184]
 [32.484943]
 [20.424612]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.449806213378906



buy possibilites: [-1] 
expected returns: [[-5.4760256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 37.25816345214844






Player: 1 
cards in hand: [0. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 25.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  6. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 25.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.  6. 16.  1. 16. 11.  1.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 25.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[0.48326397]
 [2.943954  ]
 [7.034536  ]
 [8.558769  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 25.  0.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.476025581359863



action possibilites: [-1] 
expected returns: [[-1.2781796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0. 11. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 6.015408039093018





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.243619 ]
 [-3.3561382]
 [-3.448379 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  0. 11. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8.  8.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.27817964553833



buy possibilites: [-1] 
expected returns: [[-10.765039]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  0. 11. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  8.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -1.2436192035675049






Player: 1 
cards in hand: [ 1.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  3.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  1 16 11  3 15  6 16  1 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8.  8.  5. 10.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 29. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 29. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 29. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 29. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[12.315935]
 [24.770315]
 [26.81737 ]
 [26.81737 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 29. 29.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.765039443969727



action possibilites: [-1. 11. 29.] 
expected returns: [[16.125643]
 [26.018631]
 [27.64707 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 29.  0.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.81736946105957



action possibilites: [-1. 11. 10.] 
expected returns: [[48.702423]
 [62.232483]
 [53.823097]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.647090911865234



action possibilites: [-1] 
expected returns: [[-20.14975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.87947845458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-18.730204]
 [-15.704849]
 [-16.533388]
 [-19.990845]
 [-15.073324]
 [-17.401508]
 [-18.186684]
 [-20.040098]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  5.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.149749755859375



buy possibilites: [-1] 
expected returns: [[18.01448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.  0. 25.  3. 10. 11.  0. 11. 10. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 16.  0.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -15.073318481445312






Player: 1 
cards in hand: [ 6.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.  0.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[21.810074]
 [35.194336]
 [26.768341]
 [26.768341]
 [26.768341]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11. 15.  0.  1.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.014480590820312



action possibilites: [-1] 
expected returns: [[31.1575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 15.  0.  1.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.746492385864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.05263 ]
 [33.922363]
 [33.78358 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 15.  0.  1.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.157499313354492



buy possibilites: [-1] 
expected returns: [[9.383661]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11. 15.  0.  1.] 
adversary cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 37.05263137817383






Player: 1 
cards in hand: [11. 11. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  0.  1.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 29.  0.  3. 11.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  1.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 29.  0.  3. 11.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  1.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 29.  0.  3. 11.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  1.] 
cards in discard: [ 6.  8.  3. 16.  0.  3.  0.  0.  6.  0.  3. 16.  0.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 29.  0.  3. 11.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[29.980227]
 [41.79869 ]
 [41.094757]
 [40.03919 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  3. 11.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  8.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.383661270141602



action possibilites: [-1] 
expected returns: [[7.054051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11. 11. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.79868698120117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[9.224819 ]
 [7.298181 ]
 [7.2159534]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 11. 11. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  7.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.054050922393799



buy possibilites: [-1] 
expected returns: [[-8.212976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 11. 11. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  7.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 9.224821090698242






Player: 1 
cards in hand: [6. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 27. 30.  8.  7.  8.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [ 6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 11. 29.  0.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[22.173574]
 [30.69335 ]
 [32.11151 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29.  0.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 16.  8. 16.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.212976455688477



action possibilites: [-1. 11.] 
expected returns: [[32.250206]
 [42.788334]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 16.  8. 16.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.111507415771484



action possibilites: [-1] 
expected returns: [[13.335463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 16.  8. 16.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.706539154052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.877169]
 [21.964779]
 [20.466595]
 [14.699194]
 [17.042542]
 [22.8105  ]
 [19.228022]
 [23.801132]
 [17.050362]
 [17.72804 ]
 [22.137209]
 [14.607162]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 16.  8. 16.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.33546257019043



buy possibilites: [-1] 
expected returns: [[20.393442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 16.  8. 16.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.801130294799805






Player: 1 
cards in hand: [11.  0. 16.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  8. 16.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16 11  3 15  6 16  1 11  6  8  3  0  1  3
  6 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  0.  0. 29. 29.] 
adversary cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[1.4528985]
 [9.468195 ]
 [8.9485035]
 [8.9485035]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29. 29.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  7.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.393442153930664



action possibilites: [-1] 
expected returns: [[6.86885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.468194961547852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.474514 ]
 [16.702105 ]
 [15.1819935]
 [ 9.262321 ]
 [17.602575 ]
 [13.854973 ]
 [12.355148 ]
 [ 9.170168 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  0. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  4.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.868850231170654



buy possibilites: [-1] 
expected returns: [[3.7450013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  0. 10.] 
cards in discard: [10.  0. 11. 10.  0. 10. 10.  0. 25. 29.  0.  3. 11. 11. 10. 10. 29. 29.
 11.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  3.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 17.602571487426758






Player: 1 
cards in hand: [ 1. 11.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.  0.  3.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  3.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6.  0.  3.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  3.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  6.  0.  3.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11. 25. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[ 1.2763581]
 [ 9.366674 ]
 [10.926832 ]
 [10.235798 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.7450013160705566



action possibilites: [-1] 
expected returns: [[-55.2853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.926834106445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-51.22249 ]
 [-46.937637]
 [-53.46538 ]
 [-48.57147 ]
 [-53.553997]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -55.285301208496094



buy possibilites: [-1] 
expected returns: [[-31.108889]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  3. 11.  0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6] -> size -> 30 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -46.937644958496094






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 16.  6.  3.  1.  0.  0.  3.  0. 16.  0.  8. 16.  6. 11.  1. 11.  6.
  0.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 10.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[39.146942]
 [43.104668]
 [43.104668]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -31.108888626098633



action possibilites: [-1. 10.] 
expected returns: [[ 7.898705]
 [10.794369]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 43.10465621948242



action possibilites: [-1.] 
expected returns: [[0.3215127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 10.794363021850586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[2.197102 ]
 [6.775602 ]
 [5.374575 ]
 [0.4989586]
 [7.549664 ]
 [4.253021 ]
 [2.9241152]
 [0.4261794]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  2.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.32151269912719727



buy possibilites: [-1] 
expected returns: [[-5.6666384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 7.5496506690979






Player: 1 
cards in hand: [ 3.  3.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  0.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[-11.450834  ]
 [  0.68921804]
 [  3.2648015 ]
 [  2.2069964 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  5.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.666638374328613



action possibilites: [-1] 
expected returns: [[5.3934493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0. 10. 29.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  4.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6] -> size -> 32 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.2648062705993652





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[5.9466176]
 [9.97496  ]
 [3.3606057]
 [8.259151 ]
 [3.2366252]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0. 10. 29.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 24. 30.  8.  4.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6] -> size -> 32 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.393449306488037



buy possibilites: [-1] 
expected returns: [[18.214565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0. 10. 29.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  4.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6] -> size -> 32 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 9.974971771240234






Player: 1 
cards in hand: [ 6.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  1.] 
cards in discard: [ 3.  3.  0.  1. 15.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  4.  7.  1.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 23. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 29.  0. 11.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[ 6.8824077]
 [ 9.6953125]
 [14.439753 ]
 [13.877981 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0. 11.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.21456527709961



action possibilites: [-1. 10. 11.] 
expected returns: [[33.44813]
 [37.04854]
 [43.22106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.252635955810547



action possibilites: [-1] 
expected returns: [[-3.8097491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 179 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.14910888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-1.4410496]
 [ 4.363374 ]
 [ 2.5660195]
 [-3.9344838]
 [ 1.2795591]
 [-0.5177984]
 [-4.0437164]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.809749126434326



buy possibilites: [-1] 
expected returns: [[-4.5100904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.363370418548584






Player: 1 
cards in hand: [0. 3. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 11. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  9.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 11. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 11. 10.] 
adversary cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[54.273212]
 [59.061543]
 [59.061543]
 [66.4772  ]
 [59.061543]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 10.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.510090351104736



action possibilites: [-1] 
expected returns: [[120.60247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  0.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 68.57515716552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.83132 ]
 [120.775185]
 [120.602455]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  0.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.60247039794922



buy possibilites: [-1] 
expected returns: [[87.442184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [ 3. 25. 11. 29.  0.  3. 11.  0. 11. 10. 10.  3.  3.  0.  0.  0.  3. 25.
 11. 29.  0.  0. 10. 29. 29. 15.  1. 29. 11. 10.  0.  0. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  0.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0. -40.   0.   0.
   0.   0.] 
sum of rewards: 65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 124.8313217163086






Player: 1 
cards in hand: [ 8.  0.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6.  3. 16.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0] -> size -> 39 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6.  3. 16.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0] -> size -> 39 
adversary victory points: 5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 9.545496]
 [16.957453]
 [17.682688]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.44218444824219



action possibilites: [-1. 11.] 
expected returns: [[ 5.739736]
 [18.13387 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.19137191772461



action possibilites: [-1] 
expected returns: [[3.0134034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 20.779523849487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 7.507172 ]
 [16.731163 ]
 [13.708445 ]
 [ 3.9760728]
 [11.600147 ]
 [ 8.825525 ]
 [ 3.8222384]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.0134034156799316



buy possibilites: [-1] 
expected returns: [[-21.174847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 15.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 119 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 16.73118019104004






Player: 1 
cards in hand: [ 0.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 11.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  4.  7.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10. 10.  0. 25.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  4.  6.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10. 10.  0. 25.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 22. 30.  8.  4.  6.  0.  8.  8.  5. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10. 10.  0. 25.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  4.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 1. 10. 10.  0. 25.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[-4.594226 ]
 [-1.9328418]
 [-1.9328418]
 [ 3.7488856]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0. 25.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  4.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [16.  3.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.174846649169922



action possibilites: [-1] 
expected returns: [[5.717386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0. 29. 11.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [16.  3.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.748879909515381





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 7.0590386]
 [11.6629715]
 [10.20759  ]
 [ 5.076924 ]
 [ 9.231825 ]
 [ 7.776439 ]
 [ 4.988814 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0. 29. 11.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [16.  3.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.717385768890381



buy possibilites: [-1] 
expected returns: [[-1.3070049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0. 29. 11.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [16.  3.  6.  3. 16.] 
adversary cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 11.662967681884766






Player: 1 
cards in hand: [16.  3.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  3. 16.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 11. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  3. 16.] 
cards in discard: [ 3.  3.  0.  1. 15.  6. 11.  3. 11.  6.  0.  0.  1.  8.  0.  3.  6.  1.
  3.  8.  0.  6.  3. 16. 16. 10. 11.  0.  0.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 11. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
adversary victory points: 5
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10.] 
expected returns: [[24.319796]
 [45.509495]
 [31.071634]
 [43.984573]
 [31.071634]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11. 10.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.3070049285888672



action possibilites: [-1. 10. 10.] 
expected returns: [[118.19354]
 [122.41344]
 [122.41344]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.1195068359375



action possibilites: [-1. 10. 25.] 
expected returns: [[125.2154 ]
 [129.3873 ]
 [140.41391]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 30.  8.  3.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6] -> size -> 38 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 122.41343688964844



action possibilites: [-1. 10.] 
expected returns: [[67.46879 ]
 [72.906364]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.4138946533203



action possibilites: [-1. 15.] 
expected returns: [[47.0167  ]
 [55.640717]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 25. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0
 10 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 42 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 72.90636444091797



action possibilites: [-1.] 
expected returns: [[98.70965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 25. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 4 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 55.64070129394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 98.16374 ]
 [104.26464 ]
 [ 96.355675]
 [102.479706]
 [ 97.35406 ]
 [ 95.546   ]
 [ 98.36818 ]
 [100.990105]
 [107.207825]
 [106.401566]
 [ 98.37237 ]
 [101.869064]
 [ 99.18203 ]
 [ 96.671104]
 [104.465   ]
 [ 95.43515 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 25. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  8.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.70964813232422



buy possibilites: [-1] 
expected returns: [[55.16223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 25. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.  100.    0.    0.    0.    0.  -70.
   0.    0.   62.5   0. ] 
sum of rewards: 207.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 107.20784759521484






Player: 1 
cards in hand: [ 3. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25] -> size -> 42 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [10.  0.  3.  3. 11.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25] -> size -> 42 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[46.941227]
 [51.09156 ]
 [57.388794]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 11.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  6.  1. 15. 16.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.1622314453125



action possibilites: [-1] 
expected returns: [[29.445894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  6.  1. 15. 16.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.24082946777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.591248]
 [29.576178]
 [29.445887]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  6.  1. 15. 16.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.445894241333008



buy possibilites: [-1] 
expected returns: [[5.1683593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 6.  6.  1. 15. 16.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 150.   0.   0.  20.   0.   0.   0.   0. -90.   0.   0.
   0.   0.] 
sum of rewards: 75.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 32.59124755859375






Player: 1 
cards in hand: [ 6.  6.  1. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1. 15. 16.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1. 16.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 16.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 16.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 10. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 10.] 
expected returns: [[-4.7274675]
 [ 5.783108 ]
 [-1.094871 ]
 [ 4.3315873]
 [-1.094871 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15.  0. 10.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.168359279632568



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-17.57903  ]
 [-13.873163 ]
 [-13.873163 ]
 [ -7.9129715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.188220500946045



action possibilites: [-1] 
expected returns: [[24.964989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  150    0    0   40    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.348164081573486





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.773508]
 [39.9288  ]
 [25.201992]
 [36.797405]
 [24.964972]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 22. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.964988708496094



buy possibilites: [-1] 
expected returns: [[-6.60051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 39.92881774902344






Player: 1 
cards in hand: [ 0. 16. 11.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  1.  6.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  3 15  6 16  1 11  6  8  3  0  1  3  6
 16  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3.  3.  0.  0.] 
adversary cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[74.69049]
 [85.63949]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.600510120391846



action possibilites: [-1] 
expected returns: [[62.405975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -120    0    0
   64    0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 88.16632843017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[65.651634]
 [70.64327 ]
 [62.533806]
 [68.875755]
 [62.405968]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 21. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.405975341796875



buy possibilites: [-1] 
expected returns: [[87.316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 15.  1. 29. 11.  3.  0.  0.  1. 25.  1. 10. 10.  0. 29. 11. 11. 25.
 29. 10. 25. 10. 15.  0.  0.  0. 15.  0. 11. 10.  0.  3.  3. 15. 15.  3.
 29. 11. 10.  0. 10. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: 111 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 70.6432876586914






Player: 1 
cards in hand: [ 0.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0. 29. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  8.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0. 29. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0. 29. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 11.] 
expected returns: [[12.3964405]
 [21.012447 ]
 [21.380394 ]
 [15.806978 ]
 [21.012447 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 10. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.31600189208984



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[12.373533]
 [20.56169 ]
 [15.384466]
 [20.56169 ]
 [15.384466]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.06298065185547



action possibilites: [-1] 
expected returns: [[54.393684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   40    0    0    0    0 -140    0    0
   64    0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.258996963500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.043884]
 [56.009712]
 [55.847282]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.39368438720703



buy possibilites: [-1] 
expected returns: [[56.832024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0. 15.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0. -150.
    0.    0.    0.    0.] 
sum of rewards: 95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 60.043846130371094






Player: 1 
cards in hand: [3. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 6. 3.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15.  1.  0. 25.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 6. 3.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15.  1.  0. 25.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-16.701704 ]
 [ -7.7214966]
 [ -5.380318 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0. 25.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 20. 30.  8.  2.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.83202362060547



action possibilites: [-1] 
expected returns: [[77.46227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0.  3. 25.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.380331039428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[76.62785 ]
 [84.611824]
 [82.18615 ]
 [73.191956]
 [80.34898 ]
 [77.9233  ]
 [73.04077 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3. 25.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 22. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.46227264404297



buy possibilites: [-1] 
expected returns: [[103.77256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3. 25.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -160    0    0
   54    0] 
sum of rewards: 119 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 84.61183166503906






Player: 1 
cards in hand: [11.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6. 11.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  3. 29.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  3. 29.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  3. 29.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  3. 29.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
adversary victory points: 7
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[33.58487 ]
 [36.874725]
 [43.395958]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 29.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.7725601196289



action possibilites: [-1. 10.] 
expected returns: [[86.93409 ]
 [91.961266]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 41.342979431152344



action possibilites: [-1.] 
expected returns: [[93.15286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 91.96126556396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 97.03271 ]
 [105.70027 ]
 [103.04983 ]
 [ 93.314285]
 [101.078606]
 [ 98.42815 ]
 [ 93.15286 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 21. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.15286254882812



buy possibilites: [-1] 
expected returns: [[95.56067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [0. 3. 1. 8. 3.] 
adversary cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -170    0    0
   54    0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 105.70027923583984






Player: 1 
cards in hand: [0. 3. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1] -> size -> 52 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 20. 30. 20. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1] -> size -> 52 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8. 3.] 
cards in discard: [ 6.  3. 16.  3.  0.  0.  0. 15.  6.  6.  1. 16.  1.  0. 16.  0. 11.  6.
  8.  0.  0.  3.  6. 10.  3.  8.  6.  6.  3.  6.  0.  0. 11.  0.  0.  6.
 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1] -> size -> 52 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[46.451496]
 [55.16621 ]
 [54.495182]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  3.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  2.] 
adversary cards in hand: [ 6.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.5606689453125



action possibilites: [-1] 
expected returns: [[47.980293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 6.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -180    0    0
   64    0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.7546501159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.559708]
 [48.082104]
 [47.980293]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 6.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.98029327392578



buy possibilites: [-1] 
expected returns: [[-17.088915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 6.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0. -190.
    0.    0.    0.    0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 50.55968475341797






Player: 1 
cards in hand: [ 6.  1.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16
  3  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 19. 30.  8.  1.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 15.  0. 25. 10.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0.] 
cards in discard: [6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 15.  0. 25. 10.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 15.  0. 25. 10.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [6. 0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 15.  0. 25. 10.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1. 15.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 10.] 
expected returns: [[63.785667]
 [72.10473 ]
 [74.56806 ]
 [67.25825 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 25. 10.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [16.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.08891487121582



action possibilites: [-1] 
expected returns: [[-28.572056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 10. 15.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [16.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.56806182861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-25.879564]
 [-19.726746]
 [-21.482971]
 [-25.763304]
 [-23.089365]
 [-17.463093]
 [-25.709108]
 [-24.81444 ]
 [-19.514145]
 [-28.572056]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 10. 15.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  5. 10. 10.  2. 10.  1.] 
adversary cards in hand: [16.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -28.57205581665039



buy possibilites: [-1] 
expected returns: [[-13.045664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 10. 15.  0.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [16.  8.  3. 16.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -200    0    0
  128    0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -17.463096618652344






Player: 1 
cards in hand: [16.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3. 16.  0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  3. 29.  0. 15.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 16.  0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  3. 29.  0. 15.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 16.  0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  3. 29.  0. 15.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  3. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[103.05156 ]
 [110.04747 ]
 [111.02175 ]
 [109.498886]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0. 15.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  6.  3. 11. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.045663833618164



action possibilites: [-1. 15. 11.] 
expected returns: [[71.41202]
 [82.42561]
 [83.49221]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 20. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  6.  3. 11. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 111.36112213134766



action possibilites: [-1] 
expected returns: [[84.70989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 19. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  6.  3. 11. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 82.20938873291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[87.33047]
 [91.46025]
 [90.02833]
 [84.70989]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 19. 30. 19. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  6.  3. 11. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.70989227294922



buy possibilites: [-1] 
expected returns: [[87.75231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [11.  6.  3. 11. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -220    0    0
   16    0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 91.46023559570312






Player: 1 
cards in hand: [11.  6.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 11. 15.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 29. 10.  0. 11.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 11.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 29. 10.  0. 11.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3. 11.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1. 29. 10.  0. 11.] 
adversary cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[32.80551 ]
 [46.478645]
 [37.676388]
 [45.59857 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10.  0. 11.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.75231170654297



action possibilites: [-1. 11. 10.] 
expected returns: [[-46.564507]
 [-22.500868]
 [-36.418472]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 19. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.18397521972656



action possibilites: [-1] 
expected returns: [[18.618135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 18. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -230    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -24.45435905456543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[21.108196]
 [26.688858]
 [25.023157]
 [23.692785]
 [22.027088]
 [18.618143]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 18. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.618135452270508



buy possibilites: [-1] 
expected returns: [[7.234752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [ 0. 15.  0. 29. 11. 10. 11. 10.  1. 25.  3. 15.  1.  0.  3. 25. 29.  1.
 29. 10.  3.  3.  0.  0. 15.  0. 11. 15.  3.  3.  0. 29. 25.  1. 15.  0.
 10. 15.  0.  3. 11.  1.  3. 29. 11.  0. 15.  0. 10.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -240    0    0
   54    0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.6888484954834






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1  1] -> size -> 59 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 17. 30. 18. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1  1] -> size -> 59 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1  1] -> size -> 59 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[ 0.5047946]
 [12.620018 ]
 [ 5.537149 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0. 10.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10
 11 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3
 15  0  1  1 15  0 29  1  3  1  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10.  6.  6.  0.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.234752178192139



action possibilites: [-1] 
expected returns: [[-46.839252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10.  6.  6.  0.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 12.62004280090332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-40.82986 ]
 [-27.019028]
 [-30.057953]
 [-41.062332]
 [-34.21897 ]
 [-23.728542]
 [-40.530178]
 [-38.58381 ]
 [-26.715452]
 [-46.068836]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1] -> size -> 58 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  4. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10.  6.  6.  0.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.83925247192383



buy possibilites: [-1] 
expected returns: [[-11.421795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [29.] 
cards in deck: 54 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10.  6.  6.  0.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -240    0    0
  128    0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -23.728546142578125






Player: 1 
cards in hand: [10.  6.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  0.  3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [29. 10.  0. 10. 29.] 
adversary cards in discard: [29. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  0.  3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [29. 10.  0. 10. 29.] 
adversary cards in discard: [29. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  0.  3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [29. 10.  0. 10. 29.] 
adversary cards in discard: [29. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29. 10.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 29.] 
expected returns: [[26.582495]
 [52.96419 ]
 [35.95583 ]
 [35.95583 ]
 [52.96419 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 10. 29.] 
cards in discard: [29. 15.  3.  0. 10.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.421794891357422



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[35.1699  ]
 [42.905167]
 [42.905167]
 [56.725502]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.005653381347656



action possibilites: [-1. 10.] 
expected returns: [[ 8.0896225]
 [14.651247 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 1 
buys: 0 
player value: 2 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.7803955078125



action possibilites: [-1.] 
expected returns: [[1.4453006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.] 
cards in deck: 46 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 2 
buys: 0 
player value: 2 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 14.65127182006836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 5.7693095]
 [13.380095 ]
 [10.30489  ]
 [ 1.4452767]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.] 
cards in deck: 46 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29] -> size -> 59 
action values: 2 
buys: 1 
player value: 2 
card supply: [14. 17. 30. 17. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.445300579071045



buy possibilites: [-1] 
expected returns: [[121.19433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 8.  3.  0.  6. 16.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  300    0    0   60    0    0    0    0 -250    0    0
   16    0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 13.380109786987305






Player: 1 
cards in hand: [ 8.  3.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  6. 16.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3
  0  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0
  3  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 11. 25. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 11. 25. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 11. 25. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 11. 25. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 11. 25. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 15. 15.] 
expected returns: [[-9.184889  ]
 [-5.931132  ]
 [-0.96380544]
 [ 1.2982883 ]
 [-1.8572125 ]
 [-1.8572125 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25. 15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [6. 1. 1. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.19432830810547



action possibilites: [-1] 
expected returns: [[77.73366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 15. 29.  1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [6. 1. 1. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.2982563972473145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[84.1609  ]
 [92.11399 ]
 [89.46617 ]
 [77.733696]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15. 15. 29.  1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 17. 30. 16. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [6. 1. 1. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.73365783691406



buy possibilites: [-1] 
expected returns: [[-2.0536034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15. 15. 29.  1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [6. 1. 1. 6. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -260    0    0
   16    0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 92.11397552490234






Player: 1 
cards in hand: [6. 1. 1. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 1. 6. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 29. 11. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 6. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 29. 11. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 6. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [10. 29. 11. 15. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 29. 11. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 15. 15.] 
expected returns: [[23.803965]
 [27.81301 ]
 [35.14681 ]
 [34.393154]
 [33.397682]
 [33.397682]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.053603410720825



action possibilites: [-1. 15. 15. 15.] 
expected returns: [[14.374525]
 [19.543646]
 [19.543646]
 [19.543646]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.2205810546875



action possibilites: [-1] 
expected returns: [[-21.691786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 19.543636322021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-19.869955]
 [-21.691776]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.69178581237793



buy possibilites: [-1] 
expected returns: [[-12.829578]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.   40.    0.    0.    0.    0. -270.
    0.    0.    0.    0.] 
sum of rewards: 95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -19.869962692260742






Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0
  6 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3
  0  0  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1.  0.  1. 11.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1.  0.  1. 11.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 17. 30. 15. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1.  0.  1. 11.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
adversary victory points: 10
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 14. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 1.  0.  1. 11.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-40.724205]
 [-29.589106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 11.  1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 14. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.829578399658203



action possibilites: [-1] 
expected returns: [[-35.688473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 14. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -280    0    0
   27    0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -30.748695373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-33.005287]
 [-26.972961]
 [-34.763065]
 [-28.730722]
 [-33.82264 ]
 [-32.852757]
 [-30.232847]
 [-23.63134 ]
 [-24.48733 ]
 [-32.80798 ]
 [-29.395544]
 [-31.990623]
 [-34.499397]
 [-26.775637]
 [-35.688465]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1] -> size -> 63 
action values: 0 
buys: 1 
player value: 7 
card supply: [11. 16. 30. 14. 30.  8.  0.  6.  0.  7.  7.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -35.688472747802734



buy possibilites: [-1] 
expected returns: [[27.920141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 16. 30. 14. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -290.     0.     0.    62.5    0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -23.63134002685547






Player: 1 
cards in hand: [ 0. 11.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 14. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 14. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 15. 30. 14. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [ 6.  0. 16.  6.  1.  0.  0. 16.  8.  3. 16.  0. 15. 11.  6.  3. 11.  3.
  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  0.  8.  3.  6. 16.  0.  6.
  1.  1.  6.  3.  3.  8.  0.  0.  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 82.36846]
 [115.42679]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.920141220092773



action possibilites: [-1] 
expected returns: [[-9.103155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.4267807006836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 4.3370223]
 [26.341446 ]
 [20.616081 ]
 [ 0.7926822]
 [ 5.3325667]
 [15.817171 ]
 [34.474976 ]
 [32.56013  ]
 [ 5.2127204]
 [19.063297 ]
 [ 8.437931 ]
 [-2.592366 ]
 [26.930113 ]
 [-9.103187 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25] -> size -> 64 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  6.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.103155136108398



buy possibilites: [-1] 
expected returns: [[83.22075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -300    0    0
  250    0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 34.474998474121094






Player: 1 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 10.  3.  3. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  2. 10.  1.] 
adversary cards in hand: [ 0. 10.  3.  3. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 10.  3.  3. 25.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-78.19189 ]
 [-74.083046]
 [-64.49352 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 25.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.22074890136719



action possibilites: [-1] 
expected returns: [[-36.823135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  3. 11.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -64.49354553222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-33.58012 ]
 [-36.823143]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  3. 11.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25] -> size -> 65 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -36.82313537597656



buy possibilites: [-1] 
expected returns: [[-28.510614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  3. 11.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  300.    0.    0.   20.    0.    0.    0.    0. -310.
    0.    0.    0.    0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -33.58012771606445






Player: 1 
cards in hand: [3. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [10.  0.  3.  6.  0.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 11. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [10.  0.  3.  6.  0.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 11. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 6.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 29.  1. 11. 15.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[-137.75278 ]
 [-121.089775]
 [-122.48881 ]
 [-124.17945 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 11. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -28.5106143951416



action possibilites: [-1. 15.] 
expected returns: [[-95.392815]
 [-86.28443 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -119.3968734741211



action possibilites: [-1] 
expected returns: [[-27.64605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -86.28441619873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-24.490816]
 [-17.299368]
 [-19.173933]
 [-21.29598 ]
 [-23.170546]
 [-27.646065]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0] -> size -> 66 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 15. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.64604949951172



buy possibilites: [-1] 
expected returns: [[-42.48568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -320    0    0
   54    0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -17.299346923828125






Player: 1 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.307558]
 [37.749573]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -42.485679626464844



action possibilites: [-1. 15.] 
expected returns: [[14.909723]
 [32.502502]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 15.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11
 10  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15
  0  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 67 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 37.749549865722656



action possibilites: [-1.] 
expected returns: [[-8.904454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 66 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 32.50250244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.077629 ]
 [ 3.6788702]
 [-7.2835627]
 [ 1.4729543]
 [-6.558869 ]
 [-5.583047 ]
 [-1.2257555]
 [ 7.0253606]
 [ 5.544131 ]
 [-4.912898 ]
 [-0.5136826]
 [-3.4316676]
 [-7.601105 ]
 [ 3.8436122]
 [-8.904467 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1] -> size -> 66 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  5.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.904454231262207



buy possibilites: [-1] 
expected returns: [[38.82468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29. 15.  3.  0. 10.  0.  0. 10. 11.  3. 29. 29. 10.  3.  3. 25. 10. 11.
 15. 15. 29.  1. 10. 11.  0. 29. 15. 15. 15.  1. 25. 11.  1.  0.  1.  1.
 25. 25.  0.  3.  0.  0.  3.  1.  0. 25.  0. 10.  3.  3.  3. 11.  0. 11.
  1. 29. 15.  1.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 3.  0.  6.  0. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    40.     0.     0.     0.
    0.  -320.     0.     0.    62.5    0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.025373935699463






Player: 1 
cards in hand: [ 3.  0.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 25.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  0. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 25.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  0. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 25.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-36.51269 ]
 [-25.257856]
 [-26.241999]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 62 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 6. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.82468032836914



action possibilites: [-1] 
expected returns: [[43.215675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 60 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 6. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -25.25785255432129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.98077 ]
 [66.27329 ]
 [62.272438]
 [51.075153]
 [58.749767]
 [71.030754]
 [51.4958  ]
 [54.01268 ]
 [66.71818 ]
 [43.215637]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 60 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25] -> size -> 67 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  3. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 6. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.215675354003906



buy possibilites: [-1] 
expected returns: [[-84.858604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 29.  0. 10.] 
cards in discard: [29.] 
cards in deck: 60 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 6. 1. 1. 0.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -330    0    0
  128    0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 71.03079223632812






Player: 1 
cards in hand: [3. 6. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 1. 0.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 68 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 0.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  6.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 68 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 1. 0.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 68 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[11.67321 ]
 [25.764376]
 [25.764376]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0.  1.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10
  0  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0
  1  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -84.85860443115234



action possibilites: [-1] 
expected returns: [[-36.995773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
cards in deck: 55 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 67 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 25.764392852783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-34.84529 ]
 [-29.778059]
 [-36.12129 ]
 [-31.307846]
 [-35.639545]
 [-35.04194 ]
 [-32.754585]
 [-27.350788]
 [-28.309683]
 [-34.74638 ]
 [-32.30753 ]
 [-34.01552 ]
 [-36.215927]
 [-29.645311]
 [-36.995785]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10.] 
cards in deck: 55 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29] -> size -> 67 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  4.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -36.99577331542969



buy possibilites: [-1] 
expected returns: [[27.730043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25.] 
cards in deck: 55 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    20.     0.     0.     0.
    0.  -330.     0.     0.    62.5    0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -27.350780487060547






Player: 1 
cards in hand: [ 8.  1.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  3. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  3 15  6 16  1 11  6  8  3  0  1  3  6 16  3  0  6
 11  6  3  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0
  0  0  3  1  3 10  0  0  0 16] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [25.  3. 25. 29. 15.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [25.  3. 25. 29. 15.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16] -> size -> 55 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [25.  3. 25. 29. 15.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [25.  3. 25. 29. 15.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [25.  3. 25. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 15.] 
expected returns: [[-1.2367282]
 [19.70508  ]
 [19.70508  ]
 [17.21832  ]
 [12.461864 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 25. 29. 15.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 16.  0. 10. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.730043411254883



action possibilites: [-1] 
expected returns: [[-34.0076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 15. 15. 29.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 16.  0. 10. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.70506477355957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-25.53319 ]
 [-34.007545]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 29. 15. 15. 29.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25] -> size -> 68 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 16.  0. 10. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -34.007598876953125



buy possibilites: [-1] 
expected returns: [[-42.532555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 29. 15. 15. 29.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 16.  0. 10. 16.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -340    0    0
    0    0] 
sum of rewards: 5 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -25.533246994018555






Player: 1 
cards in hand: [ 1. 16.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 10. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  1  3  6 16  3  0  6 11  6  3
  6 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3
  1  3 10  0  0  0 16  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2. 10. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 29. 10. 25.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 29. 10. 25.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 29. 10. 25.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 1. 29. 10. 25.  1.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 10. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[-105.10395 ]
 [ -96.015305]
 [-101.26173 ]
 [ -95.00579 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10. 25.  1.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 8.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -42.532554626464844



action possibilites: [-1] 
expected returns: [[42.857464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10.  1.  1. 11.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 8.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -95.00578308105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.292027]
 [52.939365]
 [44.07489 ]
 [51.090523]
 [45.211327]
 [46.40834 ]
 [49.623722]
 [56.06101 ]
 [55.264668]
 [46.531864]
 [50.55153 ]
 [47.61256 ]
 [44.336628]
 [53.15842 ]
 [42.857433]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 10.  1.  1. 11.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0] -> size -> 69 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  3.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 8.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.85746383666992



buy possibilites: [-1] 
expected returns: [[-21.64989]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 10.  1.  1. 11.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 70 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 8.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -350.     0.     0.    62.5    0. ] 
sum of rewards: 57.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 56.06101989746094






Player: 1 
cards in hand: [6. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 8.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [10. 15.  0.  3.  0.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 70 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 8.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [10. 15.  0.  3.  0.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 70 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-70.19352 ]
 [-59.380524]
 [-43.90576 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3.  0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0
  0 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1
  1 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.649890899658203



action possibilites: [-1] 
expected returns: [[-45.17256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 69 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -43.9057731628418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-42.193947]
 [-35.336075]
 [-36.99619 ]
 [-42.73627 ]
 [-39.21656 ]
 [-34.113834]
 [-42.089775]
 [-40.87187 ]
 [-35.2314  ]
 [-45.172543]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25] -> size -> 69 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  2.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -45.17256164550781



buy possibilites: [-1] 
expected returns: [[20.381086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29] -> size -> 70 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -350    0    0
  128    0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -34.11384201049805






Player: 1 
cards in hand: [0. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11.  0. 29.  3.  0.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29] -> size -> 70 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11.  0. 29.  3.  0.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29] -> size -> 70 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [11.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-15.235682]
 [ 17.655981]
 [ 19.792608]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.381086349487305



action possibilites: [-1. 11.] 
expected returns: [[24.860434]
 [47.776333]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29] -> size -> 70 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 14. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.089326858520508



action possibilites: [-1] 
expected returns: [[17.782564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1] -> size -> 71 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 13. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -360    0    0
   27    0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 46.06221008300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[29.038973]
 [46.185436]
 [40.130585]
 [17.782557]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1] -> size -> 71 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 13. 30. 13. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.782564163208008



buy possibilites: [-1] 
expected returns: [[41.315067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 13. 30. 12. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 15.  0.  0. 11.] 
adversary cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -370    0    0
   16    0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 46.185401916503906






Player: 1 
cards in hand: [11. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  0. 11.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 13. 30. 12. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [10. 15.  0.  0.  3.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 72 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  0. 11.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 13. 30. 12. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [10. 15.  0.  0.  3.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 72 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  0. 11.] 
cards in discard: [10.  0.  3.  6.  0.  0.  0.  3.  3.  0.  0.  6.  0.  0.  6.  6.  0.  3.
  0.  3.  0.  6.  0. 16. 16.  3.  6.  1.  1.  0.  0.  8. 16. 14.  0. 16.
  0. 10. 16.  6.  3.  8.  0.  8.  0.  6.  3.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 13. 30. 11. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [10. 15.  0.  0.  3.] 
adversary cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 72 
adversary victory points: 11
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-53.072327]
 [-49.302242]
 [-44.24648 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  0.  3.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0
 10 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1
 15  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 13. 30. 11. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0  3] -> size -> 58 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.315067291259766



action possibilites: [-1] 
expected returns: [[-85.653656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0 10
 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1 15
  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 71 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 13. 30. 11. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0  3] -> size -> 58 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -44.24649429321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-83.285065]
 [-77.827484]
 [-79.11836 ]
 [-83.77666 ]
 [-80.926285]
 [-76.95508 ]
 [-83.21196 ]
 [-82.21716 ]
 [-77.75439 ]
 [-85.65365 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0 10
 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1 15
  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3] -> size -> 71 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 13. 30. 11. 30.  8.  0.  5.  0.  7.  2.  1.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0  3] -> size -> 58 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -85.65365600585938



Player 0 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 7 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 8 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  0.  3.] 
cards in discard: [29. 25.  0.  3.  1. 29.  0. 10. 25. 15. 15.  0.  1.  0. 25.  3. 25. 29.
 15. 15. 29. 25. 25.  1. 29. 10.  1.  1. 11. 29. 15. 10.  3.  0. 11.  0.
  1.  3. 29. 11.  3.  0. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 11 29 10 29 29 25 10 11 10 29 10 11 25  0 10 11 10  0  0 10
 29 11  3 11  3 15  1 15  0 15  1  1 25 15  0 15  3 15  3 15  0  1  1 15
  0 29  1  3  1  1 29  3  3  0  1 25 25  0  1 25 29 25  0 25 29  1  3 29] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 13. 30. 11. 30.  8.  0.  5.  0.  7.  2.  0.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16 15  6 16 11  6  8  3  0  3  6 16  3  0  6 11  6  3  6
 11  3  8 16 10  6  6  0  1  0  8  6  0  0  3  6  0  0  3  0  0  0  3  1
  3 10  0  0  0 16  0 14  0  3] -> size -> 58 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[     -5 3000000       0     330       0       0      20       0       0
       0       0    -370       0       0      64       0] 
sum of rewards: 3000039 

action type: buy - action 29.0
Learning step: 300011.59375
desired expected reward: 299934.625



