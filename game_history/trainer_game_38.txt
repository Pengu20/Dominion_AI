 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.99606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -10    0    0   20    0    0    0    0   -3    0    0
    4    0] 
sum of rewards: -495 

action type: buy - action 8.0
Learning step: -29.07242202758789
desired expected reward: 57.375980377197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[298.3465 ]
 [306.33002]
 [286.9819 ]
 [308.7895 ]
 [325.76096]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.44327449798584
desired expected reward: 319.4579162597656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.55655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.797258377075195
desired expected reward: 316.963623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[305.2083 ]
 [313.95392]
 [313.15732]
 [296.91327]
 [294.22202]
 [310.92078]
 [324.30008]
 [315.3558 ]
 [331.61603]
 [322.2769 ]
 [305.36478]
 [310.48224]
 [314.7039 ]
 [300.88602]
 [314.96097]
 [333.8028 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.688750267028809
desired expected reward: 327.6795654296875



buy possibilites: [-1] 
expected returns: [[320.7829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.550175666809082
desired expected reward: 306.8056335449219






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[298.68994]
 [280.43216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.486623764038086
desired expected reward: 311.2962646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[272.02188]
 [280.5339 ]
 [279.68604]
 [263.00568]
 [290.74573]
 [281.9121 ]
 [281.20377]
 [300.18225]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.566119194030762
desired expected reward: 291.6142883300781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.79272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.747772216796875
desired expected reward: 292.43450927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[297.82742]
 [306.2925 ]
 [305.45212]
 [287.16718]
 [303.3501 ]
 [316.97433]
 [307.6623 ]
 [314.75482]
 [297.92587]
 [306.9562 ]
 [307.1805 ]
 [327.3795 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [0. 0. 3. 8. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.323482513427734
desired expected reward: 317.8472595214844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 8. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[341.39966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.759263038635254
desired expected reward: 318.6201477050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[321.11536]
 [328.8043 ]
 [327.82465]
 [311.31885]
 [337.56293]
 [330.09027]
 [329.22156]
 [345.24576]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.646175384521484
desired expected reward: 333.0075378417969



buy possibilites: [-1] 
expected returns: [[332.00223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -9.034461975097656
desired expected reward: 321.0557861328125






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  8  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[337.51968]
 [318.17795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  8  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.207852363586426
desired expected reward: 322.79437255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[309.08737]
 [318.3691 ]
 [317.56958]
 [297.89563]
 [329.12408]
 [319.81482]
 [319.1696 ]
 [339.06686]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  8  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.5845365524292
desired expected reward: 328.1772155761719



buy possibilites: [-1] 
expected returns: [[318.25455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [8. 0. 0. 0. 3. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  8  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.830012321472168
desired expected reward: 310.9847717285156






Player: 1 
cards in hand: [0. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [10.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  8  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  8 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[341.66257]
 [323.93866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.44315242767334
desired expected reward: 309.8114013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[310.1044 ]
 [318.60278]
 [317.73886]
 [299.20694]
 [315.65732]
 [328.51468]
 [319.97   ]
 [326.54816]
 [310.20856]
 [319.23676]
 [319.43887]
 [337.7378 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.75127124786377
desired expected reward: 331.0018310546875



buy possibilites: [-1] 
expected returns: [[315.47415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -8.326824188232422
desired expected reward: 302.67303466796875






Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [1. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [1. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [1. 0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[293.5194 ]
 [274.86765]
 [274.86765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [1. 0. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.389514923095703
desired expected reward: 306.0846252441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[268.01614]
 [257.62457]
 [297.33286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [1. 0. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  3.  0.] 
adversary cards in discard: [0. 8. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.380370140075684
desired expected reward: 285.9173278808594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3.  0.] 
cards in discard: [0. 8. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3.  0.] 
cards in discard: [0. 8. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3.  0.] 
cards in discard: [0. 8. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[315.1188 ]
 [297.18848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.947673797607422
desired expected reward: 289.38519287109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.74457]
 [295.12054]
 [294.2477 ]
 [276.64905]
 [305.25864]
 [296.51056]
 [295.77585]
 [314.4403 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.047747611999512
desired expected reward: 307.219970703125



buy possibilites: [-1] 
expected returns: [[293.67404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -7.855266094207764
desired expected reward: 297.40338134765625






Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [11.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[289.19223]
 [270.2984 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1. 3.] 
cards in discard: [11.  0.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.357405662536621
desired expected reward: 285.316650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[261.07724]
 [268.90244]
 [268.24582]
 [251.24683]
 [266.1976 ]
 [278.87152]
 [270.13998]
 [276.78757]
 [261.22375]
 [269.61807]
 [269.8285 ]
 [288.3065 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1. 3.] 
cards in discard: [11.  0.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.339181900024414
desired expected reward: 281.9402160644531



buy possibilites: [-1] 
expected returns: [[239.44966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1. 3.] 
cards in discard: [11.  0.  8.  3.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -6.6038055419921875
desired expected reward: 263.22467041015625






Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 8.  0. 10.  0.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[251.86485]
 [236.61629]
 [236.61629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.022607326507568
desired expected reward: 232.4270477294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[226.65233]
 [233.17416]
 [217.5496 ]
 [235.20935]
 [250.75946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.739017009735107
desired expected reward: 243.86569213867188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  8 10  0  0  0  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[296.86472]
 [283.5872 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -7.009260654449463
desired expected reward: 243.7501983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[276.6285 ]
 [282.48764]
 [267.8149 ]
 [284.66058]
 [297.00586]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.47474479675293
desired expected reward: 288.27813720703125



buy possibilites: [-1] 
expected returns: [[308.86005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [8. 8. 3. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -23.091398239135742
desired expected reward: 244.72357177734375






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  3. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 8. 3. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[239.66452]
 [221.22078]
 [230.40651]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  1. 11.] 
cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -11.79843807220459
desired expected reward: 297.0616149902344



action possibilites: [-1] 
expected returns: [[276.68475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -4 

action type: gain_card_n - action 9
Learning step: -5.3586602210998535
desired expected reward: 222.3226776123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[256.78055]
 [264.50375]
 [263.6455 ]
 [247.00645]
 [261.80017]
 [273.38327]
 [265.73135]
 [271.63214]
 [256.7369 ]
 [264.98767]
 [265.12518]
 [281.92468]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -8.335094451904297
desired expected reward: 268.34967041015625



buy possibilites: [-1] 
expected returns: [[249.77194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 8.  8.  3.  0.  0.  6.  0.  3. 15.  3.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -8.5 

action type: buy - action 10.0
Learning step: -8.05451488494873
desired expected reward: 256.93316650390625






Player: 1 
cards in hand: [ 8.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  8 10  0  0  0  8  3  3  8] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [15.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[219.4281 ]
 [204.7229 ]
 [205.23264]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  8  1 11 15  6 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.813529968261719
desired expected reward: 240.95840454101562



action possibilites: [-1] 
expected returns: [[214.32625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.214080810546875
desired expected reward: 200.51434326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[193.84483]
 [199.60559]
 [185.597  ]
 [201.44919]
 [214.54753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 0. 10.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -6.761528015136719
desired expected reward: 207.56472778320312






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 0. 10.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 0. 10.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  2. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 0. 10.  8.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[282.86118]
 [266.09976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  3.] 
cards in discard: [ 8. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.226936340332031
desired expected reward: 208.32061767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[258.32776]
 [265.07593]
 [248.68745]
 [267.17862]
 [282.4118 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.  3.] 
cards in discard: [ 8. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.531989097595215
desired expected reward: 270.1790466308594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[227.91626]
 [220.3982 ]
 [213.00203]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [3. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -11.269038200378418
desired expected reward: 271.14276123046875



action possibilites: [-1] 
expected returns: [[215.9606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [3. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -15 

action type: gain_card_n - action 9
Learning step: -6.960437774658203
desired expected reward: 214.4305877685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[191.19179]
 [198.62039]
 [197.89438]
 [181.65884]
 [207.32442]
 [199.80148]
 [199.19498]
 [215.24484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 15.  0.  0.  6.  0. 10.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [3. 3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -7.336880683898926
desired expected reward: 208.62371826171875






Player: 1 
cards in hand: [10.  8.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  8.] 
cards in discard: [3. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.  8.] 
cards in discard: [3. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  1.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[208.18156]
 [192.98798]
 [193.45447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -8.437214851379395
desired expected reward: 206.8076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[185.3475 ]
 [191.50287]
 [176.93591]
 [193.1623 ]
 [208.29762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.005426406860352
desired expected reward: 198.00665283203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [ 6. 10.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [ 6. 10.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[238.39279]
 [226.86139]
 [226.92307]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 15.] 
cards in discard: [ 6. 10.  1.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -7.3119659423828125
desired expected reward: 200.9856719970703



action possibilites: [-1] 
expected returns: [[251.87347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 6. 10.  1.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -6.2368316650390625
desired expected reward: 207.84286499023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[230.63222]
 [237.44771]
 [236.52687]
 [221.9001 ]
 [235.03586]
 [245.06886]
 [238.54979]
 [243.61128]
 [230.44044]
 [237.72221]
 [237.78706]
 [251.82562]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 6. 10.  1.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -8.28985595703125
desired expected reward: 243.5836181640625






Player: 1 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [0. 3. 8. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [0. 3. 8. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  1. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [0. 3. 8. 0. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[207.62877]
 [194.48955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -10.264825820922852
desired expected reward: 241.560791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[189.92526]
 [196.0398 ]
 [195.45056]
 [182.56706]
 [193.77731]
 [203.7525 ]
 [202.14384]
 [189.91968]
 [196.57169]
 [196.69342]
 [210.97392]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.835594177246094
desired expected reward: 196.52593994140625



buy possibilites: [-1] 
expected returns: [[184.03682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6. 10.  1.  8.  3. 15.  3.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 3.0
Learning step: -7.181698799133301
desired expected reward: 188.2688446044922






Player: 1 
cards in hand: [3. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 8.] 
cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3.  8.  0.  3.  8. 10.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10. 10. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10. 10. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.  8.] 
expected returns: [[199.4081 ]
 [185.28714]
 [185.28714]
 [192.50447]
 [185.99843]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.0075201988220215
desired expected reward: 178.029296875



action possibilites: [-1. 10. 11.  8.] 
expected returns: [[197.69847]
 [185.6226 ]
 [191.83871]
 [186.20859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -4.989250183105469
desired expected reward: 179.12643432617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[180.3029 ]
 [173.34172]
 [198.42308]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.730302333831787
desired expected reward: 191.96820068359375



buy possibilites: [-1] 
expected returns: [[174.63524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  0.  3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -20.437795639038086
desired expected reward: 152.90394592285156






Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  0  0  8  3  3  8  0  8  3  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10.  1.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10.  1.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 15. 10.  1.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[216.0601 ]
 [206.70827]
 [206.13568]
 [206.11879]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 10.  1.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.205317497253418
desired expected reward: 169.42991638183594



action possibilites: [-1.  8. 15.  8.] 
expected returns: [[173.54509]
 [162.25797]
 [161.74359]
 [162.25797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  1.  8.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -6.537539005279541
desired expected reward: 196.4000701904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[156.37956]
 [162.0355 ]
 [161.37717]
 [149.43336]
 [168.61357]
 [162.37506]
 [174.47635]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  1.  8.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -5.088973522186279
desired expected reward: 168.45611572265625



buy possibilites: [-1] 
expected returns: [[150.7599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  1.  8.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: -4.338581562042236
desired expected reward: 164.27500915527344






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3  3  8  0  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  3  8  8  3  8  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  3  8  8  3  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.00325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.719046592712402
desired expected reward: 145.04086303710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[117.07752 ]
 [122.37056 ]
 [121.70271 ]
 [110.92898 ]
 [128.32532 ]
 [122.621124]
 [133.59262 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.027506351470947
desired expected reward: 129.1479949951172



buy possibilites: [-1] 
expected returns: [[124.11811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6. 10. 10. 11.  8.  0.  3. 11. 10.  0.  8. 15.  1.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 1.0
Learning step: -3.407270908355713
desired expected reward: 118.9632568359375






Player: 1 
cards in hand: [ 8.  8.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  3  8  8  3  8  0  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  3  8  3  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  3  8  3  8  0] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[174.39862]
 [163.36795]
 [162.81035]
 [168.75217]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.06732177734375
desired expected reward: 121.05078887939453



action possibilites: [-1] 
expected returns: [[156.81839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: -3.822542190551758
desired expected reward: 165.1965789794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.43587]
 [140.36053]
 [159.02473]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -4.082237720489502
desired expected reward: 152.73614501953125






Player: 1 
cards in hand: [10.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  3.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15.  0.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[131.8538  ]
 [122.134254]
 [122.54335 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  3.  8.] 
cards in discard: [15. 11.  8. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.813255310058594
desired expected reward: 153.21148681640625



action possibilites: [-1] 
expected returns: [[132.21783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [15. 11.  8. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 15.0
Learning step: -2.7067410945892334
desired expected reward: 116.92610168457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[115.197495]
 [120.97252 ]
 [120.37345 ]
 [108.13045 ]
 [127.67491 ]
 [121.36682 ]
 [133.72797 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [15. 11.  8. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -3.4426345825195312
desired expected reward: 128.77520751953125






Player: 1 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 10.  6.  0.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  3  8  0  0] -> size -> 7 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 10.  6.  0.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  3  8  0  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 10.  6.  0.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 10.  6.  0.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[106.39972]
 [ 96.07443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  6.  0.] 
cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.057633876800537
desired expected reward: 128.6703338623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 91.8933  ]
 [ 96.46579 ]
 [ 95.94805 ]
 [ 86.356316]
 [101.692696]
 [ 96.73301 ]
 [106.46911 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  6.  0.] 
cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.717463254928589
desired expected reward: 102.33090209960938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[105.55197]
 [ 96.10574]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -3.722759962081909
desired expected reward: 102.7463607788086



action possibilites: [-1.  8.] 
expected returns: [[104.27948]
 [ 94.68367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -2.1956353187561035
desired expected reward: 93.57736206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 94.961716]
 [ 99.64829 ]
 [ 99.24082 ]
 [ 90.50571 ]
 [ 89.04992 ]
 [ 98.02571 ]
 [105.187035]
 [109.092995]
 [104.03416 ]
 [ 94.977455]
 [ 97.76514 ]
 [100.03629 ]
 [ 92.6144  ]
 [100.128204]
 [110.242256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [15. 11.  8. 10.  3.  0. 15.  6.  3.  8.  3.  1. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -2.5579748153686523
desired expected reward: 101.72150421142578






Player: 1 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[152.38493]
 [143.07684]
 [142.37709]
 [147.67493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.851977586746216
desired expected reward: 107.39027404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.96198]
 [129.43153]
 [151.02278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.052818298339844
desired expected reward: 147.25067138671875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  8  0  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 8. 6. 1.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 8. 6. 1.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 26. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 8. 6. 1.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 1. 8. 6. 1.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [3. 1. 8. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[136.03316]
 [125.61661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8. 6. 1.] 
cards in discard: [ 8. 10.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.255223751068115
desired expected reward: 145.76754760742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[120.72862 ]
 [126.22632 ]
 [125.47032 ]
 [113.87176 ]
 [124.28883 ]
 [132.29195 ]
 [131.05022 ]
 [120.504875]
 [126.41641 ]
 [126.38037 ]
 [137.543   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8. 6. 1.] 
cards in discard: [ 8. 10.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.517017364501953
desired expected reward: 131.12954711914062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11. 10. 15.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  8.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11. 10. 15.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 11. 10. 15.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[131.03714]
 [125.626  ]
 [119.78072]
 [119.77638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 10. 15.] 
cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -4.4559245109558105
desired expected reward: 127.83954620361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.18085]
 [107.56571]
 [131.02934]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 10. 15.] 
cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.427924633026123
desired expected reward: 126.1097183227539



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.  6.  0. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15.  0. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.  6.  0. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[90.14594 ]
 [79.39278 ]
 [79.419304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 10.  0.] 
cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.  6.  0. 11. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.326163291931152
desired expected reward: 125.70319366455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[75.83221 ]
 [80.26576 ]
 [79.6332  ]
 [70.16162 ]
 [85.150215]
 [80.40051 ]
 [90.764275]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10.  0.] 
cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.  6.  0. 11. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  8. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.225388288497925
desired expected reward: 85.805908203125



buy possibilites: [-1] 
expected returns: [[97.82001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10.  0.] 
cards in discard: [ 8. 10.  3.  0. 11.  3.  1.  8.  6.  1.  6.  0. 11. 10. 15.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -17.557130813598633
desired expected reward: 52.6044921875






Player: 1 
cards in hand: [ 3.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[134.34041]
 [123.68725]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  8  1 11 15  6 10 10 10  3  6 11  1 15  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -3.171842098236084
desired expected reward: 94.64816284179688



action possibilites: [-1] 
expected returns: [[61.00636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.602794647216797
desired expected reward: 120.90596008300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.88746 ]
 [48.120342]
 [59.641636]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -1.479723334312439
desired expected reward: 59.526634216308594






Player: 1 
cards in hand: [ 3.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[136.38258]
 [125.14266]
 [125.51183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  8.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -0.7188413739204407
desired expected reward: 58.92279052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[117.00921 ]
 [121.97953 ]
 [121.522255]
 [110.71751 ]
 [120.246735]
 [128.07379 ]
 [126.81005 ]
 [117.00622 ]
 [122.37319 ]
 [122.47978 ]
 [133.69484 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  8.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.589138507843018
desired expected reward: 130.75746154785156



buy possibilites: [-1] 
expected returns: [[154.33664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  8.] 
cards in discard: [8. 0. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -9.5 

action type: buy - action 1.0
Learning step: -3.1014015674591064
desired expected reward: 118.87811279296875






Player: 1 
cards in hand: [10.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 11.  3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[166.09135]
 [160.25137]
 [153.9668 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0. 15.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -4.772397994995117
desired expected reward: 149.56423950195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[147.61652]
 [140.98769]
 [164.62888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0. 15.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.3886942863464355
desired expected reward: 159.4588623046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  8. 10.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  8. 10.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  8. 10.] 
adversary cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 10.] 
expected returns: [[114.192055]
 [102.05527 ]
 [102.06076 ]
 [102.65396 ]
 [102.05527 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 15.  8. 10.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10 10 10  3 11  1 15  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -6.503535747528076
desired expected reward: 158.1253204345703



action possibilites: [-1] 
expected returns: [[94.330574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.9825342893600464
desired expected reward: 97.11690521240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.131256]
 [80.4596  ]
 [98.67467 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  7. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -1.760191559791565
desired expected reward: 92.57038116455078



buy possibilites: [-1] 
expected returns: [[101.04735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 8.  0.  1. 10.  0.  0.  1.  8.  3. 11.  3.  0. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  6. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -294 

action type: buy - action 6.0
Learning step: -16.44941520690918
desired expected reward: 64.01017761230469






Player: 1 
cards in hand: [ 0.  3.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 11.] 
cards in discard: [14.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  6. 10.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [14.  0.  0.  0.  0.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [14.  0.  0.  0.  0.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [14.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[112.71205]
 [101.61343]
 [107.10654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.304145097732544
desired expected reward: 97.74320220947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.22698 ]
 [101.18463 ]
 [100.36746 ]
 [ 87.74289 ]
 [ 99.06691 ]
 [107.816696]
 [106.49285 ]
 [ 94.98165 ]
 [101.394485]
 [101.40386 ]
 [113.62105 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.868391752243042
desired expected reward: 107.79180908203125



buy possibilites: [-1] 
expected returns: [[165.36865]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 11.  0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -9.5 

action type: buy - action 1.0
Learning step: -1.8134361505508423
desired expected reward: 99.37117767333984






Player: 1 
cards in hand: [ 0.  8. 16.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 10. 15.  1.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.  3. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 10. 15.  1.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 10. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[137.6671 ]
 [127.66217]
 [126.93625]
 [126.85051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 15.  1.] 
cards in discard: [ 1.  8.  0.  1. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8. 16.  3. 14.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -6.012685775756836
desired expected reward: 159.35597229003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[117.81605 ]
 [121.780334]
 [111.88217 ]
 [133.52222 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10. 15.  1.] 
cards in discard: [ 1.  8.  0.  1. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8. 16.  3. 14.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.597415924072266
desired expected reward: 130.71063232421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0.  8. 16.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  7.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  6.  0. 11.  3.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8. 16.  3. 14. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  6.  0. 11.  3.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8. 16.  3. 14. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  6.  0. 11.  3.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  8. 16.  3. 14. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  6.  0. 11.  3.] 
adversary cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[68.132034]
 [64.003296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 11.  3.] 
cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.890751838684082
desired expected reward: 127.63146209716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[61.08928 ]
 [65.24216 ]
 [64.49076 ]
 [55.884933]
 [69.745636]
 [65.22497 ]
 [74.065605]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 11.  3.] 
cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -2.482830762863159
desired expected reward: 64.513671875



buy possibilites: [-1] 
expected returns: [[91.19939]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 11.  3.] 
cards in discard: [ 1.  8.  0.  1. 11.  0.  8.  3. 10. 15.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 1.0
Learning step: -1.010122537612915
desired expected reward: 64.23204803466797






Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1. 15.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[123.33241]
 [113.48454]
 [113.92409]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8  8  8  1 11 15 10  3 11  1 15  1  6  1  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -2.5839154720306396
desired expected reward: 88.61547088623047



action possibilites: [-1] 
expected returns: [[76.40638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.5480873584747314
desired expected reward: 107.79652404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.648415]
 [60.00326 ]
 [76.24023 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -1.9079134464263916
desired expected reward: 74.49846649169922



buy possibilites: [-1] 
expected returns: [[56.631054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -3.099311351776123
desired expected reward: 61.549102783203125






Player: 1 
cards in hand: [ 0. 14. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  0.  8.] 
cards in discard: [ 0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  8.  1.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11.  0.  8.] 
cards in discard: [ 0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  8.  1.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11.  0.  8.] 
cards in discard: [ 0.  3.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3.  8.  1.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  3.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[98.46558 ]
 [91.81796 ]
 [85.449875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  1.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 16.  3.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -1.418791651725769
desired expected reward: 55.21226119995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[76.789536]
 [83.131454]
 [82.44102 ]
 [68.9704  ]
 [90.5933  ]
 [83.54503 ]
 [97.254524]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  1.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 16.  3.] 
adversary cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8.] 
adversary owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.5250051021575928
desired expected reward: 93.62884521484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 16.  3.] 
cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3 11  0  0 14 16  0 11  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6. 10.  8.] 
adversary cards in hand: [15. 10.  3.  6.  1.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [15. 10.  3.  6.  1.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 25. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [15. 10.  3.  6.  1.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 10.  0.  0. 14. 11.  0.  8. 22.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [15. 10.  3.  6.  1.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15. 10.  3.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[92.83868 ]
 [86.619316]
 [86.73426 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.  6.  1.] 
cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11. 10.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -4.081304550170898
desired expected reward: 93.1732177734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[80.60696 ]
 [83.177826]
 [76.27662 ]
 [90.27606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3.  6.  1.] 
cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [11. 10.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.756833791732788
desired expected reward: 86.29595947265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 10.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  1.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  1.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  1.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[84.29453 ]
 [76.227196]
 [80.26416 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  8. 11.] 
cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 16. 22.  0.  0.] 
adversary cards in discard: [10. 11.  0.  0. 14.  3.] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.905979871749878
desired expected reward: 86.37007904052734



action possibilites: [-1] 
expected returns: [[66.78957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 8.] 
cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 16. 22.  0.  0.] 
adversary cards in discard: [10. 11.  0.  0. 14.  3.] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: -1.5883339643478394
desired expected reward: 72.23365020751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.78028 ]
 [52.47694 ]
 [51.973507]
 [41.528263]
 [39.89646 ]
 [50.49369 ]
 [59.672066]
 [65.00148 ]
 [58.03256 ]
 [46.75312 ]
 [50.125126]
 [52.94133 ]
 [43.91976 ]
 [53.010128]
 [66.53238 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 8.] 
cards in discard: [ 0.  8.  0. 11.  3.  8.  1.  0. 15. 10.  3.  6.  1. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 16. 22.  0.  0.] 
adversary cards in discard: [10. 11.  0.  0. 14.  3.] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.2044999599456787
desired expected reward: 64.58507537841797






Player: 1 
cards in hand: [ 0. 16. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 22.  0.  0.] 
cards in discard: [10. 11.  0.  0. 14.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 22.  0.  0.] 
cards in discard: [10. 11.  0.  0. 14.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 22.  0.  0.] 
cards in discard: [10. 11.  0.  0. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[91.472176]
 [86.36329 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 15.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10. 11.  0.  0. 14.  3.  0.  0. 16. 22.  0.  0.] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.520066976547241
desired expected reward: 64.01232147216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[80.37632 ]
 [83.348724]
 [82.4961  ]
 [76.38295 ]
 [82.21743 ]
 [86.051674]
 [85.62167 ]
 [79.9062  ]
 [83.05369 ]
 [82.90418 ]
 [88.02834 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 15.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10. 11.  0.  0. 14.  3.  0.  0. 16. 22.  0.  0.] 
adversary owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.7998664379119873
desired expected reward: 86.64082336425781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [10. 11.  0.  0. 14.  3.  0.  0. 16. 22.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [1. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  0.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10. 11.  0.  0. 14.  3.  0.  0. 16. 22.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [1. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  0.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10. 11.  0.  0. 14.  3.  0.  0. 16. 22.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [1. 3. 0. 1. 0.] 
adversary cards in discard: [ 3.  0.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.60998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1. 0.] 
cards in discard: [ 3.  0.  1. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.7933013439178467
desired expected reward: 84.2350082397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[74.273895]
 [77.25697 ]
 [73.52897 ]
 [76.69365 ]
 [71.384796]
 [70.37365 ]
 [76.16346 ]
 [80.234535]
 [82.68769 ]
 [79.76611 ]
 [74.03951 ]
 [75.596664]
 [77.262634]
 [72.431984]
 [77.243996]
 [82.50885 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 0.] 
cards in discard: [ 3.  0.  1. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0. 10. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -3.4280354976654053
desired expected reward: 76.9325942993164



buy possibilites: [-1] 
expected returns: [[78.12226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 0.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 25.0
Learning step: -2.951634168624878
desired expected reward: 79.7360610961914






Player: 1 
cards in hand: [ 0.  3. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 8. 10.  1. 11.  0.] 
adversary cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 8. 10.  1. 11.  0.] 
adversary cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25] -> size -> 21 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[127.04774 ]
 [115.17762 ]
 [114.97028 ]
 [120.956245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1. 11.  0.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -2.39107084274292
desired expected reward: 75.73119354248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[109.7407  ]
 [114.43281 ]
 [114.136246]
 [103.84881 ]
 [120.967674]
 [114.981705]
 [127.059166]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1. 11.  0.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 25. 30. 24. 30.  8.  6.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -4.69357442855835
desired expected reward: 119.68184661865234



buy possibilites: [-1] 
expected returns: [[70.38415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1. 11.  0.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 25. 30. 24. 30.  8.  5.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -20.267864227294922
desired expected reward: 83.58094787597656






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 0.  3. 22.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 24. 30.  8.  5.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  8.  8. 15. 11.] 
adversary cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 0.  3. 22.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 25. 30. 24. 30.  8.  5.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  8.  8. 15. 11.] 
adversary cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 0.  3. 22.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  5.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  8.  8. 15. 11.] 
adversary cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6] -> size -> 22 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  8. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 11.] 
expected returns: [[63.271595]
 [57.71319 ]
 [57.71319 ]
 [57.171707]
 [60.087547]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 15. 11.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  5.  9.  6.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14. 11. 16.  3.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -3.878082036972046
desired expected reward: 66.50606536865234



action possibilites: [-1] 
expected returns: [[63.17747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 15.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  5.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14. 11. 16.  3.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -6 

action type: gain_card_n - action 5
Learning step: -1.618202567100525
desired expected reward: 53.17571258544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.92425]
 [45.32821]
 [63.39191]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  8. 15.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  5.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14. 11. 16.  3.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -2.5992591381073
desired expected reward: 60.57821273803711



buy possibilites: [-1] 
expected returns: [[26.853518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  8. 15.] 
cards in discard: [ 3.  0.  1. 15.  0. 25.  1.  3.  0.  1.  0.  6.  8. 10.  1. 11.  0. 11.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14. 11. 16.  3.] 
adversary cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -326 

action type: buy - action 6.0
Learning step: -17.962207794189453
desired expected reward: 27.365997314453125






Player: 1 
cards in hand: [ 0. 14. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 16.  3.] 
cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3. 15.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11. 16.  3.] 
cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3. 15.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11. 16.  3.] 
cards in discard: [ 0.  3. 22.  0.  0.  1.  0.  8.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3. 15.  6.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  6.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[76.28566 ]
 [70.35179 ]
 [73.783394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6.  1. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -1.9812507629394531
desired expected reward: 24.87226676940918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[67.959496]
 [70.10089 ]
 [64.051   ]
 [76.161316]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  1. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -4.414964199066162
desired expected reward: 70.6927719116211



buy possibilites: [-1] 
expected returns: [[84.99184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  1. 11.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -5.285658359527588
desired expected reward: 62.673828125






Player: 1 
cards in hand: [ 3.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 1.  8. 10. 11.  8.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 24. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 1.  8. 10. 11.  8.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 1.  8. 10. 11.  8.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.  8.] 
expected returns: [[47.637756]
 [39.556614]
 [39.363842]
 [43.51998 ]
 [39.556614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 10. 11.  8.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  3. 22.  8. 16.] 
adversary cards in discard: [ 3.  3.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -6.0878119468688965
desired expected reward: 78.90402221679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[36.250126]
 [39.729282]
 [31.551281]
 [48.63313 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 10. 11.  8.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  3. 22.  8. 16.] 
adversary cards in discard: [ 3.  3.  3.  0.  0. 10.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.087060451507568
desired expected reward: 41.40891647338867



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 22.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 16.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  8. 16.] 
cards in discard: [ 3.  3.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  6.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 16.  0. 11.  0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  6.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 16.  0. 11.  0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  5.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  6.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 16.  0. 11.  0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  6.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[7.620331]
 [6.190566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  0. 25.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0. 10. 11. 22.  0.  3.  8. 16.  0. 11.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -5.095571994781494
desired expected reward: 43.53755569458008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.956759 ]
 [-2.969954 ]
 [ 6.7928925]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6.  0. 25.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0. 10. 11. 22.  0.  3.  8. 16.  0. 11.  0.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.0387444496154785
desired expected reward: 3.348557949066162



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10. 11. 22.  0.  3.  8. 16.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10. 11. 22.  0.  3.  8. 16.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0. 10. 11. 22.  0.  3.  8. 16.  0. 11.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [8. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.80083]
 [21.15858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 22. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -2.5848987102508545
desired expected reward: 4.207995414733887





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.967415]
 [20.353691]
 [20.009912]
 [15.848532]
 [15.145226]
 [19.491346]
 [23.072414]
 [25.230497]
 [22.501444]
 [17.860672]
 [19.14938 ]
 [20.429451]
 [16.709614]
 [20.409225]
 [25.431873]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 24. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 22. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.578425645828247
desired expected reward: 22.222396850585938



buy possibilites: [-1] 
expected returns: [[43.957653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  1. 11.  1.  8. 10. 11.  8.  3.  6.  6.  0. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 22. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: -2.6036369800567627
desired expected reward: 17.750045776367188






Player: 1 
cards in hand: [ 0. 22. 11.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 11.  0. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1.  1.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22. 11.  0. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1.  1.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[66.40902 ]
 [64.91751 ]
 [63.078114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 11. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10.  8.  1.  3.  3.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.5619468688964844
desired expected reward: 40.39570617675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[55.34303 ]
 [57.18703 ]
 [56.85462 ]
 [53.597897]
 [52.96619 ]
 [56.47445 ]
 [59.4444  ]
 [61.667095]
 [59.01245 ]
 [55.247684]
 [56.218224]
 [57.23074 ]
 [54.26896 ]
 [57.236465]
 [62.0467  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 11. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10.  8.  1.  3.  3.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.] 
adversary owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.493954658508301
desired expected reward: 56.18239974975586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.  3.  3.] 
cards in discard: [ 0. 22. 11.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  1  0  3 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 0. 22. 11.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0. 22. 11.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[61.725815]
 [58.479248]
 [55.29406 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  8.] 
cards in discard: [ 1.  1.  0. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.091271877288818
desired expected reward: 57.95542907714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[52.57376 ]
 [55.1448  ]
 [49.389194]
 [62.707565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  8.] 
cards in discard: [ 1.  1.  0. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.9682509899139404
desired expected reward: 55.89329528808594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  3.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.44053 ]
 [18.654642]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  6  1  1  0 15 25  6 11  6
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0  1] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.964122772216797
desired expected reward: 57.74345016479492



action possibilites: [-1] 
expected returns: [[62.84758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0  1] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.49453112483024597
desired expected reward: 14.885318756103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[52.33263 ]
 [55.341217]
 [48.466866]
 [63.510788]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0. 16.  0.  0.] 
adversary cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0  1] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -2.0088539123535156
desired expected reward: 60.83872604370117






Player: 1 
cards in hand: [11.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  0.  0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0 11  0  0 22  3  0  0  3 11 10  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  9. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10. 15.  0.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10. 15.  0.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  4.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10. 15.  0.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 22. 11.  0. 14.  0.  8. 10.  3.  1. 10.  3.  0.  0.  3.  0. 25. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10. 15.  0.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [10. 15.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[18.693853]
 [14.593814]
 [14.599793]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  1.  3.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -3.985255479812622
desired expected reward: 59.52553176879883



action possibilites: [-1. 15.  8.] 
expected returns: [[13.8855295]
 [ 8.992158 ]
 [ 8.965903 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  3.  8.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  8  8 11 10  3 11  1 15  1  1  1  0 15 25 11  6  0  1] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -0.653586208820343
desired expected reward: 13.940231323242188



action possibilites: [-1. 15.] 
expected returns: [[42.92099]
 [37.66099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.7332248091697693
desired expected reward: 9.799126625061035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.773914]
 [32.224514]
 [43.870094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -0.9820405840873718
desired expected reward: 41.93895721435547






Player: 1 
cards in hand: [14.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  4.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  1.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 23. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  1.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 23. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  1.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  0.  3.  3.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  1.] 
adversary cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[36.720776]
 [34.07664 ]
 [36.19347 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 25.  1.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -356 

action type: buy - action -1.0
Learning step: -19.179025650024414
desired expected reward: 24.691068649291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[31.890978]
 [34.437695]
 [34.202908]
 [28.990755]
 [33.546368]
 [37.441364]
 [36.77214 ]
 [31.85068 ]
 [34.634712]
 [34.646385]
 [40.10062 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1. 25.  1.] 
cards in discard: [ 1.  1.  0. 11. 15.  0.  0. 11.  6.  8.  8.  0.  0. 10.  8. 15.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.796956777572632
desired expected reward: 32.923824310302734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1. 15.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1. 15.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1. 15.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 1. 15.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[50.110058]
 [41.684494]
 [46.06376 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.  1. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 8.  0. 11. 11. 22.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -3.7426979541778564
desired expected reward: 36.35792541503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.879604]
 [41.63734 ]
 [37.051918]
 [41.099197]
 [34.39497 ]
 [33.23977 ]
 [40.21147 ]
 [46.22172 ]
 [49.69683 ]
 [45.31757 ]
 [37.734287]
 [39.805843]
 [41.803062]
 [35.837086]
 [41.84565 ]
 [50.268024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  1. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 8.  0. 11. 11. 22.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.234967231750488
desired expected reward: 44.99968338012695



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 11. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11. 22.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 8.  8. 11.  0. 15.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 22.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 11.  0. 15.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 22.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 11.  0. 15.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 15.] 
expected returns: [[2.039819 ]
 [1.3731012]
 [1.3731012]
 [1.7182798]
 [1.1478293]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0. 15.] 
cards in discard: [ 1. 15.  1.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.874070167541504
desired expected reward: 37.404319763183594



action possibilites: [-1] 
expected returns: [[33.022507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.] 
cards in discard: [ 1. 15.  1.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.051135778427124
desired expected reward: -1.1682941913604736





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.631187]
 [18.72949 ]
 [31.765516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.] 
cards in discard: [ 1. 15.  1.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16. 10.  0.  0.] 
adversary cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.] 
adversary owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -2.818457841873169
desired expected reward: 30.20404815673828






Player: 1 
cards in hand: [ 0. 16. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  0.  0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  3.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11. 25.  0.  0.  0.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 22. 30.  8.  2.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11. 25.  0.  0.  0.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 22. 30.  8.  2.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11. 25.  0.  0.  0.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 3. 25. 14.  0. 10.  0.  3.  3.  0.  1.  0.  0.  3.  0. 10. 11.  8.  0.
 11. 22.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 30. 22. 30.  8.  2.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11. 25.  0.  0.  0.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [11. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[5.1937   ]
 [3.6921818]
 [5.092827 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  0.  0.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 22. 30.  8.  2.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.7805373668670654
desired expected reward: 27.98497200012207



action possibilites: [-1] 
expected returns: [[44.68592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  6.  6.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 22. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6] -> size -> 28 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 25.0
Learning step: -0.5420123934745789
desired expected reward: 4.406898498535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[34.602375]
 [36.99083 ]
 [36.80326 ]
 [32.26157 ]
 [40.03101 ]
 [37.222744]
 [42.773983]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  6.  6.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 22. 30. 22. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6] -> size -> 28 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -2.633319139480591
desired expected reward: 42.0526008605957






Player: 1 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 22. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  1.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  1.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  1.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  1.] 
adversary cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-2.9682212]
 [-2.9682212]
 [-2.9682212]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  1.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [22. 16.  3. 10.  1.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.505484580993652
desired expected reward: 38.26850128173828



action possibilites: [-1.  8.] 
expected returns: [[-2.9682212]
 [-2.9682212]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [22. 16.  3. 10.  1.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 10.0
Learning step: -1.2183738946914673
desired expected reward: -4.1865949630737305



action possibilites: [-1.] 
expected returns: [[35.568424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [22. 16.  3. 10.  1.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.6487006545066833
desired expected reward: -2.3195204734802246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[30.700567]
 [32.094345]
 [32.040024]
 [28.98351 ]
 [34.032948]
 [32.287094]
 [35.8422  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [ 1. 15.  1.  1. 11.  8. 11.  0. 15. 25. 11.  0.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [22. 16.  3. 10.  1.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -1.3114919662475586
desired expected reward: 34.25693130493164






Player: 1 
cards in hand: [22. 16.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 16.  3. 10.  1.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 25.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 22. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 16.  3.  1.  8.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 25.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 16.  3.  1.  8.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 25.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 16.  3.  1.  8.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 25.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 25.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[6.5860014]
 [6.5024805]
 [3.9345725]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.  6. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.9792938232421875
desired expected reward: 31.86292266845703



action possibilites: [-1] 
expected returns: [[-2.9682212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 15.0
Learning step: -1.5078723430633545
desired expected reward: 1.3138747215270996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-2.9682214]
 [-2.9682214]
 [-2.9682214]
 [-2.9682214]
 [-2.9682214]
 [-2.9682214]
 [-2.9682214]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 22. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -1.2183738946914673
desired expected reward: -4.1865949630737305



buy possibilites: [-1] 
expected returns: [[-2.969999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [11. 10.  3.  0.  3.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -8 

action type: buy - action 1.0
Learning step: -0.3183738887310028
desired expected reward: -3.286595106124878






Player: 1 
cards in hand: [11. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  3.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 1. 11. 11.  8.  1.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11. 25.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 25.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 21. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 1. 11. 11.  8.  1.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 1. 11. 11.  8.  1.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 1. 11. 11.  8.  1.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 1. 11. 11.  8.  1.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-2.1005762]
 [-2.4749305]
 [-2.4749305]
 [-2.830862 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.  8.  1.] 
cards in discard: [ 1. 15.  6. 25.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.702868700027466
desired expected reward: -5.672867774963379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11.  8.  1.] 
cards in discard: [ 1. 15.  6. 25.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.76179575920105
desired expected reward: -4.8623809814453125



buy possibilites: [-1] 
expected returns: [[-1.7687298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11.  8.  1.] 
cards in discard: [ 1. 15.  6. 25.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -4.191296577453613
desired expected reward: -7.1612958908081055






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  1.  3. 15.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  1.  3. 15.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  8.  1.  3. 15.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[10.717617 ]
 [ 8.0492735]
 [ 7.6619396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  3. 15.] 
cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.  0.  0.  6.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.491602659225464
desired expected reward: -4.2603325843811035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[5.4172106]
 [7.041436 ]
 [6.7089653]
 [3.9437273]
 [8.693258 ]
 [6.9919252]
 [9.979058 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  3. 15.] 
cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [14. 10.  0.  0.  0.] 
adversary cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.  0.  0.  6.  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0] -> size -> 34 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.1447865962982178
desired expected reward: 7.572835922241211



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.  0.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.  0.  8.  1.  3. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.  0.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.  0.  8.  1.  3. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  0.  0.] 
cards in discard: [ 6.  3. 10. 11.  0.  3.  0.  0.  0. 10. 22. 16.  3.  1.  8.  3.  0. 10.
 11.  3.  0.  3. 25.  0.  0.  0.  6.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.  0.  8.  1.  3. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[7.522523 ]
 [4.5078936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 10.] 
cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.  0.  8.  1.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [10. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -3.146433115005493
desired expected reward: 6.832632064819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 6.739373 ]
 [ 8.159024 ]
 [ 8.061205 ]
 [ 5.3729362]
 [ 4.9699097]
 [ 7.665949 ]
 [ 9.869319 ]
 [11.023502 ]
 [ 9.438939 ]
 [ 6.716839 ]
 [ 7.5643425]
 [ 8.303501 ]
 [ 5.9985256]
 [ 8.282654 ]
 [11.33237  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 10.] 
cards in discard: [ 1. 15.  6. 25.  6.  0.  1. 11. 11.  8.  1.  0.  8.  1.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [10. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.9585206508636475
desired expected reward: 4.564004898071289



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  1.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  1.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  1.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 6.  1.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[43.708584]
 [41.041763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 8.  0. 25. 10.  3.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -2.4122555255889893
desired expected reward: 8.920119285583496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.707787]
 [37.364136]
 [37.323494]
 [34.122513]
 [33.65663 ]
 [36.794006]
 [39.562847]
 [41.41437 ]
 [38.98847 ]
 [35.756325]
 [36.824078]
 [37.6055  ]
 [34.931736]
 [37.64867 ]
 [42.254883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 8.  0. 25. 10.  3.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0] -> size -> 36 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.057653903961182
desired expected reward: 39.01652908325195



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 25. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25. 10.  3.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25. 10.  8.  8.  1.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25. 10.  3.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25. 10.  8.  8.  1.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25. 10.  3.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [25. 10.  8.  8.  1.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [25. 10.  8.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.  8.] 
expected returns: [[-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  8.  8.  1.] 
cards in discard: [ 6.  1.  1.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [16.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.979569435119629
desired expected reward: 37.27531433105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-2.969999]
 [-2.969999]
 [-2.969999]
 [-2.969999]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  8.  8.  1.] 
cards in discard: [ 6.  1.  1.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 21. 30. 20. 30.  8.  1.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [16.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.718325138092041
desired expected reward: -5.688323974609375



buy possibilites: [-1] 
expected returns: [[-2.969999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  8.  8.  1.] 
cards in discard: [ 6.  1.  1.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 21. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [16.  0. 11. 10.  0.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0] -> size -> 37 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -18.26832389831543
desired expected reward: -21.238323211669922






Player: 1 
cards in hand: [16.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11. 10.  0.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 21. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[-2.9062471]
 [-2.969999 ]
 [-2.969999 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11. 15.] 
cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.267362594604492
desired expected reward: -6.237361907958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.969999]
 [-2.731667]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11. 15.] 
cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.2674732208251953
desired expected reward: -6.173720359802246



buy possibilites: [-1] 
expected returns: [[28.457205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11. 15.] 
cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -4.06121301651001
desired expected reward: -7.031211853027344






Player: 1 
cards in hand: [ 0.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.  0.  6.  0.  3. 11. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.  0.  6.  0.  3. 11. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.  0.  6.  0.  3. 11. 15.] 
adversary owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 7 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  0.  0.  0. 15.] 
cards in discard: [ 6.  1.  1.  0. 11.  6. 25. 10.  8.  8.  1.  0.  6.  0.  3. 11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8 11 10  3 11 15  1  1  1  0 15 25 11  6  0  1  6  1  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 20. 30.  8.  0.  9.  3.  0.  8. 10.  9. 10.  2.  9.  7.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 0. 10. 11.  3.  0.  3.  0.  8.  0. 25. 10.  3.  1.  0. 11. 16.  0. 10.
  0.  0.] 
adversary owned cards: [10  8  0  3  0  0 14 16  0  0  0 22  3  0  0  3 11 10  0  1 25 11  3  0
 10  6  0  6  3 10  0  3  0  0 10  0  0  1  0  0] -> size -> 40 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action -1
Learning step: -29.77286148071289
desired expected reward: -1.3156566619873047



